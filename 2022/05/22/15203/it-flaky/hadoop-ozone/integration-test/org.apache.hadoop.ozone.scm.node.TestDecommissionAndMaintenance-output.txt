2022-05-22 15:42:12,996 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:13,029 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(160)) - ServiceID for StorageContainerManager is null
2022-05-22 15:42:13,029 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(165)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-05-22 15:42:13,029 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:13,029 [Mini-Cluster-Provider-Create] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:13,193 [Mini-Cluster-Provider-Create] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 163 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:13,223 [Mini-Cluster-Provider-Create] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:13,224 [Mini-Cluster-Provider-Create] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:13,449 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:42:13,962 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-05-22 15:42:13,963 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-05-22 15:42:13,965 [Mini-Cluster-Provider-Create] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:13,965 [Mini-Cluster-Provider-Create] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:13,966 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-05-22 15:42:13,966 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-05-22 15:42:13,966 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(371)) - upgrade containerId to 0
2022-05-22 15:42:13,966 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-05-22 15:42:13,975 [Mini-Cluster-Provider-Create] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(148)) - Entering startup safe mode.
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(125)) - Starting RatisPipelineUtilsThread.
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:start(126)) - Starting BackgroundPipelineScrubber Service.
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-05-22 15:42:13,976 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-05-22 15:42:13,977 [Mini-Cluster-Provider-Create] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-05-22 15:42:13,977 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-05-22 15:42:13,977 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-05-22 15:42:13,977 [Mini-Cluster-Provider-Create] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-05-22 15:42:13,978 [Mini-Cluster-Provider-Create] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-05-22 15:42:13,978 [Mini-Cluster-Provider-Create] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-05-22 15:42:13,978 [Mini-Cluster-Provider-Create] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-05-22 15:42:13,985 [Mini-Cluster-Provider-Create] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:13,992 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:13,992 [Listener at 0.0.0.0/33345] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:13,993 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:13,993 [Listener at 0.0.0.0/42521] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:13,994 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:14,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:14,198 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(399)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-05-22 15:42:14,198 [Listener at 0.0.0.0/39533] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:14,198 [Listener at 0.0.0.0/39533] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-05-22 15:42:14,198 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1354)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39533
2022-05-22 15:42:14,206 [Listener at 0.0.0.0/39533] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2022-05-22 15:42:14,206 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2022-05-22 15:42:14,206 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2022-05-22 15:42:14,271 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2022-05-22 15:42:14,272 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2022-05-22 15:42:14,286 [Listener at 0.0.0.0/39533] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:39533
2022-05-22 15:42:14,286 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:14,286 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:14,344 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1369)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42521
2022-05-22 15:42:14,344 [Listener at 0.0.0.0/39533] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:42521
2022-05-22 15:42:14,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:14,346 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:14,401 [Listener at 0.0.0.0/39533] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(183)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:33345
2022-05-22 15:42:14,402 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:14,402 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:14,483 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-05-22 15:42:14,483 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:14,484 [Listener at 0.0.0.0/39533] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:14,536 [Listener at 0.0.0.0/39533] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:14,537 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:14,538 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-05-22 15:42:14,538 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:14,538 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:14,538 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 39627
2022-05-22 15:42:14,538 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:14,543 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:42:14,727 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:14,728 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:14,728 [Listener at 0.0.0.0/39533] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:14,752 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2c7e7de8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:14,752 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@44cb6831{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:42:14,754 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@68cd23ce{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:42:14,791 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@450d6a77] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:14,995 [Listener at 0.0.0.0/39533] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@7585c111{HTTP/1.1, (http/1.1)}{0.0.0.0:39627}
2022-05-22 15:42:14,995 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(415)) - Started @334374ms
2022-05-22 15:42:14,995 [Listener at 0.0.0.0/39533] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:14,997 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:14,997 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:14,997 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:14,998 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:14,998 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:14,999 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:39627
2022-05-22 15:42:14,999 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:15,000 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,011 [Listener at 0.0.0.0/39533] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-05-22 15:42:15,012 [Listener at 0.0.0.0/39533] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-05-22 15:42:15,012 [Listener at 0.0.0.0/39533] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-05-22 15:42:15,012 [Listener at 0.0.0.0/39533] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-05-22 15:42:15,012 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:15,012 [Listener at 0.0.0.0/39533] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = BUCKET_LAYOUT_SUPPORT (version = 2), software layout = BUCKET_LAYOUT_SUPPORT (version = 2)
2022-05-22 15:42:15,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:15,164 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,165 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,166 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,167 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,167 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,179 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,180 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,180 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,181 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,182 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,182 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,183 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,183 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,186 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,187 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,187 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,188 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,188 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,189 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,189 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,189 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,190 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,190 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,191 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,191 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,192 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,192 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,192 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,193 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,193 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,194 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,216 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,216 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,216 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,220 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,220 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,221 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,221 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a695f368-1363-4fa9-a034-a4c0d8b6e9f3{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36175, RATIS=42819, RATIS_ADMIN=42819, RATIS_SERVER=42819, STANDALONE=42951], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,226 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,226 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,226 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,227 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,227 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,228 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,228 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,228 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,229 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,229 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,229 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,230 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,230 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,230 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,230 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,231 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,231 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,231 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,232 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,232 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,232 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,233 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,233 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,233 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,233 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,234 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,234 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,235 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,235 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,235 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,235 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,236 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,236 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,237 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,237 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,237 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,237 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,238 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,238 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,238 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,238 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,239 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,239 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,239 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,240 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,240 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,240 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,241 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,241 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,242 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,242 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,242 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,242 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,243 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,243 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,244 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,244 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,245 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,245 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,245 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,246 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,246 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,246 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,247 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,247 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,247 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,248 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,248 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,248 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,249 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,249 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,250 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5f1e0514-5409-444d-9702-e6f9cc3ca7ec{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34843, RATIS=45559, RATIS_ADMIN=45559, RATIS_SERVER=45559, STANDALONE=44461], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,250 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 8e0bf3df-23e6-4bdc-8543-62bd365f1d94{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=33491, RATIS=43719, RATIS_ADMIN=43719, RATIS_SERVER=43719, STANDALONE=38793], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,250 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,251 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,251 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,252 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,252 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,253 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,253 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,253 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,254 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,254 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,254 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,255 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,255 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,255 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,256 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 9dbe2506-10f9-454f-92d2-c12e7ce773fb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=34701, RATIS=42281, RATIS_ADMIN=42281, RATIS_SERVER=42281, STANDALONE=43987], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,256 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,256 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,257 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,257 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,258 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,258 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,258 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,258 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,259 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,259 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,260 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,260 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,265 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,266 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,266 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,266 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,267 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,267 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,268 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,268 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,269 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 5c1f160d-ba7c-4f6c-8b7f-bb182cdf7c3b{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35723, RATIS=36853, RATIS_ADMIN=36853, RATIS_SERVER=36853, STANDALONE=44411], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,269 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,269 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,270 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,270 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,272 [IPC Server handler 17 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,275 [IPC Server handler 18 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,276 [IPC Server handler 19 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 564ddf43-755f-47ee-ace2-4b25a210bcf9{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36523, RATIS=35825, RATIS_ADMIN=35825, RATIS_SERVER=35825, STANDALONE=42077], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:15,567 [Listener at 0.0.0.0/39533] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 554 ms to scan 2 urls, producing 143 keys and 369 values [using 2 cores]
2022-05-22 15:42:15,568 [Listener at 0.0.0.0/39533] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-05-22 15:42:15,568 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:15,568 [Listener at 0.0.0.0/39533] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:42521]
2022-05-22 15:42:15,574 [Listener at 0.0.0.0/39533] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:42521]
2022-05-22 15:42:15,625 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:15,625 [Listener at 0.0.0.0/39533] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-05-22 15:42:15,627 [Listener at 0.0.0.0/39533] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-05-22 15:42:16,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:16,826 [Listener at 0.0.0.0/39533] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(3894)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-05-22 15:42:16,826 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:42:16,826 [Listener at 0.0.0.0/39533] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(395)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-05-22 15:42:16,826 [Listener at 0.0.0.0/39533] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:16,827 [Listener at 0.0.0.0/39533] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:16,827 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:42:16,827 [Listener at 0.0.0.0/39533] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:40257
2022-05-22 15:42:16,880 [Listener at 0.0.0.0/39533] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(627)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-05-22 15:42:16,887 [Listener at 0.0.0.0/39533] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 40257 (custom)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 40257 (custom)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 40257 (custom)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:16,889 [Listener at 0.0.0.0/39533] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:16,891 [Listener at 0.0.0.0/39533] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis] (custom)
2022-05-22 15:42:17,016 [Listener at 0.0.0.0/39533] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:40257|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@35458848[Not completed]
2022-05-22 15:42:17,016 [Listener at 0.0.0.0/39533] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1901)) - OzoneManager Ratis server initialized at port 40257
2022-05-22 15:42:17,017 [Listener at 0.0.0.0/39533] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1030)) - Creating RPC Server
2022-05-22 15:42:17,023 [pool-3268-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:40257|priority:0] with OzoneManagerStateMachine:uninitialized
2022-05-22 15:42:17,023 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-05-22 15:42:17,023 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-05-22 15:42:17,023 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:17,023 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:42:17,029 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:40257|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis] (custom)
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:17,030 [pool-3268-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-05-22 15:42:17,031 [pool-3268-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:17,033 [pool-3268-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-05-22 15:42:17,033 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-05-22 15:42:17,033 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:17,033 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:17,034 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:17,034 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:17,034 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:17,035 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:17,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:17,057 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-05-22 15:42:17,058 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:17,058 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-05-22 15:42:17,058 [pool-3268-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:17,058 [pool-3268-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:17,079 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:17,079 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-05-22 15:42:17,080 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-05-22 15:42:17,080 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-05-22 15:42:17,080 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-05-22 15:42:17,080 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:17,082 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:17,082 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:17,199 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:17,200 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:17,200 [pool-3268-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:18,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:18,669 [Listener at 0.0.0.0/39533] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 1649 ms to scan 19 urls, producing 61 keys and 3717 values [using 2 cores]
2022-05-22 15:42:18,670 [Listener at 0.0.0.0/39533] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:18,694 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:18,908 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-05-22 15:42:18,953 [Listener at 127.0.0.1/45987] INFO  om.OzoneManager (OzoneManager.java:start(1405)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45987
2022-05-22 15:42:18,953 [Listener at 127.0.0.1/45987] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 40257
2022-05-22 15:42:18,954 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:40257|priority:0], old=null
2022-05-22 15:42:18,954 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:18,954 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-05-22 15:42:18,954 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2022-05-22 15:42:18,955 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-05-22 15:42:18,956 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 40257
2022-05-22 15:42:18,956 [Listener at 127.0.0.1/45987] INFO  om.OzoneManager (OzoneManager.java:start(1421)) - Version File has different layout version (2) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-05-22 15:42:18,957 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@1d02635e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-05-22 15:42:18,958 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-05-22 15:42:18,958 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:18,959 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:18,977 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:18,978 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:18,978 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-05-22 15:42:18,978 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:18,979 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:18,979 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 38445
2022-05-22 15:42:18,979 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:19,005 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:19,005 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:19,005 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:42:19,005 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@732e56b0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:19,005 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@330b6b05{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:42:19,017 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4ece3b05{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-05-22 15:42:19,027 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@6c80802c{HTTP/1.1, (http/1.1)}{0.0.0.0:38445}
2022-05-22 15:42:19,028 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @338407ms
2022-05-22 15:42:19,028 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:19,028 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:38445
2022-05-22 15:42:19,031 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:19,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:19,039 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:19,073 [Listener at 127.0.0.1/45987] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1845)) - Trash Interval set to 0. Files deleted won't move to trash
2022-05-22 15:42:19,244 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@661b1ecb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:19,271 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:19,276 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:19,276 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:19,332 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:19,435 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:19,517 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 81 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:19,518 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:19,519 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:19,519 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:19,519 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data-0/containers/hdds
2022-05-22 15:42:19,520 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data-0/containers/hdds
2022-05-22 15:42:19,530 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis to VolumeSet
2022-05-22 15:42:19,530 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis
2022-05-22 15:42:19,530 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis
2022-05-22 15:42:19,570 [Thread-5508] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data-0/containers/hdds
2022-05-22 15:42:19,570 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:19,571 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:19,571 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:19,571 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:19,571 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:19,572 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:19,573 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis] (custom)
2022-05-22 15:42:19,574 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:19,625 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:19,625 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:19,626 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:19,639 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:19,671 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:19,671 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:19,671 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:19,671 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:19,672 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 36623
2022-05-22 15:42:19,672 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:19,676 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:19,676 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:19,676 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:19,677 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6d93acc0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:19,677 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@14eba010{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:19,981 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1027769505ns, electionTimeout:1025ms
2022-05-22 15:42:19,982 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-05-22 15:42:19,982 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:19,985 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:19,985 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection158
2022-05-22 15:42:20,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:20,036 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection158 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:40257|priority:0], old=null
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection158 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection158
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 3003ms
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:42:20,037 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-05-22 15:42:20,038 [om1@group-C5BA1605619E-LeaderElection158] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:20,069 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-05-22 15:42:20,151 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:40257|admin:|client:|dataStream:|priority:0], old=null
2022-05-22 15:42:20,153 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(191)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:40257"
]
2022-05-22 15:42:20,382 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@5b40261b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-36623-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-6569136428393535809/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:20,410 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@5a543bf1{HTTP/1.1, (http/1.1)}{0.0.0.0:36623}
2022-05-22 15:42:20,463 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @339843ms
2022-05-22 15:42:20,463 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:20,464 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36623
2022-05-22 15:42:20,495 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:20,495 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:20,495 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:20,499 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:20,520 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:20,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3285f7bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:20,674 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/meta/datanode.id
2022-05-22 15:42:20,675 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:20,804 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 123 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:20,836 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:20,838 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:20,838 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:20,838 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data-0/containers/hdds
2022-05-22 15:42:20,838 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data-0/containers/hdds
2022-05-22 15:42:20,852 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis to VolumeSet
2022-05-22 15:42:20,852 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis
2022-05-22 15:42:20,854 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis
2022-05-22 15:42:20,980 [Thread-5523] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data-0/containers/hdds
2022-05-22 15:42:20,980 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:20,983 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:20,984 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:20,985 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:20,985 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:20,985 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:20,985 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:20,986 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:20,986 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis] (custom)
2022-05-22 15:42:20,989 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:20,991 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:20,991 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:20,992 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:20,992 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:20,993 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:20,993 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:20,993 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:20,993 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:20,994 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 37901
2022-05-22 15:42:20,994 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:20,995 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:20,995 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:20,995 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:42:20,995 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@9e804ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:20,996 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@238651bf{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:21,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:21,728 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@1f23a6d6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-37901-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-282628668923460354/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:21,733 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@343a0836{HTTP/1.1, (http/1.1)}{0.0.0.0:37901}
2022-05-22 15:42:21,733 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @341112ms
2022-05-22 15:42:21,733 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:21,733 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:37901
2022-05-22 15:42:21,747 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:21,748 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:21,748 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:21,758 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:21,764 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:21,804 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1326cadb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:21,840 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/meta/datanode.id
2022-05-22 15:42:21,897 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:21,962 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 63 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:21,964 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:22,010 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:22,010 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:22,010 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data-0/containers/hdds
2022-05-22 15:42:22,017 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data-0/containers/hdds
2022-05-22 15:42:22,028 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis to VolumeSet
2022-05-22 15:42:22,028 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis
2022-05-22 15:42:22,029 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis
2022-05-22 15:42:22,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:22,157 [Thread-5536] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data-0/containers/hdds
2022-05-22 15:42:22,157 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:22,159 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:22,162 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:22,162 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:22,163 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:22,163 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:22,163 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:22,163 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis] (custom)
2022-05-22 15:42:22,164 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:22,193 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:22,193 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:22,193 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:22,207 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:22,208 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:22,208 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:22,208 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:22,208 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:22,209 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 43773
2022-05-22 15:42:22,209 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:22,252 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:22,252 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:22,252 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:22,253 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@57b6f462{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:22,253 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@68d9ef0c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:22,743 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:22,744 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:22,744 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 36139
2022-05-22 15:42:22,746 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:22,748 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start RPC server
2022-05-22 15:42:22,768 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: GrpcService started, listening on 39927
2022-05-22 15:42:22,807 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 1bd1ad93-a217-4aba-aed5-0a262321f6e0 is started using port 39927 for RATIS
2022-05-22 15:42:22,807 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 1bd1ad93-a217-4aba-aed5-0a262321f6e0 is started using port 39927 for RATIS_ADMIN
2022-05-22 15:42:22,807 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 1bd1ad93-a217-4aba-aed5-0a262321f6e0 is started using port 39927 for RATIS_SERVER
2022-05-22 15:42:22,808 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3cefacb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-1bd1ad93-a217-4aba-aed5-0a262321f6e0: Started
2022-05-22 15:42:22,866 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 1bd1ad93-a217-4aba-aed5-0a262321f6e0 is started using port 34847
2022-05-22 15:42:23,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:23,073 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@6d723c6b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-43773-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1984100173448528776/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:23,140 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@794ff3e5{HTTP/1.1, (http/1.1)}{0.0.0.0:43773}
2022-05-22 15:42:23,140 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @342520ms
2022-05-22 15:42:23,140 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:23,141 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43773
2022-05-22 15:42:23,180 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:23,180 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:23,180 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:23,187 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:23,191 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:23,262 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2271e817] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:23,304 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:23,316 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/meta/datanode.id
2022-05-22 15:42:23,543 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 238 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:23,563 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:23,566 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:23,566 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:23,566 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data-0/containers/hdds
2022-05-22 15:42:23,566 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data-0/containers/hdds
2022-05-22 15:42:23,639 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis to VolumeSet
2022-05-22 15:42:23,639 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis
2022-05-22 15:42:23,639 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis
2022-05-22 15:42:23,660 [Thread-5552] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data-0/containers/hdds
2022-05-22 15:42:23,660 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:23,662 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:23,664 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:23,664 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:23,664 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:23,664 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:23,665 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:23,665 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis] (custom)
2022-05-22 15:42:23,666 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:23,681 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:23,682 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:23,682 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:23,731 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:23,732 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:23,733 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:23,733 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:23,733 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:23,733 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 44337
2022-05-22 15:42:23,733 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:23,764 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:23,765 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:23,765 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:42:23,765 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@469155ac{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:23,765 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@40c41167{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:23,852 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:23,853 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:23,853 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 39419
2022-05-22 15:42:23,933 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:23,957 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start RPC server
2022-05-22 15:42:23,957 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: GrpcService started, listening on 39347
2022-05-22 15:42:23,958 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e5a271d5-f691-48ef-8105-b2d60b002f9a is started using port 39347 for RATIS
2022-05-22 15:42:23,958 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e5a271d5-f691-48ef-8105-b2d60b002f9a is started using port 39347 for RATIS_ADMIN
2022-05-22 15:42:23,958 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e5a271d5-f691-48ef-8105-b2d60b002f9a is started using port 39347 for RATIS_SERVER
2022-05-22 15:42:23,958 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@729c8021] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-e5a271d5-f691-48ef-8105-b2d60b002f9a: Started
2022-05-22 15:42:23,958 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc e5a271d5-f691-48ef-8105-b2d60b002f9a is started using port 37173
2022-05-22 15:42:24,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:24,650 [IPC Server handler 3 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:24,650 [IPC Server handler 3 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:24,687 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-05-22 15:42:24,688 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-05-22 15:42:24,753 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:24,754 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-05-22 15:42:24,755 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=ed0d79bc-0e63-4a9b-8384-008ac268cda9 to datanode:1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:24,765 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: ed0d79bc-0e63-4a9b-8384-008ac268cda9, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:24.755Z[Etc/UTC]].
2022-05-22 15:42:24,980 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@a74f186{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44337-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-6478374133285575957/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:25,002 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@b0cf05e{HTTP/1.1, (http/1.1)}{0.0.0.0:44337}
2022-05-22 15:42:25,002 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @344382ms
2022-05-22 15:42:25,002 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:25,003 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44337
2022-05-22 15:42:25,011 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:25,011 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:25,011 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:25,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:25,063 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:25,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3dad6c06] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:25,231 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/meta/datanode.id
2022-05-22 15:42:25,281 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:25,342 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:25,359 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:25,360 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:25,375 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 45929
2022-05-22 15:42:25,379 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:25,396 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start RPC server
2022-05-22 15:42:25,397 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: GrpcService started, listening on 42763
2022-05-22 15:42:25,399 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 56e641d3-eb56-493e-85a5-4bb0b1b5352d is started using port 42763 for RATIS
2022-05-22 15:42:25,399 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 56e641d3-eb56-493e-85a5-4bb0b1b5352d is started using port 42763 for RATIS_ADMIN
2022-05-22 15:42:25,399 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 56e641d3-eb56-493e-85a5-4bb0b1b5352d is started using port 42763 for RATIS_SERVER
2022-05-22 15:42:25,400 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@6860cdb3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-56e641d3-eb56-493e-85a5-4bb0b1b5352d: Started
2022-05-22 15:42:25,414 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 56e641d3-eb56-493e-85a5-4bb0b1b5352d is started using port 39265
2022-05-22 15:42:25,662 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 318 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:25,663 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:25,664 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:25,664 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:25,665 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data-0/containers/hdds
2022-05-22 15:42:25,675 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data-0/containers/hdds
2022-05-22 15:42:25,702 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis to VolumeSet
2022-05-22 15:42:25,703 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis
2022-05-22 15:42:25,703 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis
2022-05-22 15:42:25,713 [Thread-5577] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data-0/containers/hdds
2022-05-22 15:42:25,713 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:25,714 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:25,714 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:25,714 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:25,714 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:25,715 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:25,716 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis] (custom)
2022-05-22 15:42:25,734 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:25,808 [IPC Server handler 1 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:25,808 [IPC Server handler 1 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:25,808 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:25,816 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-05-22 15:42:25,839 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:25,839 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:25,840 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:25,875 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:25,875 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:25,876 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:25,876 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:25,876 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:25,876 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 32769
2022-05-22 15:42:25,876 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:25,970 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:25,970 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:25,970 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:25,971 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@5914a04{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:25,971 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@549b099f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:26,008 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016 to datanode:e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:26,008 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 7643202f-040e-4a0b-8e86-d3fd8a4c4016, Nodes: e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:26.008Z[Etc/UTC]].
2022-05-22 15:42:26,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:26,375 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@451d50df{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-32769-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-7545780324347278278/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:26,547 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@5f567a56{HTTP/1.1, (http/1.1)}{0.0.0.0:32769}
2022-05-22 15:42:26,548 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @345927ms
2022-05-22 15:42:26,548 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:26,552 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:32769
2022-05-22 15:42:26,555 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:26,555 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:26,556 [Listener at 127.0.0.1/45987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:26,639 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:26,689 [Listener at 127.0.0.1/45987] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:26,782 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:26,792 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@dbc9a90] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:26,805 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/meta/datanode.id
2022-05-22 15:42:27,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:27,062 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 279 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:27,063 [Listener at 127.0.0.1/45987] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:27,134 [Listener at 127.0.0.1/45987] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:27,134 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:27,134 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data-0/containers/hdds
2022-05-22 15:42:27,147 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data-0/containers/hdds
2022-05-22 15:42:27,159 [Listener at 127.0.0.1/45987] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis to VolumeSet
2022-05-22 15:42:27,159 [Listener at 127.0.0.1/45987] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis
2022-05-22 15:42:27,159 [Listener at 127.0.0.1/45987] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis
2022-05-22 15:42:27,249 [Thread-5592] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data-0/containers/hdds
2022-05-22 15:42:27,249 [Listener at 127.0.0.1/45987] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:27,250 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:27,251 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:27,251 [Listener at 127.0.0.1/45987] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:27,251 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:27,251 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:27,251 [Listener at 127.0.0.1/45987] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:27,253 [Listener at 127.0.0.1/45987] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:27,253 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:27,253 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:27,253 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:27,253 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:27,270 [IPC Server handler 15 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:27,270 [IPC Server handler 15 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:27,270 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-05-22 15:42:27,270 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:27,271 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=b33389d2-cd81-48e4-be65-b563385f6b43 to datanode:56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:27,271 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: b33389d2-cd81-48e4-be65-b563385f6b43, Nodes: 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:27.271Z[Etc/UTC]].
2022-05-22 15:42:27,274 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 to datanode:1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:27,274 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 to datanode:56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:27,274 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 to datanode:e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:27,274 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 9d6c0e09-87af-45d5-ad1c-fab0d27550b0, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:27.274Z[Etc/UTC]].
2022-05-22 15:42:27,319 [Listener at 127.0.0.1/45987] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis] (custom)
2022-05-22 15:42:27,333 [Listener at 127.0.0.1/45987] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:27,351 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:27,351 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:27,356 [Listener at 127.0.0.1/45987] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:27,356 [Listener at 127.0.0.1/45987] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:27,357 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:27,357 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:27,357 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:27,357 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:27,358 [Listener at 127.0.0.1/45987] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 40369
2022-05-22 15:42:27,358 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:27,358 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:27,359 [Listener at 127.0.0.1/45987] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:27,362 [Listener at 127.0.0.1/45987] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:42:27,364 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@43ff7eb9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:27,364 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@38813dac{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:27,382 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:27,382 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:27,383 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 41697
2022-05-22 15:42:27,385 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:27,388 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start RPC server
2022-05-22 15:42:27,391 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: GrpcService started, listening on 34125
2022-05-22 15:42:27,392 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa is started using port 34125 for RATIS
2022-05-22 15:42:27,392 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa is started using port 34125 for RATIS_ADMIN
2022-05-22 15:42:27,392 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa is started using port 34125 for RATIS_SERVER
2022-05-22 15:42:27,392 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3e19e627] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: Started
2022-05-22 15:42:27,406 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa is started using port 46383
2022-05-22 15:42:27,669 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: addNew group-008AC268CDA9:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:1] returns group-008AC268CDA9:java.util.concurrent.CompletableFuture@686b0b7a[Not completed]
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: new RaftServerImpl for group-008AC268CDA9:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: ConfigurationManager, init=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:27,670 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis] (custom)
2022-05-22 15:42:27,671 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:27,671 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:27,671 [pool-3282-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9 does not exist. Creating ...
2022-05-22 15:42:27,676 [pool-3282-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:27,681 [pool-3282-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9 has been successfully formatted.
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-008AC268CDA9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:27,682 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:27,683 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:27,684 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:27,687 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:27,687 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:27,687 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:27,691 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:27,692 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:27,696 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: ed0d79bc-0e63-4a9b-8384-008ac268cda9, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1bd1ad93-a217-4aba-aed5-0a262321f6e0, CreationTimestamp2022-05-22T15:42:24.755Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:27,722 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:27,742 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: start as a follower, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:1], old=null
2022-05-22 15:42:27,745 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:27,746 [pool-3282-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState
2022-05-22 15:42:27,791 [pool-3282-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-008AC268CDA9,id=1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:27,839 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=ed0d79bc-0e63-4a9b-8384-008ac268cda9
2022-05-22 15:42:27,839 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ed0d79bc-0e63-4a9b-8384-008ac268cda9.
2022-05-22 15:42:27,839 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: addNew group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0] returns group-FAB0D27550B0:java.util.concurrent.CompletableFuture@6c5492af[Not completed]
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: new RaftServerImpl for group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: ConfigurationManager, init=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:27,840 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis] (custom)
2022-05-22 15:42:27,841 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:27,841 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:27,841 [pool-3282-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 does not exist. Creating ...
2022-05-22 15:42:27,939 [pool-3282-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:27,950 [pool-3282-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 has been successfully formatted.
2022-05-22 15:42:27,950 [pool-3282-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FAB0D27550B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:27,951 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:27,951 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:27,952 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:27,952 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:27,952 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:27,953 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:27,955 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:27,972 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:27,972 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:27,972 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:27,972 [pool-3282-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:27,973 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: start as a follower, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0], old=null
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:28,032 [pool-3282-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:28,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:28,077 [pool-3282-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:28,092 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:28,143 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: addNew group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0] returns group-FAB0D27550B0:java.util.concurrent.CompletableFuture@1a62ea48[Not completed]
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: new RaftServerImpl for group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:28,144 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:28,145 [pool-3326-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: ConfigurationManager, init=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:28,145 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis] (custom)
2022-05-22 15:42:28,145 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:28,145 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:28,145 [pool-3326-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 does not exist. Creating ...
2022-05-22 15:42:28,148 [pool-3326-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:28,157 [pool-3326-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 has been successfully formatted.
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FAB0D27550B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:28,223 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:28,225 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:28,229 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:28,229 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:28,229 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:28,230 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,230 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,237 [Listener at 127.0.0.1/45987] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@41e81d9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40369-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4918819420334825353/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:28,249 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: addNew group-B563385F6B43:[56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1] returns group-B563385F6B43:java.util.concurrent.CompletableFuture@451fc47b[Not completed]
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:28,273 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: new RaftServerImpl for group-B563385F6B43:[56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:28,277 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:28,278 [pool-3326-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: ConfigurationManager, init=-1: [56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:28,281 [Listener at 127.0.0.1/45987] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@2cae2e7a{HTTP/1.1, (http/1.1)}{0.0.0.0:40369}
2022-05-22 15:42:28,281 [Listener at 127.0.0.1/45987] INFO  server.Server (Server.java:doStart(415)) - Started @347661ms
2022-05-22 15:42:28,281 [Listener at 127.0.0.1/45987] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:28,282 [Listener at 127.0.0.1/45987] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40369
2022-05-22 15:42:28,282 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 3 of 6 DN Heartbeats.
2022-05-22 15:42:28,283 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:28,283 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:28,283 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:28,291 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3dfa59ba] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:28,300 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/meta/datanode.id
2022-05-22 15:42:28,356 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis] (custom)
2022-05-22 15:42:28,356 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:28,356 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:28,356 [pool-3326-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43 does not exist. Creating ...
2022-05-22 15:42:28,358 [pool-3326-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:28,363 [pool-3326-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43 has been successfully formatted.
2022-05-22 15:42:28,363 [pool-3326-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B563385F6B43: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:28,428 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:28,429 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:28,430 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:28,430 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:28,430 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:28,442 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:28,443 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:28,443 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:28,443 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,443 [pool-3326-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,444 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: b33389d2-cd81-48e4-be65-b563385f6b43, Nodes: 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:42:27.271Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:28,447 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:28,493 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: start as a follower, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:28,497 [pool-3326-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:28,502 [pool-3326-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:28,635 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: start as a follower, conf=-1: [56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1], old=null
2022-05-22 15:42:28,636 [pool-3326-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:28,636 [pool-3326-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState
2022-05-22 15:42:28,652 [pool-3326-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B563385F6B43,id=56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:28,673 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=b33389d2-cd81-48e4-be65-b563385f6b43
2022-05-22 15:42:28,673 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=b33389d2-cd81-48e4-be65-b563385f6b43.
2022-05-22 15:42:28,811 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: addNew group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0] returns group-FAB0D27550B0:java.util.concurrent.CompletableFuture@129583f[Not completed]
2022-05-22 15:42:28,812 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: addNew group-D3FD8A4C4016:[e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:1] returns group-D3FD8A4C4016:java.util.concurrent.CompletableFuture@72170b69[Not completed]
2022-05-22 15:42:28,812 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: new RaftServerImpl for group-FAB0D27550B0:[1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:28,812 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:28,812 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:28,812 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:28,812 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: ConfigurationManager, init=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis] (custom)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:28,813 [pool-3304-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 does not exist. Creating ...
2022-05-22 15:42:28,814 [pool-3304-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0 has been successfully formatted.
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FAB0D27550B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:28,816 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,817 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:28,818 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:28,818 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:28,820 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:28,822 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:28,823 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:28,824 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 7643202f-040e-4a0b-8e86-d3fd8a4c4016, Nodes: e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e5a271d5-f691-48ef-8105-b2d60b002f9a, CreationTimestamp2022-05-22T15:42:26.008Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:28,824 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:28,825 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:28,825 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:28,828 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 38803
2022-05-22 15:42:28,882 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:28,884 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:28,884 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:28,884 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:28,884 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:28,886 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: new RaftServerImpl for group-D3FD8A4C4016:[e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: ConfigurationManager, init=-1: [e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis] (custom)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:28,887 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:28,888 [pool-3304-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016 does not exist. Creating ...
2022-05-22 15:42:28,896 [pool-3304-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:28,897 [pool-3304-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016 has been successfully formatted.
2022-05-22 15:42:28,959 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-D3FD8A4C4016: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:28,981 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - c72cb747-71cd-49bf-9573-30515b8c4828: start RPC server
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:28,981 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:28,982 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - c72cb747-71cd-49bf-9573-30515b8c4828: GrpcService started, listening on 39895
2022-05-22 15:42:28,982 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:28,982 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis c72cb747-71cd-49bf-9573-30515b8c4828 is started using port 39895 for RATIS
2022-05-22 15:42:28,982 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis c72cb747-71cd-49bf-9573-30515b8c4828 is started using port 39895 for RATIS_ADMIN
2022-05-22 15:42:28,982 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis c72cb747-71cd-49bf-9573-30515b8c4828 is started using port 39895 for RATIS_SERVER
2022-05-22 15:42:28,982 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@40493c39] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-c72cb747-71cd-49bf-9573-30515b8c4828: Started
2022-05-22 15:42:28,982 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc c72cb747-71cd-49bf-9573-30515b8c4828 is started using port 35729
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:29,026 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:29,027 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:29,027 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:29,027 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:29,027 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:29,029 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:29,029 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:29,029 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:29,030 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:29,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: start as a follower, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:29,039 [pool-3304-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:29,044 [pool-3304-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:29,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:29,068 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: start as a follower, conf=-1: [e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:1], old=null
2022-05-22 15:42:29,069 [pool-3304-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:29,069 [pool-3304-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState
2022-05-22 15:42:29,069 [pool-3304-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D3FD8A4C4016,id=e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:29,086 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016
2022-05-22 15:42:29,086 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016.
2022-05-22 15:42:29,092 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0.
2022-05-22 15:42:29,184 [IPC Server handler 10 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:29,184 [IPC Server handler 10 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:29,184 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:29,186 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=ad7bd58a-6c08-45ff-8812-8cf4b692cf1d to datanode:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:29,187 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: ad7bd58a-6c08-45ff-8812-8cf4b692cf1d, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:29.186Z[Etc/UTC]].
2022-05-22 15:42:29,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-05-22 15:42:29,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:29,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:29,435 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:29,991 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:30,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:30,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-05-22 15:42:30,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:30,305 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:30,311 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:30,311 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:30,312 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 39117
2022-05-22 15:42:30,374 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:30,393 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start RPC server
2022-05-22 15:42:30,410 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: GrpcService started, listening on 34801
2022-05-22 15:42:30,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:30,432 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis edd315a5-4c31-41f4-a5d0-8e213ccdb1da is started using port 34801 for RATIS
2022-05-22 15:42:30,432 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis edd315a5-4c31-41f4-a5d0-8e213ccdb1da is started using port 34801 for RATIS_ADMIN
2022-05-22 15:42:30,432 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis edd315a5-4c31-41f4-a5d0-8e213ccdb1da is started using port 34801 for RATIS_SERVER
2022-05-22 15:42:30,433 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@16849745] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-edd315a5-4c31-41f4-a5d0-8e213ccdb1da: Started
2022-05-22 15:42:30,449 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc edd315a5-4c31-41f4-a5d0-8e213ccdb1da is started using port 42931
2022-05-22 15:42:30,796 [IPC Server handler 15 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:30,796 [IPC Server handler 15 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:30,796 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:30,796 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=ec4c1daa-d486-44a6-8c53-304440fff12b to datanode:c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:30,797 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: ec4c1daa-d486-44a6-8c53-304440fff12b, Nodes: c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:30.796Z[Etc/UTC]].
2022-05-22 15:42:30,954 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:30,995 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:31,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:31,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:42:31,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:31,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:31,955 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:32,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:32,191 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: addNew group-8CF4B692CF1D:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:1] returns group-8CF4B692CF1D:java.util.concurrent.CompletableFuture@2f403f57[Not completed]
2022-05-22 15:42:32,192 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: new RaftServerImpl for group-8CF4B692CF1D:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:32,192 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:32,192 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:32,192 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:32,192 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: ConfigurationManager, init=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis] (custom)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:32,193 [pool-3348-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d does not exist. Creating ...
2022-05-22 15:42:32,218 [pool-3348-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:32,231 [pool-3348-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d has been successfully formatted.
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-8CF4B692CF1D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:32,232 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:32,233 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:32,233 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:32,233 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d
2022-05-22 15:42:32,233 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:32,234 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:32,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: ad7bd58a-6c08-45ff-8812-8cf4b692cf1d, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, CreationTimestamp2022-05-22T15:42:29.186Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:32,237 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:32,260 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:32,260 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:32,260 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:32,260 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:32,261 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:32,272 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: start as a follower, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:1], old=null
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:32,275 [pool-3348-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState
2022-05-22 15:42:32,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:42:32,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:32,306 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:32,324 [pool-3348-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8CF4B692CF1D,id=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:32,327 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=ad7bd58a-6c08-45ff-8812-8cf4b692cf1d
2022-05-22 15:42:32,327 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ad7bd58a-6c08-45ff-8812-8cf4b692cf1d.
2022-05-22 15:42:32,331 [IPC Server handler 4 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:32,331 [IPC Server handler 4 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:32,331 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:32,333 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=252f1828-f4b3-439c-a5e2-ff0e293dadae to datanode:edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:32,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 252f1828-f4b3-439c-a5e2-ff0e293dadae, Nodes: edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:32.333Z[Etc/UTC]].
2022-05-22 15:42:32,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 to datanode:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:32,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 to datanode:edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:32,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 to datanode:c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:32,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: d451f14d-141e-4bf0-bcdf-9e28c69a43e8, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:32.334Z[Etc/UTC]].
2022-05-22 15:42:32,509 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:32,951 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5205306730ns, electionTimeout:5158ms
2022-05-22 15:42:32,951 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState
2022-05-22 15:42:32,951 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:32,951 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:32,952 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159 ELECTION round 0: submit vote requests at term 1 for -1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:1], old=null
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-008AC268CDA9 with new leaderId: 1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:32,975 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: change Leader from null to 1bd1ad93-a217-4aba-aed5-0a262321f6e0 at term 1 for becomeLeader, leader elected after 5293ms
2022-05-22 15:42:32,976 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:32,976 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:32,976 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:32,976 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:32,977 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderStateImpl
2022-05-22 15:42:32,978 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:32,982 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9/current/log_inprogress_0
2022-05-22 15:42:33,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:33,055 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderElection159] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: set configuration 0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:1], old=null
2022-05-22 15:42:33,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,155 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122899252ns, electionTimeout:5078ms
2022-05-22 15:42:33,156 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,156 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:33,156 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:33,156 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160
2022-05-22 15:42:33,183 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160 ELECTION round 0: submit vote requests at term 1 for -1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0], old=null
2022-05-22 15:42:33,220 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: receive requestVote(ELECTION, 1bd1ad93-a217-4aba-aed5-0a262321f6e0, group-FAB0D27550B0, 1, (t:0, i:0))
2022-05-22 15:42:33,220 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FOLLOWER: accept ELECTION from 1bd1ad93-a217-4aba-aed5-0a262321f6e0: our priority 0 <= candidate's priority 0
2022-05-22 15:42:33,220 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:33,220 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,220 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,220 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:33,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,276 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0 replies to ELECTION vote request: 1bd1ad93-a217-4aba-aed5-0a262321f6e0<-e5a271d5-f691-48ef-8105-b2d60b002f9a#0:OK-t1. Peer's state: e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0:t1, leader=null, voted=1bd1ad93-a217-4aba-aed5-0a262321f6e0, raftlog=e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c-1, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:33,288 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: receive requestVote(ELECTION, 1bd1ad93-a217-4aba-aed5-0a262321f6e0, group-FAB0D27550B0, 1, (t:0, i:0))
2022-05-22 15:42:33,289 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FOLLOWER: reject ELECTION from 1bd1ad93-a217-4aba-aed5-0a262321f6e0: our priority 1 > candidate's priority 0
2022-05-22 15:42:33,289 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:33,289 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,289 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,289 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:33,294 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0 replies to ELECTION vote request: 1bd1ad93-a217-4aba-aed5-0a262321f6e0<-56e641d3-eb56-493e-85a5-4bb0b1b5352d#0:FAIL-t1. Peer's state: 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0:t1, leader=null, voted=null, raftlog=56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c-1, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:33,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:33,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:33,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 1bd1ad93-a217-4aba-aed5-0a262321f6e0<-e5a271d5-f691-48ef-8105-b2d60b002f9a#0:OK-t1
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 1bd1ad93-a217-4aba-aed5-0a262321f6e0<-56e641d3-eb56-493e-85a5-4bb0b1b5352d#0:FAIL-t1
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160 ELECTION round 0: result REJECTED
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160
2022-05-22 15:42:33,333 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:33,445 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,760 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5123923947ns, electionTimeout:5105ms
2022-05-22 15:42:33,760 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState
2022-05-22 15:42:33,760 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:33,760 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:33,760 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161 ELECTION round 0: submit vote requests at term 1 for -1: [56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1], old=null
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B563385F6B43 with new leaderId: 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: change Leader from null to 56e641d3-eb56-493e-85a5-4bb0b1b5352d at term 1 for becomeLeader, leader elected after 5350ms
2022-05-22 15:42:33,778 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:33,779 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:33,779 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderStateImpl
2022-05-22 15:42:33,780 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:33,783 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43/current/log_inprogress_0
2022-05-22 15:42:33,783 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderElection161] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: set configuration 0: [56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1], old=null
2022-05-22 15:42:33,809 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c72cb747-71cd-49bf-9573-30515b8c4828: addNew group-304440FFF12B:[c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:1] returns group-304440FFF12B:java.util.concurrent.CompletableFuture@6bb75267[Not completed]
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - c72cb747-71cd-49bf-9573-30515b8c4828: new RaftServerImpl for group-304440FFF12B:[c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:33,817 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:33,818 [pool-3370-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: ConfigurationManager, init=-1: [c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:33,818 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis] (custom)
2022-05-22 15:42:33,818 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:33,818 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:33,818 [pool-3370-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b does not exist. Creating ...
2022-05-22 15:42:33,850 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,858 [pool-3370-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:33,862 [pool-3370-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b has been successfully formatted.
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-304440FFF12B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:33,863 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:33,863 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: ec4c1daa-d486-44a6-8c53-304440fff12b, Nodes: c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c72cb747-71cd-49bf-9573-30515b8c4828, CreationTimestamp2022-05-22T15:42:30.796Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:33,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:33,868 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:33,870 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:33,871 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:33,871 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:33,871 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:33,871 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:33,907 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:33,910 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:33,910 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:33,910 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:33,910 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:33,911 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:33,911 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: start as a follower, conf=-1: [c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:1], old=null
2022-05-22 15:42:33,911 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:33,911 [pool-3370-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState
2022-05-22 15:42:33,911 [pool-3370-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-304440FFF12B,id=c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:33,912 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=ec4c1daa-d486-44a6-8c53-304440fff12b
2022-05-22 15:42:33,913 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ec4c1daa-d486-44a6-8c53-304440fff12b.
2022-05-22 15:42:33,913 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c72cb747-71cd-49bf-9573-30515b8c4828: addNew group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0] returns group-9E28C69A43E8:java.util.concurrent.CompletableFuture@6f88cbc9[Not completed]
2022-05-22 15:42:33,915 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - c72cb747-71cd-49bf-9573-30515b8c4828: new RaftServerImpl for group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:33,915 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:33,915 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:33,915 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: ConfigurationManager, init=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis] (custom)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:33,916 [pool-3370-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 does not exist. Creating ...
2022-05-22 15:42:33,921 [pool-3370-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:33,923 [pool-3370-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 has been successfully formatted.
2022-05-22 15:42:33,924 [pool-3370-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9E28C69A43E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:33,924 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:33,937 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:33,937 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:33,937 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:33,937 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:33,937 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:33,938 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:33,925 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,971 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:33,971 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:33,971 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:33,971 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:33,973 [pool-3370-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:33,973 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:33,973 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:33,974 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:33,974 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:33,974 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:33,974 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: start as a follower, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:33,977 [pool-3370-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:33,978 [pool-3370-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:33,979 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8
2022-05-22 15:42:33,991 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: addNew group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0] returns group-9E28C69A43E8:java.util.concurrent.CompletableFuture@5c4ee95b[Not completed]
2022-05-22 15:42:33,993 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,999 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:33,992 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: new RaftServerImpl for group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: ConfigurationManager, init=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:34,003 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis] (custom)
2022-05-22 15:42:34,004 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:34,004 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:34,004 [pool-3348-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 does not exist. Creating ...
2022-05-22 15:42:34,005 [pool-3348-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:34,007 [pool-3348-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 has been successfully formatted.
2022-05-22 15:42:34,007 [pool-3348-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9E28C69A43E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:34,007 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:34,007 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:34,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:34,007 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:34,008 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:34,008 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:34,008 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:34,009 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:34,012 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:34,056 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:34,056 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:34,056 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:34,056 [pool-3348-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:34,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:34,072 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: start as a follower, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:34,075 [pool-3348-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:34,108 [pool-3348-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:34,108 [pool-3348-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:34,163 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094039146ns, electionTimeout:5092ms
2022-05-22 15:42:34,163 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState
2022-05-22 15:42:34,163 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:34,163 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:34,163 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162
2022-05-22 15:42:34,186 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: addNew group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0] returns group-9E28C69A43E8:java.util.concurrent.CompletableFuture@7747fbc1[Not completed]
2022-05-22 15:42:34,188 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: new RaftServerImpl for group-9E28C69A43E8:[a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:42:34,188 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:34,188 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: ConfigurationManager, init=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis] (custom)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:34,189 [pool-3392-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 does not exist. Creating ...
2022-05-22 15:42:34,190 [pool-3392-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:34,190 [pool-3392-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8 has been successfully formatted.
2022-05-22 15:42:34,239 [pool-3392-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9E28C69A43E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:34,239 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:34,240 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:34,240 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:34,240 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:34,240 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:34,240 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:34,241 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:34,252 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162 ELECTION round 0: submit vote requests at term 1 for -1: [e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:1], old=null
2022-05-22 15:42:34,252 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:34,252 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-D3FD8A4C4016 with new leaderId: e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: change Leader from null to e5a271d5-f691-48ef-8105-b2d60b002f9a at term 1 for becomeLeader, leader elected after 5271ms
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:34,253 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderStateImpl
2022-05-22 15:42:34,254 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:34,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:34,257 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016/current/log_inprogress_0
2022-05-22 15:42:34,264 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:34,264 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:34,265 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:34,265 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:34,265 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:34,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:34,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:34,309 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:34,321 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderElection162] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: set configuration 0: [e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:1], old=null
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:34,337 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:34,340 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:34,340 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: start as a follower, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:34,341 [pool-3392-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:34,485 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8.
2022-05-22 15:42:34,976 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:35,014 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:35,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:35,296 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: addNew group-FF0E293DADAE:[edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1] returns group-FF0E293DADAE:java.util.concurrent.CompletableFuture@6f8f3f49[Not completed]
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: new RaftServerImpl for group-FF0E293DADAE:[edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: ConfigurationManager, init=-1: [edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:35,297 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis] (custom)
2022-05-22 15:42:35,298 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:35,298 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:35,298 [pool-3392-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae does not exist. Creating ...
2022-05-22 15:42:35,300 [pool-3392-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:35,307 [pool-3392-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae has been successfully formatted.
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FF0E293DADAE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:35,308 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:35,309 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:35,310 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:35,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:35,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:35,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:35,310 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:35,310 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:35,334 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:35,335 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:35,335 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:35,335 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:35,335 [pool-3392-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:35,336 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: start as a follower, conf=-1: [edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1], old=null
2022-05-22 15:42:35,339 [pool-3392-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:35,345 [pool-3392-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState
2022-05-22 15:42:35,347 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 252f1828-f4b3-439c-a5e2-ff0e293dadae, Nodes: edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:42:32.333Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:35,347 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:35,351 [pool-3392-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF0E293DADAE,id=edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:35,355 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=252f1828-f4b3-439c-a5e2-ff0e293dadae
2022-05-22 15:42:35,356 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=252f1828-f4b3-439c-a5e2-ff0e293dadae.
2022-05-22 15:42:35,779 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:35,928 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:36,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:36,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:36,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:36,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:36,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:36,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:36,784 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:36,930 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:36,977 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:37,023 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:37,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:37,263 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:37,310 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:37,311 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:37,311 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:37,347 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:37,518 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5242894368ns, electionTimeout:5191ms
2022-05-22 15:42:37,519 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState
2022-05-22 15:42:37,519 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:37,519 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:37,519 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163
2022-05-22 15:42:37,554 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163 ELECTION round 0: submit vote requests at term 1 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:1], old=null
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-8CF4B692CF1D with new leaderId: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: change Leader from null to a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at term 1 for becomeLeader, leader elected after 5322ms
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:37,555 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:37,556 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:37,556 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderStateImpl
2022-05-22 15:42:37,557 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:37,573 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d/current/log_inprogress_0
2022-05-22 15:42:37,647 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderElection163] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: set configuration 0: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:1], old=null
2022-05-22 15:42:37,785 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:38,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:38,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:38,311 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:38,311 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:38,311 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:38,317 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5028150761ns, electionTimeout:5023ms
2022-05-22 15:42:38,317 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:38,317 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-05-22 15:42:38,317 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:38,317 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164
2022-05-22 15:42:38,346 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164 ELECTION round 0: submit vote requests at term 2 for -1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:38,362 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: receive requestVote(ELECTION, 56e641d3-eb56-493e-85a5-4bb0b1b5352d, group-FAB0D27550B0, 2, (t:0, i:0))
2022-05-22 15:42:38,362 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FOLLOWER: accept ELECTION from 56e641d3-eb56-493e-85a5-4bb0b1b5352d: our priority 0 <= candidate's priority 1
2022-05-22 15:42:38,362 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:38,362 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:38,368 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: start 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:38,372 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:38,381 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: receive requestVote(ELECTION, 56e641d3-eb56-493e-85a5-4bb0b1b5352d, group-FAB0D27550B0, 2, (t:0, i:0))
2022-05-22 15:42:38,381 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FOLLOWER: accept ELECTION from 56e641d3-eb56-493e-85a5-4bb0b1b5352d: our priority 0 <= candidate's priority 1
2022-05-22 15:42:38,381 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:38,381 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:38,381 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: start e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:38,381 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:38,382 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0 replies to ELECTION vote request: 56e641d3-eb56-493e-85a5-4bb0b1b5352d<-1bd1ad93-a217-4aba-aed5-0a262321f6e0#0:OK-t2. Peer's state: 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0:t2, leader=null, voted=56e641d3-eb56-493e-85a5-4bb0b1b5352d, raftlog=1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c-1, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|priority:0], old=null
2022-05-22 15:42:38,384 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-05-22 15:42:38,384 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 56e641d3-eb56-493e-85a5-4bb0b1b5352d<-1bd1ad93-a217-4aba-aed5-0a262321f6e0#0:OK-t2
2022-05-22 15:42:38,384 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164 ELECTION round 0: result PASSED
2022-05-22 15:42:38,384 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FAB0D27550B0 with new leaderId: 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: change Leader from null to 56e641d3-eb56-493e-85a5-4bb0b1b5352d at term 2 for becomeLeader, leader elected after 10161ms
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:38,385 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:38,386 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:38,386 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:38,386 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:38,386 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:38,386 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:38,388 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0 replies to ELECTION vote request: 56e641d3-eb56-493e-85a5-4bb0b1b5352d<-e5a271d5-f691-48ef-8105-b2d60b002f9a#0:OK-t2. Peer's state: e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0:t2, leader=null, voted=56e641d3-eb56-493e-85a5-4bb0b1b5352d, raftlog=e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c-1, conf=-1: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:38,471 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:38,481 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: start 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderStateImpl
2022-05-22 15:42:38,482 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:38,484 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/current/log_inprogress_0
2022-05-22 15:42:38,510 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 9d6c0e09-87af-45d5-ad1c-fab0d27550b0, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:42:27.274Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(251)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-05-22 15:42:38,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:notifyStatusChanged(88)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-05-22 15:42:38,511 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-05-22 15:42:38,599 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderElection164] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: set configuration 0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:38,669 [1bd1ad93-a217-4aba-aed5-0a262321f6e0-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FAB0D27550B0 with new leaderId: 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:38,669 [1bd1ad93-a217-4aba-aed5-0a262321f6e0-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: change Leader from null to 56e641d3-eb56-493e-85a5-4bb0b1b5352d at term 2 for appendEntries, leader elected after 10718ms
2022-05-22 15:42:38,699 [1bd1ad93-a217-4aba-aed5-0a262321f6e0-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: set configuration 0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:38,700 [1bd1ad93-a217-4aba-aed5-0a262321f6e0-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:38,702 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/current/log_inprogress_0
2022-05-22 15:42:38,736 [e5a271d5-f691-48ef-8105-b2d60b002f9a-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FAB0D27550B0 with new leaderId: 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:38,736 [e5a271d5-f691-48ef-8105-b2d60b002f9a-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: change Leader from null to 56e641d3-eb56-493e-85a5-4bb0b1b5352d at term 2 for appendEntries, leader elected after 9919ms
2022-05-22 15:42:38,759 [e5a271d5-f691-48ef-8105-b2d60b002f9a-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: set configuration 0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null
2022-05-22 15:42:38,760 [e5a271d5-f691-48ef-8105-b2d60b002f9a-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:38,762 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/current/log_inprogress_0
2022-05-22 15:42:38,988 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077056773ns, electionTimeout:5066ms
2022-05-22 15:42:38,988 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState
2022-05-22 15:42:38,988 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:38,988 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:38,988 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165 ELECTION round 0: submit vote requests at term 1 for -1: [c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:1], old=null
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-304440FFF12B with new leaderId: c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:38,993 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: change Leader from null to c72cb747-71cd-49bf-9573-30515b8c4828 at term 1 for becomeLeader, leader elected after 5130ms
2022-05-22 15:42:38,994 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:39,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:39,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:39,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:39,008 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:39,008 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:39,008 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:39,008 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:39,008 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderStateImpl
2022-05-22 15:42:39,009 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:39,010 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderElection165] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: set configuration 0: [c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:1], old=null
2022-05-22 15:42:39,010 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b/current/log_inprogress_0
2022-05-22 15:42:39,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:39,063 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5085450680ns, electionTimeout:5084ms
2022-05-22 15:42:39,063 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,063 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:39,063 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:39,063 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166
2022-05-22 15:42:39,103 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166 ELECTION round 0: submit vote requests at term 1 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:39,139 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5030440865ns, electionTimeout:5029ms
2022-05-22 15:42:39,139 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,139 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:39,187 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:39,187 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167
2022-05-22 15:42:39,233 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167 ELECTION round 0: submit vote requests at term 1 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:39,234 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: receive requestVote(ELECTION, c72cb747-71cd-49bf-9573-30515b8c4828, group-9E28C69A43E8, 1, (t:0, i:0))
2022-05-22 15:42:39,234 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-CANDIDATE: reject ELECTION from c72cb747-71cd-49bf-9573-30515b8c4828: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 1
2022-05-22 15:42:39,234 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8 replies to ELECTION vote request: c72cb747-71cd-49bf-9573-30515b8c4828<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t1. Peer's state: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8:t1, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:39,241 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, c72cb747-71cd-49bf-9573-30515b8c4828, group-9E28C69A43E8, 1, (t:0, i:0))
2022-05-22 15:42:39,241 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FOLLOWER: reject ELECTION from c72cb747-71cd-49bf-9573-30515b8c4828: our priority 1 > candidate's priority 0
2022-05-22 15:42:39,241 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:39,241 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,242 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,242 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:42:39,303 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: c72cb747-71cd-49bf-9573-30515b8c4828<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t1. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t1, leader=null, voted=null, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:39,312 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:39,312 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Cluster exits safe mode
2022-05-22 15:42:39,312 [Listener at 127.0.0.1/45987] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:39,313 [Listener at 127.0.0.1/45987] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:39,318 [Listener at 127.0.0.1/45987] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(160)) - ServiceID for StorageContainerManager is null
2022-05-22 15:42:39,318 [Listener at 127.0.0.1/45987] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(165)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-05-22 15:42:39,319 [Listener at 127.0.0.1/45987] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:39,319 [Listener at 127.0.0.1/45987] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:39,395 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 1, (t:0, i:0))
2022-05-22 15:42:39,395 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FOLLOWER: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: our priority 1 > candidate's priority 0
2022-05-22 15:42:39,395 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:39,395 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,395 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,411 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t1. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t1, leader=null, voted=null, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:39,412 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:39,412 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c72cb747-71cd-49bf-9573-30515b8c4828<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t1
2022-05-22 15:42:39,412 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: c72cb747-71cd-49bf-9573-30515b8c4828<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t1
2022-05-22 15:42:39,413 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 1, (t:0, i:0))
2022-05-22 15:42:39,413 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-CANDIDATE: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for c72cb747-71cd-49bf-9573-30515b8c4828 at current term 1
2022-05-22 15:42:39,414 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t1. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t1, leader=null, voted=c72cb747-71cd-49bf-9573-30515b8c4828, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:39,432 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:42:39,466 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166 ELECTION round 0: result REJECTED
2022-05-22 15:42:39,466 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:42:39,466 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166
2022-05-22 15:42:39,466 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,562 [Listener at 127.0.0.1/45987] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 242 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-05-22 15:42:39,566 [Listener at 0.0.0.0/38371] INFO  rpc.RpcClient (RpcClient.java:createVolume(448)) - Creating Volume: vol1, with user54540 as owner and space quota set to -1 bytes, counts quota set to -1
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t1
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167 ELECTION round 0: result REJECTED
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167
2022-05-22 15:42:39,566 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:39,647 [Listener at 127.0.0.1/45987] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:39,647 [Listener at 127.0.0.1/45987] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:39,794 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user54540
2022-05-22 15:42:40,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:40,127 [Listener at 0.0.0.0/38371] INFO  rpc.RpcClient (RpcClient.java:createBucket(637)) - Creating Bucket: vol1/bucket1, with runner as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
2022-05-22 15:42:40,144 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(258)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2022-05-22 15:42:40,239 [IPC Server handler 3 on default port 42521] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(127)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2022-05-22 15:42:40,239 [IPC Server handler 3 on default port 42521] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(235)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
2022-05-22 15:42:40,239 [IPC Server handler 3 on default port 42521] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(127)) - Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
2022-05-22 15:42:40,337 [Listener at 127.0.0.1/45987] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-05-22 15:42:40,337 [Listener at 127.0.0.1/45987] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-05-22 15:42:40,346 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:40,346 [Listener at 127.0.0.1/45987] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:40,346 [Listener at 127.0.0.1/45987] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-05-22 15:42:40,346 [Listener at 127.0.0.1/45987] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-05-22 15:42:40,346 [Listener at 127.0.0.1/45987] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(371)) - upgrade containerId to 0
2022-05-22 15:42:40,347 [Listener at 127.0.0.1/45987] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-05-22 15:42:40,347 [Listener at 127.0.0.1/45987] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(148)) - Entering startup safe mode.
2022-05-22 15:42:40,357 [Listener at 127.0.0.1/45987] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-05-22 15:42:40,358 [Listener at 127.0.0.1/45987] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-05-22 15:42:40,358 [Listener at 127.0.0.1/45987] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-05-22 15:42:40,358 [Listener at 127.0.0.1/45987] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-05-22 15:42:40,359 [Listener at 127.0.0.1/45987] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(125)) - Starting RatisPipelineUtilsThread.
2022-05-22 15:42:40,359 [Listener at 127.0.0.1/45987] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:start(126)) - Starting BackgroundPipelineScrubber Service.
2022-05-22 15:42:40,361 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5016047340ns, electionTimeout:5008ms
2022-05-22 15:42:40,361 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState
2022-05-22 15:42:40,361 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:40,366 [Listener at 127.0.0.1/45987] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-05-22 15:42:40,366 [Listener at 127.0.0.1/45987] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-05-22 15:42:40,366 [Listener at 127.0.0.1/45987] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-05-22 15:42:40,366 [Listener at 127.0.0.1/45987] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-05-22 15:42:40,367 [Listener at 127.0.0.1/45987] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-05-22 15:42:40,367 [Listener at 127.0.0.1/45987] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-05-22 15:42:40,430 [Listener at 127.0.0.1/45987] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-05-22 15:42:40,431 [Listener at 127.0.0.1/45987] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-05-22 15:42:40,437 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:40,437 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168
2022-05-22 15:42:40,437 [Listener at 127.0.0.1/45987] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-05-22 15:42:40,463 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168 ELECTION round 0: submit vote requests at term 1 for -1: [edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1], old=null
2022-05-22 15:42:40,464 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:40,464 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168
2022-05-22 15:42:40,464 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:40,464 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FF0E293DADAE with new leaderId: edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:40,464 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: change Leader from null to edd315a5-4c31-41f4-a5d0-8e213ccdb1da at term 1 for becomeLeader, leader elected after 5156ms
2022-05-22 15:42:40,465 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:40,486 [Listener at 127.0.0.1/45987] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:40,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:40,487 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:40,488 [Listener at 0.0.0.0/35219] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:40,488 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:40,489 [Listener at 0.0.0.0/33495] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:40,490 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:40,536 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:40,536 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:40,537 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderStateImpl
2022-05-22 15:42:40,538 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:40,539 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae/current/log_inprogress_0
2022-05-22 15:42:40,540 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: set configuration 0: [edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1], old=null
2022-05-22 15:42:40,713 [Listener at 0.0.0.0/42757] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(399)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-05-22 15:42:40,713 [Listener at 0.0.0.0/42757] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:40,713 [Listener at 0.0.0.0/42757] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-05-22 15:42:40,713 [Listener at 0.0.0.0/42757] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1354)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42757
2022-05-22 15:42:40,713 [Listener at 0.0.0.0/42757] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2022-05-22 15:42:40,830 [Listener at 0.0.0.0/42757] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:42757
2022-05-22 15:42:40,922 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:40,923 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:40,925 [Listener at 0.0.0.0/42757] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1369)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33495
2022-05-22 15:42:40,926 [Listener at 0.0.0.0/42757] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:33495
2022-05-22 15:42:40,926 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:40,926 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:40,956 [Listener at 0.0.0.0/42757] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(183)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:35219
2022-05-22 15:42:40,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:40,956 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:41,056 [Listener at 0.0.0.0/42757] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-05-22 15:42:41,056 [Listener at 0.0.0.0/42757] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:41,057 [Listener at 0.0.0.0/42757] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:41,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:41,103 [Listener at 0.0.0.0/42757] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:41,104 [Listener at 0.0.0.0/42757] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:41,104 [Listener at 0.0.0.0/42757] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-05-22 15:42:41,104 [Listener at 0.0.0.0/42757] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:41,104 [Listener at 0.0.0.0/42757] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:41,105 [Listener at 0.0.0.0/42757] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 46547
2022-05-22 15:42:41,105 [Listener at 0.0.0.0/42757] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:41,140 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71de65fe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:41,143 [Listener at 0.0.0.0/42757] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:41,143 [Listener at 0.0.0.0/42757] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:41,144 [Listener at 0.0.0.0/42757] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:41,144 [Listener at 0.0.0.0/42757] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@14f0e2a5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:41,144 [Listener at 0.0.0.0/42757] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2526f635{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:42:41,200 [Listener at 0.0.0.0/42757] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@cc44703{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:42:41,294 [Listener at 0.0.0.0/42757] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@5c0dc34b{HTTP/1.1, (http/1.1)}{0.0.0.0:46547}
2022-05-22 15:42:41,295 [Listener at 0.0.0.0/42757] INFO  server.Server (Server.java:doStart(415)) - Started @360674ms
2022-05-22 15:42:41,295 [Listener at 0.0.0.0/42757] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:41,373 [Listener at 0.0.0.0/42757] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:46547
2022-05-22 15:42:41,373 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:41,383 [Listener at 0.0.0.0/42757] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = BUCKET_LAYOUT_SUPPORT (version = 2), software layout = BUCKET_LAYOUT_SUPPORT (version = 2)
2022-05-22 15:42:41,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:41,979 [Listener at 0.0.0.0/42757] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 497 ms to scan 2 urls, producing 143 keys and 369 values [using 2 cores]
2022-05-22 15:42:41,979 [Listener at 0.0.0.0/42757] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-05-22 15:42:41,979 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:41,980 [Listener at 0.0.0.0/42757] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33495]
2022-05-22 15:42:41,980 [Listener at 0.0.0.0/42757] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33495]
2022-05-22 15:42:42,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2022-05-22 15:42:42,127 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:42,127 [Listener at 0.0.0.0/42757] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-05-22 15:42:42,127 [Listener at 0.0.0.0/42757] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-05-22 15:42:42,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:42,860 [Listener at 0.0.0.0/42757] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(3894)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-05-22 15:42:42,861 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:42:42,861 [Listener at 0.0.0.0/42757] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(395)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-05-22 15:42:42,861 [Listener at 0.0.0.0/42757] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:42,861 [Listener at 0.0.0.0/42757] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:42,861 [Listener at 0.0.0.0/42757] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:42:42,862 [Listener at 0.0.0.0/42757] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:44261
2022-05-22 15:42:42,862 [Listener at 0.0.0.0/42757] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(627)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-05-22 15:42:42,908 [Listener at 0.0.0.0/42757] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:42,908 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:42,908 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-05-22 15:42:42,908 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 44261 (custom)
2022-05-22 15:42:42,908 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 44261 (custom)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 44261 (custom)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:42,909 [Listener at 0.0.0.0/42757] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:42,910 [Listener at 0.0.0.0/42757] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis] (custom)
2022-05-22 15:42:42,968 [Listener at 0.0.0.0/42757] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:44261|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@57c25551[Not completed]
2022-05-22 15:42:42,968 [Listener at 0.0.0.0/42757] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1901)) - OzoneManager Ratis server initialized at port 44261
2022-05-22 15:42:42,969 [Listener at 0.0.0.0/42757] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1030)) - Creating RPC Server
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:44261|priority:0] with OzoneManagerStateMachine:uninitialized
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:44261|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis] (custom)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:42,971 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:42,972 [pool-3501-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-05-22 15:42:42,973 [pool-3501-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:42,995 [pool-3501-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:42,996 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:43,012 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-05-22 15:42:43,013 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:43,013 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-05-22 15:42:43,013 [pool-3501-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:43,013 [pool-3501-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:43,019 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:43,019 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:43,020 [pool-3501-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:43,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:43,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:44,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:42:44,466 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5071422330ns, electionTimeout:5052ms
2022-05-22 15:42:44,467 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:44,467 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-05-22 15:42:44,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:44,540 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:44,540 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169
2022-05-22 15:42:44,607 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169 ELECTION round 0: submit vote requests at term 2 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:44,619 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5152875376ns, electionTimeout:5139ms
2022-05-22 15:42:44,619 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:44,619 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-05-22 15:42:44,689 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122505382ns, electionTimeout:5036ms
2022-05-22 15:42:44,689 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:44,689 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-05-22 15:42:44,689 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:44,689 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171
2022-05-22 15:42:44,735 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:44,735 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170
2022-05-22 15:42:44,744 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171 ELECTION round 0: submit vote requests at term 2 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:44,763 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:44,764 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-CANDIDATE: reject ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 2
2022-05-22 15:42:44,764 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t2. Peer's state: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8:t2, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:44,764 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170 ELECTION round 0: submit vote requests at term 2 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:44,776 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:44,776 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-CANDIDATE: reject ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: already has voted for c72cb747-71cd-49bf-9573-30515b8c4828 at current term 2
2022-05-22 15:42:44,776 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t2. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t2, leader=null, voted=c72cb747-71cd-49bf-9573-30515b8c4828, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:44,882 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:44,882 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-CANDIDATE: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for edd315a5-4c31-41f4-a5d0-8e213ccdb1da at current term 2
2022-05-22 15:42:44,882 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t2. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t2, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:44,948 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: receive requestVote(ELECTION, c72cb747-71cd-49bf-9573-30515b8c4828, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:44,948 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-CANDIDATE: reject ELECTION from c72cb747-71cd-49bf-9573-30515b8c4828: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 2
2022-05-22 15:42:44,948 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8 replies to ELECTION vote request: c72cb747-71cd-49bf-9573-30515b8c4828<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t2. Peer's state: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8:t2, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:44,991 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-05-22 15:42:44,991 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t2
2022-05-22 15:42:44,991 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171 ELECTION round 0: result REJECTED
2022-05-22 15:42:44,992 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-05-22 15:42:44,992 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171
2022-05-22 15:42:44,992 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t2
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t2
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169 ELECTION round 0: result REJECTED
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169
2022-05-22 15:42:44,995 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:45,005 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, c72cb747-71cd-49bf-9573-30515b8c4828, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:45,005 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FOLLOWER: reject ELECTION from c72cb747-71cd-49bf-9573-30515b8c4828: already has voted for edd315a5-4c31-41f4-a5d0-8e213ccdb1da at current term 2
2022-05-22 15:42:45,005 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: c72cb747-71cd-49bf-9573-30515b8c4828<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t2. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t2, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c72cb747-71cd-49bf-9573-30515b8c4828<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t2
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: c72cb747-71cd-49bf-9573-30515b8c4828<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t2
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170 ELECTION round 0: result REJECTED
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170
2022-05-22 15:42:45,006 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:45,006 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 2, (t:0, i:0))
2022-05-22 15:42:45,008 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FOLLOWER: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for c72cb747-71cd-49bf-9573-30515b8c4828 at current term 2
2022-05-22 15:42:45,008 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t2. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t2, leader=null, voted=c72cb747-71cd-49bf-9573-30515b8c4828, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:45,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:45,288 [Listener at 0.0.0.0/42757] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 2272 ms to scan 19 urls, producing 61 keys and 3717 values [using 2 cores]
2022-05-22 15:42:45,289 [Listener at 0.0.0.0/42757] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:45,302 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:42:45,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:45,584 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-05-22 15:42:45,601 [Listener at 127.0.0.1/35755] INFO  om.OzoneManager (OzoneManager.java:start(1405)) - OzoneManager RPC server is listening at localhost/127.0.0.1:35755
2022-05-22 15:42:45,602 [Listener at 127.0.0.1/35755] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 44261
2022-05-22 15:42:45,602 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:44261|priority:0], old=null
2022-05-22 15:42:45,602 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:45,602 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-05-22 15:42:45,602 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:42:45,602 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2022-05-22 15:42:45,602 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-05-22 15:42:45,603 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 44261
2022-05-22 15:42:45,603 [Listener at 127.0.0.1/35755] INFO  om.OzoneManager (OzoneManager.java:start(1421)) - Version File has different layout version (2) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-05-22 15:42:45,603 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5a871eae] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-05-22 15:42:45,660 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-05-22 15:42:45,660 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:45,661 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:45,680 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:45,681 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:45,681 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-05-22 15:42:45,681 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:45,681 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:45,681 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 33335
2022-05-22 15:42:45,682 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:45,712 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:45,712 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:45,712 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:45,713 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2bff2702{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:45,713 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@66c9f174{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:42:45,715 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@30f94f6c{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-05-22 15:42:45,728 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1f21d156{HTTP/1.1, (http/1.1)}{0.0.0.0:33335}
2022-05-22 15:42:45,728 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @365107ms
2022-05-22 15:42:45,728 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:45,729 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:33335
2022-05-22 15:42:45,738 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:45,738 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:42:45,739 [Listener at 127.0.0.1/35755] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1845)) - Trash Interval set to 0. Files deleted won't move to trash
2022-05-22 15:42:45,748 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:45,748 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:45,748 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:45,759 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d43b694] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:45,890 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:45,973 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:46,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:42:46,246 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 272 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:46,289 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:46,336 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:46,336 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:46,336 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data-0/containers/hdds
2022-05-22 15:42:46,417 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data-0/containers/hdds
2022-05-22 15:42:46,442 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis to VolumeSet
2022-05-22 15:42:46,443 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis
2022-05-22 15:42:46,452 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis
2022-05-22 15:42:46,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:46,599 [Thread-5931] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data-0/containers/hdds
2022-05-22 15:42:46,602 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:46,603 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:46,604 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:46,604 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:46,604 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:46,604 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:46,605 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis] (custom)
2022-05-22 15:42:46,676 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1074612837ns, electionTimeout:1074ms
2022-05-22 15:42:46,676 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-05-22 15:42:46,677 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:42:46,683 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:46,690 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:46,691 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection172
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection172 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:44261|priority:0], old=null
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection172 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection172
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 3730ms
2022-05-22 15:42:46,726 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:42:46,752 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:42:46,753 [om1@group-C5BA1605619E-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-05-22 15:42:46,753 [om1@group-C5BA1605619E-LeaderElection172] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:42:46,766 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-05-22 15:42:46,767 [om1@group-C5BA1605619E-LeaderElection172] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:44261|admin:|client:|dataStream:|priority:0], old=null
2022-05-22 15:42:46,791 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:46,792 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:46,864 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(191)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:44261"
]
2022-05-22 15:42:46,881 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:46,884 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:46,884 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:46,885 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:46,885 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:46,885 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:46,885 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 45555
2022-05-22 15:42:46,885 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:46,952 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:46,952 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:46,952 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:46,953 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@28bde1c2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:46,953 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@57b06fe1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:47,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:47,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:48,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:48,091 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@6d96e2b7{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45555-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3837239134916948671/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:48,225 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1d64db8f{HTTP/1.1, (http/1.1)}{0.0.0.0:45555}
2022-05-22 15:42:48,226 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @367605ms
2022-05-22 15:42:48,226 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:48,226 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45555
2022-05-22 15:42:48,239 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:48,239 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:48,239 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:48,244 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:48,259 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:48,278 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a633cb2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:48,285 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/meta/datanode.id
2022-05-22 15:42:48,375 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:48,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:48,684 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 308 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:48,685 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:48,865 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:48,865 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:48,865 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data-0/containers/hdds
2022-05-22 15:42:48,952 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data-0/containers/hdds
2022-05-22 15:42:49,054 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis to VolumeSet
2022-05-22 15:42:49,054 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis
2022-05-22 15:42:49,054 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis
2022-05-22 15:42:49,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:49,223 [Thread-6017] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data-0/containers/hdds
2022-05-22 15:42:49,223 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:49,225 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:49,227 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:49,228 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:49,228 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:49,229 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis] (custom)
2022-05-22 15:42:49,297 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:49,368 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:49,369 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:49,369 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:49,399 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:49,423 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:49,423 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:49,423 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:49,424 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:49,424 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 46327
2022-05-22 15:42:49,424 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:49,452 [IPC Server handler 12 on default port 39533] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(361)) - Starting Maintenance for node e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:49,468 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:49,468 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:49,468 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:49,479 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@5b9ac5d3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:49,480 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6479c10c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:49,489 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-05-22 15:42:49,489 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:49,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:49,737 [IPC Server handler 13 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(487)) - Scheduling a command to update the operationalState persisted on e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2022-05-22 15:42:49,997 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(279)) - Waiting for pipelines to close for e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. There are 2 pipelines
2022-05-22 15:42:49,998 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:49,998 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(56)) - Admin start on datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. Finalizing its pipelines [PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0, PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016]
2022-05-22 15:42:50,008 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(389)) - Container #1 closed for pipeline=PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(389)) - Container #2 closed for pipeline=PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(389)) - Container #3 closed for pipeline=PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: 9d6c0e09-87af-45d5-ad1c-fab0d27550b0, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:42:27.274Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 close command to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 close command to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:50,009 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 close command to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:50,056 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 9d6c0e09-87af-45d5-ad1c-fab0d27550b0, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:42:27.274Z[Etc/UTC]] removed.
2022-05-22 15:42:50,056 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: 7643202f-040e-4a0b-8e86-d3fd8a4c4016, Nodes: e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:e5a271d5-f691-48ef-8105-b2d60b002f9a, CreationTimestamp2022-05-22T15:42:26.008Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:42:50,056 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016 close command to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:50,056 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 7643202f-040e-4a0b-8e86-d3fd8a4c4016, Nodes: e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:e5a271d5-f691-48ef-8105-b2d60b002f9a, CreationTimestamp2022-05-22T15:42:26.008Z[Etc/UTC]] removed.
2022-05-22 15:42:50,063 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #1
2022-05-22 15:42:50,064 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #2
2022-05-22 15:42:50,064 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #3
2022-05-22 15:42:50,070 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@a04d304{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-46327-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-7860184587896837326/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:50,107 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5115725426ns, electionTimeout:5111ms
2022-05-22 15:42:50,107 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,107 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:42:50,108 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:50,108 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173
2022-05-22 15:42:50,117 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5110524659ns, electionTimeout:5108ms
2022-05-22 15:42:50,117 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,117 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:42:50,121 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173 ELECTION round 0: submit vote requests at term 3 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:50,127 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5131835932ns, electionTimeout:5120ms
2022-05-22 15:42:50,127 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,127 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:42:50,147 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 3, (t:0, i:0))
2022-05-22 15:42:50,148 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@3a8d8eac{HTTP/1.1, (http/1.1)}{0.0.0.0:46327}
2022-05-22 15:42:50,148 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @369528ms
2022-05-22 15:42:50,148 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:50,149 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:46327
2022-05-22 15:42:50,157 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:50,157 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:50,157 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:50,167 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:50,167 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:50,172 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 3, (t:0, i:0))
2022-05-22 15:42:50,243 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:50,280 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76a226f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:50,291 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:50,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:42:50,306 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/meta/datanode.id
2022-05-22 15:42:50,355 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:50,355 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection175
2022-05-22 15:42:50,395 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:50,395 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection174
2022-05-22 15:42:50,395 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-CANDIDATE: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: our priority 1 > candidate's priority 0
2022-05-22 15:42:50,395 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 3 for candidate:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:50,395 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection175
2022-05-22 15:42:50,400 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:run(231)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection175: skip running since this is already CLOSING
2022-05-22 15:42:50,403 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-CANDIDATE: accept ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: our priority 0 <= candidate's priority 0
2022-05-22 15:42:50,403 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 3 for candidate:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:50,403 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection174
2022-05-22 15:42:50,403 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,403 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:run(231)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-LeaderElection174: skip running since this is already CLOSING
2022-05-22 15:42:50,407 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:OK-t3. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t3, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:50,431 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,461 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t3. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t3, leader=null, voted=null, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:50,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t3
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:OK-t3
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173 ELECTION round 0: result REJECTED
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173
2022-05-22 15:42:50,567 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:50,578 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:50,578 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:50,583 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37315
2022-05-22 15:42:50,585 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:50,589 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start RPC server
2022-05-22 15:42:50,602 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: GrpcService started, listening on 38735
2022-05-22 15:42:50,612 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9cf969b5-3654-4d78-9d8f-3cca557d6deb is started using port 38735 for RATIS
2022-05-22 15:42:50,612 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9cf969b5-3654-4d78-9d8f-3cca557d6deb is started using port 38735 for RATIS_ADMIN
2022-05-22 15:42:50,612 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9cf969b5-3654-4d78-9d8f-3cca557d6deb is started using port 38735 for RATIS_SERVER
2022-05-22 15:42:50,612 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@15393c36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9cf969b5-3654-4d78-9d8f-3cca557d6deb: Started
2022-05-22 15:42:50,623 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9cf969b5-3654-4d78-9d8f-3cca557d6deb is started using port 44455
2022-05-22 15:42:50,685 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 is not found
2022-05-22 15:42:50,754 [IPC Server handler 14 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(487)) - Scheduling a command to update the operationalState persisted on e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2022-05-22 15:42:50,758 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 is not found
2022-05-22 15:42:50,785 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 509 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:50,786 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:50,794 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:50,794 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:50,794 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data-0/containers/hdds
2022-05-22 15:42:50,824 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data-0/containers/hdds
2022-05-22 15:42:50,835 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis to VolumeSet
2022-05-22 15:42:50,836 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis
2022-05-22 15:42:50,837 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis
2022-05-22 15:42:50,846 [Thread-6051] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data-0/containers/hdds
2022-05-22 15:42:50,846 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:50,848 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:50,849 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis] (custom)
2022-05-22 15:42:50,888 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:50,892 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:50,892 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:50,893 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:50,893 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:50,894 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:50,894 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:50,894 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:50,894 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:50,894 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 38389
2022-05-22 15:42:50,895 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:50,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:50,982 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:50,982 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:50,982 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:50,983 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@38997f0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:50,983 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@485b5a01{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,292 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:51,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:51,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:51,607 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: remove  FOLLOWER 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0:t2, leader=56e641d3-eb56-493e-85a5-4bb0b1b5352d, voted=56e641d3-eb56-493e-85a5-4bb0b1b5352d, raftlog=1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c78, conf=0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null RUNNING
2022-05-22 15:42:51,608 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: shutdown
2022-05-22 15:42:51,608 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:51,608 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:51,608 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater: set stopIndex = 78
2022-05-22 15:42:51,608 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:51,612 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-FAB0D27550B0: Taking a snapshot at:(t:2, i:78) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_78
2022-05-22 15:42:51,616 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-FAB0D27550B0: Finished taking a snapshot at:(t:2, i:78) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_78 took: 4 ms
2022-05-22 15:42:51,616 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater: Took a snapshot at index 78
2022-05-22 15:42:51,616 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 78
2022-05-22 15:42:51,627 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: closes. applyIndex: 78
2022-05-22 15:42:51,628 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:42:51,629 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0-SegmentedRaftLogWorker close()
2022-05-22 15:42:51,652 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:51,652 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:51,658 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #1 to QUASI_CLOSED state, datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-05-22 15:42:51,665 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:51,665 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:51,670 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #2 to QUASI_CLOSED state, datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-05-22 15:42:51,693 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:51,693 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:51,701 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-FAB0D27550B0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:51,701 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 command on datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0.
2022-05-22 15:42:51,712 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #3 to QUASI_CLOSED state, datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-05-22 15:42:51,733 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 is not found
2022-05-22 15:42:51,733 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016 is not found
2022-05-22 15:42:51,898 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@7e44353a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38389-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2024425509602875277/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:51,979 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1a116da2{HTTP/1.1, (http/1.1)}{0.0.0.0:38389}
2022-05-22 15:42:51,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #1 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e5a271d5-f691-48ef-8105-b2d60b002f9a, sequenceId=74, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=56e641d3-eb56-493e-85a5-4bb0b1b5352d, sequenceId=74, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=1bd1ad93-a217-4aba-aed5-0a262321f6e0, sequenceId=74, keyCount=7, bytesUsed=133}}
2022-05-22 15:42:51,979 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @371358ms
2022-05-22 15:42:51,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #2 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=56e641d3-eb56-493e-85a5-4bb0b1b5352d, sequenceId=78, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=1bd1ad93-a217-4aba-aed5-0a262321f6e0, sequenceId=78, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e5a271d5-f691-48ef-8105-b2d60b002f9a, sequenceId=78, keyCount=7, bytesUsed=133}}
2022-05-22 15:42:51,979 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:51,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #3 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e5a271d5-f691-48ef-8105-b2d60b002f9a, sequenceId=70, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=1bd1ad93-a217-4aba-aed5-0a262321f6e0, sequenceId=70, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=56e641d3-eb56-493e-85a5-4bb0b1b5352d, sequenceId=70, keyCount=6, bytesUsed=114}}
2022-05-22 15:42:51,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has 3 sufficientlyReplicated, 0 underReplicated and 3 unhealthy containers
2022-05-22 15:42:51,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:51,980 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38389
2022-05-22 15:42:51,980 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:51,980 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:51,980 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:51,987 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:51,994 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:52,063 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2322a7ae] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:52,064 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/meta/datanode.id
2022-05-22 15:42:52,120 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:52,277 [IPC Server handler 2 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:52,277 [IPC Server handler 2 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9cf969b5-3654-4d78-9d8f-3cca557d6deb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37315, RATIS=38735, RATIS_ADMIN=38735, RATIS_SERVER=38735, STANDALONE=44455], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:52,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:42:52,344 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:52,344 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:52,374 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 44383
2022-05-22 15:42:52,386 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:52,417 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start RPC server
2022-05-22 15:42:52,418 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: GrpcService started, listening on 35845
2022-05-22 15:42:52,418 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 2ad339c1-c64b-40f8-8805-fdb409c2806d is started using port 35845 for RATIS
2022-05-22 15:42:52,418 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 2ad339c1-c64b-40f8-8805-fdb409c2806d is started using port 35845 for RATIS_ADMIN
2022-05-22 15:42:52,418 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 2ad339c1-c64b-40f8-8805-fdb409c2806d is started using port 35845 for RATIS_SERVER
2022-05-22 15:42:52,419 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3237443d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-2ad339c1-c64b-40f8-8805-fdb409c2806d: Started
2022-05-22 15:42:52,435 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 2ad339c1-c64b-40f8-8805-fdb409c2806d is started using port 39607
2022-05-22 15:42:52,441 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 320 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:52,442 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:52,458 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-05-22 15:42:52,458 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-05-22 15:42:52,508 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:52,508 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:52,508 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data-0/containers/hdds
2022-05-22 15:42:52,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:52,546 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data-0/containers/hdds
2022-05-22 15:42:52,554 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-05-22 15:42:52,554 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:52,555 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=999c793e-8891-4f98-90d9-d89f05e02d54 to datanode:9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:52,556 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 999c793e-8891-4f98-90d9-d89f05e02d54, Nodes: 9cf969b5-3654-4d78-9d8f-3cca557d6deb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37315, RATIS=38735, RATIS_ADMIN=38735, RATIS_SERVER=38735, STANDALONE=44455], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:52.555Z[Etc/UTC]].
2022-05-22 15:42:52,629 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis to VolumeSet
2022-05-22 15:42:52,629 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis
2022-05-22 15:42:52,652 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis
2022-05-22 15:42:52,682 [Thread-6074] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data-0/containers/hdds
2022-05-22 15:42:52,682 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:52,683 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:52,684 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:52,685 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:52,685 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:52,685 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:52,693 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:52,694 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:52,694 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis] (custom)
2022-05-22 15:42:52,694 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 is not found
2022-05-22 15:42:52,699 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:52,704 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:52,704 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:52,705 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:52,735 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: remove  FOLLOWER e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0:t2, leader=56e641d3-eb56-493e-85a5-4bb0b1b5352d, voted=56e641d3-eb56-493e-85a5-4bb0b1b5352d, raftlog=e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c80, conf=0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null RUNNING
2022-05-22 15:42:52,736 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: shutdown
2022-05-22 15:42:52,736 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:52,736 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState
2022-05-22 15:42:52,748 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:52,749 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:52,749 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:52,749 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:52,749 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:52,750 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 42243
2022-05-22 15:42:52,750 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:52,757 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:52,757 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:52,757 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:42:52,758 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6897ab86{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:52,758 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3e3761c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:52,759 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater: set stopIndex = 80
2022-05-22 15:42:52,760 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-FollowerState was interrupted
2022-05-22 15:42:52,763 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-FAB0D27550B0: Taking a snapshot at:(t:2, i:80) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_80
2022-05-22 15:42:52,779 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-FAB0D27550B0: Finished taking a snapshot at:(t:2, i:80) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_80 took: 16 ms
2022-05-22 15:42:52,779 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater: Took a snapshot at index 80
2022-05-22 15:42:52,779 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 80
2022-05-22 15:42:52,780 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: closes. applyIndex: 80
2022-05-22 15:42:52,780 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:42:52,780 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0-SegmentedRaftLogWorker close()
2022-05-22 15:42:52,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:52,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:52,801 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: remove    LEADER 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0:t2, leader=56e641d3-eb56-493e-85a5-4bb0b1b5352d, voted=56e641d3-eb56-493e-85a5-4bb0b1b5352d, raftlog=56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLog:OPENED:c80, conf=0: [1bd1ad93-a217-4aba-aed5-0a262321f6e0|rpc:10.1.0.29:39927|dataStream:|priority:0, 56e641d3-eb56-493e-85a5-4bb0b1b5352d|rpc:10.1.0.29:42763|dataStream:|priority:1, e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:0], old=null RUNNING
2022-05-22 15:42:52,801 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: shutdown
2022-05-22 15:42:52,801 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAB0D27550B0,id=56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:52,801 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-LeaderStateImpl
2022-05-22 15:42:52,801 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-PendingRequests: sendNotLeaderResponses
2022-05-22 15:42:52,803 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->e5a271d5-f691-48ef-8105-b2d60b002f9a-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->e5a271d5-f691-48ef-8105-b2d60b002f9a-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-05-22 15:42:52,804 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->1bd1ad93-a217-4aba-aed5-0a262321f6e0-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->1bd1ad93-a217-4aba-aed5-0a262321f6e0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-05-22 15:42:52,804 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: Completed APPEND_ENTRIES, lastRequest: 56e641d3-eb56-493e-85a5-4bb0b1b5352d->e5a271d5-f691-48ef-8105-b2d60b002f9a#822-t2,previous=(t:2, i:79),leaderCommit=78,initializing? true,entries: size=1, first=(t:2, i:80), METADATAENTRY(c:78)
2022-05-22 15:42:52,805 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: Completed APPEND_ENTRIES, lastRequest: 56e641d3-eb56-493e-85a5-4bb0b1b5352d->1bd1ad93-a217-4aba-aed5-0a262321f6e0#806-t2,previous=(t:2, i:79),leaderCommit=78,initializing? true,entries: size=1, first=(t:2, i:80), METADATAENTRY(c:78)
2022-05-22 15:42:52,805 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->1bd1ad93-a217-4aba-aed5-0a262321f6e0-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-05-22 15:42:52,806 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->1bd1ad93-a217-4aba-aed5-0a262321f6e0: nextIndex: updateUnconditionally 81 -> 80
2022-05-22 15:42:52,807 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->e5a271d5-f691-48ef-8105-b2d60b002f9a-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-05-22 15:42:52,807 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0->e5a271d5-f691-48ef-8105-b2d60b002f9a: nextIndex: updateUnconditionally 81 -> 80
2022-05-22 15:42:52,878 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-FAB0D27550B0: Taking a snapshot at:(t:2, i:80) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_80
2022-05-22 15:42:52,878 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater: set stopIndex = 80
2022-05-22 15:42:52,879 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-FAB0D27550B0: Finished taking a snapshot at:(t:2, i:80) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0/sm/snapshot.2_80 took: 1 ms
2022-05-22 15:42:52,879 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater: Took a snapshot at index 80
2022-05-22 15:42:52,879 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 80
2022-05-22 15:42:52,880 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: closes. applyIndex: 80
2022-05-22 15:42:52,880 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:42:52,880 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0-SegmentedRaftLogWorker close()
2022-05-22 15:42:52,903 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:52,903 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:52,932 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:53,016 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:52,988 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #2 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=CLOSING, datanodeDetails=56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=56e641d3-eb56-493e-85a5-4bb0b1b5352d, sequenceId=78, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=1bd1ad93-a217-4aba-aed5-0a262321f6e0, sequenceId=78, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=CLOSING, datanodeDetails=e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e5a271d5-f691-48ef-8105-b2d60b002f9a, sequenceId=78, keyCount=7, bytesUsed=133}}
2022-05-22 15:42:53,017 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #3 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=1bd1ad93-a217-4aba-aed5-0a262321f6e0, sequenceId=70, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e5a271d5-f691-48ef-8105-b2d60b002f9a, sequenceId=70, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=56e641d3-eb56-493e-85a5-4bb0b1b5352d, sequenceId=70, keyCount=6, bytesUsed=114}}
2022-05-22 15:42:53,017 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has 3 sufficientlyReplicated, 0 underReplicated and 2 unhealthy containers
2022-05-22 15:42:53,017 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:53,019 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:53,019 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:52,932 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:53,019 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:53,020 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-FAB0D27550B0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:53,021 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 command on datanode e5a271d5-f691-48ef-8105-b2d60b002f9a.
2022-05-22 15:42:53,021 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: remove    LEADER e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016:t1, leader=e5a271d5-f691-48ef-8105-b2d60b002f9a, voted=e5a271d5-f691-48ef-8105-b2d60b002f9a, raftlog=e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLog:OPENED:c0, conf=0: [e5a271d5-f691-48ef-8105-b2d60b002f9a|rpc:10.1.0.29:39347|dataStream:|priority:1], old=null RUNNING
2022-05-22 15:42:53,021 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: shutdown
2022-05-22 15:42:53,021 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D3FD8A4C4016,id=e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:53,021 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-LeaderStateImpl
2022-05-22 15:42:53,021 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-PendingRequests: sendNotLeaderResponses
2022-05-22 15:42:53,022 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:42:53,022 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-D3FD8A4C4016: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016/sm/snapshot.1_0
2022-05-22 15:42:53,023 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-D3FD8A4C4016: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016/sm/snapshot.1_0 took: 1 ms
2022-05-22 15:42:53,023 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:42:53,023 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:42:53,024 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: closes. applyIndex: 0
2022-05-22 15:42:53,024 [e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:42:53,024 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:53,025 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:53,025 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016-SegmentedRaftLogWorker close()
2022-05-22 15:42:53,026 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-FAB0D27550B0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/9d6c0e09-87af-45d5-ad1c-fab0d27550b0
2022-05-22 15:42:53,026 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=9d6c0e09-87af-45d5-ad1c-fab0d27550b0 command on datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d.
2022-05-22 15:42:53,029 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - e5a271d5-f691-48ef-8105-b2d60b002f9a@group-D3FD8A4C4016: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-1/data/ratis/7643202f-040e-4a0b-8e86-d3fd8a4c4016
2022-05-22 15:42:53,029 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7643202f-040e-4a0b-8e86-d3fd8a4c4016 command on datanode e5a271d5-f691-48ef-8105-b2d60b002f9a.
2022-05-22 15:42:53,294 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #1 with BCSID 74, which is in QUASI_CLOSED state.
2022-05-22 15:42:53,294 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,294 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #2 with BCSID 78, which is in QUASI_CLOSED state.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #3 with BCSID 70, which is in QUASI_CLOSED state.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:53,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:42:53,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:53,668 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@6b285ee5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-42243-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5843165459249732266/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:53,724 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@469fc85c{HTTP/1.1, (http/1.1)}{0.0.0.0:42243}
2022-05-22 15:42:53,724 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @373103ms
2022-05-22 15:42:53,724 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:53,724 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42243
2022-05-22 15:42:53,747 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:53,747 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:53,747 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:42:53,787 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:53,792 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:53,801 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ed8d6a2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:53,802 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/meta/datanode.id
2022-05-22 15:42:53,908 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:53,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2022-05-22 15:42:53,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(362)) - Datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has entered maintenance
2022-05-22 15:42:53,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:53,979 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-05-22 15:42:53,979 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:54,047 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 137 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:54,064 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:54,065 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:54,065 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:54,065 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data-0/containers/hdds
2022-05-22 15:42:54,065 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data-0/containers/hdds
2022-05-22 15:42:54,076 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis to VolumeSet
2022-05-22 15:42:54,078 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis
2022-05-22 15:42:54,078 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis
2022-05-22 15:42:54,104 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:54,104 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:54,105 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 43935
2022-05-22 15:42:54,116 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:54,128 [IPC Server handler 17 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(487)) - Scheduling a command to update the operationalState persisted on e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2022-05-22 15:42:54,157 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start RPC server
2022-05-22 15:42:54,158 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: GrpcService started, listening on 34729
2022-05-22 15:42:54,158 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9b2d287e-9c2c-442e-b286-c4ec9a231851 is started using port 34729 for RATIS
2022-05-22 15:42:54,158 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9b2d287e-9c2c-442e-b286-c4ec9a231851 is started using port 34729 for RATIS_ADMIN
2022-05-22 15:42:54,158 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9b2d287e-9c2c-442e-b286-c4ec9a231851 is started using port 34729 for RATIS_SERVER
2022-05-22 15:42:54,158 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5cd2b293] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9b2d287e-9c2c-442e-b286-c4ec9a231851: Started
2022-05-22 15:42:54,159 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9b2d287e-9c2c-442e-b286-c4ec9a231851 is started using port 40861
2022-05-22 15:42:54,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #1 with BCSID 74, which is in QUASI_CLOSED state.
2022-05-22 15:42:54,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,295 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #1 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #2 with BCSID 78, which is in QUASI_CLOSED state.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #2 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(999)) - Force closing container #3 with BCSID 70, which is in QUASI_CLOSED state.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1408)) - Sending close container command for container #3 to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-05-22 15:42:54,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:42:54,375 [IPC Server handler 18 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:54,375 [IPC Server handler 18 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 2ad339c1-c64b-40f8-8805-fdb409c2806d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=44383, RATIS=35845, RATIS_ADMIN=35845, RATIS_SERVER=35845, STANDALONE=39607], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:54,375 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:54,388 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-05-22 15:42:54,444 [Thread-6091] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data-0/containers/hdds
2022-05-22 15:42:54,444 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=a5a54e7b-9c28-4a31-a0cb-45b626f3bac7 to datanode:2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:54,445 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: a5a54e7b-9c28-4a31-a0cb-45b626f3bac7, Nodes: 2ad339c1-c64b-40f8-8805-fdb409c2806d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=44383, RATIS=35845, RATIS_ADMIN=35845, RATIS_SERVER=35845, STANDALONE=39607], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:54.444Z[Etc/UTC]].
2022-05-22 15:42:54,445 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:54,446 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:54,446 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:54,447 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:54,451 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:54,451 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:54,451 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:54,451 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:54,451 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:54,452 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis] (custom)
2022-05-22 15:42:54,468 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:54,508 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:54,508 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:54,510 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:54,543 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:54,543 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:54,544 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:54,544 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:54,544 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:54,544 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 41417
2022-05-22 15:42:54,544 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:54,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:54,711 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,712 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,714 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 1 is closed with bcsId 74.
2022-05-22 15:42:54,796 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,796 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,840 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 1 is closed with bcsId 74.
2022-05-22 15:42:54,840 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:54,840 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:54,850 [IPC Server handler 1 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(487)) - Scheduling a command to update the operationalState persisted on e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2022-05-22 15:42:54,851 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #1 to CLOSED state, datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-05-22 15:42:54,896 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 2 is closed with bcsId 78.
2022-05-22 15:42:54,906 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:54,906 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:54,906 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:54,911 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,911 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 1 is synced with bcsId 74.
2022-05-22 15:42:54,914 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 1 is closed with bcsId 74.
2022-05-22 15:42:54,979 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:42:55,052 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@39b34b0b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:55,052 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@c0bf9c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:55,055 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:55,056 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:55,056 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:55,056 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 2 is synced with bcsId 78.
2022-05-22 15:42:55,057 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,057 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,062 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 2 is closed with bcsId 78.
2022-05-22 15:42:55,062 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,062 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,062 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 3 is closed with bcsId 70.
2022-05-22 15:42:55,176 [IPC Server handler 11 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(487)) - Scheduling a command to update the operationalState persisted on e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2022-05-22 15:42:55,176 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 2 is closed with bcsId 78.
2022-05-22 15:42:55,176 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,176 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(427)) - Container 3 is synced with bcsId 70.
2022-05-22 15:42:55,180 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #2 to CLOSED state, datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-05-22 15:42:55,180 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #3 to CLOSED state, datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-05-22 15:42:55,184 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 3 is closed with bcsId 70.
2022-05-22 15:42:55,187 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(364)) - Container 3 is closed with bcsId 70.
2022-05-22 15:42:55,206 [Listener at 0.0.0.0/38371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(359)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2022-05-22 15:42:55,206 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1441)) - Stopping Container Balancer service.
2022-05-22 15:42:55,206 [Listener at 0.0.0.0/38371] INFO  balancer.ContainerBalancer (ContainerBalancer.java:stopBalancer(923)) - Container Balancer is not running.
2022-05-22 15:42:55,206 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1448)) - Stopping Replication Manager Service.
2022-05-22 15:42:55,206 [Listener at 0.0.0.0/38371] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-05-22 15:42:55,225 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1455)) - Stopping the Datanode Admin Monitor.
2022-05-22 15:42:55,225 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1462)) - Stopping Lease Manager of the command watchers
2022-05-22 15:42:55,225 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1469)) - Stopping datanode service RPC server
2022-05-22 15:42:55,225 [Listener at 0.0.0.0/38371] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(400)) - Stopping the RPC server for DataNodes
2022-05-22 15:42:55,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-05-22 15:42:55,227 [Listener at 0.0.0.0/38371] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 33345
2022-05-22 15:42:55,309 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: addNew group-D89F05E02D54:[9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1] returns group-D89F05E02D54:java.util.concurrent.CompletableFuture@6f2c6f17[Not completed]
2022-05-22 15:42:55,310 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: new RaftServerImpl for group-D89F05E02D54:[9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: ConfigurationManager, init=-1: [9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis] (custom)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:55,311 [pool-3524-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/999c793e-8891-4f98-90d9-d89f05e02d54 does not exist. Creating ...
2022-05-22 15:42:55,332 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-05-22 15:42:55,334 [pool-3524-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/999c793e-8891-4f98-90d9-d89f05e02d54/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/999c793e-8891-4f98-90d9-d89f05e02d54 has been successfully formatted.
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-D89F05E02D54: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:55,342 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:55,343 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/999c793e-8891-4f98-90d9-d89f05e02d54
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:55,344 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 999c793e-8891-4f98-90d9-d89f05e02d54, Nodes: 9cf969b5-3654-4d78-9d8f-3cca557d6deb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37315, RATIS=38735, RATIS_ADMIN=38735, RATIS_SERVER=38735, STANDALONE=44455], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9cf969b5-3654-4d78-9d8f-3cca557d6deb, CreationTimestamp2022-05-22T15:42:52.555Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:55,344 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:55,383 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:55,390 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:55,391 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:55,391 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:55,391 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:55,391 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:55,399 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:55,402 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: start as a follower, conf=-1: [9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:55,403 [pool-3524-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState
2022-05-22 15:42:55,423 [pool-3524-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D89F05E02D54,id=9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:55,435 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=999c793e-8891-4f98-90d9-d89f05e02d54
2022-05-22 15:42:55,435 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=999c793e-8891-4f98-90d9-d89f05e02d54.
2022-05-22 15:42:55,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:42:55,472 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(236)) - Unable to communicate to SCM server at 0.0.0.0:33345 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az40-114/10.1.0.29"; destination host is: "0.0.0.0":33345; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
	at com.sun.proxy.$Proxy53.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:183)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:85)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-05-22 15:42:55,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:55,580 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(815)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-05-22 15:42:55,580 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1477)) - Stopping block service RPC server
2022-05-22 15:42:55,580 [Listener at 0.0.0.0/38371] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-05-22 15:42:55,586 [Listener at 0.0.0.0/38371] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 42521
2022-05-22 15:42:55,606 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1484)) - Stopping the StorageContainerLocationProtocol RPC server
2022-05-22 15:42:55,606 [Listener at 0.0.0.0/38371] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-05-22 15:42:55,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:42:55,611 [Listener at 0.0.0.0/38371] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 39533
2022-05-22 15:42:55,643 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5211880291ns, electionTimeout:5177ms
2022-05-22 15:42:55,643 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,643 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-05-22 15:42:55,644 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:55,644 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176
2022-05-22 15:42:55,681 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176 ELECTION round 0: submit vote requests at term 4 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:55,704 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1491)) - Stopping Storage Container Manager HTTP server.
2022-05-22 15:42:55,704 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:42:55,705 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-05-22 15:42:55,715 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-05-22 15:42:55,719 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5151797617ns, electionTimeout:5040ms
2022-05-22 15:42:55,719 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,719 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-05-22 15:42:55,719 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:42:55,719 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177
2022-05-22 15:42:55,731 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177 ELECTION round 0: submit vote requests at term 4 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:55,733 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 4, (t:0, i:0))
2022-05-22 15:42:55,733 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-CANDIDATE: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for edd315a5-4c31-41f4-a5d0-8e213ccdb1da at current term 4
2022-05-22 15:42:55,733 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t4. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t4, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:55,734 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 4, (t:0, i:0))
2022-05-22 15:42:55,734 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FOLLOWER: accept ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: our priority 0 <= candidate's priority 0
2022-05-22 15:42:55,734 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:55,734 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,734 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,734 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:42:55,746 [Listener at 0.0.0.0/38371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@68cd23ce{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:42:55,746 [Listener at 0.0.0.0/38371] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@7585c111{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:42:55,746 [Listener at 0.0.0.0/38371] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:42:55,748 [Listener at 0.0.0.0/38371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@44cb6831{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-05-22 15:42:55,817 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 4, (t:0, i:0))
2022-05-22 15:42:55,817 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-CANDIDATE: reject ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 4
2022-05-22 15:42:55,817 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t4. Peer's state: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8:t4, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:42:55,845 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:OK-t4. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t4, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:55,851 [Listener at 0.0.0.0/38371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@2c7e7de8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t4
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177 ELECTION round 0: result REJECTED
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177
2022-05-22 15:42:55,855 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection177] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,863 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 4, (t:0, i:0))
2022-05-22 15:42:55,863 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FOLLOWER: reject ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 4
2022-05-22 15:42:55,863 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t4. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t4, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:42:55,871 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:55,872 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:55,875 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 35001
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t4
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t4
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176 ELECTION round 0: result REJECTED
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176
2022-05-22 15:42:55,885 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:42:55,887 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1502)) - Stopping Block Manager Service.
2022-05-22 15:42:55,888 [Listener at 0.0.0.0/38371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:42:55,888 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:42:56,030 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start RPC server
2022-05-22 15:42:56,031 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: GrpcService started, listening on 36425
2022-05-22 15:42:56,031 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 6c03b4ed-3732-4e8d-ac40-6e00ca884577 is started using port 36425 for RATIS
2022-05-22 15:42:56,031 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 6c03b4ed-3732-4e8d-ac40-6e00ca884577 is started using port 36425 for RATIS_ADMIN
2022-05-22 15:42:56,031 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 6c03b4ed-3732-4e8d-ac40-6e00ca884577 is started using port 36425 for RATIS_SERVER
2022-05-22 15:42:56,031 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@70e690] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-6c03b4ed-3732-4e8d-ac40-6e00ca884577: Started
2022-05-22 15:42:56,065 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 6c03b4ed-3732-4e8d-ac40-6e00ca884577 is started using port 34093
2022-05-22 15:42:56,139 [Listener at 0.0.0.0/38371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:42:56,139 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1529)) - Stopping SCM Event Queue.
2022-05-22 15:42:56,223 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1540)) - Stopping SCM HA services.
2022-05-22 15:42:56,224 [Listener at 0.0.0.0/38371] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - Stopping RatisPipelineUtilsThread.
2022-05-22 15:42:56,224 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(177)) - RatisPipelineUtilsThread is interrupted.
2022-05-22 15:42:56,227 [Listener at 0.0.0.0/38371] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:stop(143)) - Stopping BackgroundPipelineScrubber Service.
2022-05-22 15:42:56,227 [PipelineScrubberThread] WARN  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:run(164)) - PipelineScrubberThread is interrupted, exit
2022-05-22 15:42:56,228 [Listener at 0.0.0.0/38371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1550)) - Stopping SCM MetadataStore.
2022-05-22 15:42:56,229 [Listener at 0.0.0.0/38371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2022-05-22 15:42:56,236 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2022-05-22 15:42:56,245 [Listener at 0.0.0.0/38371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2022-05-22 15:42:56,245 [Listener at 0.0.0.0/38371] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(160)) - ServiceID for StorageContainerManager is null
2022-05-22 15:42:56,246 [Listener at 0.0.0.0/38371] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(165)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-05-22 15:42:56,246 [Listener at 0.0.0.0/38371] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:56,246 [Listener at 0.0.0.0/38371] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:56,384 [IPC Server handler 17 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:56,384 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:56,486 [IPC Server handler 17 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9b2d287e-9c2c-442e-b286-c4ec9a231851{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43935, RATIS=34729, RATIS_ADMIN=34729, RATIS_SERVER=34729, STANDALONE=40861], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:56,487 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-05-22 15:42:56,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:56,515 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=6d3cf068-956e-427b-920e-069a5950610b to datanode:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:56,515 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 6d3cf068-956e-427b-920e-069a5950610b, Nodes: 9b2d287e-9c2c-442e-b286-c4ec9a231851{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43935, RATIS=34729, RATIS_ADMIN=34729, RATIS_SERVER=34729, STANDALONE=40861], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:56.515Z[Etc/UTC]].
2022-05-22 15:42:56,516 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=db80ca8b-95c1-4b3b-bac4-b4f3f607b559 to datanode:9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:56,516 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=db80ca8b-95c1-4b3b-bac4-b4f3f607b559 to datanode:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:56,516 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=db80ca8b-95c1-4b3b-bac4-b4f3f607b559 to datanode:2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:56,516 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: db80ca8b-95c1-4b3b-bac4-b4f3f607b559, Nodes: 9cf969b5-3654-4d78-9d8f-3cca557d6deb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37315, RATIS=38735, RATIS_ADMIN=38735, RATIS_SERVER=38735, STANDALONE=44455], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b2d287e-9c2c-442e-b286-c4ec9a231851{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43935, RATIS=34729, RATIS_ADMIN=34729, RATIS_SERVER=34729, STANDALONE=40861], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2ad339c1-c64b-40f8-8805-fdb409c2806d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=44383, RATIS=35845, RATIS_ADMIN=35845, RATIS_SERVER=35845, STANDALONE=39607], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:56.516Z[Etc/UTC]].
2022-05-22 15:42:56,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:56,657 [Listener at 0.0.0.0/38371] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 400 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:56,659 [Listener at 0.0.0.0/38371] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:56,689 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:42:56,704 [Listener at 0.0.0.0/38371] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:42:56,766 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@31f67861{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41417-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2237919158369847557/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:56,841 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1e570e83{HTTP/1.1, (http/1.1)}{0.0.0.0:41417}
2022-05-22 15:42:56,842 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @376221ms
2022-05-22 15:42:56,842 [Listener at 127.0.0.1/35755] ERROR ozone.HddsDatanodeService (HddsDatanodeService.java:start(285)) - HttpServer failed to start.
java.lang.NullPointerException: config
	at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277)
	at org.apache.hadoop.hdds.server.http.BaseHttpServer.start(BaseHttpServer.java:300)
	at org.apache.hadoop.ozone.HddsDatanodeService.start(HddsDatanodeService.java:283)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.lambda$startHddsDatanodes$4(MiniOzoneClusterImpl.java:493)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.startHddsDatanodes(MiniOzoneClusterImpl.java:491)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:616)
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:234)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:42:56,853 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:56,853 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:56,855 [Listener at 127.0.0.1/35755] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-hddsdatanode.properties,hadoop-metrics2.properties
2022-05-22 15:42:56,855 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:56,860 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2022-05-22 15:42:56,860 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - HddsDatanode metrics system started
2022-05-22 15:42:56,892 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f2f697f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:56,933 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/meta/datanode.id
2022-05-22 15:42:56,970 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2022-05-22 15:42:56,970 [Listener at 127.0.0.1/35755] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2022-05-22 15:42:56,975 [Listener at 0.0.0.0/38371] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-05-22 15:42:56,975 [Listener at 0.0.0.0/38371] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-05-22 15:42:56,977 [Listener at 0.0.0.0/38371] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:56,977 [Listener at 0.0.0.0/38371] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:42:56,977 [Listener at 0.0.0.0/38371] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-05-22 15:42:56,988 [Listener at 127.0.0.1/35755] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:42:56,991 [Listener at 0.0.0.0/38371] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(148)) - Entering startup safe mode.
2022-05-22 15:42:56,992 [Listener at 0.0.0.0/38371] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-05-22 15:42:56,993 [Listener at 0.0.0.0/38371] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-05-22 15:42:56,993 [Listener at 0.0.0.0/38371] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-05-22 15:42:56,993 [Listener at 0.0.0.0/38371] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(125)) - Starting RatisPipelineUtilsThread.
2022-05-22 15:42:56,997 [Listener at 0.0.0.0/38371] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:start(126)) - Starting BackgroundPipelineScrubber Service.
2022-05-22 15:42:56,997 [Listener at 0.0.0.0/38371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-05-22 15:42:56,997 [Listener at 0.0.0.0/38371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-05-22 15:42:56,998 [Listener at 0.0.0.0/38371] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-05-22 15:42:56,998 [Listener at 0.0.0.0/38371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-05-22 15:42:56,999 [Listener at 0.0.0.0/38371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-05-22 15:42:56,999 [Listener at 0.0.0.0/38371] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-05-22 15:42:57,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:57,108 [Listener at 0.0.0.0/38371] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2022-05-22 15:42:57,108 [Listener at 0.0.0.0/38371] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-05-22 15:42:57,108 [Listener at 0.0.0.0/38371] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-05-22 15:42:57,120 [Listener at 0.0.0.0/38371] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:57,125 [Socket Reader #1 for port 33345] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 33345
2022-05-22 15:42:57,200 [Listener at 0.0.0.0/33345] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:57,210 [Socket Reader #1 for port 42521] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 42521
2022-05-22 15:42:57,236 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:42:57,236 [Listener at 0.0.0.0/42521] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:42:57,250 [Socket Reader #1 for port 39533] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 39533
2022-05-22 15:42:57,269 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@15393c36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9cf969b5-3654-4d78-9d8f-3cca557d6deb: Detected pause in JVM or host machine (eg GC): pause of approximately 138856485ns. No GCs detected.
2022-05-22 15:42:57,285 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: addNew group-45B626F3BAC7:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:1] returns group-45B626F3BAC7:java.util.concurrent.CompletableFuture@6ca83b2e[Not completed]
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: new RaftServerImpl for group-45B626F3BAC7:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:57,292 [pool-3554-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: ConfigurationManager, init=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:57,332 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis] (custom)
2022-05-22 15:42:57,468 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:57,468 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:57,468 [pool-3554-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/a5a54e7b-9c28-4a31-a0cb-45b626f3bac7 does not exist. Creating ...
2022-05-22 15:42:57,472 [pool-3554-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/a5a54e7b-9c28-4a31-a0cb-45b626f3bac7/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:57,535 [pool-3554-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/a5a54e7b-9c28-4a31-a0cb-45b626f3bac7 has been successfully formatted.
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-45B626F3BAC7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:57,536 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:57,537 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/a5a54e7b-9c28-4a31-a0cb-45b626f3bac7
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:57,538 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:57,543 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: a5a54e7b-9c28-4a31-a0cb-45b626f3bac7, Nodes: 2ad339c1-c64b-40f8-8805-fdb409c2806d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=44383, RATIS=35845, RATIS_ADMIN=35845, RATIS_SERVER=35845, STANDALONE=39607], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2ad339c1-c64b-40f8-8805-fdb409c2806d, CreationTimestamp2022-05-22T15:42:54.444Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:57,545 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:57,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:57,554 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:57,555 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:57,555 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:57,555 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:57,555 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:57,585 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:57,608 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(399)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-05-22 15:42:57,608 [Listener at 0.0.0.0/39533] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:57,609 [Listener at 0.0.0.0/39533] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: start as a follower, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:1], old=null
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:57,627 [pool-3554-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState
2022-05-22 15:42:57,627 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1354)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39533
2022-05-22 15:42:57,628 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2022-05-22 15:42:57,653 [pool-3554-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-45B626F3BAC7,id=2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:57,670 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=a5a54e7b-9c28-4a31-a0cb-45b626f3bac7
2022-05-22 15:42:57,671 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a5a54e7b-9c28-4a31-a0cb-45b626f3bac7.
2022-05-22 15:42:57,671 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: addNew group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1] returns group-B4F3F607B559:java.util.concurrent.CompletableFuture@6897b263[Not completed]
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: new RaftServerImpl for group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: ConfigurationManager, init=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:57,672 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis] (custom)
2022-05-22 15:42:57,673 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:57,673 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:57,673 [pool-3554-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 does not exist. Creating ...
2022-05-22 15:42:57,674 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 437 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:42:57,674 [pool-3554-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:57,676 [Listener at 127.0.0.1/35755] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:42:57,681 [pool-3554-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 has been successfully formatted.
2022-05-22 15:42:57,691 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B4F3F607B559: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:57,758 [Listener at 127.0.0.1/35755] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:42:57,759 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data-0/containers/hdds to VolumeSet
2022-05-22 15:42:57,759 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data-0/containers/hdds
2022-05-22 15:42:57,758 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:57,759 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:57,760 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:57,760 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:57,760 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559
2022-05-22 15:42:57,760 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:57,761 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:57,761 [Listener at 0.0.0.0/39533] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:39533
2022-05-22 15:42:57,761 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:57,761 [IPC Server listener on 39533] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 39533: starting
2022-05-22 15:42:57,773 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1369)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42521
2022-05-22 15:42:57,773 [Listener at 0.0.0.0/39533] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:42521
2022-05-22 15:42:57,774 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:57,774 [IPC Server listener on 42521] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 42521: starting
2022-05-22 15:42:57,775 [Listener at 0.0.0.0/39533] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(183)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:33345
2022-05-22 15:42:57,799 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:42:57,807 [IPC Server listener on 33345] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 33345: starting
2022-05-22 15:42:57,809 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:39627
2022-05-22 15:42:57,809 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:57,810 [Listener at 0.0.0.0/39533] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:57,810 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@705eb026] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:57,811 [Listener at 0.0.0.0/39533] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:57,811 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:57,817 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-05-22 15:42:57,817 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:57,817 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:57,817 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 39627
2022-05-22 15:42:57,817 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:57,840 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:57,840 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:57,840 [Listener at 0.0.0.0/39533] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:57,841 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@28941a68{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:57,841 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@24fc9aa5{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:42:57,843 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@3e4ead73{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:42:57,902 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:57,903 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:57,903 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:57,903 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:57,903 [pool-3554-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:57,939 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:57,939 [Listener at 0.0.0.0/39533] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1d988297{HTTP/1.1, (http/1.1)}{0.0.0.0:39627}
2022-05-22 15:42:57,939 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(415)) - Started @377319ms
2022-05-22 15:42:57,939 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data-0/containers/hdds
2022-05-22 15:42:57,939 [Listener at 0.0.0.0/39533] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:57,943 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:39627
2022-05-22 15:42:57,943 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 0 of 6 DN Heartbeats.
2022-05-22 15:42:57,943 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:57,943 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:57,951 [Listener at 127.0.0.1/35755] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis to VolumeSet
2022-05-22 15:42:57,951 [Listener at 127.0.0.1/35755] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis
2022-05-22 15:42:57,951 [Listener at 127.0.0.1/35755] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:58,001 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:58,007 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:42:58,024 [IPC Server handler 5 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,024 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,024 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,024 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,024 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,024 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: start as a follower, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:42:58,065 [pool-3554-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:58,067 [pool-3554-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:42:58,071 [pool-3554-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4F3F607B559,id=2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:42:58,074 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=db80ca8b-95c1-4b3b-bac4-b4f3f607b559
2022-05-22 15:42:58,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:58,113 [IPC Server handler 2 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:42:58,113 [IPC Server handler 2 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 6c03b4ed-3732-4e8d-ac40-6e00ca884577{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35001, RATIS=36425, RATIS_ADMIN=36425, RATIS_SERVER=36425, STANDALONE=34093], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:58,113 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:58,196 [Thread-6209] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data-0/containers/hdds
2022-05-22 15:42:58,196 [Listener at 127.0.0.1/35755] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:42:58,197 [Listener at 127.0.0.1/35755] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:42:58,197 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:42:58,197 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:42:58,201 [IPC Server handler 6 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,202 [IPC Server handler 7 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,203 [IPC Server handler 8 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,203 [IPC Server handler 9 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,204 [IPC Server handler 10 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,204 [IPC Server handler 11 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,205 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,205 [IPC Server handler 13 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,206 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,207 [IPC Server handler 15 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,207 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=58320827-1fba-4fed-a122-827cad3c4215 to datanode:6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:42:58,207 [IPC Server handler 16 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:42:58,207 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 58320827-1fba-4fed-a122-827cad3c4215, Nodes: 6c03b4ed-3732-4e8d-ac40-6e00ca884577{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35001, RATIS=36425, RATIS_ADMIN=36425, RATIS_SERVER=36425, STANDALONE=34093], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:42:58.207Z[Etc/UTC]].
2022-05-22 15:42:58,211 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: addNew group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1] returns group-B4F3F607B559:java.util.concurrent.CompletableFuture@5b7c55d8[Not completed]
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: new RaftServerImpl for group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:58,212 [pool-3524-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: ConfigurationManager, init=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:58,213 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis] (custom)
2022-05-22 15:42:58,213 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:58,213 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:58,213 [pool-3524-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 does not exist. Creating ...
2022-05-22 15:42:58,214 [pool-3524-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:58,218 [pool-3524-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 has been successfully formatted.
2022-05-22 15:42:58,218 [pool-3524-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B4F3F607B559: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:58,219 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:58,220 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:58,221 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:58,221 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:58,221 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:58,221 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:58,223 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:58,231 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:42:58,231 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:42:58,250 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:42:58,250 [Listener at 127.0.0.1/35755] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:58,251 [Listener at 127.0.0.1/35755] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis] (custom)
2022-05-22 15:42:58,268 [Listener at 127.0.0.1/35755] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:42:58,316 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:42:58,316 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:42:58,317 [Listener at 127.0.0.1/35755] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:42:58,343 [Listener at 127.0.0.1/35755] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:42:58,344 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:42:58,344 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:42:58,344 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:42:58,344 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:42:58,345 [Listener at 127.0.0.1/35755] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 40661
2022-05-22 15:42:58,345 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:42:58,404 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:42:58,404 [Listener at 127.0.0.1/35755] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:42:58,404 [Listener at 127.0.0.1/35755] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:42:58,405 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@b8f7155{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:42:58,405 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@772fb7ec{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:42:58,444 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:58,444 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:58,445 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:58,447 [IPC Server handler 17 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:42:58,447 [IPC Server handler 17 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:58,451 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2022-05-22 15:42:58,451 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-05-22 15:42:58,451 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: start as a follower, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:58,493 [pool-3524-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:42:58,535 [pool-3524-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4F3F607B559,id=9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:42:58,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:58,562 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:58,562 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-05-22 15:42:58,588 [IPC Server handler 18 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:42:58,588 [IPC Server handler 18 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:58,589 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:58,592 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-05-22 15:42:58,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:58,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:58,615 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: addNew group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1] returns group-B4F3F607B559:java.util.concurrent.CompletableFuture@7d4010f2[Not completed]
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: new RaftServerImpl for group-B4F3F607B559:[2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: ConfigurationManager, init=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis] (custom)
2022-05-22 15:42:58,625 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:58,626 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:58,631 [pool-3576-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 does not exist. Creating ...
2022-05-22 15:42:58,632 [pool-3576-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:58,639 [pool-3576-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559 has been successfully formatted.
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B4F3F607B559: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:58,640 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:58,641 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:58,642 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:58,642 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:58,642 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:58,642 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:58,642 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:58,645 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:58,646 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:58,646 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:58,646 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:58,646 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:58,647 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:58,650 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: start as a follower, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:42:58,651 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:58,651 [pool-3576-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:42:58,651 [pool-3576-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4F3F607B559,id=9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:58,658 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=db80ca8b-95c1-4b3b-bac4-b4f3f607b559.
2022-05-22 15:42:58,699 [IPC Server handler 19 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:42:58,699 [IPC Server handler 19 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:58,699 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-05-22 15:42:58,700 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:58,700 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:58,759 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:58,918 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:42:58,918 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:42:58,923 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37203
2022-05-22 15:42:58,943 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 3 of 6 DN Heartbeats.
2022-05-22 15:42:58,944 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:58,944 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:58,978 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:42:59,007 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start RPC server
2022-05-22 15:42:59,007 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: GrpcService started, listening on 36589
2022-05-22 15:42:59,018 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9f373e4e-4e35-4a2f-a705-a71ce933fdce is started using port 36589 for RATIS
2022-05-22 15:42:59,018 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9f373e4e-4e35-4a2f-a705-a71ce933fdce is started using port 36589 for RATIS_ADMIN
2022-05-22 15:42:59,018 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9f373e4e-4e35-4a2f-a705-a71ce933fdce is started using port 36589 for RATIS_SERVER
2022-05-22 15:42:59,025 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@615bc59d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9f373e4e-4e35-4a2f-a705-a71ce933fdce: Started
2022-05-22 15:42:59,027 [IPC Server handler 5 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:42:59,027 [IPC Server handler 5 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:59,027 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9f373e4e-4e35-4a2f-a705-a71ce933fdce is started using port 34243
2022-05-22 15:42:59,031 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:59,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,084 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: addNew group-069A5950610B:[9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:1] returns group-069A5950610B:java.util.concurrent.CompletableFuture@597f9673[Not completed]
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: new RaftServerImpl for group-069A5950610B:[9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: ConfigurationManager, init=-1: [9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis] (custom)
2022-05-22 15:42:59,086 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:42:59,087 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:42:59,087 [pool-3576-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/6d3cf068-956e-427b-920e-069a5950610b does not exist. Creating ...
2022-05-22 15:42:59,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:59,095 [pool-3576-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/6d3cf068-956e-427b-920e-069a5950610b/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:42:59,098 [pool-3576-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/6d3cf068-956e-427b-920e-069a5950610b has been successfully formatted.
2022-05-22 15:42:59,098 [pool-3576-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-069A5950610B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:42:59,098 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:42:59,099 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:42:59,099 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:42:59,099 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:42:59,099 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:42:59,099 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/6d3cf068-956e-427b-920e-069a5950610b
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:42:59,100 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:42:59,101 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:42:59,101 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:42:59,101 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:42:59,103 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:42:59,106 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:42:59,106 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:42:59,106 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:59,106 [pool-3576-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:42:59,112 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 6d3cf068-956e-427b-920e-069a5950610b, Nodes: 9b2d287e-9c2c-442e-b286-c4ec9a231851{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43935, RATIS=34729, RATIS_ADMIN=34729, RATIS_SERVER=34729, STANDALONE=40861], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b2d287e-9c2c-442e-b286-c4ec9a231851, CreationTimestamp2022-05-22T15:42:56.515Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:42:59,113 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,179 [IPC Server handler 6 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:42:59,181 [IPC Server handler 6 on default port 33345] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(325)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2022-05-22 15:42:59,181 [IPC Server handler 6 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:59,181 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:59,181 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(262)) - Continue admin for datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:59,205 [IPC Server handler 12 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:42:59,205 [IPC Server handler 12 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:42:59,209 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:42:59,212 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: start as a follower, conf=-1: [9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:1], old=null
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:42:59,213 [pool-3576-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState
2022-05-22 15:42:59,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,248 [Listener at 127.0.0.1/35755] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4fe45896{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40661-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5892665403417041746/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:42:59,289 [pool-3576-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-069A5950610B,id=9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:42:59,348 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:42:59,424 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,489 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,489 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=6d3cf068-956e-427b-920e-069a5950610b
2022-05-22 15:42:59,489 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=6d3cf068-956e-427b-920e-069a5950610b.
2022-05-22 15:42:59,503 [Listener at 127.0.0.1/35755] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@278b013d{HTTP/1.1, (http/1.1)}{0.0.0.0:40661}
2022-05-22 15:42:59,504 [Listener at 127.0.0.1/35755] INFO  server.Server (Server.java:doStart(415)) - Started @378883ms
2022-05-22 15:42:59,504 [Listener at 127.0.0.1/35755] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:42:59,520 [Listener at 127.0.0.1/35755] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40661
2022-05-22 15:42:59,528 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-05-22 15:42:59,528 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:59,528 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:42:59,543 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:42:59,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:42:59,626 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,665 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cd272cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:42:59,699 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,764 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:42:59,774 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/meta/datanode.id
2022-05-22 15:42:59,944 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:42:59,944 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:42:59,944 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:00,035 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:00,113 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:00,133 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(56)) - Admin start on datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Finalizing its pipelines []
2022-05-22 15:43:00,196 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,529 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5126524745ns, electionTimeout:5097ms
2022-05-22 15:43:00,530 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState
2022-05-22 15:43:00,530 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:00,530 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:00,530 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178
2022-05-22 15:43:00,530 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-05-22 15:43:00,530 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:00,530 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:00,542 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178 ELECTION round 0: submit vote requests at term 1 for -1: [9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:00,542 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:00,542 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178
2022-05-22 15:43:00,542 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:00,542 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-D89F05E02D54 with new leaderId: 9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:00,550 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,551 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: change Leader from null to 9cf969b5-3654-4d78-9d8f-3cca557d6deb at term 1 for becomeLeader, leader elected after 5199ms
2022-05-22 15:43:00,551 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:00,551 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:00,551 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:00,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:00,552 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderStateImpl
2022-05-22 15:43:00,553 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:00,556 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/999c793e-8891-4f98-90d9-d89f05e02d54/current/log_inprogress_0
2022-05-22 15:43:00,625 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,655 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54-LeaderElection178] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-D89F05E02D54: set configuration 0: [9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:00,789 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,808 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: addNew group-827CAD3C4215:[6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:1] returns group-827CAD3C4215:java.util.concurrent.CompletableFuture@28e84bb4[Not completed]
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: new RaftServerImpl for group-827CAD3C4215:[6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: ConfigurationManager, init=-1: [6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis] (custom)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:00,809 [pool-3598-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/58320827-1fba-4fed-a122-827cad3c4215 does not exist. Creating ...
2022-05-22 15:43:00,816 [pool-3598-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/58320827-1fba-4fed-a122-827cad3c4215/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:00,830 [pool-3598-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/58320827-1fba-4fed-a122-827cad3c4215 has been successfully formatted.
2022-05-22 15:43:00,830 [pool-3598-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-827CAD3C4215: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:00,831 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 58320827-1fba-4fed-a122-827cad3c4215, Nodes: 6c03b4ed-3732-4e8d-ac40-6e00ca884577{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35001, RATIS=36425, RATIS_ADMIN=36425, RATIS_SERVER=36425, STANDALONE=34093], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6c03b4ed-3732-4e8d-ac40-6e00ca884577, CreationTimestamp2022-05-22T15:42:58.207Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:00,832 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:00,834 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:00,834 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:00,836 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:00,836 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:00,836 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:00,836 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/58320827-1fba-4fed-a122-827cad3c4215
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:00,838 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:00,849 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:00,849 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:00,849 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:00,849 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:00,849 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:00,868 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: start as a follower, conf=-1: [6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:1], old=null
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:00,877 [pool-3598-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState
2022-05-22 15:43:00,916 [pool-3598-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-827CAD3C4215,id=6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:43:00,917 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=58320827-1fba-4fed-a122-827cad3c4215
2022-05-22 15:43:00,917 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=58320827-1fba-4fed-a122-827cad3c4215.
2022-05-22 15:43:00,921 [IPC Server handler 10 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:00,921 [IPC Server handler 10 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9f373e4e-4e35-4a2f-a705-a71ce933fdce{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37203, RATIS=36589, RATIS_ADMIN=36589, RATIS_SERVER=36589, STANDALONE=34243], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:00,923 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:00,924 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=8a0bb07d-1309-41bc-b463-953a2fab94dd to datanode:9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:00,924 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 8a0bb07d-1309-41bc-b463-953a2fab94dd, Nodes: 9f373e4e-4e35-4a2f-a705-a71ce933fdce{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37203, RATIS=36589, RATIS_ADMIN=36589, RATIS_SERVER=36589, STANDALONE=34243], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:00.924Z[Etc/UTC]].
2022-05-22 15:43:00,955 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:00,956 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:00,956 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:01,030 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:01,043 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5157882831ns, electionTimeout:5143ms
2022-05-22 15:43:01,043 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:01,044 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-05-22 15:43:01,044 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:01,044 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179
2022-05-22 15:43:01,050 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5195204210ns, electionTimeout:5092ms
2022-05-22 15:43:01,050 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:01,050 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-05-22 15:43:01,071 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:01,071 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180
2022-05-22 15:43:01,073 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179 ELECTION round 0: submit vote requests at term 5 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,083 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 5, (t:0, i:0))
2022-05-22 15:43:01,084 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, edd315a5-4c31-41f4-a5d0-8e213ccdb1da, group-9E28C69A43E8, 5, (t:0, i:0))
2022-05-22 15:43:01,084 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FOLLOWER: accept ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: our priority 0 <= candidate's priority 1
2022-05-22 15:43:01,084 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:01,084 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:01,085 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c72cb747-71cd-49bf-9573-30515b8c4828: start c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:01,085 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:43:01,085 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180 ELECTION round 0: submit vote requests at term 5 for -1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:01,087 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-CANDIDATE: reject ELECTION from edd315a5-4c31-41f4-a5d0-8e213ccdb1da: already has voted for a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa at current term 5
2022-05-22 15:43:01,087 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t5. Peer's state: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8:t5, leader=null, voted=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, raftlog=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,093 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:OK-t5. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t5, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:43:01,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:01,109 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 5, (t:0, i:0))
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FOLLOWER: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for edd315a5-4c31-41f4-a5d0-8e213ccdb1da at current term 5
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-c72cb747-71cd-49bf-9573-30515b8c4828#0:FAIL-t5. Peer's state: c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t5, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|priority:0], old=null
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: receive requestVote(ELECTION, a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, group-9E28C69A43E8, 5, (t:0, i:0))
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-CANDIDATE: reject ELECTION from a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: already has voted for edd315a5-4c31-41f4-a5d0-8e213ccdb1da at current term 5
2022-05-22 15:43:01,115 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8 replies to ELECTION vote request: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t5. Peer's state: edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8:t5, leader=null, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c-1, conf=-1: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179: ELECTION PASSED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#0:FAIL-t5
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: edd315a5-4c31-41f4-a5d0-8e213ccdb1da<-c72cb747-71cd-49bf-9573-30515b8c4828#0:OK-t5
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179 ELECTION round 0: result PASSED
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9E28C69A43E8 with new leaderId: edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: change Leader from null to edd315a5-4c31-41f4-a5d0-8e213ccdb1da at term 5 for becomeLeader, leader elected after 26876ms
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:01,116 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:01,117 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:01,120 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa<-edd315a5-4c31-41f4-a5d0-8e213ccdb1da#0:FAIL-t5
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180 ELECTION round 0: result REJECTED
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180
2022-05-22 15:43:01,120 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-LeaderElection180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: start a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:01,121 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:01,121 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:01,121 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: d451f14d-141e-4bf0-bcdf-9e28c69a43e8, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:42:56.993Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(251)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:notifyStatusChanged(88)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-05-22 15:43:01,122 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-05-22 15:43:01,138 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:01,138 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:01,138 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:01,141 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: start edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderStateImpl
2022-05-22 15:43:01,142 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:01,146 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/current/log_inprogress_0
2022-05-22 15:43:01,184 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderElection179] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: set configuration 0: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,216 [c72cb747-71cd-49bf-9573-30515b8c4828-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9E28C69A43E8 with new leaderId: edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:01,216 [c72cb747-71cd-49bf-9573-30515b8c4828-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: change Leader from null to edd315a5-4c31-41f4-a5d0-8e213ccdb1da at term 5 for appendEntries, leader elected after 27291ms
2022-05-22 15:43:01,231 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9E28C69A43E8 with new leaderId: edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:01,231 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: change Leader from null to edd315a5-4c31-41f4-a5d0-8e213ccdb1da at term 5 for appendEntries, leader elected after 27223ms
2022-05-22 15:43:01,258 [c72cb747-71cd-49bf-9573-30515b8c4828-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: set configuration 0: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,258 [c72cb747-71cd-49bf-9573-30515b8c4828-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:01,263 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/current/log_inprogress_0
2022-05-22 15:43:01,418 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: set configuration 0: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null
2022-05-22 15:43:01,418 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:01,437 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/current/log_inprogress_0
2022-05-22 15:43:01,531 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:01,531 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:01,531 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:01,543 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:01,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:01,702 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:01,702 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:01,706 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 45631
2022-05-22 15:43:01,718 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:01,799 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start RPC server
2022-05-22 15:43:01,800 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: GrpcService started, listening on 45847
2022-05-22 15:43:01,815 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9dd8a712-1e0d-4857-830c-d22a0163750c is started using port 45847 for RATIS
2022-05-22 15:43:01,815 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9dd8a712-1e0d-4857-830c-d22a0163750c is started using port 45847 for RATIS_ADMIN
2022-05-22 15:43:01,815 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9dd8a712-1e0d-4857-830c-d22a0163750c is started using port 45847 for RATIS_SERVER
2022-05-22 15:43:01,815 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@7fb68a11] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9dd8a712-1e0d-4857-830c-d22a0163750c: Started
2022-05-22 15:43:01,842 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:01,842 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:01,852 [EndpointStateMachine task thread for /0.0.0.0:35219 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9dd8a712-1e0d-4857-830c-d22a0163750c is started using port 33359
2022-05-22 15:43:01,959 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:01,960 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Cluster exits safe mode
2022-05-22 15:43:01,960 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:02,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:02,111 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:02,120 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:02,533 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:02,533 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:02,533 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:02,548 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:02,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:02,730 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103233380ns, electionTimeout:5076ms
2022-05-22 15:43:02,731 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState
2022-05-22 15:43:02,731 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:02,731 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:02,731 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181 ELECTION round 0: submit vote requests at term 1 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:1], old=null
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-45B626F3BAC7 with new leaderId: 2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: change Leader from null to 2ad339c1-c64b-40f8-8805-fdb409c2806d at term 1 for becomeLeader, leader elected after 5259ms
2022-05-22 15:43:02,795 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:02,796 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:02,801 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:02,801 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:02,802 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:02,802 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:02,802 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:02,802 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:02,802 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:02,817 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderStateImpl
2022-05-22 15:43:02,818 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:02,823 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/a5a54e7b-9c28-4a31-a0cb-45b626f3bac7/current/log_inprogress_0
2022-05-22 15:43:02,839 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7-LeaderElection181] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-45B626F3BAC7: set configuration 0: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:1], old=null
2022-05-22 15:43:03,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:03,110 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:03,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:03,179 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113848802ns, electionTimeout:5104ms
2022-05-22 15:43:03,179 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,179 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:03,180 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:03,180 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182
2022-05-22 15:43:03,194 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182 ELECTION round 0: submit vote requests at term 1 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:03,205 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: receive requestVote(ELECTION, 2ad339c1-c64b-40f8-8805-fdb409c2806d, group-B4F3F607B559, 1, (t:0, i:0))
2022-05-22 15:43:03,205 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FOLLOWER: accept ELECTION from 2ad339c1-c64b-40f8-8805-fdb409c2806d: our priority 0 <= candidate's priority 0
2022-05-22 15:43:03,205 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:43:03,205 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,205 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,205 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:03,232 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559 replies to ELECTION vote request: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:OK-t1. Peer's state: 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559:t1, leader=null, voted=2ad339c1-c64b-40f8-8805-fdb409c2806d, raftlog=9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:03,392 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: receive requestVote(ELECTION, 2ad339c1-c64b-40f8-8805-fdb409c2806d, group-B4F3F607B559, 1, (t:0, i:0))
2022-05-22 15:43:03,393 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FOLLOWER: reject ELECTION from 2ad339c1-c64b-40f8-8805-fdb409c2806d: our priority 1 > candidate's priority 0
2022-05-22 15:43:03,393 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2ad339c1-c64b-40f8-8805-fdb409c2806d
2022-05-22 15:43:03,393 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,393 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,393 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:03,404 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559 replies to ELECTION vote request: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t1. Peer's state: 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559:t1, leader=null, voted=null, raftlog=9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:OK-t1
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t1
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182 ELECTION round 0: result REJECTED
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182
2022-05-22 15:43:03,426 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:03,536 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:03,536 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:03,536 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:03,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:03,672 [IPC Server handler 12 on default port 35219] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:03,672 [IPC Server handler 12 on default port 35219] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9dd8a712-1e0d-4857-830c-d22a0163750c{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45631, RATIS=45847, RATIS_ADMIN=45847, RATIS_SERVER=45847, STANDALONE=33359], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:03,672 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:03,676 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=b14c07ff-b372-4976-948e-966685eacf86 to datanode:9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:03,676 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: b14c07ff-b372-4976-948e-966685eacf86, Nodes: 9dd8a712-1e0d-4857-830c-d22a0163750c{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45631, RATIS=45847, RATIS_ADMIN=45847, RATIS_SERVER=45847, STANDALONE=33359], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:03.675Z[Etc/UTC]].
2022-05-22 15:43:03,676 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=484a336d-2899-4279-b113-6603db1e3033 to datanode:9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:03,676 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=484a336d-2899-4279-b113-6603db1e3033 to datanode:9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:03,676 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=484a336d-2899-4279-b113-6603db1e3033 to datanode:6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:43:03,677 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 484a336d-2899-4279-b113-6603db1e3033, Nodes: 9dd8a712-1e0d-4857-830c-d22a0163750c{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45631, RATIS=45847, RATIS_ADMIN=45847, RATIS_SERVER=45847, STANDALONE=33359], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9f373e4e-4e35-4a2f-a705-a71ce933fdce{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37203, RATIS=36589, RATIS_ADMIN=36589, RATIS_SERVER=36589, STANDALONE=34243], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6c03b4ed-3732-4e8d-ac40-6e00ca884577{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35001, RATIS=36425, RATIS_ADMIN=36425, RATIS_SERVER=36425, STANDALONE=34093], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:03.676Z[Etc/UTC]].
2022-05-22 15:43:03,834 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:03,895 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: addNew group-953A2FAB94DD:[9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1] returns group-953A2FAB94DD:java.util.concurrent.CompletableFuture@4a75c045[Not completed]
2022-05-22 15:43:03,916 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: new RaftServerImpl for group-953A2FAB94DD:[9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:03,916 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:03,916 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:03,916 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:03,916 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: ConfigurationManager, init=-1: [9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis] (custom)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:03,917 [pool-3620-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/8a0bb07d-1309-41bc-b463-953a2fab94dd does not exist. Creating ...
2022-05-22 15:43:03,963 [pool-3620-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/8a0bb07d-1309-41bc-b463-953a2fab94dd/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:03,973 [pool-3620-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/8a0bb07d-1309-41bc-b463-953a2fab94dd has been successfully formatted.
2022-05-22 15:43:03,973 [pool-3620-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-953A2FAB94DD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:03,974 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 8a0bb07d-1309-41bc-b463-953a2fab94dd, Nodes: 9f373e4e-4e35-4a2f-a705-a71ce933fdce{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37203, RATIS=36589, RATIS_ADMIN=36589, RATIS_SERVER=36589, STANDALONE=34243], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9f373e4e-4e35-4a2f-a705-a71ce933fdce, CreationTimestamp2022-05-22T15:43:00.924Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:03,974 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:03,974 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:03,974 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:03,974 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:03,974 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:03,974 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:03,975 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/8a0bb07d-1309-41bc-b463-953a2fab94dd
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:03,976 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:03,985 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: start as a follower, conf=-1: [9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1], old=null
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState
2022-05-22 15:43:03,989 [pool-3620-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-953A2FAB94DD,id=9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:03,991 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=8a0bb07d-1309-41bc-b463-953a2fab94dd
2022-05-22 15:43:03,991 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=8a0bb07d-1309-41bc-b463-953a2fab94dd.
2022-05-22 15:43:03,991 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: addNew group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0] returns group-6603DB1E3033:java.util.concurrent.CompletableFuture@4e4a5dd3[Not completed]
2022-05-22 15:43:03,991 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: new RaftServerImpl for group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: ConfigurationManager, init=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis] (custom)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:03,992 [pool-3620-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/484a336d-2899-4279-b113-6603db1e3033 does not exist. Creating ...
2022-05-22 15:43:03,993 [pool-3620-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/484a336d-2899-4279-b113-6603db1e3033/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/484a336d-2899-4279-b113-6603db1e3033 has been successfully formatted.
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-6603DB1E3033: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:03,994 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:04,004 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:04,007 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/484a336d-2899-4279-b113-6603db1e3033
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:04,009 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:04,012 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:04,012 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:04,012 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:04,028 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:04,029 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: start as a follower, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0], old=null
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState
2022-05-22 15:43:04,033 [pool-3620-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6603DB1E3033,id=9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:04,061 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=484a336d-2899-4279-b113-6603db1e3033
2022-05-22 15:43:04,076 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: addNew group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0] returns group-6603DB1E3033:java.util.concurrent.CompletableFuture@1fbeaf75[Not completed]
2022-05-22 15:43:04,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:04,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: new RaftServerImpl for group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: ConfigurationManager, init=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis] (custom)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:04,156 [pool-3673-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/484a336d-2899-4279-b113-6603db1e3033 does not exist. Creating ...
2022-05-22 15:43:04,157 [pool-3673-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/484a336d-2899-4279-b113-6603db1e3033/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:04,163 [pool-3673-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/484a336d-2899-4279-b113-6603db1e3033 has been successfully formatted.
2022-05-22 15:43:04,163 [pool-3673-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-6603DB1E3033: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:04,164 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:04,164 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:04,164 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:04,164 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:04,164 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:04,165 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/484a336d-2899-4279-b113-6603db1e3033
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:04,166 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:04,169 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:04,170 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:04,170 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:04,174 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,174 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:04,197 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: start as a follower, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:04,203 [pool-3673-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState
2022-05-22 15:43:04,204 [pool-3673-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6603DB1E3033,id=9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:04,223 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: addNew group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0] returns group-6603DB1E3033:java.util.concurrent.CompletableFuture@2056cc64[Not completed]
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: new RaftServerImpl for group-6603DB1E3033:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: ConfigurationManager, init=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis] (custom)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:04,224 [pool-3598-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/484a336d-2899-4279-b113-6603db1e3033 does not exist. Creating ...
2022-05-22 15:43:04,227 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines []
2022-05-22 15:43:04,231 [pool-3598-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/484a336d-2899-4279-b113-6603db1e3033/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/484a336d-2899-4279-b113-6603db1e3033 has been successfully formatted.
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-6603DB1E3033: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:04,274 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:04,275 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,276 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:04,276 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:04,276 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/484a336d-2899-4279-b113-6603db1e3033
2022-05-22 15:43:04,276 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:04,276 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:04,277 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:04,277 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:04,300 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:04,300 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:04,300 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:04,300 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,301 [pool-3598-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:04,316 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:04,405 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5191858764ns, electionTimeout:5113ms
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: start as a follower, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:04,451 [pool-3598-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FollowerState
2022-05-22 15:43:04,451 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState
2022-05-22 15:43:04,451 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:04,458 [pool-3598-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6603DB1E3033,id=6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:43:04,475 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:04,475 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183
2022-05-22 15:43:04,487 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=484a336d-2899-4279-b113-6603db1e3033.
2022-05-22 15:43:04,531 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183 ELECTION round 0: submit vote requests at term 1 for -1: [9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:1], old=null
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-069A5950610B with new leaderId: 9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: change Leader from null to 9b2d287e-9c2c-442e-b286-c4ec9a231851 at term 1 for becomeLeader, leader elected after 5433ms
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:04,532 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:04,533 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderStateImpl
2022-05-22 15:43:04,534 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:04,537 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:04,537 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:04,537 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:04,537 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-LeaderElection183] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B: set configuration 0: [9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:1], old=null
2022-05-22 15:43:04,550 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:04,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:04,604 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-069A5950610B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/6d3cf068-956e-427b-920e-069a5950610b/current/log_inprogress_0
2022-05-22 15:43:04,606 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:04,667 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: addNew group-966685EACF86:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:1] returns group-966685EACF86:java.util.concurrent.CompletableFuture@ef602c5[Not completed]
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: new RaftServerImpl for group-966685EACF86:[9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: ConfigurationManager, init=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis] (custom)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:04,672 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:04,673 [pool-3673-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/b14c07ff-b372-4976-948e-966685eacf86 does not exist. Creating ...
2022-05-22 15:43:04,676 [pool-3673-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/b14c07ff-b372-4976-948e-966685eacf86/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:04,679 [pool-3673-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/b14c07ff-b372-4976-948e-966685eacf86 has been successfully formatted.
2022-05-22 15:43:04,679 [pool-3673-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-966685EACF86: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:04,679 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:04,686 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:04,686 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:04,686 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:04,689 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:04,689 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,690 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:04,690 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:04,690 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/b14c07ff-b372-4976-948e-966685eacf86
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:04,691 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:04,684 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: b14c07ff-b372-4976-948e-966685eacf86, Nodes: 9dd8a712-1e0d-4857-830c-d22a0163750c{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45631, RATIS=45847, RATIS_ADMIN=45847, RATIS_SERVER=45847, STANDALONE=33359], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9dd8a712-1e0d-4857-830c-d22a0163750c, CreationTimestamp2022-05-22T15:43:03.675Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:04,692 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:04,722 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:04,722 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:04,722 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:04,722 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,722 [pool-3673-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:04,728 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: start as a follower, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:1], old=null
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:04,738 [pool-3673-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState
2022-05-22 15:43:04,766 [pool-3673-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-966685EACF86,id=9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:04,771 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=b14c07ff-b372-4976-948e-966685eacf86
2022-05-22 15:43:04,771 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=b14c07ff-b372-4976-948e-966685eacf86.
2022-05-22 15:43:04,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:05,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:05,111 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:05,279 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:05,538 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:05,538 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:05,538 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:05,551 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:05,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:05,610 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:05,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:05,995 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,071 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194249944ns, electionTimeout:5150ms
2022-05-22 15:43:06,072 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: shutdown 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState
2022-05-22 15:43:06,072 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:06,072 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:06,072 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184 ELECTION round 0: submit vote requests at term 1 for -1: [6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:1], old=null
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: shutdown 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-827CAD3C4215 with new leaderId: 6c03b4ed-3732-4e8d-ac40-6e00ca884577
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: change Leader from null to 6c03b4ed-3732-4e8d-ac40-6e00ca884577 at term 1 for becomeLeader, leader elected after 5252ms
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:06,087 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:06,088 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderStateImpl
2022-05-22 15:43:06,089 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:06,096 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-LeaderElection184] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215: set configuration 0: [6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:1], old=null
2022-05-22 15:43:06,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:06,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:06,177 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-827CAD3C4215-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/58320827-1fba-4fed-a122-827cad3c4215/current/log_inprogress_0
2022-05-22 15:43:06,181 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,539 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:06,539 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:06,539 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:06,552 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:06,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:06,998 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:07,041 [Listener at 0.0.0.0/39533] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:07,044 [Listener at 0.0.0.0/39533] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: close
2022-05-22 15:43:07,044 [Listener at 0.0.0.0/39533] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown server with port 39347 now
2022-05-22 15:43:07,050 [Listener at 0.0.0.0/39533] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - e5a271d5-f691-48ef-8105-b2d60b002f9a: shutdown server with port 39347 successfully
2022-05-22 15:43:07,111 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:07,124 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@729c8021] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-e5a271d5-f691-48ef-8105-b2d60b002f9a: Stopped
2022-05-22 15:43:07,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:07,178 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:07,223 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. e5a271d5-f691-48ef-8105-b2d60b002f9a{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39419, RATIS=39347, RATIS_ADMIN=39347, RATIS_SERVER=39347, STANDALONE=37173], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:07,223 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/e5a271d5-f691-48ef-8105-b2d60b002f9a
2022-05-22 15:43:07,539 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:07,540 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:07,540 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:07,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:07,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:07,997 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:08,112 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:08,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:08,189 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:08,460 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5228377607ns, electionTimeout:5074ms
2022-05-22 15:43:08,461 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,461 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-05-22 15:43:08,461 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:08,461 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185
2022-05-22 15:43:08,473 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185 ELECTION round 0: submit vote requests at term 2 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:08,511 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 2, (t:0, i:0))
2022-05-22 15:43:08,511 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FOLLOWER: accept ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: our priority 0 <= candidate's priority 0
2022-05-22 15:43:08,511 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:43:08,511 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,523 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,523 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:08,526 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 2, (t:0, i:0))
2022-05-22 15:43:08,526 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FOLLOWER: reject ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: our priority 1 > candidate's priority 0
2022-05-22 15:43:08,526 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:43:08,526 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,527 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,527 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:08,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:08,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:08,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:08,548 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:08,548 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t2. Peer's state: 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559:t2, leader=null, voted=9b2d287e-9c2c-442e-b286-c4ec9a231851, raftlog=2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:08,549 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t2. Peer's state: 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559:t2, leader=null, voted=null, raftlog=9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t2
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t2
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185 ELECTION round 0: result REJECTED
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185
2022-05-22 15:43:08,550 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:08,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:08,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:08,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:09,039 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5049513405ns, electionTimeout:5048ms
2022-05-22 15:43:09,039 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: shutdown 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState
2022-05-22 15:43:09,039 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:09,039 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:09,039 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186 ELECTION round 0: submit vote requests at term 1 for -1: [9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1], old=null
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: shutdown 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-953A2FAB94DD with new leaderId: 9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: change Leader from null to 9f373e4e-4e35-4a2f-a705-a71ce933fdce at term 1 for becomeLeader, leader elected after 5075ms
2022-05-22 15:43:09,050 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:09,051 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,051 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:09,082 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderStateImpl
2022-05-22 15:43:09,083 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:09,091 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/8a0bb07d-1309-41bc-b463-953a2fab94dd/current/log_inprogress_0
2022-05-22 15:43:09,102 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD-LeaderElection186] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-953A2FAB94DD: set configuration 0: [9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1], old=null
2022-05-22 15:43:09,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:09,133 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:09,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:09,158 [Listener at 0.0.0.0/39533] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:09,208 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5175214606ns, electionTimeout:5132ms
2022-05-22 15:43:09,209 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: shutdown 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState
2022-05-22 15:43:09,209 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:09,209 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:09,209 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187
2022-05-22 15:43:09,267 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5a871eae] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 121755722ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=34ms
2022-05-22 15:43:09,267 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@40493c39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-c72cb747-71cd-49bf-9573-30515b8c4828: Detected pause in JVM or host machine (eg GC): pause of approximately 121900223ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=34ms
2022-05-22 15:43:09,303 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187 ELECTION round 0: submit vote requests at term 1 for -1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0], old=null
2022-05-22 15:43:09,387 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184176314ns, electionTimeout:5179ms
2022-05-22 15:43:09,387 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: shutdown 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState
2022-05-22 15:43:09,388 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:09,388 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:09,388 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188
2022-05-22 15:43:09,431 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188 ELECTION round 0: submit vote requests at term 1 for -1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,537 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: receive requestVote(ELECTION, 9f373e4e-4e35-4a2f-a705-a71ce933fdce, group-6603DB1E3033, 1, (t:0, i:0))
2022-05-22 15:43:09,538 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-CANDIDATE: reject ELECTION from 9f373e4e-4e35-4a2f-a705-a71ce933fdce: already has voted for 9dd8a712-1e0d-4857-830c-d22a0163750c at current term 1
2022-05-22 15:43:09,538 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033 replies to ELECTION vote request: 9f373e4e-4e35-4a2f-a705-a71ce933fdce<-9dd8a712-1e0d-4857-830c-d22a0163750c#0:FAIL-t1. Peer's state: 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033:t1, leader=null, voted=9dd8a712-1e0d-4857-830c-d22a0163750c, raftlog=9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLog:OPENED:c-1, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,538 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: receive requestVote(ELECTION, 9f373e4e-4e35-4a2f-a705-a71ce933fdce, group-6603DB1E3033, 1, (t:0, i:0))
2022-05-22 15:43:09,538 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FOLLOWER: accept ELECTION from 9f373e4e-4e35-4a2f-a705-a71ce933fdce: our priority 0 <= candidate's priority 1
2022-05-22 15:43:09,538 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:09,539 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: shutdown 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FollowerState
2022-05-22 15:43:09,539 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577: start 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FollowerState
2022-05-22 15:43:09,539 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FollowerState was interrupted
2022-05-22 15:43:09,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:09,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:09,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:09,544 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: receive requestVote(ELECTION, 9dd8a712-1e0d-4857-830c-d22a0163750c, group-6603DB1E3033, 1, (t:0, i:0))
2022-05-22 15:43:09,544 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-CANDIDATE: reject ELECTION from 9dd8a712-1e0d-4857-830c-d22a0163750c: already has voted for 9f373e4e-4e35-4a2f-a705-a71ce933fdce at current term 1
2022-05-22 15:43:09,544 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033 replies to ELECTION vote request: 9dd8a712-1e0d-4857-830c-d22a0163750c<-9f373e4e-4e35-4a2f-a705-a71ce933fdce#0:FAIL-t1. Peer's state: 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033:t1, leader=null, voted=9f373e4e-4e35-4a2f-a705-a71ce933fdce, raftlog=9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLog:OPENED:c-1, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|priority:0], old=null
2022-05-22 15:43:09,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:09,583 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033 replies to ELECTION vote request: 9f373e4e-4e35-4a2f-a705-a71ce933fdce<-6c03b4ed-3732-4e8d-ac40-6e00ca884577#0:OK-t1. Peer's state: 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033:t1, leader=null, voted=9f373e4e-4e35-4a2f-a705-a71ce933fdce, raftlog=6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLog:OPENED:c-1, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,594 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-05-22 15:43:09,594 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9dd8a712-1e0d-4857-830c-d22a0163750c<-9f373e4e-4e35-4a2f-a705-a71ce933fdce#0:FAIL-t1
2022-05-22 15:43:09,594 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188 ELECTION round 0: result REJECTED
2022-05-22 15:43:09,594 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:43:09,595 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: shutdown 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188
2022-05-22 15:43:09,595 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-FollowerState
2022-05-22 15:43:09,666 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187: ELECTION PASSED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:09,666 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9f373e4e-4e35-4a2f-a705-a71ce933fdce<-9dd8a712-1e0d-4857-830c-d22a0163750c#0:FAIL-t1
2022-05-22 15:43:09,666 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: receive requestVote(ELECTION, 9dd8a712-1e0d-4857-830c-d22a0163750c, group-6603DB1E3033, 1, (t:0, i:0))
2022-05-22 15:43:09,666 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9f373e4e-4e35-4a2f-a705-a71ce933fdce<-6c03b4ed-3732-4e8d-ac40-6e00ca884577#0:OK-t1
2022-05-22 15:43:09,666 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-FOLLOWER: reject ELECTION from 9dd8a712-1e0d-4857-830c-d22a0163750c: already has voted for 9f373e4e-4e35-4a2f-a705-a71ce933fdce at current term 1
2022-05-22 15:43:09,666 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033 replies to ELECTION vote request: 9dd8a712-1e0d-4857-830c-d22a0163750c<-6c03b4ed-3732-4e8d-ac40-6e00ca884577#0:FAIL-t1. Peer's state: 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033:t1, leader=null, voted=9f373e4e-4e35-4a2f-a705-a71ce933fdce, raftlog=6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLog:OPENED:c-1, conf=-1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,666 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187 ELECTION round 0: result PASSED
2022-05-22 15:43:09,691 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:09,734 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: shutdown 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-6603DB1E3033 with new leaderId: 9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: change Leader from null to 9f373e4e-4e35-4a2f-a705-a71ce933fdce at term 1 for becomeLeader, leader elected after 5740ms
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,735 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:09,735 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 484a336d-2899-4279-b113-6603db1e3033, Nodes: 9dd8a712-1e0d-4857-830c-d22a0163750c{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45631, RATIS=45847, RATIS_ADMIN=45847, RATIS_SERVER=45847, STANDALONE=33359], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9f373e4e-4e35-4a2f-a705-a71ce933fdce{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37203, RATIS=36589, RATIS_ADMIN=36589, RATIS_SERVER=36589, STANDALONE=34243], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6c03b4ed-3732-4e8d-ac40-6e00ca884577{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=35001, RATIS=36425, RATIS_ADMIN=36425, RATIS_SERVER=36425, STANDALONE=34093], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:9f373e4e-4e35-4a2f-a705-a71ce933fdce, CreationTimestamp2022-05-22T15:43:03.676Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(251)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:notifyStatusChanged(88)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-05-22 15:43:09,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-05-22 15:43:09,738 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:09,738 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:09,738 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:09,738 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,738 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:09,744 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:09,747 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:09,761 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce: start 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderStateImpl
2022-05-22 15:43:09,762 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:09,765 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-4/data/ratis/484a336d-2899-4279-b113-6603db1e3033/current/log_inprogress_0
2022-05-22 15:43:09,791 [9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033-LeaderElection187] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9f373e4e-4e35-4a2f-a705-a71ce933fdce@group-6603DB1E3033: set configuration 0: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,858 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5120016581ns, electionTimeout:5087ms
2022-05-22 15:43:09,858 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: shutdown 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState
2022-05-22 15:43:09,859 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:09,859 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:09,859 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189
2022-05-22 15:43:09,872 [9dd8a712-1e0d-4857-830c-d22a0163750c-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-6603DB1E3033 with new leaderId: 9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:09,872 [9dd8a712-1e0d-4857-830c-d22a0163750c-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: change Leader from null to 9f373e4e-4e35-4a2f-a705-a71ce933fdce at term 1 for appendEntries, leader elected after 5708ms
2022-05-22 15:43:09,879 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189 ELECTION round 0: submit vote requests at term 1 for -1: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|priority:1], old=null
2022-05-22 15:43:09,879 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:09,879 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: shutdown 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189
2022-05-22 15:43:09,879 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:09,879 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-966685EACF86 with new leaderId: 9dd8a712-1e0d-4857-830c-d22a0163750c
2022-05-22 15:43:09,894 [9dd8a712-1e0d-4857-830c-d22a0163750c-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033: set configuration 0: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:09,895 [9dd8a712-1e0d-4857-830c-d22a0163750c-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:09,897 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-6603DB1E3033-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/484a336d-2899-4279-b113-6603db1e3033/current/log_inprogress_0
2022-05-22 15:43:09,983 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: change Leader from null to 9dd8a712-1e0d-4857-830c-d22a0163750c at term 1 for becomeLeader, leader elected after 5200ms
2022-05-22 15:43:09,983 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:09,984 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,984 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9dd8a712-1e0d-4857-830c-d22a0163750c: start 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderStateImpl
2022-05-22 15:43:09,985 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:09,992 [6c03b4ed-3732-4e8d-ac40-6e00ca884577-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-6603DB1E3033 with new leaderId: 9f373e4e-4e35-4a2f-a705-a71ce933fdce
2022-05-22 15:43:09,992 [6c03b4ed-3732-4e8d-ac40-6e00ca884577-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: change Leader from null to 9f373e4e-4e35-4a2f-a705-a71ce933fdce at term 1 for appendEntries, leader elected after 5717ms
2022-05-22 15:43:09,996 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-5/data/ratis/b14c07ff-b372-4976-948e-966685eacf86/current/log_inprogress_0
2022-05-22 15:43:10,023 [6c03b4ed-3732-4e8d-ac40-6e00ca884577-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033: set configuration 0: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:0, 9f373e4e-4e35-4a2f-a705-a71ce933fdce|rpc:10.1.0.29:36589|dataStream:|priority:1, 6c03b4ed-3732-4e8d-ac40-6e00ca884577|rpc:10.1.0.29:36425|dataStream:|priority:0], old=null
2022-05-22 15:43:10,024 [6c03b4ed-3732-4e8d-ac40-6e00ca884577-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:10,027 [9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86-LeaderElection189] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9dd8a712-1e0d-4857-830c-d22a0163750c@group-966685EACF86: set configuration 0: [9dd8a712-1e0d-4857-830c-d22a0163750c|rpc:10.1.0.29:45847|dataStream:|priority:1], old=null
2022-05-22 15:43:10,033 [6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 6c03b4ed-3732-4e8d-ac40-6e00ca884577@group-6603DB1E3033-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-3/data/ratis/484a336d-2899-4279-b113-6603db1e3033/current/log_inprogress_0
2022-05-22 15:43:10,111 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:10,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:10,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:10,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Cluster exits safe mode
2022-05-22 15:43:10,542 [Listener at 127.0.0.1/35755] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:10,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:10,600 [Listener at 127.0.0.1/35755] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:10,610 [Listener at 127.0.0.1/35755] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(160)) - ServiceID for StorageContainerManager is null
2022-05-22 15:43:10,610 [Listener at 127.0.0.1/35755] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(165)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-05-22 15:43:10,611 [Listener at 127.0.0.1/35755] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:10,611 [Listener at 127.0.0.1/35755] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:10,704 [Listener at 127.0.0.1/35755] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 80 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:10,707 [Listener at 127.0.0.1/35755] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:10,714 [Listener at 127.0.0.1/35755] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:11,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:11,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:11,156 [Listener at 127.0.0.1/35755] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-05-22 15:43:11,157 [Listener at 127.0.0.1/35755] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-05-22 15:43:11,198 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:11,198 [Listener at 127.0.0.1/35755] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:11,198 [Listener at 127.0.0.1/35755] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-05-22 15:43:11,198 [Listener at 127.0.0.1/35755] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-05-22 15:43:11,199 [Listener at 127.0.0.1/35755] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(371)) - upgrade containerId to 0
2022-05-22 15:43:11,199 [Listener at 127.0.0.1/35755] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-05-22 15:43:11,214 [Listener at 127.0.0.1/35755] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(148)) - Entering startup safe mode.
2022-05-22 15:43:11,261 [Listener at 127.0.0.1/35755] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-05-22 15:43:11,269 [Listener at 127.0.0.1/35755] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-05-22 15:43:11,269 [Listener at 127.0.0.1/35755] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-05-22 15:43:11,269 [Listener at 127.0.0.1/35755] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-05-22 15:43:11,270 [Listener at 127.0.0.1/35755] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(125)) - Starting RatisPipelineUtilsThread.
2022-05-22 15:43:11,278 [Listener at 127.0.0.1/35755] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:start(126)) - Starting BackgroundPipelineScrubber Service.
2022-05-22 15:43:11,278 [Listener at 127.0.0.1/35755] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-05-22 15:43:11,278 [Listener at 127.0.0.1/35755] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-05-22 15:43:11,279 [Listener at 127.0.0.1/35755] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-05-22 15:43:11,279 [Listener at 127.0.0.1/35755] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-05-22 15:43:11,279 [Listener at 127.0.0.1/35755] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-05-22 15:43:11,279 [Listener at 127.0.0.1/35755] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-05-22 15:43:11,284 [Listener at 127.0.0.1/35755] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-05-22 15:43:11,284 [Listener at 127.0.0.1/35755] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-05-22 15:43:11,284 [Listener at 127.0.0.1/35755] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-05-22 15:43:11,287 [Listener at 127.0.0.1/35755] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:11,289 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:43:11,294 [Listener at 0.0.0.0/35029] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:11,295 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:43:11,299 [Listener at 0.0.0.0/33323] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:11,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:11,355 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:43:11,465 [Listener at 0.0.0.0/46811] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(399)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-05-22 15:43:11,465 [Listener at 0.0.0.0/46811] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:11,465 [Listener at 0.0.0.0/46811] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-05-22 15:43:11,465 [Listener at 0.0.0.0/46811] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1354)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:46811
2022-05-22 15:43:11,465 [Listener at 0.0.0.0/46811] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2022-05-22 15:43:11,496 [Listener at 0.0.0.0/46811] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:46811
2022-05-22 15:43:11,497 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:11,497 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:43:11,498 [Listener at 0.0.0.0/46811] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1369)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33323
2022-05-22 15:43:11,499 [Listener at 0.0.0.0/46811] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:33323
2022-05-22 15:43:11,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:11,499 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:43:11,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:11,595 [Listener at 0.0.0.0/46811] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(183)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:35029
2022-05-22 15:43:11,604 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:11,605 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:43:11,609 [Listener at 0.0.0.0/46811] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-05-22 15:43:11,609 [Listener at 0.0.0.0/46811] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:11,610 [Listener at 0.0.0.0/46811] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:11,613 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76870adf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:11,613 [Listener at 0.0.0.0/46811] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:11,614 [Listener at 0.0.0.0/46811] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:11,614 [Listener at 0.0.0.0/46811] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-05-22 15:43:11,614 [Listener at 0.0.0.0/46811] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:11,614 [Listener at 0.0.0.0/46811] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:11,618 [Listener at 0.0.0.0/46811] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 45921
2022-05-22 15:43:11,618 [Listener at 0.0.0.0/46811] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:11,667 [Listener at 0.0.0.0/46811] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:11,667 [Listener at 0.0.0.0/46811] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:11,667 [Listener at 0.0.0.0/46811] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:43:11,672 [Listener at 0.0.0.0/46811] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@463e2351{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:11,672 [Listener at 0.0.0.0/46811] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@48f5b378{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:43:11,674 [Listener at 0.0.0.0/46811] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@790e85a4{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:43:11,770 [Listener at 0.0.0.0/46811] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@4b72469d{HTTP/1.1, (http/1.1)}{0.0.0.0:45921}
2022-05-22 15:43:11,770 [Listener at 0.0.0.0/46811] INFO  server.Server (Server.java:doStart(415)) - Started @391150ms
2022-05-22 15:43:11,770 [Listener at 0.0.0.0/46811] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:11,775 [Listener at 0.0.0.0/46811] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:45921
2022-05-22 15:43:11,775 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:11,784 [Listener at 0.0.0.0/46811] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-05-22 15:43:11,784 [Listener at 0.0.0.0/46811] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-05-22 15:43:11,784 [Listener at 0.0.0.0/46811] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-05-22 15:43:11,784 [Listener at 0.0.0.0/46811] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-05-22 15:43:11,784 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:11,785 [Listener at 0.0.0.0/46811] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = BUCKET_LAYOUT_SUPPORT (version = 2), software layout = BUCKET_LAYOUT_SUPPORT (version = 2)
2022-05-22 15:43:12,108 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-05-22 15:43:12,140 [Listener at 0.0.0.0/46811] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 355 ms to scan 2 urls, producing 143 keys and 369 values [using 2 cores]
2022-05-22 15:43:12,140 [Listener at 0.0.0.0/46811] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-05-22 15:43:12,140 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:12,141 [Listener at 0.0.0.0/46811] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33323]
2022-05-22 15:43:12,141 [Listener at 0.0.0.0/46811] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33323]
2022-05-22 15:43:12,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:12,260 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:12,260 [Listener at 0.0.0.0/46811] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-05-22 15:43:12,261 [Listener at 0.0.0.0/46811] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-05-22 15:43:12,287 [Listener at 0.0.0.0/39533] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:12,334 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1f23a6d6{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:12,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:12,356 [Listener at 0.0.0.0/39533] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@343a0836{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:12,356 [Listener at 0.0.0.0/39533] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:12,406 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@238651bf{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:12,411 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@9e804ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:12,412 [Listener at 0.0.0.0/39533] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(359)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1441)) - Stopping Container Balancer service.
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  balancer.ContainerBalancer (ContainerBalancer.java:stopBalancer(923)) - Container Balancer is not running.
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1448)) - Stopping Replication Manager Service.
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1455)) - Stopping the Datanode Admin Monitor.
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1462)) - Stopping Lease Manager of the command watchers
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1469)) - Stopping datanode service RPC server
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(400)) - Stopping the RPC server for DataNodes
2022-05-22 15:43:12,413 [Listener at 0.0.0.0/39533] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 33345
2022-05-22 15:43:12,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-05-22 15:43:12,464 [IPC Server listener on 33345] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 33345
2022-05-22 15:43:12,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:12,465 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(236)) - Unable to communicate to SCM server at 0.0.0.0:33345 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az40-114/10.1.0.29"; destination host is: "0.0.0.0":33345; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
	at com.sun.proxy.$Proxy53.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:183)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:85)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-05-22 15:43:12,467 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(815)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-05-22 15:43:12,481 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1477)) - Stopping block service RPC server
2022-05-22 15:43:12,481 [Listener at 0.0.0.0/39533] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-05-22 15:43:12,481 [Listener at 0.0.0.0/39533] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 42521
2022-05-22 15:43:12,485 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1484)) - Stopping the StorageContainerLocationProtocol RPC server
2022-05-22 15:43:12,485 [Listener at 0.0.0.0/39533] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-05-22 15:43:12,485 [Listener at 0.0.0.0/39533] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 39533
2022-05-22 15:43:12,488 [IPC Server listener on 42521] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 42521
2022-05-22 15:43:12,485 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:12,490 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1491)) - Stopping Storage Container Manager HTTP server.
2022-05-22 15:43:12,490 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@3e4ead73{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:43:12,491 [IPC Server listener on 39533] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 39533
2022-05-22 15:43:12,491 [Listener at 0.0.0.0/39533] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@1d988297{HTTP/1.1, (http/1.1)}{0.0.0.0:39627}
2022-05-22 15:43:12,491 [Listener at 0.0.0.0/39533] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:12,492 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@24fc9aa5{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-05-22 15:43:12,492 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@28941a68{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:12,493 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1502)) - Stopping Block Manager Service.
2022-05-22 15:43:12,493 [Listener at 0.0.0.0/39533] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:43:12,493 [Listener at 0.0.0.0/39533] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:43:12,493 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1529)) - Stopping SCM Event Queue.
2022-05-22 15:43:12,494 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:12,512 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1540)) - Stopping SCM HA services.
2022-05-22 15:43:12,512 [Listener at 0.0.0.0/39533] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - Stopping RatisPipelineUtilsThread.
2022-05-22 15:43:12,512 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(177)) - RatisPipelineUtilsThread is interrupted.
2022-05-22 15:43:12,512 [Listener at 0.0.0.0/39533] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:stop(143)) - Stopping BackgroundPipelineScrubber Service.
2022-05-22 15:43:12,512 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1550)) - Stopping SCM MetadataStore.
2022-05-22 15:43:12,513 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2022-05-22 15:43:12,513 [PipelineScrubberThread] WARN  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:run(164)) - PipelineScrubberThread is interrupted, exit
2022-05-22 15:43:12,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:12,662 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2022-05-22 15:43:12,704 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2022-05-22 15:43:12,705 [Listener at 0.0.0.0/39533] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(160)) - ServiceID for StorageContainerManager is null
2022-05-22 15:43:12,705 [Listener at 0.0.0.0/39533] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(165)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-05-22 15:43:12,705 [Listener at 0.0.0.0/39533] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:12,706 [Listener at 0.0.0.0/39533] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(3894)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(395)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:12,896 [Listener at 0.0.0.0/46811] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:33877
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(627)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 33877 (custom)
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-05-22 15:43:12,897 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 33877 (custom)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 33877 (custom)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:12,898 [Listener at 0.0.0.0/46811] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:12,899 [Listener at 0.0.0.0/46811] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis] (custom)
2022-05-22 15:43:12,900 [Listener at 0.0.0.0/46811] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:33877|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@4fba1093[Not completed]
2022-05-22 15:43:12,900 [Listener at 0.0.0.0/46811] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1901)) - OzoneManager Ratis server initialized at port 33877
2022-05-22 15:43:12,901 [Listener at 0.0.0.0/46811] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1030)) - Creating RPC Server
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:33877|priority:0] with OzoneManagerStateMachine:uninitialized
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:33877|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:12,904 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis] (custom)
2022-05-22 15:43:12,905 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:12,905 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:12,905 [pool-3740-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-05-22 15:43:12,906 [pool-3740-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-05-22 15:43:12,907 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-05-22 15:43:12,908 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-05-22 15:43:12,908 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:12,908 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:12,908 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:12,908 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:12,991 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-05-22 15:43:12,992 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:12,992 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-05-22 15:43:12,992 [pool-3740-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:12,992 [pool-3740-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:12,998 [pool-3740-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:13,093 [Listener at 0.0.0.0/39533] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 386 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:13,094 [Listener at 0.0.0.0/39533] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:13,108 [Listener at 0.0.0.0/39533] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-05-22 15:43:13,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:13,542 [Listener at 0.0.0.0/39533] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-05-22 15:43:13,542 [Listener at 0.0.0.0/39533] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-05-22 15:43:13,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:13,580 [Listener at 0.0.0.0/39533] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:13,580 [Listener at 0.0.0.0/39533] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:13,580 [Listener at 0.0.0.0/39533] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-05-22 15:43:13,598 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047570148ns, electionTimeout:5019ms
2022-05-22 15:43:13,598 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:13,598 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:43:13,607 [Listener at 0.0.0.0/39533] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(148)) - Entering startup safe mode.
2022-05-22 15:43:13,608 [Listener at 0.0.0.0/39533] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-05-22 15:43:13,609 [Listener at 0.0.0.0/39533] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-05-22 15:43:13,609 [Listener at 0.0.0.0/39533] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-05-22 15:43:13,610 [Listener at 0.0.0.0/39533] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(125)) - Starting RatisPipelineUtilsThread.
2022-05-22 15:43:13,611 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5083999311ns, electionTimeout:5080ms
2022-05-22 15:43:13,611 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:13,611 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:43:13,617 [Listener at 0.0.0.0/39533] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:start(126)) - Starting BackgroundPipelineScrubber Service.
2022-05-22 15:43:13,617 [Listener at 0.0.0.0/39533] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-05-22 15:43:13,624 [Listener at 0.0.0.0/39533] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-05-22 15:43:13,625 [Listener at 0.0.0.0/39533] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-05-22 15:43:13,626 [Listener at 0.0.0.0/39533] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-05-22 15:43:13,626 [Listener at 0.0.0.0/39533] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-05-22 15:43:13,626 [Listener at 0.0.0.0/39533] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-05-22 15:43:13,623 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5095507157ns, electionTimeout:5091ms
2022-05-22 15:43:13,627 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:13,627 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-05-22 15:43:13,712 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:43:13,716 [Listener at 0.0.0.0/39533] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2022-05-22 15:43:13,716 [Listener at 0.0.0.0/39533] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2022-05-22 15:43:13,716 [Listener at 0.0.0.0/39533] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2022-05-22 15:43:13,724 [Listener at 0.0.0.0/39533] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:13,748 [Socket Reader #1 for port 33345] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 33345
2022-05-22 15:43:13,771 [Listener at 0.0.0.0/33345] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:13,800 [Socket Reader #1 for port 42521] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 42521
2022-05-22 15:43:13,822 [Listener at 0.0.0.0/42521] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:13,823 [Socket Reader #1 for port 39533] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 39533
2022-05-22 15:43:13,838 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:13,838 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:13,838 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190
2022-05-22 15:43:13,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:13,838 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192
2022-05-22 15:43:13,838 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:13,838 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191
2022-05-22 15:43:13,875 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190 ELECTION round 0: submit vote requests at term 3 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:13,879 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191 ELECTION round 0: submit vote requests at term 3 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:13,901 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:13,903 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-CANDIDATE: reject ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: already has voted for 2ad339c1-c64b-40f8-8805-fdb409c2806d at current term 3
2022-05-22 15:43:13,904 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:FAIL-t3. Peer's state: 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559:t3, leader=null, voted=2ad339c1-c64b-40f8-8805-fdb409c2806d, raftlog=2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:13,904 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192 ELECTION round 0: submit vote requests at term 3 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:14,005 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:14,005 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-CANDIDATE: reject ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: already has voted for 9cf969b5-3654-4d78-9d8f-3cca557d6deb at current term 3
2022-05-22 15:43:14,005 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t3. Peer's state: 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559:t3, leader=null, voted=9cf969b5-3654-4d78-9d8f-3cca557d6deb, raftlog=9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:14,005 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: receive requestVote(ELECTION, 2ad339c1-c64b-40f8-8805-fdb409c2806d, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:14,005 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-CANDIDATE: reject ELECTION from 2ad339c1-c64b-40f8-8805-fdb409c2806d: already has voted for 9b2d287e-9c2c-442e-b286-c4ec9a231851 at current term 3
2022-05-22 15:43:14,005 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559 replies to ELECTION vote request: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:FAIL-t3. Peer's state: 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559:t3, leader=null, voted=9b2d287e-9c2c-442e-b286-c4ec9a231851, raftlog=9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:14,075 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:43:14,081 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(399)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-05-22 15:43:14,141 [Listener at 0.0.0.0/39533] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:14,141 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: receive requestVote(ELECTION, 2ad339c1-c64b-40f8-8805-fdb409c2806d, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:14,141 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-CANDIDATE: reject ELECTION from 2ad339c1-c64b-40f8-8805-fdb409c2806d: already has voted for 9cf969b5-3654-4d78-9d8f-3cca557d6deb at current term 3
2022-05-22 15:43:14,141 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559 replies to ELECTION vote request: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t3. Peer's state: 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559:t3, leader=null, voted=9cf969b5-3654-4d78-9d8f-3cca557d6deb, raftlog=9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:14,141 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:14,142 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:FAIL-t3
2022-05-22 15:43:14,142 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t3
2022-05-22 15:43:14,142 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190 ELECTION round 0: result REJECTED
2022-05-22 15:43:14,141 [Listener at 0.0.0.0/39533] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-05-22 15:43:14,142 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1354)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39533
2022-05-22 15:43:14,142 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-05-22 15:43:14,145 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190
2022-05-22 15:43:14,145 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:FAIL-t3
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 2ad339c1-c64b-40f8-8805-fdb409c2806d<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t3
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192 ELECTION round 0: result REJECTED
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192
2022-05-22 15:43:14,145 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:14,192 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:43:14,269 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: receive requestVote(ELECTION, 9cf969b5-3654-4d78-9d8f-3cca557d6deb, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:14,269 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FOLLOWER: reject ELECTION from 9cf969b5-3654-4d78-9d8f-3cca557d6deb: already has voted for 2ad339c1-c64b-40f8-8805-fdb409c2806d at current term 3
2022-05-22 15:43:14,269 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559 replies to ELECTION vote request: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:FAIL-t3. Peer's state: 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559:t3, leader=null, voted=2ad339c1-c64b-40f8-8805-fdb409c2806d, raftlog=2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:14,345 [Listener at 0.0.0.0/39533] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2022-05-22 15:43:14,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:14,386 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2022-05-22 15:43:14,386 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2022-05-22 15:43:14,446 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:43:14,552 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: receive requestVote(ELECTION, 9cf969b5-3654-4d78-9d8f-3cca557d6deb, group-B4F3F607B559, 3, (t:0, i:0))
2022-05-22 15:43:14,553 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FOLLOWER: reject ELECTION from 9cf969b5-3654-4d78-9d8f-3cca557d6deb: already has voted for 9b2d287e-9c2c-442e-b286-c4ec9a231851 at current term 3
2022-05-22 15:43:14,553 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559 replies to ELECTION vote request: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:FAIL-t3. Peer's state: 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559:t3, leader=null, voted=9b2d287e-9c2c-442e-b286-c4ec9a231851, raftlog=9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:14,556 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:14,556 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:FAIL-t3
2022-05-22 15:43:14,556 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:FAIL-t3
2022-05-22 15:43:14,556 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191 ELECTION round 0: result REJECTED
2022-05-22 15:43:14,557 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-05-22 15:43:14,557 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191
2022-05-22 15:43:14,557 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:14,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:14,684 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2022-05-22 15:43:14,684 [Listener at 0.0.0.0/39533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2022-05-22 15:43:14,712 [EndpointStateMachine task thread for /0.0.0.0:33345 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(977)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33345. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2022-05-22 15:43:14,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:14,879 [Listener at 0.0.0.0/39533] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:39533
2022-05-22 15:43:14,879 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:14,889 [IPC Server listener on 39533] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 39533: starting
2022-05-22 15:43:14,890 [Listener at 0.0.0.0/39533] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1369)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42521
2022-05-22 15:43:14,890 [Listener at 0.0.0.0/39533] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:42521
2022-05-22 15:43:14,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:14,891 [IPC Server listener on 42521] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 42521: starting
2022-05-22 15:43:15,012 [Listener at 0.0.0.0/39533] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(183)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:33345
2022-05-22 15:43:15,012 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:15,013 [IPC Server listener on 33345] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 33345: starting
2022-05-22 15:43:15,116 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:39627
2022-05-22 15:43:15,116 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:15,117 [Listener at 0.0.0.0/39533] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:15,122 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@85eba52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:15,129 [Listener at 0.0.0.0/39533] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:15,130 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:15,130 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-05-22 15:43:15,130 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:15,131 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:15,139 [Listener at 0.0.0.0/39533] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 39627
2022-05-22 15:43:15,139 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:15,159 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:15,159 [Listener at 0.0.0.0/39533] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:15,160 [Listener at 0.0.0.0/39533] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:43:15,223 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:43:15,223 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:482)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2022-05-22 15:43:15,351 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,351 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,167 [Listener at 0.0.0.0/46811] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 2197 ms to scan 19 urls, producing 61 keys and 3717 values [using 2 cores]
2022-05-22 15:43:15,352 [Listener at 0.0.0.0/46811] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-05-22 15:43:15,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:15,340 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@62977afb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:15,356 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@77604a86{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:43:15,358 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,358 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,358 [IPC Server handler 0 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,359 [Listener at 0.0.0.0/39533] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4e0139{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:43:15,366 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-05-22 15:43:15,433 [Listener at 0.0.0.0/39533] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@2446be5f{HTTP/1.1, (http/1.1)}{0.0.0.0:39627}
2022-05-22 15:43:15,433 [Listener at 0.0.0.0/39533] INFO  server.Server (Server.java:doStart(415)) - Started @394813ms
2022-05-22 15:43:15,433 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,433 [IPC Server handler 2 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,433 [IPC Server handler 1 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,434 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,518 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,518 [IPC Server handler 4 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,434 [Listener at 0.0.0.0/39533] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:15,520 [IPC Server handler 6 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:43:15,520 [IPC Server handler 6 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:15,440 [IPC Server handler 3 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,521 [IPC Server handler 12 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,521 [Listener at 0.0.0.0/39533] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:39627
2022-05-22 15:43:15,522 [IPC Server handler 14 on default port 33345] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(103)) - SCM received heartbeat from an unregistered datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2022-05-22 15:43:15,527 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-05-22 15:43:15,535 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2022-05-22 15:43:15,535 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-05-22 15:43:15,535 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-05-22 15:43:15,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:15,606 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:15,617 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:15,687 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2022-05-22 15:43:15,712 [IPC Server handler 15 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:15,712 [IPC Server handler 15 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:15,712 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:15,712 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-05-22 15:43:15,712 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2022-05-22 15:43:15,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:15,721 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-05-22 15:43:15,810 [Listener at 127.0.0.1/39969] INFO  om.OzoneManager (OzoneManager.java:start(1405)) - OzoneManager RPC server is listening at localhost/127.0.0.1:39969
2022-05-22 15:43:15,810 [Listener at 127.0.0.1/39969] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 33877
2022-05-22 15:43:15,812 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:33877|priority:0], old=null
2022-05-22 15:43:15,812 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:15,812 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-05-22 15:43:15,816 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:15,817 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:15,820 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-05-22 15:43:15,823 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 33877
2022-05-22 15:43:15,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:15,850 [Listener at 127.0.0.1/39969] INFO  om.OzoneManager (OzoneManager.java:start(1421)) - Version File has different layout version (2) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-05-22 15:43:15,850 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@2f60f320] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-05-22 15:43:15,856 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-05-22 15:43:15,856 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:15,857 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:15,880 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 34133
2022-05-22 15:43:15,881 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:15,907 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:15,907 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:15,907 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:43:15,921 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@4d8dfb9c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:15,921 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@13acd6d0{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-05-22 15:43:15,923 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4cb76698{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-05-22 15:43:15,963 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@14d1492d{HTTP/1.1, (http/1.1)}{0.0.0.0:34133}
2022-05-22 15:43:15,964 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @395343ms
2022-05-22 15:43:15,964 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:15,971 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:34133
2022-05-22 15:43:15,975 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-05-22 15:43:15,975 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-05-22 15:43:15,976 [Listener at 127.0.0.1/39969] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1845)) - Trash Interval set to 0. Files deleted won't move to trash
2022-05-22 15:43:16,103 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@160fd35f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:16,124 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:16,124 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:16,124 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:16,154 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:16,156 [IPC Server handler 0 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:16,156 [IPC Server handler 0 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:16,156 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-05-22 15:43:16,193 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:16,193 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:16,296 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:16,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:16,359 [IPC Server handler 2 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:43:16,360 [IPC Server handler 2 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:16,360 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:16,364 [IPC Server handler 1 on default port 33345] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:16,364 [IPC Server handler 1 on default port 33345] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:16,365 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:16,388 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:16,489 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:16,514 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-05-22 15:43:16,514 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-05-22 15:43:16,514 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:43:16,514 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:43:16,514 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:16,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:43:16,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(251)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-05-22 15:43:16,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:notifyStatusChanged(88)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-05-22 15:43:16,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-05-22 15:43:16,515 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:43:16,515 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:43:16,515 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:16,515 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:43:16,524 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 227 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:16,525 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:16,526 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:16,526 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:16,526 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data-0/containers/hdds
2022-05-22 15:43:16,527 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data-0/containers/hdds
2022-05-22 15:43:16,574 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis to VolumeSet
2022-05-22 15:43:16,574 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis
2022-05-22 15:43:16,574 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis
2022-05-22 15:43:16,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:16,594 [Thread-6568] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data-0/containers/hdds
2022-05-22 15:43:16,594 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:16,595 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:16,595 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:16,595 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:16,595 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:16,596 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:16,598 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis] (custom)
2022-05-22 15:43:16,628 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:16,633 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:16,633 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:16,634 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:16,643 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:16,644 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:16,644 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:16,644 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:16,644 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:16,645 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 43075
2022-05-22 15:43:16,645 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:16,688 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:16,688 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:16,688 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:43:16,688 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@41596794{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:16,689 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@32987a25{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:16,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:16,896 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1083851263ns, electionTimeout:1072ms
2022-05-22 15:43:16,896 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-05-22 15:43:16,896 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:16,896 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:16,896 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection193
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection193 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:33877|priority:0], old=null
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection193 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection193
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 4016ms
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:16,923 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-05-22 15:43:16,924 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:16,924 [om1@group-C5BA1605619E-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-05-22 15:43:16,924 [om1@group-C5BA1605619E-LeaderElection193] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:16,968 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-05-22 15:43:17,038 [om1@group-C5BA1605619E-LeaderElection193] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:33877|admin:|client:|dataStream:|priority:0], old=null
2022-05-22 15:43:17,039 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(191)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:33877"
]
2022-05-22 15:43:17,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:17,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:17,665 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@29a917fd{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-43075-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4998401007283933008/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:17,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:17,843 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@9a96435{HTTP/1.1, (http/1.1)}{0.0.0.0:43075}
2022-05-22 15:43:17,843 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @397222ms
2022-05-22 15:43:17,843 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:17,847 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43075
2022-05-22 15:43:17,866 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:17,866 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:17,866 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:17,875 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:17,877 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:17,922 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:17,977 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@11ba2c4d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:18,024 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/meta/datanode.id
2022-05-22 15:43:18,132 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 210 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:18,134 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:18,135 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:18,135 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:18,135 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data-0/containers/hdds
2022-05-22 15:43:18,136 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data-0/containers/hdds
2022-05-22 15:43:18,159 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis to VolumeSet
2022-05-22 15:43:18,160 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis
2022-05-22 15:43:18,160 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis
2022-05-22 15:43:18,182 [Thread-6587] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data-0/containers/hdds
2022-05-22 15:43:18,182 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:18,184 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:18,185 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis] (custom)
2022-05-22 15:43:18,187 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:18,188 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:18,189 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:18,189 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:18,232 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:18,232 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:18,233 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:18,233 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:18,233 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:18,233 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 40943
2022-05-22 15:43:18,233 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:18,254 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:18,254 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:18,254 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:43:18,256 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@f4f49f3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:18,256 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@37707d0b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:18,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:18,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:18,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:18,863 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4d198099{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40943-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-7650232689747958416/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:18,900 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@7ff7dd32{HTTP/1.1, (http/1.1)}{0.0.0.0:40943}
2022-05-22 15:43:18,900 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @398280ms
2022-05-22 15:43:18,900 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:18,903 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40943
2022-05-22 15:43:18,908 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:18,908 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:18,908 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:18,943 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:18,947 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:19,011 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:19,014 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fe37994] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:19,032 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/meta/datanode.id
2022-05-22 15:43:19,178 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5032530894ns, electionTimeout:5030ms
2022-05-22 15:43:19,178 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,178 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-05-22 15:43:19,178 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:19,178 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194
2022-05-22 15:43:19,185 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 173 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:19,185 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194 ELECTION round 0: submit vote requests at term 4 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:19,186 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:19,188 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 4, (t:0, i:0))
2022-05-22 15:43:19,189 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FOLLOWER: accept ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: our priority 0 <= candidate's priority 0
2022-05-22 15:43:19,189 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:43:19,189 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,191 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:19,191 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:19,191 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data-0/containers/hdds
2022-05-22 15:43:19,192 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: receive requestVote(ELECTION, 9b2d287e-9c2c-442e-b286-c4ec9a231851, group-B4F3F607B559, 4, (t:0, i:0))
2022-05-22 15:43:19,192 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FOLLOWER: reject ELECTION from 9b2d287e-9c2c-442e-b286-c4ec9a231851: our priority 1 > candidate's priority 0
2022-05-22 15:43:19,192 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:9b2d287e-9c2c-442e-b286-c4ec9a231851
2022-05-22 15:43:19,192 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,202 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:shouldRun(117)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState: Stopping now (isRunning? false, role = FOLLOWER)
2022-05-22 15:43:19,212 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,212 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data-0/containers/hdds
2022-05-22 15:43:19,234 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,234 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:19,235 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t4. Peer's state: 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559:t4, leader=null, voted=9b2d287e-9c2c-442e-b286-c4ec9a231851, raftlog=2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:19,236 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis to VolumeSet
2022-05-22 15:43:19,236 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis
2022-05-22 15:43:19,256 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559 replies to ELECTION vote request: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t4. Peer's state: 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559:t4, leader=null, voted=null, raftlog=9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t4
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9b2d287e-9c2c-442e-b286-c4ec9a231851<-9cf969b5-3654-4d78-9d8f-3cca557d6deb#0:FAIL-t4
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194 ELECTION round 0: result REJECTED
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194
2022-05-22 15:43:19,260 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:19,260 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis
2022-05-22 15:43:19,348 [Thread-6607] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data-0/containers/hdds
2022-05-22 15:43:19,348 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:19,349 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:19,350 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:19,356 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis] (custom)
2022-05-22 15:43:19,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:19,360 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:19,424 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:19,424 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:19,425 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:19,428 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:19,428 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:19,429 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:19,429 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:19,429 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:19,429 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 37303
2022-05-22 15:43:19,429 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:19,430 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:19,430 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:19,430 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:43:19,431 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@606e006c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:19,431 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@759ebfa2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:19,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:19,848 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2022-05-22 15:43:19,848 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #1 to datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:19,880 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-05-22 15:43:19,880 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #2 to datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:19,880 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-05-22 15:43:19,880 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #3 to datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:19,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 33 milliseconds for processing 3 containers.
2022-05-22 15:43:20,104 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:20,104 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:20,106 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 40821
2022-05-22 15:43:20,128 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:20,149 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start RPC server
2022-05-22 15:43:20,158 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: GrpcService started, listening on 34253
2022-05-22 15:43:20,172 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e30a79fb-17da-4f0f-8b7c-18871dbe2f08 is started using port 34253 for RATIS
2022-05-22 15:43:20,172 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e30a79fb-17da-4f0f-8b7c-18871dbe2f08 is started using port 34253 for RATIS_ADMIN
2022-05-22 15:43:20,172 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis e30a79fb-17da-4f0f-8b7c-18871dbe2f08 is started using port 34253 for RATIS_SERVER
2022-05-22 15:43:20,173 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5442ed2b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-e30a79fb-17da-4f0f-8b7c-18871dbe2f08: Started
2022-05-22 15:43:20,179 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc e30a79fb-17da-4f0f-8b7c-18871dbe2f08 is started using port 38263
2022-05-22 15:43:20,315 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@64371425{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-37303-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1777105765552334622/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:20,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:20,391 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@843e11d{HTTP/1.1, (http/1.1)}{0.0.0.0:37303}
2022-05-22 15:43:20,391 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @399771ms
2022-05-22 15:43:20,391 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:20,427 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:37303
2022-05-22 15:43:20,433 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:20,433 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:20,433 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:20,448 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:20,464 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:20,496 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@140ae5d1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:20,503 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/meta/datanode.id
2022-05-22 15:43:20,542 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:20,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:20,613 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 70 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:20,614 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:20,615 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:20,615 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:20,615 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data-0/containers/hdds
2022-05-22 15:43:20,615 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data-0/containers/hdds
2022-05-22 15:43:20,651 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis to VolumeSet
2022-05-22 15:43:20,651 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis
2022-05-22 15:43:20,662 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis
2022-05-22 15:43:20,811 [Thread-6628] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data-0/containers/hdds
2022-05-22 15:43:20,812 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:20,820 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:20,821 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:20,822 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis] (custom)
2022-05-22 15:43:20,828 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:20,830 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:20,830 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:20,831 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:20,831 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 34927
2022-05-22 15:43:20,832 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:20,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:20,893 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:20,893 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:20,893 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-05-22 15:43:20,893 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@68525eff{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:20,893 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@a11edcd{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:21,065 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:21,065 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:21,065 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 43435
2022-05-22 15:43:21,068 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:21,081 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - f32dce45-0ff4-4afd-af37-86dd80543351: start RPC server
2022-05-22 15:43:21,081 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - f32dce45-0ff4-4afd-af37-86dd80543351: GrpcService started, listening on 34325
2022-05-22 15:43:21,081 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f32dce45-0ff4-4afd-af37-86dd80543351 is started using port 34325 for RATIS
2022-05-22 15:43:21,082 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f32dce45-0ff4-4afd-af37-86dd80543351 is started using port 34325 for RATIS_ADMIN
2022-05-22 15:43:21,082 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f32dce45-0ff4-4afd-af37-86dd80543351 is started using port 34325 for RATIS_SERVER
2022-05-22 15:43:21,082 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@6dcb7cee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-f32dce45-0ff4-4afd-af37-86dd80543351: Started
2022-05-22 15:43:21,082 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc f32dce45-0ff4-4afd-af37-86dd80543351 is started using port 40619
2022-05-22 15:43:21,374 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:21,383 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (1) to other datanode
2022-05-22 15:43:21,398 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12464 bytes for container 1
2022-05-22 15:43:21,415 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/replication/work/container-1.tar.gz
2022-05-22 15:43:21,417 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 12464, starting to import.
2022-05-22 15:43:21,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:21,505 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:21,518 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-05-22 15:43:21,523 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12305 bytes for container 3
2022-05-22 15:43:21,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:21,606 [grpc-default-executor-2] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/replication/work/container-3.tar.gz
2022-05-22 15:43:21,615 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 12305, starting to import.
2022-05-22 15:43:21,628 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2022-05-22 15:43:21,628 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 1 is replicated.
2022-05-22 15:43:21,746 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(456)) - Shutting down the Mini Ozone Cluster
2022-05-22 15:43:21,746 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2022-05-22 15:43:21,746 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2022-05-22 15:43:21,746 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(1960)) - om1[localhost:0]: Stopping Ozone Manager
2022-05-22 15:43:21,746 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 45987
2022-05-22 15:43:21,766 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-05-22 15:43:21,766 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-05-22 15:43:21,766 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-05-22 15:43:21,783 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:21,845 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-05-22 15:43:21,876 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:21,876 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - om1: close
2022-05-22 15:43:21,876 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - om1@group-C5BA1605619E: shutdown
2022-05-22 15:43:21,876 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2022-05-22 15:43:21,877 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2022-05-22 15:43:21,877 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:21,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:21,887 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12410 bytes for container 2
2022-05-22 15:43:21,906 [grpc-default-executor-2] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/replication/work/container-2.tar.gz
2022-05-22 15:43:22,013 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@3ed8cd8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34927-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-8500759398341777945/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:22,027 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 84
2022-05-22 15:43:22,028 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(436)) - Current Snapshot Index (t:1, i:84)
2022-05-22 15:43:22,028 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 84
2022-05-22 15:43:22,028 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 84
2022-05-22 15:43:22,028 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(490)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-05-22 15:43:22,028 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(465)) - Stopping OMDoubleBuffer flush thread
2022-05-22 15:43:22,042 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 12410, starting to import.
2022-05-22 15:43:22,044 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(385)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2022-05-22 15:43:22,056 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@685d0161{HTTP/1.1, (http/1.1)}{0.0.0.0:34927}
2022-05-22 15:43:22,056 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @401435ms
2022-05-22 15:43:22,056 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:22,059 [IPC Server handler 17 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:22,059 [IPC Server handler 17 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : e30a79fb-17da-4f0f-8b7c-18871dbe2f08{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34253, RATIS_ADMIN=34253, RATIS_SERVER=34253, STANDALONE=38263], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:22,060 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - om1@group-C5BA1605619E: closes. applyIndex: 84
2022-05-22 15:43:22,060 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34927
2022-05-22 15:43:22,061 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:22,061 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2022-05-22 15:43:22,068 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:22,068 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:22,068 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:22,086 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:22,113 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:22,165 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@306d2bc4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:22,222 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:22,240 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/meta/datanode.id
2022-05-22 15:43:22,247 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-05-22 15:43:22,248 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-05-22 15:43:22,248 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - om1: shutdown server with port 40257 now
2022-05-22 15:43:22,256 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-05-22 15:43:22,254 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-05-22 15:43:22,325 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - om1: shutdown server with port 40257 successfully
2022-05-22 15:43:22,330 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:22,331 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-05-22 15:43:22,331 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=823edfba-7515-4273-9776-803798aff3ae to datanode:e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:22,334 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 823edfba-7515-4273-9776-803798aff3ae, Nodes: e30a79fb-17da-4f0f-8b7c-18871dbe2f08{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34253, RATIS_ADMIN=34253, RATIS_SERVER=34253, STANDALONE=38263], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:22.331Z[Etc/UTC]].
2022-05-22 15:43:22,399 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@1d02635e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-om1: Stopped
2022-05-22 15:43:22,403 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(490)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-05-22 15:43:22,403 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(477)) - OMDoubleBuffer flush thread is not running.
2022-05-22 15:43:22,403 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service KeyDeletingService
2022-05-22 15:43:22,404 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service DirectoryDeletingService
2022-05-22 15:43:22,415 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@4ece3b05{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-05-22 15:43:22,420 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@6c80802c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:22,421 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:22,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:22,465 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@330b6b05{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-05-22 15:43:22,467 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@732e56b0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:22,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:22,594 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2022-05-22 15:43:22,675 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:22,675 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:22,678 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37545
2022-05-22 15:43:22,681 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:22,693 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start RPC server
2022-05-22 15:43:22,695 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: GrpcService started, listening on 41195
2022-05-22 15:43:22,695 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9a9a8948-e89e-4530-b27c-73e7a1307dc8 is started using port 41195 for RATIS
2022-05-22 15:43:22,695 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9a9a8948-e89e-4530-b27c-73e7a1307dc8 is started using port 41195 for RATIS_ADMIN
2022-05-22 15:43:22,696 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9a9a8948-e89e-4530-b27c-73e7a1307dc8 is started using port 41195 for RATIS_SERVER
2022-05-22 15:43:22,696 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3855531c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9a9a8948-e89e-4530-b27c-73e7a1307dc8: Started
2022-05-22 15:43:22,735 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9a9a8948-e89e-4530-b27c-73e7a1307dc8 is started using port 41071
2022-05-22 15:43:22,863 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 640 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:22,864 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:22,868 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:22,868 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:22,868 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data-0/containers/hdds
2022-05-22 15:43:22,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:22,890 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data-0/containers/hdds
2022-05-22 15:43:22,993 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis to VolumeSet
2022-05-22 15:43:22,993 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis
2022-05-22 15:43:23,062 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis
2022-05-22 15:43:23,142 [IPC Server handler 18 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:23,142 [IPC Server handler 18 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : f32dce45-0ff4-4afd-af37-86dd80543351{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43435, RATIS=34325, RATIS_ADMIN=34325, RATIS_SERVER=34325, STANDALONE=40619], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:23,142 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:23,143 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=da31b700-06ff-4995-bf1a-cabfb8e3f8b9 to datanode:f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:23,145 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-05-22 15:43:23,148 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: da31b700-06ff-4995-bf1a-cabfb8e3f8b9, Nodes: f32dce45-0ff4-4afd-af37-86dd80543351{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43435, RATIS=34325, RATIS_ADMIN=34325, RATIS_SERVER=34325, STANDALONE=40619], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:23.143Z[Etc/UTC]].
2022-05-22 15:43:23,300 [Thread-6658] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data-0/containers/hdds
2022-05-22 15:43:23,302 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:23,304 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:23,305 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:23,305 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:23,305 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:23,306 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis] (custom)
2022-05-22 15:43:23,321 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:23,331 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:23,331 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:23,332 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:23,441 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:23,442 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:23,442 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:23,442 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:23,443 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:23,443 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 44037
2022-05-22 15:43:23,443 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:23,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:23,468 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:23,468 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:23,468 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:43:23,469 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@334780c8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:23,469 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6f532cde{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:23,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:23,780 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:23,824 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: close
2022-05-22 15:43:23,824 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: shutdown
2022-05-22 15:43:23,824 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B563385F6B43,id=56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:43:23,824 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-LeaderStateImpl
2022-05-22 15:43:23,824 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:23,826 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:23,826 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-B563385F6B43: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43/sm/snapshot.1_0
2022-05-22 15:43:23,828 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-B563385F6B43: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-2/data/ratis/b33389d2-cd81-48e4-be65-b563385f6b43/sm/snapshot.1_0 took: 2 ms
2022-05-22 15:43:23,828 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:23,828 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:23,831 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43: closes. applyIndex: 0
2022-05-22 15:43:23,832 [56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:23,832 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d@group-B563385F6B43-SegmentedRaftLogWorker close()
2022-05-22 15:43:23,832 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown server with port 42763 now
2022-05-22 15:43:23,854 [grpc-default-executor-2] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-05-22 15:43:23,857 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 56e641d3-eb56-493e-85a5-4bb0b1b5352d: shutdown server with port 42763 successfully
2022-05-22 15:43:23,859 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@6860cdb3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-56e641d3-eb56-493e-85a5-4bb0b1b5352d: Stopped
2022-05-22 15:43:23,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:24,134 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@18775050{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44037-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-988479779475538743/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:24,224 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@8473c38{HTTP/1.1, (http/1.1)}{0.0.0.0:44037}
2022-05-22 15:43:24,224 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @403604ms
2022-05-22 15:43:24,224 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:24,226 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44037
2022-05-22 15:43:24,231 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:24,232 [Listener at 127.0.0.1/39969] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-05-22 15:43:24,232 [Listener at 127.0.0.1/39969] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-05-22 15:43:24,237 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:24,237 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:24,237 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 40089
2022-05-22 15:43:24,310 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:24,389 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:24,399 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5164678120ns, electionTimeout:5148ms
2022-05-22 15:43:24,399 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState
2022-05-22 15:43:24,399 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-05-22 15:43:24,433 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172549219ns, electionTimeout:5113ms
2022-05-22 15:43:24,433 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:24,433 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-05-22 15:43:24,439 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:24,439 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195
2022-05-22 15:43:24,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:24,474 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195 ELECTION round 0: submit vote requests at term 5 for -1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:24,559 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47d99ffb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:24,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:24,672 [IPC Server handler 19 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:24,672 [IPC Server handler 19 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9a9a8948-e89e-4530-b27c-73e7a1307dc8{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37545, RATIS=41195, RATIS_ADMIN=41195, RATIS_SERVER=41195, STANDALONE=41071], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:24,672 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:24,673 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=26ba7f85-1247-4f4b-986f-c4fb8a1c93fe to datanode:9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:24,673 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 26ba7f85-1247-4f4b-986f-c4fb8a1c93fe, Nodes: 9a9a8948-e89e-4530-b27c-73e7a1307dc8{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37545, RATIS=41195, RATIS_ADMIN=41195, RATIS_SERVER=41195, STANDALONE=41071], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:24.673Z[Etc/UTC]].
2022-05-22 15:43:24,676 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/meta/datanode.id
2022-05-22 15:43:24,704 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: receive requestVote(ELECTION, 9cf969b5-3654-4d78-9d8f-3cca557d6deb, group-B4F3F607B559, 5, (t:0, i:0))
2022-05-22 15:43:24,705 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FOLLOWER: accept ELECTION from 9cf969b5-3654-4d78-9d8f-3cca557d6deb: our priority 0 <= candidate's priority 1
2022-05-22 15:43:24,705 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:24,705 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: shutdown 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:24,721 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:24,721 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection196
2022-05-22 15:43:24,722 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: receive requestVote(ELECTION, 9cf969b5-3654-4d78-9d8f-3cca557d6deb, group-B4F3F607B559, 5, (t:0, i:0))
2022-05-22 15:43:24,748 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d: start 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState
2022-05-22 15:43:24,748 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-CANDIDATE: accept ELECTION from 9cf969b5-3654-4d78-9d8f-3cca557d6deb: our priority 0 <= candidate's priority 1
2022-05-22 15:43:24,748 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: changes role from CANDIDATE to FOLLOWER at term 5 for candidate:9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:24,748 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: shutdown 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection196
2022-05-22 15:43:24,748 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:run(231)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-LeaderElection196: skip running since this is already CLOSING
2022-05-22 15:43:24,748 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-FollowerState was interrupted
2022-05-22 15:43:24,762 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559 replies to ELECTION vote request: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t5. Peer's state: 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559:t5, leader=null, voted=9cf969b5-3654-4d78-9d8f-3cca557d6deb, raftlog=2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|priority:1], old=null
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-05-22 15:43:24,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:24,768 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0 to datanode:9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:24,768 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0 to datanode:f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:24,768 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0 to datanode:e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:24,768 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: d4b35d53-2c8e-4248-8048-57a765679fa0, Nodes: 9a9a8948-e89e-4530-b27c-73e7a1307dc8{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37545, RATIS=41195, RATIS_ADMIN=41195, RATIS_SERVER=41195, STANDALONE=41071], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f32dce45-0ff4-4afd-af37-86dd80543351{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43435, RATIS=34325, RATIS_ADMIN=34325, RATIS_SERVER=34325, STANDALONE=40619], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e30a79fb-17da-4f0f-8b7c-18871dbe2f08{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34253, RATIS_ADMIN=34253, RATIS_SERVER=34253, STANDALONE=38263], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:24.768Z[Etc/UTC]].
2022-05-22 15:43:24,771 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@6dcb7cee] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-f32dce45-0ff4-4afd-af37-86dd80543351: Detected pause in JVM or host machine (eg GC): pause of approximately 186629687ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=31ms
2022-05-22 15:43:24,772 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start RPC server
2022-05-22 15:43:24,772 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: GrpcService started, listening on 34329
2022-05-22 15:43:24,782 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 951c35ae-fd53-4948-8b06-2e5622a34ffa is started using port 34329 for RATIS
2022-05-22 15:43:24,782 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 951c35ae-fd53-4948-8b06-2e5622a34ffa is started using port 34329 for RATIS_ADMIN
2022-05-22 15:43:24,782 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 951c35ae-fd53-4948-8b06-2e5622a34ffa is started using port 34329 for RATIS_SERVER
2022-05-22 15:43:24,782 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@aa6ee36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-951c35ae-fd53-4948-8b06-2e5622a34ffa: Started
2022-05-22 15:43:24,783 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 951c35ae-fd53-4948-8b06-2e5622a34ffa is started using port 45519
2022-05-22 15:43:24,783 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851: start 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-FollowerState
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-2ad339c1-c64b-40f8-8805-fdb409c2806d#0:OK-t5
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195 ELECTION round 0: result PASSED
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: shutdown 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B4F3F607B559 with new leaderId: 9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: change Leader from null to 9cf969b5-3654-4d78-9d8f-3cca557d6deb at term 5 for becomeLeader, leader elected after 26661ms
2022-05-22 15:43:24,880 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:24,881 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:24,881 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:24,882 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:24,882 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:24,882 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:24,882 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:24,882 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:24,884 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:24,884 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:24,884 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:24,885 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:24,885 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:24,885 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:24,889 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559 replies to ELECTION vote request: 9cf969b5-3654-4d78-9d8f-3cca557d6deb<-9b2d287e-9c2c-442e-b286-c4ec9a231851#0:OK-t5. Peer's state: 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559:t5, leader=null, voted=9cf969b5-3654-4d78-9d8f-3cca557d6deb, raftlog=9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLog:OPENED:c-1, conf=-1: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:24,889 [Listener at 127.0.0.1/39969] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net ip:10.1.0.29
2022-05-22 15:43:24,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:24,899 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:24,900 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb: start 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderStateImpl
2022-05-22 15:43:24,901 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:24,903 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: db80ca8b-95c1-4b3b-bac4-b4f3f607b559, Nodes: 9cf969b5-3654-4d78-9d8f-3cca557d6deb{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37315, RATIS=38735, RATIS_ADMIN=38735, RATIS_SERVER=38735, STANDALONE=44455], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b2d287e-9c2c-442e-b286-c4ec9a231851{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43935, RATIS=34729, RATIS_ADMIN=34729, RATIS_SERVER=34729, STANDALONE=40861], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2ad339c1-c64b-40f8-8805-fdb409c2806d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=44383, RATIS=35845, RATIS_ADMIN=35845, RATIS_SERVER=35845, STANDALONE=39607], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:9cf969b5-3654-4d78-9d8f-3cca557d6deb, CreationTimestamp2022-05-22T15:42:56.516Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:24,962 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-0/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/current/log_inprogress_0
2022-05-22 15:43:25,031 [Listener at 127.0.0.1/39969] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(79)) - Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
2022-05-22 15:43:25,058 [9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559-LeaderElection195] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9cf969b5-3654-4d78-9d8f-3cca557d6deb@group-B4F3F607B559: set configuration 0: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:25,059 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: addNew group-803798AFF3AE:[e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] returns group-803798AFF3AE:java.util.concurrent.CompletableFuture@73353a06[Not completed]
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: new RaftServerImpl for group-803798AFF3AE:[e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: ConfigurationManager, init=-1: [e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis] (custom)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:25,098 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:25,099 [pool-3782-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/823edfba-7515-4273-9776-803798aff3ae does not exist. Creating ...
2022-05-22 15:43:25,111 [pool-3782-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/823edfba-7515-4273-9776-803798aff3ae/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:25,113 [pool-3782-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/823edfba-7515-4273-9776-803798aff3ae has been successfully formatted.
2022-05-22 15:43:25,156 [pool-3782-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-803798AFF3AE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:25,156 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:25,156 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:25,156 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:25,157 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:25,157 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:25,157 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:25,164 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 823edfba-7515-4273-9776-803798aff3ae, Nodes: e30a79fb-17da-4f0f-8b7c-18871dbe2f08{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34253, RATIS_ADMIN=34253, RATIS_SERVER=34253, STANDALONE=38263], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e30a79fb-17da-4f0f-8b7c-18871dbe2f08, CreationTimestamp2022-05-22T15:43:22.331Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:25,190 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:25,248 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:25,249 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: close
2022-05-22 15:43:25,249 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: shutdown
2022-05-22 15:43:25,252 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:25,252 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:25,252 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:25,252 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:43:25,261 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-9E28C69A43E8: Taking a snapshot at:(t:5, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0
2022-05-22 15:43:25,261 [2ad339c1-c64b-40f8-8805-fdb409c2806d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B4F3F607B559 with new leaderId: 9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:25,261 [2ad339c1-c64b-40f8-8805-fdb409c2806d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: change Leader from null to 9cf969b5-3654-4d78-9d8f-3cca557d6deb at term 5 for appendEntries, leader elected after 27502ms
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/823edfba-7515-4273-9776-803798aff3ae
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:25,262 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:25,262 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-9E28C69A43E8: Finished taking a snapshot at:(t:5, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0 took: 2 ms
2022-05-22 15:43:25,263 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:25,263 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:25,263 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8: closes. applyIndex: 0
2022-05-22 15:43:25,275 [9b2d287e-9c2c-442e-b286-c4ec9a231851-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B4F3F607B559 with new leaderId: 9cf969b5-3654-4d78-9d8f-3cca557d6deb
2022-05-22 15:43:25,275 [9b2d287e-9c2c-442e-b286-c4ec9a231851-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: change Leader from null to 9cf969b5-3654-4d78-9d8f-3cca557d6deb at term 5 for appendEntries, leader elected after 26635ms
2022-05-22 15:43:25,371 [9b2d287e-9c2c-442e-b286-c4ec9a231851-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559: set configuration 0: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:25,372 [9b2d287e-9c2c-442e-b286-c4ec9a231851-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:25,376 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8, PipelineID=ad7bd58a-6c08-45ff-8812-8cf4b692cf1d]
2022-05-22 15:43:25,377 [9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9b2d287e-9c2c-442e-b286-c4ec9a231851@group-B4F3F607B559-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-2/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/current/log_inprogress_0
2022-05-22 15:43:25,378 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: d451f14d-141e-4bf0-bcdf-9e28c69a43e8, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:25,379 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: ad7bd58a-6c08-45ff-8812-8cf4b692cf1d, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:25,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:25,454 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:25,454 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-9E28C69A43E8-SegmentedRaftLogWorker close()
2022-05-22 15:43:25,458 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:25,459 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:25,459 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:25,459 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:25,459 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:25,459 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: shutdown
2022-05-22 15:43:25,459 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8CF4B692CF1D,id=a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:25,459 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-LeaderStateImpl
2022-05-22 15:43:25,459 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:25,461 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:25,461 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-8CF4B692CF1D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d/sm/snapshot.1_0
2022-05-22 15:43:25,463 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-8CF4B692CF1D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-3/data/ratis/ad7bd58a-6c08-45ff-8812-8cf4b692cf1d/sm/snapshot.1_0 took: 2 ms
2022-05-22 15:43:25,464 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:25,464 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:25,464 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D: closes. applyIndex: 0
2022-05-22 15:43:25,464 [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:25,465 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa@group-8CF4B692CF1D-SegmentedRaftLogWorker close()
2022-05-22 15:43:25,465 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown server with port 34125 now
2022-05-22 15:43:25,531 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: installSnapshot onError, lastRequest: edd315a5-4c31-41f4-a5d0-8e213ccdb1da->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa#1-t5,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:5, i:0), CONFIGURATIONENTRY: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-05-22 15:43:25,561 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2022-05-22 15:43:25,562 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=662, lastRpcResponseTime=659) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:25,568 [2ad339c1-c64b-40f8-8805-fdb409c2806d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559: set configuration 0: [2ad339c1-c64b-40f8-8805-fdb409c2806d|rpc:10.1.0.29:35845|dataStream:|priority:0, 9b2d287e-9c2c-442e-b286-c4ec9a231851|rpc:10.1.0.29:34729|dataStream:|priority:0, 9cf969b5-3654-4d78-9d8f-3cca557d6deb|rpc:10.1.0.29:38735|dataStream:|priority:1], old=null
2022-05-22 15:43:25,569 [2ad339c1-c64b-40f8-8805-fdb409c2806d-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:25,572 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: shutdown server with port 34125 successfully
2022-05-22 15:43:25,583 [2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 2ad339c1-c64b-40f8-8805-fdb409c2806d@group-B4F3F607B559-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-665cf1ae-bb97-463e-b12c-0bc53627f970/datanode-1/data/ratis/db80ca8b-95c1-4b3b-bac4-b4f3f607b559/current/log_inprogress_0
2022-05-22 15:43:25,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:43:25,599 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3e19e627] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa: Stopped
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:25,620 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: start as a follower, conf=-1: [e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:25,624 [pool-3782-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState
2022-05-22 15:43:25,640 [pool-3782-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-803798AFF3AE,id=e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:25,677 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=b33389d2-cd81-48e4-be65-b563385f6b43]
2022-05-22 15:43:25,677 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(795)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2022-05-22 15:43:25,678 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: b33389d2-cd81-48e4-be65-b563385f6b43, Nodes: 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:25,767 [Listener at 127.0.0.1/39969] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 728 ms to scan 7 urls, producing 127 keys and 292 values 
2022-05-22 15:43:25,782 [Listener at 127.0.0.1/39969] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(233)) - Datanode State Machine Task Thread Pool size 2
2022-05-22 15:43:25,816 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=823edfba-7515-4273-9776-803798aff3ae
2022-05-22 15:43:25,816 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=823edfba-7515-4273-9776-803798aff3ae.
2022-05-22 15:43:25,816 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: addNew group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] returns group-57A765679FA0:java.util.concurrent.CompletableFuture@770ab0b8[Not completed]
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: new RaftServerImpl for group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: ConfigurationManager, init=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis] (custom)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:25,817 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:25,818 [pool-3782-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 does not exist. Creating ...
2022-05-22 15:43:25,818 [pool-3782-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:25,830 [pool-3782-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 has been successfully formatted.
2022-05-22 15:43:25,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:25,922 [Listener at 127.0.0.1/39969] INFO  volume.HddsVolume (HddsVolume.java:<init>(120)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-05-22 15:43:25,922 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data-0/containers/hdds to VolumeSet
2022-05-22 15:43:25,922 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data-0/containers/hdds
2022-05-22 15:43:25,963 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data-0/containers/hdds
2022-05-22 15:43:25,969 [pool-3782-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-57A765679FA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:25,969 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:25,970 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:25,970 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:25,970 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:25,970 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:25,970 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:25,972 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:25,972 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:25,979 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:25,979 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:25,979 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:25,979 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:25,980 [pool-3782-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:25,992 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: start as a follower, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:26,009 [pool-3782-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState
2022-05-22 15:43:26,024 [Listener at 127.0.0.1/39969] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(168)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis to VolumeSet
2022-05-22 15:43:26,024 [Listener at 127.0.0.1/39969] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis
2022-05-22 15:43:26,032 [pool-3782-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-57A765679FA0,id=e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:26,095 [Listener at 127.0.0.1/39969] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis
2022-05-22 15:43:26,098 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0
2022-05-22 15:43:26,106 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - f32dce45-0ff4-4afd-af37-86dd80543351: addNew group-CABFB8E3F8B9:[f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:1] returns group-CABFB8E3F8B9:java.util.concurrent.CompletableFuture@2e434e36[Not completed]
2022-05-22 15:43:26,112 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - f32dce45-0ff4-4afd-af37-86dd80543351: new RaftServerImpl for group-CABFB8E3F8B9:[f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:26,112 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: ConfigurationManager, init=-1: [f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis] (custom)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:26,113 [pool-3804-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/da31b700-06ff-4995-bf1a-cabfb8e3f8b9 does not exist. Creating ...
2022-05-22 15:43:26,178 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: addNew group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1] returns group-57A765679FA0:java.util.concurrent.CompletableFuture@203054aa[Not completed]
2022-05-22 15:43:26,195 [pool-3804-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/da31b700-06ff-4995-bf1a-cabfb8e3f8b9/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: new RaftServerImpl for group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: ConfigurationManager, init=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis] (custom)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:26,200 [pool-3826-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 does not exist. Creating ...
2022-05-22 15:43:26,207 [pool-3804-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/da31b700-06ff-4995-bf1a-cabfb8e3f8b9 has been successfully formatted.
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-CABFB8E3F8B9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:26,208 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/da31b700-06ff-4995-bf1a-cabfb8e3f8b9
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:26,210 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:26,214 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: da31b700-06ff-4995-bf1a-cabfb8e3f8b9, Nodes: f32dce45-0ff4-4afd-af37-86dd80543351{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43435, RATIS=34325, RATIS_ADMIN=34325, RATIS_SERVER=34325, STANDALONE=40619], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f32dce45-0ff4-4afd-af37-86dd80543351, CreationTimestamp2022-05-22T15:43:23.143Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:26,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:26,223 [pool-3826-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:26,317 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:26,336 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:26,336 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:26,336 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,337 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,308 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3cefacb0] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-1bd1ad93-a217-4aba-aed5-0a262321f6e0: Detected pause in JVM or host machine (eg GC): pause of approximately 126100616ns. No GCs detected.
2022-05-22 15:43:26,303 [IPC Server handler 14 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:26,340 [IPC Server handler 14 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 951c35ae-fd53-4948-8b06-2e5622a34ffa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40089, RATIS=34329, RATIS_ADMIN=34329, RATIS_SERVER=34329, STANDALONE=45519], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:26,301 [Thread-6704] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data-0/containers/hdds
2022-05-22 15:43:26,343 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:26,343 [Listener at 127.0.0.1/39969] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(257)) - Build ContainerSet costs 0s
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-05-22 15:43:26,345 [Listener at 127.0.0.1/39969] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:26,347 [Listener at 127.0.0.1/39969] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis] (custom)
2022-05-22 15:43:26,349 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=17457b2b-31d3-432a-9f5a-c00b6b8756c0 to datanode:951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:26,351 [pool-3826-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 has been successfully formatted.
2022-05-22 15:43:26,351 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 17457b2b-31d3-432a-9f5a-c00b6b8756c0, Nodes: 951c35ae-fd53-4948-8b06-2e5622a34ffa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40089, RATIS=34329, RATIS_ADMIN=34329, RATIS_SERVER=34329, STANDALONE=45519], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:26.349Z[Etc/UTC]].
2022-05-22 15:43:26,389 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:26,389 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:26,390 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:26,390 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:26,390 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:26,390 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: start as a follower, conf=-1: [f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:1], old=null
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:26,394 [pool-3804-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-57A765679FA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:26,407 [pool-3804-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CABFB8E3F8B9,id=f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:26,407 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:26,409 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:26,434 [Listener at 127.0.0.1/39969] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-05-22 15:43:26,445 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=da31b700-06ff-4995-bf1a-cabfb8e3f8b9
2022-05-22 15:43:26,445 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=da31b700-06ff-4995-bf1a-cabfb8e3f8b9.
2022-05-22 15:43:26,445 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - f32dce45-0ff4-4afd-af37-86dd80543351: addNew group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] returns group-57A765679FA0:java.util.concurrent.CompletableFuture@2a7ccf26[Not completed]
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - f32dce45-0ff4-4afd-af37-86dd80543351: new RaftServerImpl for group-57A765679FA0:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: ConfigurationManager, init=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis] (custom)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:26,446 [pool-3804-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 does not exist. Creating ...
2022-05-22 15:43:26,450 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:26,450 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:26,450 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:26,451 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,451 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,451 [pool-3804-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:26,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:26,465 [pool-3804-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0 has been successfully formatted.
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:26,512 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: start as a follower, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:26,533 [pool-3826-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState
2022-05-22 15:43:26,543 [pool-3826-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-57A765679FA0,id=9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:26,589 [pool-3804-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-57A765679FA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:26,590 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:26,616 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:26,617 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:26,617 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:26,617 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:26,648 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:26,651 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-05-22 15:43:26,651 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-05-22 15:43:26,652 [Listener at 127.0.0.1/39969] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-05-22 15:43:26,692 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:26,716 [Listener at 127.0.0.1/39969] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-05-22 15:43:26,717 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1030)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-05-22 15:43:26,717 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1006)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-05-22 15:43:26,717 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-05-22 15:43:26,717 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1014)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-05-22 15:43:26,718 [Listener at 127.0.0.1/39969] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1249)) - Jetty bound to port 34679
2022-05-22 15:43:26,718 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-05-22 15:43:26,824 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-05-22 15:43:26,824 [Listener at 127.0.0.1/39969] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-05-22 15:43:26,824 [Listener at 127.0.0.1/39969] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-05-22 15:43:26,825 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3eb7d49b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-05-22 15:43:26,825 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@5e8313ec{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-05-22 15:43:26,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:26,987 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:26,988 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:26,988 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:26,988 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,988 [pool-3804-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:26,991 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:26,991 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:26,991 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 41049
2022-05-22 15:43:27,038 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:27,038 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:27,038 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:27,038 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:27,038 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:27,049 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:27,049 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: start as a follower, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:27,069 [pool-3804-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState
2022-05-22 15:43:27,076 [pool-3804-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-57A765679FA0,id=f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:27,082 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0
2022-05-22 15:43:27,185 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - cb84caf1-a153-4209-9c1b-eeb875809600: start RPC server
2022-05-22 15:43:27,188 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - cb84caf1-a153-4209-9c1b-eeb875809600: GrpcService started, listening on 38061
2022-05-22 15:43:27,238 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis cb84caf1-a153-4209-9c1b-eeb875809600 is started using port 38061 for RATIS
2022-05-22 15:43:27,238 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis cb84caf1-a153-4209-9c1b-eeb875809600 is started using port 38061 for RATIS_ADMIN
2022-05-22 15:43:27,238 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis cb84caf1-a153-4209-9c1b-eeb875809600 is started using port 38061 for RATIS_SERVER
2022-05-22 15:43:27,239 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@33ecdc8c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-cb84caf1-a153-4209-9c1b-eeb875809600: Started
2022-05-22 15:43:27,331 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc cb84caf1-a153-4209-9c1b-eeb875809600 is started using port 35665
2022-05-22 15:43:27,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:27,457 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:27,458 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=2558, lastRpcResponseTime=2555) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:27,502 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: addNew group-C4FB8A1C93FE:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:1] returns group-C4FB8A1C93FE:java.util.concurrent.CompletableFuture@5180df21[Not completed]
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: new RaftServerImpl for group-C4FB8A1C93FE:[9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:27,502 [pool-3826-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: ConfigurationManager, init=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:27,503 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis] (custom)
2022-05-22 15:43:27,503 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:27,503 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:27,503 [pool-3826-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/26ba7f85-1247-4f4b-986f-c4fb8a1c93fe does not exist. Creating ...
2022-05-22 15:43:27,513 [pool-3826-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/26ba7f85-1247-4f4b-986f-c4fb8a1c93fe/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:27,513 [pool-3826-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/26ba7f85-1247-4f4b-986f-c4fb8a1c93fe has been successfully formatted.
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C4FB8A1C93FE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:27,514 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:27,520 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 26ba7f85-1247-4f4b-986f-c4fb8a1c93fe, Nodes: 9a9a8948-e89e-4530-b27c-73e7a1307dc8{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37545, RATIS=41195, RATIS_ADMIN=41195, RATIS_SERVER=41195, STANDALONE=41071], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9a9a8948-e89e-4530-b27c-73e7a1307dc8, CreationTimestamp2022-05-22T15:43:24.673Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:27,520 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/26ba7f85-1247-4f4b-986f-c4fb8a1c93fe
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:27,534 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:27,549 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:27,549 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:27,549 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:27,549 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:27,549 [pool-3826-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:27,560 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:27,560 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:27,560 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:27,562 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:27,562 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:27,562 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: start as a follower, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:1], old=null
2022-05-22 15:43:27,590 [pool-3826-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:27,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:27,608 [pool-3826-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState
2022-05-22 15:43:27,623 [pool-3826-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4FB8A1C93FE,id=9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:27,649 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0.
2022-05-22 15:43:27,735 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=26ba7f85-1247-4f4b-986f-c4fb8a1c93fe
2022-05-22 15:43:27,736 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=26ba7f85-1247-4f4b-986f-c4fb8a1c93fe.
2022-05-22 15:43:27,884 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:27,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:28,028 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=d4b35d53-2c8e-4248-8048-57a765679fa0.
2022-05-22 15:43:28,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:28,412 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:28,412 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 close command to datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:28,412 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 close command to datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:28,412 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 close command to datanode c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:28,422 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: d451f14d-141e-4bf0-bcdf-9e28c69a43e8, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:28,422 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=ad7bd58a-6c08-45ff-8812-8cf4b692cf1d close command to datanode a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:28,422 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: ad7bd58a-6c08-45ff-8812-8cf4b692cf1d, Nodes: a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41697, RATIS=34125, RATIS_ADMIN=34125, RATIS_SERVER=34125, STANDALONE=46383], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:28,422 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa
2022-05-22 15:43:28,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:28,519 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:28,520 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=b33389d2-cd81-48e4-be65-b563385f6b43 close command to datanode 56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:43:28,520 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: b33389d2-cd81-48e4-be65-b563385f6b43, Nodes: 56e641d3-eb56-493e-85a5-4bb0b1b5352d{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=45929, RATIS=42763, RATIS_ADMIN=42763, RATIS_SERVER=42763, STANDALONE=39265], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:56e641d3-eb56-493e-85a5-4bb0b1b5352d, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:28,520 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/56e641d3-eb56-493e-85a5-4bb0b1b5352d
2022-05-22 15:43:28,521 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:28,607 [IPC Server handler 11 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:28,607 [IPC Server handler 11 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : cb84caf1-a153-4209-9c1b-eeb875809600{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41049, RATIS=38061, RATIS_ADMIN=38061, RATIS_SERVER=38061, STANDALONE=35665], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:28,612 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:28,612 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=437bf5c8-9d07-41e3-8338-f6e664364ef3 to datanode:cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:28,613 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 437bf5c8-9d07-41e3-8338-f6e664364ef3, Nodes: cb84caf1-a153-4209-9c1b-eeb875809600{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41049, RATIS=38061, RATIS_ADMIN=38061, RATIS_SERVER=38061, STANDALONE=35665], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:28.612Z[Etc/UTC]].
2022-05-22 15:43:28,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 45 milliseconds for processing 0 containers.
2022-05-22 15:43:28,644 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:29,167 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:29,168 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=4, lastRpcResponseTime=4265) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:29,195 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@7fb68a11] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9dd8a712-1e0d-4857-830c-d22a0163750c: Detected pause in JVM or host machine (eg GC): pause of approximately 180104588ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,199 [Listener at 127.0.0.1/39969] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@3ec67c1d{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34679-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5105017481663031274/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:29,203 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@16849745] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-edd315a5-4c31-41f4-a5d0-8e213ccdb1da: Detected pause in JVM or host machine (eg GC): pause of approximately 235286385ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,203 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@2f60f320] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 241423763ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,203 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5a871eae] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 300545209ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2022-05-22 15:43:29,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #1 to datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #2 is under replicated. Expected replica count is 3, but found 1.
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #2 to datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #2 to datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1092)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1446)) - Sending replicate container command for container #3 to datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:29,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:29,205 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:29,207 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@aa6ee36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-951c35ae-fd53-4948-8b06-2e5622a34ffa: Detected pause in JVM or host machine (eg GC): pause of approximately 336647266ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,207 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@40493c39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-c72cb747-71cd-49bf-9573-30515b8c4828: Detected pause in JVM or host machine (eg GC): pause of approximately 344001558ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,208 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3cefacb0] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-1bd1ad93-a217-4aba-aed5-0a262321f6e0: Detected pause in JVM or host machine (eg GC): pause of approximately 360181762ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,211 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@6dcb7cee] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-f32dce45-0ff4-4afd-af37-86dd80543351: Detected pause in JVM or host machine (eg GC): pause of approximately 406661450ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,212 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5cd2b293] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9b2d287e-9c2c-442e-b286-c4ec9a231851: Detected pause in JVM or host machine (eg GC): pause of approximately 436108121ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,212 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@615bc59d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9f373e4e-4e35-4a2f-a705-a71ce933fdce: Detected pause in JVM or host machine (eg GC): pause of approximately 436762329ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,212 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@70e690] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-6c03b4ed-3732-4e8d-ac40-6e00ca884577: Detected pause in JVM or host machine (eg GC): pause of approximately 438010145ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,213 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 is not found
2022-05-22 15:43:29,213 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@33ecdc8c] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-cb84caf1-a153-4209-9c1b-eeb875809600: Detected pause in JVM or host machine (eg GC): pause of approximately 470452655ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,214 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3855531c] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9a9a8948-e89e-4530-b27c-73e7a1307dc8: Detected pause in JVM or host machine (eg GC): pause of approximately 499202718ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,214 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5442ed2b] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-e30a79fb-17da-4f0f-8b7c-18871dbe2f08: Detected pause in JVM or host machine (eg GC): pause of approximately 531934232ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=481ms
2022-05-22 15:43:29,373 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: addNew group-C00B6B8756C0:[951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1] returns group-C00B6B8756C0:java.util.concurrent.CompletableFuture@465cbf1e[Not completed]
2022-05-22 15:43:29,373 [Listener at 127.0.0.1/39969] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@1144d4a0{HTTP/1.1, (http/1.1)}{0.0.0.0:34679}
2022-05-22 15:43:29,373 [Listener at 127.0.0.1/39969] INFO  server.Server (Server.java:doStart(415)) - Started @408753ms
2022-05-22 15:43:29,373 [Listener at 127.0.0.1/39969] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-05-22 15:43:29,374 [Listener at 127.0.0.1/39969] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34679
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: new RaftServerImpl for group-C00B6B8756C0:[951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: ConfigurationManager, init=-1: [951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis] (custom)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:29,375 [pool-3848-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/17457b2b-31d3-432a-9f5a-c00b6b8756c0 does not exist. Creating ...
2022-05-22 15:43:29,380 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:29,380 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:29,380 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:29,381 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(481)) - Ozone container server started.
2022-05-22 15:43:29,383 [pool-3848-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/17457b2b-31d3-432a-9f5a-c00b6b8756c0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:29,391 [pool-3848-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/17457b2b-31d3-432a-9f5a-c00b6b8756c0 has been successfully formatted.
2022-05-22 15:43:29,429 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@586379e2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-05-22 15:43:29,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:29,455 [pool-3848-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C00B6B8756C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:29,456 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:29,457 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/17457b2b-31d3-432a-9f5a-c00b6b8756c0
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:29,458 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:29,465 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:29,466 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:29,466 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:29,466 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:29,466 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:29,469 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/meta/datanode.id
2022-05-22 15:43:29,543 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 17457b2b-31d3-432a-9f5a-c00b6b8756c0, Nodes: 951c35ae-fd53-4948-8b06-2e5622a34ffa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40089, RATIS=34329, RATIS_ADMIN=34329, RATIS_SERVER=34329, STANDALONE=45519], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:951c35ae-fd53-4948-8b06-2e5622a34ffa, CreationTimestamp2022-05-22T15:43:26.349Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:29,543 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:29,552 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:29,552 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:29,552 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:29,552 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:29,619 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:29,620 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:29,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:29,705 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: start as a follower, conf=-1: [951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1], old=null
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:29,706 [pool-3848-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState
2022-05-22 15:43:29,735 [pool-3848-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C00B6B8756C0,id=951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:29,747 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=17457b2b-31d3-432a-9f5a-c00b6b8756c0
2022-05-22 15:43:29,748 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=17457b2b-31d3-432a-9f5a-c00b6b8756c0.
2022-05-22 15:43:29,923 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:30,160 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 is not found
2022-05-22 15:43:30,187 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@6d723c6b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:30,188 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@794ff3e5{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:30,188 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:30,197 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@68d9ef0c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:30,202 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@57b6f462{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:30,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:30,207 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:30,387 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:30,387 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:30,387 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:30,422 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:30,423 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=2, lastRpcResponseTime=5520) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:30,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:30,519 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:30,543 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:30,602 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:30,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:30,688 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5063338156ns, electionTimeout:5039ms
2022-05-22 15:43:30,688 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: shutdown e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState
2022-05-22 15:43:30,688 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:30,688 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:30,688 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197
2022-05-22 15:43:30,715 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197 ELECTION round 0: submit vote requests at term 1 for -1: [e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:30,715 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:30,715 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: shutdown e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197
2022-05-22 15:43:30,715 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:30,716 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-803798AFF3AE with new leaderId: e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:30,728 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: change Leader from null to e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at term 1 for becomeLeader, leader elected after 5559ms
2022-05-22 15:43:30,728 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:30,728 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:30,728 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:30,729 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:30,729 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:30,729 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:30,729 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:30,729 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:30,730 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderStateImpl
2022-05-22 15:43:30,730 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:30,732 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:30,736 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/823edfba-7515-4273-9776-803798aff3ae/current/log_inprogress_0
2022-05-22 15:43:30,804 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE-LeaderElection197] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-803798AFF3AE: set configuration 0: [e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:30,981 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:31,040 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@a74f186{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:31,079 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069870228ns, electionTimeout:5045ms
2022-05-22 15:43:31,079 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: shutdown e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState
2022-05-22 15:43:31,079 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:31,079 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:31,080 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198
2022-05-22 15:43:31,127 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@b0cf05e{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:31,127 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:31,146 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@40c41167{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:31,146 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@469155ac{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:31,159 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - c72cb747-71cd-49bf-9573-30515b8c4828: remove  FOLLOWER c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8:t5, leader=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, voted=edd315a5-4c31-41f4-a5d0-8e213ccdb1da, raftlog=c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLog:OPENED:c0, conf=0: [a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa|rpc:10.1.0.29:34125|dataStream:|priority:0, edd315a5-4c31-41f4-a5d0-8e213ccdb1da|rpc:10.1.0.29:34801|dataStream:|priority:1, c72cb747-71cd-49bf-9573-30515b8c4828|rpc:10.1.0.29:39895|dataStream:|priority:0], old=null RUNNING
2022-05-22 15:43:31,159 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: shutdown
2022-05-22 15:43:31,159 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:31,159 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState
2022-05-22 15:43:31,159 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:31,163 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 is not found
2022-05-22 15:43:31,184 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-9E28C69A43E8: Taking a snapshot at:(t:5, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0
2022-05-22 15:43:31,195 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-9E28C69A43E8: Finished taking a snapshot at:(t:5, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0 took: 11 ms
2022-05-22 15:43:31,195 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:31,195 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:31,196 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: closes. applyIndex: 0
2022-05-22 15:43:31,196 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:31,196 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-SegmentedRaftLogWorker close()
2022-05-22 15:43:31,203 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8
2022-05-22 15:43:31,204 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=d451f14d-141e-4bf0-bcdf-9e28c69a43e8 command on datanode c72cb747-71cd-49bf-9573-30515b8c4828.
2022-05-22 15:43:31,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:31,216 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198 ELECTION round 0: submit vote requests at term 1 for -1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:31,220 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:31,271 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-05-22 15:43:31,285 [c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-9E28C69A43E8-FollowerState was interrupted
2022-05-22 15:43:31,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:31,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:31,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=816, target=10.1.0.29:33727} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSingleNodeWithOpenPipelineCanGotoMaintenance(TestDecommissionAndMaintenance.java:293)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,388 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1133, target=10.1.0.29:35047} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testStoppedDecommissionedNodeTakesSCMStateOnRestart(TestDecommissionAndMaintenance.java:257)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,521 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5126699334ns, electionTimeout:5111ms
2022-05-22 15:43:31,521 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f32dce45-0ff4-4afd-af37-86dd80543351: shutdown f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState
2022-05-22 15:43:31,521 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:31,521 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:31,521 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1029, target=10.1.0.29:36853} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:485)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,551 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:31,556 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(335)) - Attempting to start container services.
2022-05-22 15:43:31,556 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(270)) - Background container scanner has been disabled.
2022-05-22 15:43:31,557 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 38123
2022-05-22 15:43:31,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199 ELECTION round 0: submit vote requests at term 1 for -1: [f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:1], old=null
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f32dce45-0ff4-4afd-af37-86dd80543351: shutdown f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-CABFB8E3F8B9 with new leaderId: f32dce45-0ff4-4afd-af37-86dd80543351
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: change Leader from null to f32dce45-0ff4-4afd-af37-86dd80543351 at term 1 for becomeLeader, leader elected after 5349ms
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:31,557 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:31,558 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:31,558 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:31,558 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:31,559 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:31,559 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:31,559 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:31,559 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderStateImpl
2022-05-22 15:43:31,559 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:31,562 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:31,563 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/da31b700-06ff-4995-bf1a-cabfb8e3f8b9/current/log_inprogress_0
2022-05-22 15:43:31,571 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5038468417ns, electionTimeout:5021ms
2022-05-22 15:43:31,572 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: shutdown 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState
2022-05-22 15:43:31,572 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:31,607 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:31,607 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1141, target=10.1.0.29:41927} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testStoppedDecommissionedNodeTakesSCMStateOnRestart(TestDecommissionAndMaintenance.java:257)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,617 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - cb84caf1-a153-4209-9c1b-eeb875809600: addNew group-F6E664364EF3:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:1] returns group-F6E664364EF3:java.util.concurrent.CompletableFuture@726bb727[Not completed]
2022-05-22 15:43:31,664 [f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9-LeaderElection199] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-CABFB8E3F8B9: set configuration 0: [f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:1], old=null
2022-05-22 15:43:31,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:31,664 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:31,646 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:31,676 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200 ELECTION round 0: submit vote requests at term 1 for -1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1036, target=10.1.0.29:35825} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:485)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,686 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:31,686 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=1266, lastRpcResponseTime=6784) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - cb84caf1-a153-4209-9c1b-eeb875809600: new RaftServerImpl for group-F6E664364EF3:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: ConfigurationManager, init=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis] (custom)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:31,825 [pool-3882-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/437bf5c8-9d07-41e3-8338-f6e664364ef3 does not exist. Creating ...
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=388, target=10.1.0.29:41695} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testContainerIsReplicatedWhenAllNodesGotoMaintenance(TestDecommissionAndMaintenance.java:358)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,838 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start RPC server
2022-05-22 15:43:31,841 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: GrpcService started, listening on 46817
2022-05-22 15:43:31,842 [grpc-default-executor-6] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=809, target=10.1.0.29:40765} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSingleNodeWithOpenPipelineCanGotoMaintenance(TestDecommissionAndMaintenance.java:293)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,868 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685 is started using port 46817 for RATIS
2022-05-22 15:43:31,869 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685 is started using port 46817 for RATIS_ADMIN
2022-05-22 15:43:31,869 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685 is started using port 46817 for RATIS_SERVER
2022-05-22 15:43:31,869 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5b6e6a18] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: Started
2022-05-22 15:43:31,884 [grpc-default-executor-6] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 19803 bytes for container 2
2022-05-22 15:43:31,897 [EndpointStateMachine task thread for /0.0.0.0:35029 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685 is started using port 36559
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=603, target=10.1.0.29:35253} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testMaintenanceEndsAutomaticallyAtTimeout(TestDecommissionAndMaintenance.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:31,920 [pool-3882-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/437bf5c8-9d07-41e3-8338-f6e664364ef3/in_use.lock acquired by nodename 28065@fv-az40-114
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=381, target=10.1.0.29:40569} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testContainerIsReplicatedWhenAllNodesGotoMaintenance(TestDecommissionAndMaintenance.java:358)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:32,013 [pool-3882-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/437bf5c8-9d07-41e3-8338-f6e664364ef3 has been successfully formatted.
2022-05-22 15:43:32,051 [pool-3882-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-F6E664364EF3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:32,052 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/437bf5c8-9d07-41e3-8338-f6e664364ef3
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:32,054 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:32,071 [grpc-default-executor-7] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/replication/work/container-2.tar.gz
2022-05-22 15:43:32,158 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:32,159 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:32,159 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:32,159 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:32,159 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:32,173 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103732225ns, electionTimeout:5094ms
2022-05-22 15:43:32,173 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f32dce45-0ff4-4afd-af37-86dd80543351: shutdown f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState
2022-05-22 15:43:32,173 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:32,173 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:32,173 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-LeaderElection201
2022-05-22 15:43:32,174 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 19803, starting to import.
May 22, 2022 3:43:31 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=608, target=10.1.0.29:39701} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$3(XceiverClientRatis.java:225)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:159)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:210)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:306)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:356)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:104)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testMaintenanceEndsAutomaticallyAtTimeout(TestDecommissionAndMaintenance.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-05-22 15:43:32,178 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: receive requestVote(ELECTION, e30a79fb-17da-4f0f-8b7c-18871dbe2f08, group-57A765679FA0, 1, (t:0, i:0))
2022-05-22 15:43:32,178 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: receive requestVote(ELECTION, e30a79fb-17da-4f0f-8b7c-18871dbe2f08, group-57A765679FA0, 1, (t:0, i:0))
2022-05-22 15:43:32,178 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-CANDIDATE: reject ELECTION from e30a79fb-17da-4f0f-8b7c-18871dbe2f08: already has voted for 9a9a8948-e89e-4530-b27c-73e7a1307dc8 at current term 1
2022-05-22 15:43:32,179 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0 replies to ELECTION vote request: e30a79fb-17da-4f0f-8b7c-18871dbe2f08<-9a9a8948-e89e-4530-b27c-73e7a1307dc8#0:FAIL-t1. Peer's state: 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0:t1, leader=null, voted=9a9a8948-e89e-4530-b27c-73e7a1307dc8, raftlog=9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLog:OPENED:c-1, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:32,180 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:32,180 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:32,180 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:32,180 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:32,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:32,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:32,187 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: receive requestVote(ELECTION, 9a9a8948-e89e-4530-b27c-73e7a1307dc8, group-57A765679FA0, 1, (t:0, i:0))
2022-05-22 15:43:32,187 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: receive requestVote(ELECTION, 9a9a8948-e89e-4530-b27c-73e7a1307dc8, group-57A765679FA0, 1, (t:0, i:0))
2022-05-22 15:43:32,187 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(48)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-CANDIDATE: reject ELECTION from 9a9a8948-e89e-4530-b27c-73e7a1307dc8: already has voted for e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at current term 1
2022-05-22 15:43:32,187 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0 replies to ELECTION vote request: 9a9a8948-e89e-4530-b27c-73e7a1307dc8<-e30a79fb-17da-4f0f-8b7c-18871dbe2f08#0:FAIL-t1. Peer's state: e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0:t1, leader=null, voted=e30a79fb-17da-4f0f-8b7c-18871dbe2f08, raftlog=e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLog:OPENED:c-1, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:32,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:32,255 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 437bf5c8-9d07-41e3-8338-f6e664364ef3, Nodes: cb84caf1-a153-4209-9c1b-eeb875809600{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41049, RATIS=38061, RATIS_ADMIN=38061, RATIS_SERVER=38061, STANDALONE=35665], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:cb84caf1-a153-4209-9c1b-eeb875809600, CreationTimestamp2022-05-22T15:43:28.612Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:32,256 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:32,312 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-CANDIDATE: accept ELECTION from e30a79fb-17da-4f0f-8b7c-18871dbe2f08: our priority 0 <= candidate's priority 1
2022-05-22 15:43:32,312 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: changes role from CANDIDATE to FOLLOWER at term 1 for candidate:e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:32,312 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f32dce45-0ff4-4afd-af37-86dd80543351: shutdown f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-LeaderElection201
2022-05-22 15:43:32,312 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f32dce45-0ff4-4afd-af37-86dd80543351: start f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FollowerState
2022-05-22 15:43:32,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:32,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for cluster to exit safe mode
2022-05-22 15:43:32,388 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:32,392 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0 replies to ELECTION vote request: e30a79fb-17da-4f0f-8b7c-18871dbe2f08<-f32dce45-0ff4-4afd-af37-86dd80543351#0:OK-t1. Peer's state: f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0:t1, leader=null, voted=e30a79fb-17da-4f0f-8b7c-18871dbe2f08, raftlog=f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLog:OPENED:c-1, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:32,392 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-FOLLOWER: reject ELECTION from 9a9a8948-e89e-4530-b27c-73e7a1307dc8: already has voted for e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at current term 1
2022-05-22 15:43:32,392 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0 replies to ELECTION vote request: 9a9a8948-e89e-4530-b27c-73e7a1307dc8<-f32dce45-0ff4-4afd-af37-86dd80543351#0:FAIL-t1. Peer's state: f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0:t1, leader=null, voted=e30a79fb-17da-4f0f-8b7c-18871dbe2f08, raftlog=f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLog:OPENED:c-1, conf=-1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|priority:1], old=null
2022-05-22 15:43:32,396 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-05-22 15:43:32,396 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-05-22 15:43:32,427 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (1) to other datanode
2022-05-22 15:43:32,438 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12286 bytes for container 1
2022-05-22 15:43:32,520 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=ed0d79bc-0e63-4a9b-8384-008ac268cda9]
2022-05-22 15:43:32,520 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: ed0d79bc-0e63-4a9b-8384-008ac268cda9, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1bd1ad93-a217-4aba-aed5-0a262321f6e0, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:32,551 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:32,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: start as a follower, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:1], old=null
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:32,575 [pool-3882-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cb84caf1-a153-4209-9c1b-eeb875809600: start cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState
2022-05-22 15:43:32,638 [pool-3882-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6E664364EF3,id=cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:32,640 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/replication/work/container-1.tar.gz
2022-05-22 15:43:32,640 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198: ELECTION PASSED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:32,640 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: e30a79fb-17da-4f0f-8b7c-18871dbe2f08<-9a9a8948-e89e-4530-b27c-73e7a1307dc8#0:FAIL-t1
2022-05-22 15:43:32,640 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: e30a79fb-17da-4f0f-8b7c-18871dbe2f08<-f32dce45-0ff4-4afd-af37-86dd80543351#0:OK-t1
2022-05-22 15:43:32,640 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-05-22 15:43:32,640 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9a9a8948-e89e-4530-b27c-73e7a1307dc8<-f32dce45-0ff4-4afd-af37-86dd80543351#0:FAIL-t1
2022-05-22 15:43:32,640 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9a9a8948-e89e-4530-b27c-73e7a1307dc8<-e30a79fb-17da-4f0f-8b7c-18871dbe2f08#0:FAIL-t1
2022-05-22 15:43:32,640 [grpc-default-executor-7] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-05-22 15:43:32,643 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=437bf5c8-9d07-41e3-8338-f6e664364ef3
2022-05-22 15:43:32,643 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=437bf5c8-9d07-41e3-8338-f6e664364ef3.
2022-05-22 15:43:32,644 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 12286, starting to import.
2022-05-22 15:43:32,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:32,684 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:32,702 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094117889ns, electionTimeout:5077ms
2022-05-22 15:43:32,702 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: shutdown 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState
2022-05-22 15:43:32,702 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:32,703 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:32,703 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202
2022-05-22 15:43:32,736 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:32,809 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200 ELECTION round 0: result REJECTED
2022-05-22 15:43:32,809 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-05-22 15:43:32,809 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: shutdown 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200
2022-05-22 15:43:32,809 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-LeaderElection200] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-FollowerState
2022-05-22 15:43:32,820 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202 ELECTION round 0: submit vote requests at term 1 for -1: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|priority:1], old=null
2022-05-22 15:43:32,820 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:32,820 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: shutdown 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202
2022-05-22 15:43:32,820 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:32,820 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C4FB8A1C93FE with new leaderId: 9a9a8948-e89e-4530-b27c-73e7a1307dc8
2022-05-22 15:43:32,872 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198 ELECTION round 0: result PASSED
2022-05-22 15:43:32,872 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: shutdown e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198
2022-05-22 15:43:32,872 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:32,873 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-57A765679FA0 with new leaderId: e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:32,873 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: change Leader from null to e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at term 1 for becomeLeader, leader elected after 6903ms
2022-05-22 15:43:32,873 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:32,873 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:32,873 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:32,874 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:32,874 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:32,874 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:32,874 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:32,874 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:32,875 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: change Leader from null to 9a9a8948-e89e-4530-b27c-73e7a1307dc8 at term 1 for becomeLeader, leader elected after 5306ms
2022-05-22 15:43:32,875 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:32,876 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:32,876 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8: start 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderStateImpl
2022-05-22 15:43:32,877 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:32,881 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/26ba7f85-1247-4f4b-986f-c4fb8a1c93fe/current/log_inprogress_0
2022-05-22 15:43:32,883 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:32,883 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:32,884 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:32,897 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE-LeaderElection202] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-C4FB8A1C93FE: set configuration 0: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:1], old=null
2022-05-22 15:43:32,911 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2022-05-22 15:43:32,911 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 1 is replicated.
2022-05-22 15:43:32,912 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: d4b35d53-2c8e-4248-8048-57a765679fa0, Nodes: 9a9a8948-e89e-4530-b27c-73e7a1307dc8{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=37545, RATIS=41195, RATIS_ADMIN=41195, RATIS_SERVER=41195, STANDALONE=41071], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f32dce45-0ff4-4afd-af37-86dd80543351{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=43435, RATIS=34325, RATIS_ADMIN=34325, RATIS_SERVER=34325, STANDALONE=40619], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e30a79fb-17da-4f0f-8b7c-18871dbe2f08{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34253, RATIS_ADMIN=34253, RATIS_SERVER=34253, STANDALONE=38263], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e30a79fb-17da-4f0f-8b7c-18871dbe2f08, CreationTimestamp2022-05-22T15:43:24.768Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(194)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(211)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(251)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:notifyStatusChanged(88)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-05-22 15:43:32,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-05-22 15:43:32,937 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:32,937 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:32,937 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:32,939 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:32,940 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=2, lastRpcResponseTime=8037) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:32,946 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:32,947 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08: start e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderStateImpl
2022-05-22 15:43:32,947 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:32,972 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-0/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/current/log_inprogress_0
2022-05-22 15:43:33,030 [e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0-LeaderElection198] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - e30a79fb-17da-4f0f-8b7c-18871dbe2f08@group-57A765679FA0: set configuration 0: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:33,035 [grpc-default-executor-7] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 19699 bytes for container 3
2022-05-22 15:43:33,036 [grpc-default-executor-6] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/replication/work/container-3.tar.gz
2022-05-22 15:43:33,037 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 19699, starting to import.
2022-05-22 15:43:33,087 [f32dce45-0ff4-4afd-af37-86dd80543351-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-57A765679FA0 with new leaderId: e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:33,087 [f32dce45-0ff4-4afd-af37-86dd80543351-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: change Leader from null to e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at term 1 for appendEntries, leader elected after 6496ms
2022-05-22 15:43:33,128 [f32dce45-0ff4-4afd-af37-86dd80543351-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0: set configuration 0: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:33,129 [f32dce45-0ff4-4afd-af37-86dd80543351-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:33,129 [9a9a8948-e89e-4530-b27c-73e7a1307dc8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-57A765679FA0 with new leaderId: e30a79fb-17da-4f0f-8b7c-18871dbe2f08
2022-05-22 15:43:33,129 [9a9a8948-e89e-4530-b27c-73e7a1307dc8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: change Leader from null to e30a79fb-17da-4f0f-8b7c-18871dbe2f08 at term 1 for appendEntries, leader elected after 6722ms
2022-05-22 15:43:33,131 [f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - f32dce45-0ff4-4afd-af37-86dd80543351@group-57A765679FA0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-1/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/current/log_inprogress_0
2022-05-22 15:43:33,150 [9a9a8948-e89e-4530-b27c-73e7a1307dc8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0: set configuration 0: [9a9a8948-e89e-4530-b27c-73e7a1307dc8|rpc:10.1.0.29:41195|dataStream:|priority:0, f32dce45-0ff4-4afd-af37-86dd80543351|rpc:10.1.0.29:34325|dataStream:|priority:0, e30a79fb-17da-4f0f-8b7c-18871dbe2f08|rpc:10.1.0.29:34253|dataStream:|priority:1], old=null
2022-05-22 15:43:33,150 [9a9a8948-e89e-4530-b27c-73e7a1307dc8-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:33,180 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-05-22 15:43:33,180 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-05-22 15:43:33,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:33,251 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=252f1828-f4b3-439c-a5e2-ff0e293dadae]
2022-05-22 15:43:33,252 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: 252f1828-f4b3-439c-a5e2-ff0e293dadae, Nodes: edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:33,281 [9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9a9a8948-e89e-4530-b27c-73e7a1307dc8@group-57A765679FA0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-2/data/ratis/d4b35d53-2c8e-4248-8048-57a765679fa0/current/log_inprogress_0
2022-05-22 15:43:33,391 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-05-22 15:43:33,391 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Cluster exits safe mode
2022-05-22 15:43:33,391 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:33,468 [IPC Server handler 13 on default port 35029] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:33,468 [IPC Server handler 13 on default port 35029] INFO  node.SCMNodeManager (SCMNodeManager.java:register(393)) - Registered Data node : 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38123, RATIS=46817, RATIS_ADMIN=46817, RATIS_SERVER=46817, STANDALONE=36559], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:33,469 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(272)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-05-22 15:43:33,469 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=a5b74119-3168-484c-bfc3-5bb1371d0eb0 to datanode:9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:33,469 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: a5b74119-3168-484c-bfc3-5bb1371d0eb0, Nodes: 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38123, RATIS=46817, RATIS_ADMIN=46817, RATIS_SERVER=46817, STANDALONE=36559], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:33.469Z[Etc/UTC]].
2022-05-22 15:43:33,470 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 to datanode:951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:33,470 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 to datanode:9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:33,470 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 to datanode:cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:33,470 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 26353f24-4ad7-4c6d-bb7a-9fc4c564ea35, Nodes: 951c35ae-fd53-4948-8b06-2e5622a34ffa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40089, RATIS=34329, RATIS_ADMIN=34329, RATIS_SERVER=34329, STANDALONE=45519], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9e0f6ba6-bbca-42ad-b967-4cd66dfc2685{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38123, RATIS=46817, RATIS_ADMIN=46817, RATIS_SERVER=46817, STANDALONE=36559], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}cb84caf1-a153-4209-9c1b-eeb875809600{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41049, RATIS=38061, RATIS_ADMIN=38061, RATIS_SERVER=38061, STANDALONE=35665], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-22T15:43:33.470Z[Etc/UTC]].
2022-05-22 15:43:33,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:33,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:34,192 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:34,193 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=9290) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:34,211 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:34,211 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:34,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:34,397 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-05-22 15:43:34,397 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Cluster exits safe mode
2022-05-22 15:43:34,397 [Listener at 127.0.0.1/39969] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - SCM became leader
2022-05-22 15:43:34,548 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: addNew group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:0] returns group-9FC4C564EA35:java.util.concurrent.CompletableFuture@4263330d[Not completed]
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: new RaftServerImpl for group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:34,549 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:34,550 [pool-3848-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: ConfigurationManager, init=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:34,550 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis] (custom)
2022-05-22 15:43:34,550 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:34,550 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:34,550 [pool-3848-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 does not exist. Creating ...
2022-05-22 15:43:34,552 [pool-3848-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 has been successfully formatted.
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9FC4C564EA35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:34,553 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:34,555 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:34,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:34,578 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:34,578 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:34,579 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:34,588 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:34,588 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:34,588 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:34,588 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:34,588 [pool-3848-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:34,589 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:34,611 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: start as a follower, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:0], old=null
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:34,612 [pool-3848-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:34,660 [pool-3848-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9FC4C564EA35,id=951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:34,661 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=26353f24-4ad7-4c6d-bb7a-9fc4c564ea35
2022-05-22 15:43:34,667 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: addNew group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0] returns group-9FC4C564EA35:java.util.concurrent.CompletableFuture@774ef33a[Not completed]
2022-05-22 15:43:34,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: new RaftServerImpl for group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: ConfigurationManager, init=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis] (custom)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:34,740 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:34,741 [pool-3908-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 does not exist. Creating ...
2022-05-22 15:43:34,747 [pool-3908-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:34,750 [pool-3908-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 has been successfully formatted.
2022-05-22 15:43:34,755 [pool-3908-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9FC4C564EA35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:34,756 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:34,759 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:34,863 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:34,863 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:34,863 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:34,863 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:34,863 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:34,867 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:34,867 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:34,867 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5161470278ns, electionTimeout:5125ms
2022-05-22 15:43:34,868 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: shutdown 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState
2022-05-22 15:43:34,868 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:34,868 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:34,868 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203
2022-05-22 15:43:34,867 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:34,870 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:34,870 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:34,884 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203 ELECTION round 0: submit vote requests at term 1 for -1: [951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1], old=null
2022-05-22 15:43:34,884 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:34,884 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: shutdown 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203
2022-05-22 15:43:34,884 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:34,884 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C00B6B8756C0 with new leaderId: 951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:34,917 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:34,917 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:34,917 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:34,917 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:34,918 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:34,918 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:34,923 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: change Leader from null to 951c35ae-fd53-4948-8b06-2e5622a34ffa at term 1 for becomeLeader, leader elected after 5428ms
2022-05-22 15:43:34,923 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:34,924 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:34,925 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:34,925 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:34,925 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:34,925 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:34,925 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:34,926 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:34,926 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderStateImpl
2022-05-22 15:43:34,926 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: start as a follower, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:34,927 [pool-3908-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:34,943 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/17457b2b-31d3-432a-9f5a-c00b6b8756c0/current/log_inprogress_0
2022-05-22 15:43:34,966 [pool-3908-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9FC4C564EA35,id=9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:35,127 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0-LeaderElection203] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-C00B6B8756C0: set configuration 0: [951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1], old=null
2022-05-22 15:43:35,166 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - cb84caf1-a153-4209-9c1b-eeb875809600: addNew group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0] returns group-9FC4C564EA35:java.util.concurrent.CompletableFuture@2505df46[Not completed]
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - cb84caf1-a153-4209-9c1b-eeb875809600: new RaftServerImpl for group-9FC4C564EA35:[cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: ConfigurationManager, init=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:35,167 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis] (custom)
2022-05-22 15:43:35,168 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:35,168 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:35,168 [pool-3882-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 does not exist. Creating ...
2022-05-22 15:43:35,171 [pool-3882-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:35,184 [pool-3882-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35 has been successfully formatted.
2022-05-22 15:43:35,184 [pool-3882-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9FC4C564EA35: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:35,184 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:35,185 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:35,185 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:35,185 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:35,185 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:35,185 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:35,186 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:35,187 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:35,187 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:35,187 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:35,190 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:35,190 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:35,190 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:35,190 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:35,191 [pool-3882-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:35,211 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:35,211 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:35,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:35,269 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: start as a follower, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:35,274 [pool-3882-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cb84caf1-a153-4209-9c1b-eeb875809600: start cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:35,275 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:35,328 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: close
2022-05-22 15:43:35,328 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: shutdown
2022-05-22 15:43:35,328 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-008AC268CDA9,id=1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:43:35,328 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-LeaderStateImpl
2022-05-22 15:43:35,328 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:35,330 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:35,330 [pool-3882-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9FC4C564EA35,id=cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:35,330 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-008AC268CDA9: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9/sm/snapshot.1_0
2022-05-22 15:43:35,331 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-008AC268CDA9: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-0/data/ratis/ed0d79bc-0e63-4a9b-8384-008ac268cda9/sm/snapshot.1_0 took: 1 ms
2022-05-22 15:43:35,331 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:35,331 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:35,332 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9: closes. applyIndex: 0
2022-05-22 15:43:35,343 [1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:35,344 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0@group-008AC268CDA9-SegmentedRaftLogWorker close()
2022-05-22 15:43:35,344 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown server with port 39927 now
2022-05-22 15:43:35,364 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 1bd1ad93-a217-4aba-aed5-0a262321f6e0: shutdown server with port 39927 successfully
2022-05-22 15:43:35,371 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3cefacb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-1bd1ad93-a217-4aba-aed5-0a262321f6e0: Stopped
2022-05-22 15:43:35,443 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-05-22 15:43:35,444 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa-GrpcLogAppender: Leader has not got in touch with Follower edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->a16e4f2e-75b1-4b5c-ab7a-2c183aef41fa(c0,m0,n1, attendVote=true, lastRpcSendTime=1251, lastRpcResponseTime=10541) yet, just keep nextIndex unchanged and retry.
2022-05-22 15:43:35,464 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=26353f24-4ad7-4c6d-bb7a-9fc4c564ea35.
2022-05-22 15:43:35,546 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:35,546 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=ed0d79bc-0e63-4a9b-8384-008ac268cda9 close command to datanode 1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:43:35,546 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: ed0d79bc-0e63-4a9b-8384-008ac268cda9, Nodes: 1bd1ad93-a217-4aba-aed5-0a262321f6e0{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=36139, RATIS=39927, RATIS_ADMIN=39927, RATIS_SERVER=39927, STANDALONE=34847], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1bd1ad93-a217-4aba-aed5-0a262321f6e0, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:35,546 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/1bd1ad93-a217-4aba-aed5-0a262321f6e0
2022-05-22 15:43:35,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-05-22 15:43:35,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:36,197 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:36,205 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: close
2022-05-22 15:43:36,206 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: shutdown
2022-05-22 15:43:36,206 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E28C69A43E8,id=edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:36,206 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-LeaderStateImpl
2022-05-22 15:43:36,206 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->c72cb747-71cd-49bf-9573-30515b8c4828-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->c72cb747-71cd-49bf-9573-30515b8c4828-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-05-22 15:43:36,207 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - c72cb747-71cd-49bf-9573-30515b8c4828: Completed APPEND_ENTRIES, lastRequest: edd315a5-4c31-41f4-a5d0-8e213ccdb1da->c72cb747-71cd-49bf-9573-30515b8c4828#1-t5,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:5, i:0), CONFIGURATIONENTRY
2022-05-22 15:43:36,208 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->c72cb747-71cd-49bf-9573-30515b8c4828-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-05-22 15:43:36,208 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8->c72cb747-71cd-49bf-9573-30515b8c4828: nextIndex: updateUnconditionally 1 -> 0
2022-05-22 15:43:36,206 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:36,210 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-9E28C69A43E8: Taking a snapshot at:(t:5, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0
2022-05-22 15:43:36,211 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:36,212 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:36,212 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:36,212 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:36,212 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:36,212 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:36,212 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:36,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:36,212 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-9E28C69A43E8: Finished taking a snapshot at:(t:5, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/d451f14d-141e-4bf0-bcdf-9e28c69a43e8/sm/snapshot.5_0 took: 2 ms
2022-05-22 15:43:36,212 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:36,212 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:36,241 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8: closes. applyIndex: 0
2022-05-22 15:43:36,250 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:36,250 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=252f1828-f4b3-439c-a5e2-ff0e293dadae close command to datanode edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:36,250 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 252f1828-f4b3-439c-a5e2-ff0e293dadae, Nodes: edd315a5-4c31-41f4-a5d0-8e213ccdb1da{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=39117, RATIS=34801, RATIS_ADMIN=34801, RATIS_SERVER=34801, STANDALONE=42931], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:edd315a5-4c31-41f4-a5d0-8e213ccdb1da, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:36,250 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:36,270 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:36,270 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-9E28C69A43E8-SegmentedRaftLogWorker close()
2022-05-22 15:43:36,270 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: shutdown
2022-05-22 15:43:36,270 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF0E293DADAE,id=edd315a5-4c31-41f4-a5d0-8e213ccdb1da
2022-05-22 15:43:36,270 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-LeaderStateImpl
2022-05-22 15:43:36,271 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:36,283 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:36,284 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-FF0E293DADAE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae/sm/snapshot.1_0
2022-05-22 15:43:36,288 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-FF0E293DADAE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-5/data/ratis/252f1828-f4b3-439c-a5e2-ff0e293dadae/sm/snapshot.1_0 took: 4 ms
2022-05-22 15:43:36,288 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:36,288 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:36,289 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE: closes. applyIndex: 0
2022-05-22 15:43:36,289 [edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:36,292 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da@group-FF0E293DADAE-SegmentedRaftLogWorker close()
2022-05-22 15:43:36,292 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown server with port 34801 now
2022-05-22 15:43:36,407 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - edd315a5-4c31-41f4-a5d0-8e213ccdb1da: shutdown server with port 34801 successfully
2022-05-22 15:43:36,415 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@16849745] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-edd315a5-4c31-41f4-a5d0-8e213ccdb1da: Stopped
2022-05-22 15:43:36,430 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: addNew group-5BB1371D0EB0:[9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:1] returns group-5BB1371D0EB0:java.util.concurrent.CompletableFuture@3c5b6db2[Not completed]
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: new RaftServerImpl for group-5BB1371D0EB0:[9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:1] with ContainerStateMachine:uninitialized
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: ConfigurationManager, init=-1: [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:1], old=null, confs=<EMPTY_MAP>
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis] (custom)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-05-22 15:43:36,432 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-05-22 15:43:36,433 [pool-3908-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/a5b74119-3168-484c-bfc3-5bb1371d0eb0 does not exist. Creating ...
2022-05-22 15:43:36,436 [pool-3908-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/a5b74119-3168-484c-bfc3-5bb1371d0eb0/in_use.lock acquired by nodename 28065@fv-az40-114
2022-05-22 15:43:36,438 [pool-3908-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/a5b74119-3168-484c-bfc3-5bb1371d0eb0 has been successfully formatted.
2022-05-22 15:43:36,438 [pool-3908-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-5BB1371D0EB0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-05-22 15:43:36,438 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-05-22 15:43:36,438 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-05-22 15:43:36,439 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-05-22 15:43:36,439 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:36,439 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-05-22 15:43:36,439 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:36,440 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: a5b74119-3168-484c-bfc3-5bb1371d0eb0, Nodes: 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38123, RATIS=46817, RATIS_ADMIN=46817, RATIS_SERVER=46817, STANDALONE=36559], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9e0f6ba6-bbca-42ad-b967-4cd66dfc2685, CreationTimestamp2022-05-22T15:43:33.469Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/a5b74119-3168-484c-bfc3-5bb1371d0eb0
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-05-22 15:43:36,442 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-05-22 15:43:36,445 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-05-22 15:43:36,457 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-05-22 15:43:36,457 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-05-22 15:43:36,457 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:36,457 [pool-3908-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-05-22 15:43:36,458 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: start as a follower, conf=-1: [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:1], old=null
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState
2022-05-22 15:43:36,462 [pool-3908-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BB1371D0EB0,id=9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:36,464 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=a5b74119-3168-484c-bfc3-5bb1371d0eb0
2022-05-22 15:43:36,464 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a5b74119-3168-484c-bfc3-5bb1371d0eb0.
2022-05-22 15:43:36,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:36,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:37,213 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:37,213 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:37,213 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:37,213 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:37,213 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:37,213 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:37,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:37,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:37,570 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:37,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:37,895 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5320390595ns, electionTimeout:5086ms
2022-05-22 15:43:37,896 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cb84caf1-a153-4209-9c1b-eeb875809600: shutdown cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState
2022-05-22 15:43:37,896 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:37,896 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:37,896 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cb84caf1-a153-4209-9c1b-eeb875809600: start cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204
2022-05-22 15:43:37,997 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204 ELECTION round 0: submit vote requests at term 1 for -1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:1], old=null
2022-05-22 15:43:37,997 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - cb84caf1-a153-4209-9c1b-eeb875809600: shutdown cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-F6E664364EF3 with new leaderId: cb84caf1-a153-4209-9c1b-eeb875809600
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: change Leader from null to cb84caf1-a153-4209-9c1b-eeb875809600 at term 1 for becomeLeader, leader elected after 5946ms
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:37,998 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:37,999 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:37,999 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:37,999 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:37,999 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:38,006 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:38,006 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cb84caf1-a153-4209-9c1b-eeb875809600: start cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderStateImpl
2022-05-22 15:43:38,007 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:38,063 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-LeaderElection204] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3: set configuration 0: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:1], old=null
2022-05-22 15:43:38,080 [cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-F6E664364EF3-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/437bf5c8-9d07-41e3-8338-f6e664364ef3/current/log_inprogress_0
2022-05-22 15:43:38,213 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:38,214 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:38,214 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:38,214 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:38,214 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:38,214 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:38,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:38,342 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5cd2b293] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9b2d287e-9c2c-442e-b286-c4ec9a231851: Detected pause in JVM or host machine (eg GC): pause of approximately 103589691ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=15ms
2022-05-22 15:43:38,343 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@615bc59d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9f373e4e-4e35-4a2f-a705-a71ce933fdce: Detected pause in JVM or host machine (eg GC): pause of approximately 103738993ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=15ms
2022-05-22 15:43:38,343 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@70e690] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-6c03b4ed-3732-4e8d-ac40-6e00ca884577: Detected pause in JVM or host machine (eg GC): pause of approximately 103789593ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=15ms
2022-05-22 15:43:38,343 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@33ecdc8c] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-cb84caf1-a153-4209-9c1b-eeb875809600: Detected pause in JVM or host machine (eg GC): pause of approximately 103829194ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=15ms
2022-05-22 15:43:38,343 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5442ed2b] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-e30a79fb-17da-4f0f-8b7c-18871dbe2f08: Detected pause in JVM or host machine (eg GC): pause of approximately 104150098ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=15ms
2022-05-22 15:43:38,491 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:38,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:38,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:39,214 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:39,214 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:39,215 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:39,215 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:39,215 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:39,215 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:39,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:39,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:39,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:39,727 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5115521361ns, electionTimeout:5064ms
2022-05-22 15:43:39,728 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: shutdown 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:39,728 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:39,728 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:39,728 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205
2022-05-22 15:43:39,739 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205 ELECTION round 0: submit vote requests at term 1 for -1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:0], old=null
2022-05-22 15:43:39,744 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: receive requestVote(ELECTION, 951c35ae-fd53-4948-8b06-2e5622a34ffa, group-9FC4C564EA35, 1, (t:0, i:0))
2022-05-22 15:43:39,744 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FOLLOWER: accept ELECTION from 951c35ae-fd53-4948-8b06-2e5622a34ffa: our priority 0 <= candidate's priority 1
2022-05-22 15:43:39,744 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:39,744 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cb84caf1-a153-4209-9c1b-eeb875809600: shutdown cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:39,744 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cb84caf1-a153-4209-9c1b-eeb875809600: start cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:39,744 [cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-FollowerState was interrupted
2022-05-22 15:43:39,752 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: receive requestVote(ELECTION, 951c35ae-fd53-4948-8b06-2e5622a34ffa, group-9FC4C564EA35, 1, (t:0, i:0))
2022-05-22 15:43:39,752 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FOLLOWER: accept ELECTION from 951c35ae-fd53-4948-8b06-2e5622a34ffa: our priority 0 <= candidate's priority 1
2022-05-22 15:43:39,752 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:39,752 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: shutdown 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:39,768 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FollowerState
2022-05-22 15:43:39,769 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35 replies to ELECTION vote request: 951c35ae-fd53-4948-8b06-2e5622a34ffa<-cb84caf1-a153-4209-9c1b-eeb875809600#0:OK-t1. Peer's state: cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35:t1, leader=null, voted=951c35ae-fd53-4948-8b06-2e5622a34ffa, raftlog=cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLog:OPENED:c-1, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:39,770 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-FollowerState was interrupted
2022-05-22 15:43:39,797 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-05-22 15:43:39,797 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 951c35ae-fd53-4948-8b06-2e5622a34ffa<-cb84caf1-a153-4209-9c1b-eeb875809600#0:OK-t1
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205 ELECTION round 0: result PASSED
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: shutdown 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9FC4C564EA35 with new leaderId: 951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: change Leader from null to 951c35ae-fd53-4948-8b06-2e5622a34ffa at term 1 for becomeLeader, leader elected after 5244ms
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:39,798 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:39,799 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:39,799 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:39,799 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:39,799 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:39,799 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:39,800 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(336)) - Pipeline Pipeline[ Id: 26353f24-4ad7-4c6d-bb7a-9fc4c564ea35, Nodes: 951c35ae-fd53-4948-8b06-2e5622a34ffa{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=40089, RATIS=34329, RATIS_ADMIN=34329, RATIS_SERVER=34329, STANDALONE=45519], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9e0f6ba6-bbca-42ad-b967-4cd66dfc2685{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38123, RATIS=46817, RATIS_ADMIN=46817, RATIS_SERVER=46817, STANDALONE=36559], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}cb84caf1-a153-4209-9c1b-eeb875809600{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=41049, RATIS=38061, RATIS_ADMIN=38061, RATIS_SERVER=38061, STANDALONE=35665], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:951c35ae-fd53-4948-8b06-2e5622a34ffa, CreationTimestamp2022-05-22T15:43:33.470Z[Etc/UTC]] moved to OPEN state
2022-05-22 15:43:39,803 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35 replies to ELECTION vote request: 951c35ae-fd53-4948-8b06-2e5622a34ffa<-9e0f6ba6-bbca-42ad-b967-4cd66dfc2685#0:OK-t1. Peer's state: 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35:t1, leader=null, voted=951c35ae-fd53-4948-8b06-2e5622a34ffa, raftlog=9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLog:OPENED:c-1, conf=-1: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:39,806 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:39,809 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-05-22 15:43:39,810 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa: start 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderStateImpl
2022-05-22 15:43:39,811 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:39,823 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-3/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/current/log_inprogress_0
2022-05-22 15:43:39,877 [951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35-LeaderElection205] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 951c35ae-fd53-4948-8b06-2e5622a34ffa@group-9FC4C564EA35: set configuration 0: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:39,951 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9FC4C564EA35 with new leaderId: 951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:39,951 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: change Leader from null to 951c35ae-fd53-4948-8b06-2e5622a34ffa at term 1 for appendEntries, leader elected after 5194ms
2022-05-22 15:43:39,951 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35: set configuration 0: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:39,952 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:39,955 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-9FC4C564EA35-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/current/log_inprogress_0
2022-05-22 15:43:39,956 [cb84caf1-a153-4209-9c1b-eeb875809600-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9FC4C564EA35 with new leaderId: 951c35ae-fd53-4948-8b06-2e5622a34ffa
2022-05-22 15:43:39,956 [cb84caf1-a153-4209-9c1b-eeb875809600-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: change Leader from null to 951c35ae-fd53-4948-8b06-2e5622a34ffa at term 1 for appendEntries, leader elected after 4771ms
2022-05-22 15:43:39,964 [cb84caf1-a153-4209-9c1b-eeb875809600-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35: set configuration 0: [cb84caf1-a153-4209-9c1b-eeb875809600|rpc:10.1.0.29:38061|dataStream:|priority:0, 951c35ae-fd53-4948-8b06-2e5622a34ffa|rpc:10.1.0.29:34329|dataStream:|priority:1, 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:0], old=null
2022-05-22 15:43:39,964 [cb84caf1-a153-4209-9c1b-eeb875809600-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:39,966 [cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - cb84caf1-a153-4209-9c1b-eeb875809600@group-9FC4C564EA35-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-4/data/ratis/26353f24-4ad7-4c6d-bb7a-9fc4c564ea35/current/log_inprogress_0
2022-05-22 15:43:40,215 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:40,215 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:40,215 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:40,216 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:40,216 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:40,216 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:40,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:40,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:40,679 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:40,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:40,864 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@5b40261b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:40,868 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@5a543bf1{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:40,868 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:40,868 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@14eba010{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:40,868 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@6d93acc0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:41,216 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:41,217 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:41,217 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:41,217 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:41,217 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:41,217 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:41,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:41,495 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033417277ns, electionTimeout:5029ms
2022-05-22 15:43:41,496 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: shutdown 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState
2022-05-22 15:43:41,496 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-05-22 15:43:41,496 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-05-22 15:43:41,496 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206
2022-05-22 15:43:41,510 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206 ELECTION round 0: submit vote requests at term 1 for -1: [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|priority:1], old=null
2022-05-22 15:43:41,510 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206 ELECTION round 0: result PASSED (term=1)
2022-05-22 15:43:41,510 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: shutdown 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206
2022-05-22 15:43:41,510 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-05-22 15:43:41,510 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-5BB1371D0EB0 with new leaderId: 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685
2022-05-22 15:43:41,515 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: change Leader from null to 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685 at term 1 for becomeLeader, leader elected after 5071ms
2022-05-22 15:43:41,518 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-05-22 15:43:41,519 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:41,519 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-05-22 15:43:41,520 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: start 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderStateImpl
2022-05-22 15:43:41,521 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker: Starting segment from index:0
2022-05-22 15:43:41,522 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-LeaderElection206] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0: set configuration 0: [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685|rpc:10.1.0.29:46817|dataStream:|priority:1], old=null
2022-05-22 15:43:41,523 [9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 9e0f6ba6-bbca-42ad-b967-4cd66dfc2685@group-5BB1371D0EB0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-afe33d20-2fe8-492e-9244-072a7f487af9/datanode-5/data/ratis/a5b74119-3168-484c-bfc3-5bb1371d0eb0/current/log_inprogress_0
2022-05-22 15:43:41,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:41,609 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:41,646 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@41e81d9{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:41,646 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@2cae2e7a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:41,646 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:41,647 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@38813dac{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:41,647 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@43ff7eb9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:41,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:42,217 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:42,217 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:42,218 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:42,218 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:42,218 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:42,218 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:42,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:42,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:42,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:43,218 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:43,218 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:43,218 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:43,218 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:43,219 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-05-22 15:43:43,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1125)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1089)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:430)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-05-22 15:43:43,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:43,232 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=ec4c1daa-d486-44a6-8c53-304440fff12b]
2022-05-22 15:43:43,232 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(410)) - Pipeline Pipeline[ Id: ec4c1daa-d486-44a6-8c53-304440fff12b, Nodes: c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c72cb747-71cd-49bf-9573-30515b8c4828, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] moved to CLOSED state
2022-05-22 15:43:43,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:43,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:44,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:44,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:44,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:44,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:44,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:44,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:45,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:45,220 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:45,220 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:45,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:45,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:43:45,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:45,892 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(356)) - Attempting to stop container services.
2022-05-22 15:43:45,894 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - c72cb747-71cd-49bf-9573-30515b8c4828: close
2022-05-22 15:43:45,894 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: shutdown
2022-05-22 15:43:45,894 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-304440FFF12B,id=c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:45,895 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-LeaderStateImpl
2022-05-22 15:43:45,895 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-PendingRequests: sendNotLeaderResponses
2022-05-22 15:43:45,896 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-304440FFF12B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b/sm/snapshot.1_0
2022-05-22 15:43:45,897 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater: set stopIndex = 0
2022-05-22 15:43:45,900 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-304440FFF12B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-eca0c91b-45fe-4c39-a8af-9767de1249ff/datanode-4/data/ratis/ec4c1daa-d486-44a6-8c53-304440fff12b/sm/snapshot.1_0 took: 4 ms
2022-05-22 15:43:45,900 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater: Took a snapshot at index 0
2022-05-22 15:43:45,900 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-05-22 15:43:45,900 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B: closes. applyIndex: 0
2022-05-22 15:43:45,904 [c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-05-22 15:43:45,905 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - c72cb747-71cd-49bf-9573-30515b8c4828@group-304440FFF12B-SegmentedRaftLogWorker close()
2022-05-22 15:43:45,905 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown server with port 39895 now
2022-05-22 15:43:45,961 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - c72cb747-71cd-49bf-9573-30515b8c4828: shutdown server with port 39895 successfully
2022-05-22 15:43:45,962 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@40493c39] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-c72cb747-71cd-49bf-9573-30515b8c4828: Stopped
2022-05-22 15:43:46,227 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:46,228 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:46,228 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:46,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:46,272 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-05-22 15:43:46,273 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=ec4c1daa-d486-44a6-8c53-304440fff12b close command to datanode c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:46,273 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: ec4c1daa-d486-44a6-8c53-304440fff12b, Nodes: c72cb747-71cd-49bf-9573-30515b8c4828{ip: 10.1.0.29, host: fv-az40-114.rqf5bxgtie1u1lrk4cuotvq0td.cx.internal.cloudapp.net, ports: [REPLICATION=38803, RATIS=39895, RATIS_ADMIN=39895, RATIS_SERVER=39895, STANDALONE=35729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c72cb747-71cd-49bf-9573-30515b8c4828, CreationTimestamp2022-05-22T15:43:13.609Z[Etc/UTC]] removed.
2022-05-22 15:43:46,273 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/c72cb747-71cd-49bf-9573-30515b8c4828
2022-05-22 15:43:46,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:46,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:47,228 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:47,228 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:47,228 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:47,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:47,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:47,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:48,198 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-05-22 15:43:48,231 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:48,231 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:48,231 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:48,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-05-22 15:43:48,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:48,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:49,233 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:49,233 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:49,233 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:49,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:49,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:49,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:50,234 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:50,234 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:50,234 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:50,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:50,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:50,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:51,234 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #1, no healthy replica found.
2022-05-22 15:43:51,235 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #2, no healthy replica found.
2022-05-22 15:43:51,235 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1121)) - Cannot replicate container #3, no healthy replica found.
2022-05-22 15:43:51,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-05-22 15:43:51,368 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(569)) - Ozone container server stopped.
2022-05-22 15:43:51,391 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@451d50df{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-05-22 15:43:51,438 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@5f567a56{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-05-22 15:43:51,438 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:51,439 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@549b099f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-05-22 15:43:51,439 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@5914a04{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:51,452 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(545)) - Stopping the StorageContainerManager
2022-05-22 15:43:51,452 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1441)) - Stopping Container Balancer service.
2022-05-22 15:43:51,452 [Mini-Cluster-Provider-Reap] INFO  balancer.ContainerBalancer (ContainerBalancer.java:stopBalancer(923)) - Container Balancer is not running.
2022-05-22 15:43:51,452 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1448)) - Stopping Replication Manager Service.
2022-05-22 15:43:51,452 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-05-22 15:43:51,455 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1455)) - Stopping the Datanode Admin Monitor.
2022-05-22 15:43:51,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-05-22 15:43:51,455 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1462)) - Stopping Lease Manager of the command watchers
2022-05-22 15:43:51,455 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1469)) - Stopping datanode service RPC server
2022-05-22 15:43:51,462 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(400)) - Stopping the RPC server for DataNodes
2022-05-22 15:43:51,469 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 33345
2022-05-22 15:43:51,572 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:51,579 [IPC Server listener on 33345] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 33345
2022-05-22 15:43:51,602 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(815)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-05-22 15:43:51,602 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1477)) - Stopping block service RPC server
2022-05-22 15:43:51,602 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-05-22 15:43:51,603 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 42521
2022-05-22 15:43:51,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:51,612 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1484)) - Stopping the StorageContainerLocationProtocol RPC server
2022-05-22 15:43:51,612 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-05-22 15:43:51,612 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:51,615 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 39533
2022-05-22 15:43:51,631 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1491)) - Stopping Storage Container Manager HTTP server.
2022-05-22 15:43:51,631 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-05-22 15:43:51,632 [IPC Server listener on 39533] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 39533
2022-05-22 15:43:51,654 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@4e0139{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-05-22 15:43:51,655 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@2446be5f{HTTP/1.1, (http/1.1)}{0.0.0.0:39627}
2022-05-22 15:43:51,656 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-05-22 15:43:51,656 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@77604a86{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-05-22 15:43:51,656 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@62977afb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-05-22 15:43:51,663 [IPC Server listener on 42521] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 42521
2022-05-22 15:43:51,669 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1502)) - Stopping Block Manager Service.
2022-05-22 15:43:51,669 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:43:51,671 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-05-22 15:43:51,672 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1529)) - Stopping SCM Event Queue.
2022-05-22 15:43:51,696 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1540)) - Stopping SCM HA services.
2022-05-22 15:43:51,696 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - Stopping RatisPipelineUtilsThread.
2022-05-22 15:43:51,699 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(177)) - RatisPipelineUtilsThread is interrupted.
2022-05-22 15:43:51,702 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:stop(143)) - Stopping BackgroundPipelineScrubber Service.
2022-05-22 15:43:51,702 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1550)) - Stopping SCM MetadataStore.
2022-05-22 15:43:51,703 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2022-05-22 15:43:51,706 [PipelineScrubberThread] WARN  pipeline.BackgroundPipelineScrubber (BackgroundPipelineScrubber.java:run(164)) - PipelineScrubberThread is interrupted, exit
2022-05-22 15:43:51,714 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2022-05-22 15:43:51,716 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2022-05-22 15:43:51,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:52,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:52,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:52,854 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@3855531c] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9a9a8948-e89e-4530-b27c-73e7a1307dc8: Detected pause in JVM or host machine (eg GC): pause of approximately 108873110ns. No GCs detected.
2022-05-22 15:43:53,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:53,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:54,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:54,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:55,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:55,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:56,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:56,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:57,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:57,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:58,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:58,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:59,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:43:59,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:00,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:00,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:01,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:01,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:02,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:02,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:03,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:03,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:04,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:04,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:05,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:05,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:06,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:06,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:07,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:07,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:08,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:08,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:09,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:09,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:10,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:44:10,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:11,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:11,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:12,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:12,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:13,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:13,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:44:14,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:14,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:15,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:15,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:16,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:16,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:17,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:17,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:18,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:18,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:19,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:19,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:20,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:20,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:21,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:21,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:22,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:44:22,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:23,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:23,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:24,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:24,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:25,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:25,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:26,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:26,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:27,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:27,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:28,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:28,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:29,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:29,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:30,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:30,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:44:31,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:31,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:32,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:32,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:33,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:33,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:34,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:34,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:35,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:35,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:36,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:36,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:37,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:37,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:38,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:38,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:44:39,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:39,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:40,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:40,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:41,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:41,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:42,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:42,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:43,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:43,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:44,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:44,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:45,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:45,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:46,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:46,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:47,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:47,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:48,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:48,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:49,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:49,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:50,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:50,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:51,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:51,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:52,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:52,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:53,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:53,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:54,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:54,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:55,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:55,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:56,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:56,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:57,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:57,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:58,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:58,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:59,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:44:59,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:00,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:00,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:01,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:01,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:45:02,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:02,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:03,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:03,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:04,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:04,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:05,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:05,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:06,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:06,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:07,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:07,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:08,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:08,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:09,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:09,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:10,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:10,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:11,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:11,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:12,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:12,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:13,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:13,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:45:14,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:14,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:15,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:15,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:16,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:16,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:17,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:17,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:18,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:18,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:19,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:19,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:20,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:20,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:21,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:21,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:22,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:22,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:23,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:23,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:24,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:24,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:25,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:25,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:26,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:26,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:27,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:27,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:28,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:28,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:29,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:45:29,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:30,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:30,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:31,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:31,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:32,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:32,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:33,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:33,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:34,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:34,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:35,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:35,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:36,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:36,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:37,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:37,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:38,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:38,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:39,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:39,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:40,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:40,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:41,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:41,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:42,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:42,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:43,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:43,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:44,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:44,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:45,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:45,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:46,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:46,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:47,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:47,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:48,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:49,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:49,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:50,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:50,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:51,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:51,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:52,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:52,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:53,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:45:53,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:54,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:54,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:55,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:45:55,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:56,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:56,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:57,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:57,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:58,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:58,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:59,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:45:59,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:00,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:00,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:01,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:01,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:02,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:02,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:03,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:03,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:04,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:04,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:05,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:05,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:06,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:06,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:07,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:07,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:08,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:08,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:09,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:09,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:10,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:10,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:11,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:11,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 3 milliseconds for processing 0 containers.
2022-05-22 15:46:12,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:12,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:13,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:13,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:14,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:14,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:15,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:15,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:16,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:16,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:17,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:17,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:18,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:18,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:19,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:19,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:20,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:20,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:21,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:21,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:22,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:22,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:23,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:23,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:24,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:24,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:25,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:25,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:26,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:26,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:27,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:27,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:28,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:28,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:29,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:29,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:30,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:30,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:31,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:31,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:32,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:32,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:33,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:33,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:34,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:34,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:35,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:35,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:36,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:36,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:37,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:37,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:38,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:38,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:39,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:39,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:40,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:46:40,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:41,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:41,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:42,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:42,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:43,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:43,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:44,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:44,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:45,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:45,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:46,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:46,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:47,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:47,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:48,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:48,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:49,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:49,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:50,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:50,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:51,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:51,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:52,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:52,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:53,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:53,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:54,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:54,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:55,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:55,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:56,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:56,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:57,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:57,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:58,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:58,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:59,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:46:59,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:00,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:00,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:01,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:01,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:02,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:02,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:03,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:03,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:04,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:04,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:05,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:05,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:06,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:06,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:07,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:07,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:08,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:08,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:09,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:09,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:10,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:10,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:11,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:11,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:12,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:12,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:13,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:13,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:14,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:47:14,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:15,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:15,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:16,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:16,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:17,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:17,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:18,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:18,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:19,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:19,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:20,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:20,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:21,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:21,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:22,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:47:22,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:23,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:23,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:24,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:24,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:25,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:25,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:26,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:26,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:27,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:27,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:28,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:28,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:29,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:29,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:30,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:30,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:31,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:31,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:32,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:32,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:33,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:33,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:34,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:34,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:35,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:35,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:36,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:36,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:47:37,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:37,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:38,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:38,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:39,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:47:39,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:40,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:40,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:41,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:41,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:42,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:42,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:43,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:43,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:44,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:44,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:45,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:45,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:46,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:46,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:47,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:47,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:47:48,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:48,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:49,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:49,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:50,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:50,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:51,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:51,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:52,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:52,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:53,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:53,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:54,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:54,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:55,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:55,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:56,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:56,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:57,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:57,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:58,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:58,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:59,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:47:59,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:00,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:48:00,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:01,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:01,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:02,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:02,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:03,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:03,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:04,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:04,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:05,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:05,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:06,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:06,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:07,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:07,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:08,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:08,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:09,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:09,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:10,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:10,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:11,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:11,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:12,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:12,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:13,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:13,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:14,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:14,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:15,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:15,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:16,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:16,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:17,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:17,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:18,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:18,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:19,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:19,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:20,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:20,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:21,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:21,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:22,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:22,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:23,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:23,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:24,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:24,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:25,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:25,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:48:26,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:26,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:27,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:27,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:28,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:28,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:29,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:29,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:30,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:30,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:31,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:31,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:32,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:32,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:33,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:33,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:34,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:34,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:35,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:35,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:36,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:36,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:37,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:37,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:38,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:38,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:39,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:39,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:40,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:40,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:41,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:41,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:42,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:42,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:43,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:43,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:44,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:44,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:45,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:45,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:46,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:46,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:47,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:47,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:48,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:48,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:49,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:49,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:50,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:50,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:51,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:51,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:52,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:52,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:53,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:48:53,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:54,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:54,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:48:55,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:55,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:56,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:56,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:57,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:57,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:58,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:58,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:59,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:48:59,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:00,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:00,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:01,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:01,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:02,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:02,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:03,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:03,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:04,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:49:04,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:05,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:05,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:06,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:06,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:07,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:07,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:08,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:08,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:09,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:09,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:10,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:10,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:11,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:11,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:12,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:12,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:13,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:13,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:14,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:14,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:15,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:15,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:16,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:16,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:17,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:17,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:18,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:18,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:19,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:19,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:49:20,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:20,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:21,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:21,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:22,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:22,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:23,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:23,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:24,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:24,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:25,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:25,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:26,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:26,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:27,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:27,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:28,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:28,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:29,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:29,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:30,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:30,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:31,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:31,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:32,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:33,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:33,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:34,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:34,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:35,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:35,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:36,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:36,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:37,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:37,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:38,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:38,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:39,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:39,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:40,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:40,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:41,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:41,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:42,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:42,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:43,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:43,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:44,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:44,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:45,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:49:45,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:46,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:46,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:47,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:47,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:48,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:48,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:49,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:49,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:50,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:50,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:51,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:51,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:52,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:52,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:53,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:53,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:54,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:54,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:55,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:55,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:56,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:56,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:57,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:57,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:58,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:58,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:59,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:49:59,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:00,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:00,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 4 milliseconds for processing 0 containers.
2022-05-22 15:50:01,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:01,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:02,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:02,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:03,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:03,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:04,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:04,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:05,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:05,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:06,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:06,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:07,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:07,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:08,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:08,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:09,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:09,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:10,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:10,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:11,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:11,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:12,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:12,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:13,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:13,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:14,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:14,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:15,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:15,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:16,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:16,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:17,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:17,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:18,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:18,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:19,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:19,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:20,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:20,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:21,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:21,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:22,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:22,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:23,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:23,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:24,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:24,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:25,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:25,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:26,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:26,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:27,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:27,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:28,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:28,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:29,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:29,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:30,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:30,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:31,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:31,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:32,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:32,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:33,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:33,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:34,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:34,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:35,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:35,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:36,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:36,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:37,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:37,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:38,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:38,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:39,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:39,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:40,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:40,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:41,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:41,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:42,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:42,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:43,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:43,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:44,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:44,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:45,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:45,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:46,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:46,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:47,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:47,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:48,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:48,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:49,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:49,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:50,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:50,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:51,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:51,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:52,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:52,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:53,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:53,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:54,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:54,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:55,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:55,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:50:56,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:56,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:57,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:57,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:58,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:58,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:59,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:50:59,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:00,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:00,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:01,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:01,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:02,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:02,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:03,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:03,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:04,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:04,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:05,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:05,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:06,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:06,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:07,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:07,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:08,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:08,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:09,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:09,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:10,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:10,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:11,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:11,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:12,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:12,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:13,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:13,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:14,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:14,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:15,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:15,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:16,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:16,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:17,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:17,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:18,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:18,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:19,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:19,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:20,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:20,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:21,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:21,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:22,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:22,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:23,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:23,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:24,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:24,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:25,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:25,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:26,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:26,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:27,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:27,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:28,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:28,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:29,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:29,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:30,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:30,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:31,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:31,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:32,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:32,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:33,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:33,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:34,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:34,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:35,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:35,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:36,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:36,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:37,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:37,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:38,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:38,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:39,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:39,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:40,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:40,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:41,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:41,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:42,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:42,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:43,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:51:43,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:44,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:44,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:45,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:45,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:46,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:46,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:47,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:47,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:48,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:48,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:49,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:49,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:50,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:50,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:51,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:51,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:52,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:52,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:53,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:53,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:54,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:54,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:55,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:55,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:56,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:56,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:57,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:57,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:58,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:58,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:59,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:51:59,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:00,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:00,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:01,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:01,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:02,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:02,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:03,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:03,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:04,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:04,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:05,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:05,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:06,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:06,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:07,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:07,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:08,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:08,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:09,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:09,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:10,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:10,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:11,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:11,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:12,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:12,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:13,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:13,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:14,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:14,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:15,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:15,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:16,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:16,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:17,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:17,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:18,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:18,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:19,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:19,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:20,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:20,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:21,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:21,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:22,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:22,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:23,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:23,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:24,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:24,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:25,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:25,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:26,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:26,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:27,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:27,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:28,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:28,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:29,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:29,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:30,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:30,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:31,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:31,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:32,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:32,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:33,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:33,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:34,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:34,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:35,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:35,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:36,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:36,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:37,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:37,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:38,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:38,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:39,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:39,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:40,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:40,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:41,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:41,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:42,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:42,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:43,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:43,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:44,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:44,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:45,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:45,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:46,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:46,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:47,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:47,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:48,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:48,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:49,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:49,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:50,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:50,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:51,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:51,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:52,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:52,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:53,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:53,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:54,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:54,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:55,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:55,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:56,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:56,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:57,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:57,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:52:58,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:58,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:59,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:52:59,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:00,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:00,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:01,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:01,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:02,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:02,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:03,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:03,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:04,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:04,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:05,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:05,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:06,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:06,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:07,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:07,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:08,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:08,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:09,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:09,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:10,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:10,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:11,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:11,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:12,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:12,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:13,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:13,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:14,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:14,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:15,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:15,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:16,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:16,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:17,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:17,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:18,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:18,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:19,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:19,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:20,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:20,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:21,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:21,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:22,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:22,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:23,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:23,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:24,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:24,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:25,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:25,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:26,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:26,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:27,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:27,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:28,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:28,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:29,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:29,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:30,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:30,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:31,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:31,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:32,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:32,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:33,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:33,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:34,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:34,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:35,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:35,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:36,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:36,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:37,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:37,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:38,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:38,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:39,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:39,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:40,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:40,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:41,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:41,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:42,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:42,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:43,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:43,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:44,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:44,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:45,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:45,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:46,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:46,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:47,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:47,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:48,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:48,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:49,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:49,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:50,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:50,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:51,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:51,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:52,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:52,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:53,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:53,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:54,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:54,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:55,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:55,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:56,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:56,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:53:57,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:57,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:58,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:58,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:59,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:53:59,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:00,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:00,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:01,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:01,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:02,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:02,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:03,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:03,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:04,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:04,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:05,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:05,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:06,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:06,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:07,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:07,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:08,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:08,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:09,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:09,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:10,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:10,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:11,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:11,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:12,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:12,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:13,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:13,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:14,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:14,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:15,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:15,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:16,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:16,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:17,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:17,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:18,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:18,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:19,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:19,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:20,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:20,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:21,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:21,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:22,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:22,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:23,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:23,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:24,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:24,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:25,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:25,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:26,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:26,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:27,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:27,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:28,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:28,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:29,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:29,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:30,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:30,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:31,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:31,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:32,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:32,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:33,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:33,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:34,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:34,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:35,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:35,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:36,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:36,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:37,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:37,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:38,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:38,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:39,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:39,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:40,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:40,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:41,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:41,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:42,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:42,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:43,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:43,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:44,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:44,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:45,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:45,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:46,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:46,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:47,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:47,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:48,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:48,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:49,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:49,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:50,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:50,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:51,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:51,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:52,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:52,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:53,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:54:53,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:54,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:54,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:55,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:55,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:56,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:56,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:57,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:57,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:58,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:58,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:59,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:54:59,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:00,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:00,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:01,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:01,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:02,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:02,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:03,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:03,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:04,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:04,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:05,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:05,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:06,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:06,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:07,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:07,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:08,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:08,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:09,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:09,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:10,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:10,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:11,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:11,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:12,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:12,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:13,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:13,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:14,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:14,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:15,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:15,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:16,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:16,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:17,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:17,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:18,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:18,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:19,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:19,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:20,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:20,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:21,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:21,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:22,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:22,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:23,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:23,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:24,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:24,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:25,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:25,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:26,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:26,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:27,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:27,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:28,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:28,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:29,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:29,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:30,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:30,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:31,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:31,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:32,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:32,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:33,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:33,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:34,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:34,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:35,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:35,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:36,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:36,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:37,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:37,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:38,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:38,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:39,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:39,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:40,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:40,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:41,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:41,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:42,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:42,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:43,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:43,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:44,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:44,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:45,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:45,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:46,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:46,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:47,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:47,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:48,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:48,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:49,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:55:49,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:50,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:50,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:51,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:51,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:52,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:52,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:53,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:53,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:54,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:54,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:55,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:55,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:56,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:56,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:57,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:57,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:58,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:58,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:59,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:55:59,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:00,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:00,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:01,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:01,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:02,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:02,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:03,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:03,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:04,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:04,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:05,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:05,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:06,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:06,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:07,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:07,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:08,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:08,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:09,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:09,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:10,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:10,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:11,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:11,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:12,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:12,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:13,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:13,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:14,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:14,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:15,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:15,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:16,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:16,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:17,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:17,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:18,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:18,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:19,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:19,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:20,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:20,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:21,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:21,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:22,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:22,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:23,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:23,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:24,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:24,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:25,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:25,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:26,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:26,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:27,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:27,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:28,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:28,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:29,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:29,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:30,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:30,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:31,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:31,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:32,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:32,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:33,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:33,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:34,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:34,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:35,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:35,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:36,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:36,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:37,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:37,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:38,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:38,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:39,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:39,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:40,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:40,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:41,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:41,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:42,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:42,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:43,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:43,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:44,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:44,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:45,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:45,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:46,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:46,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:47,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:47,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:48,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:48,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:49,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:49,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:50,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:50,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:51,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:51,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:52,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:52,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:53,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:53,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:54,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:54,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:55,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:55,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:56,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:56:56,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:57,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:57,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:58,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:58,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:59,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:56:59,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:00,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:00,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:01,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:01,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:02,374 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5b6e6a18] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-9e0f6ba6-bbca-42ad-b967-4cd66dfc2685: Detected pause in JVM or host machine (eg GC): pause of approximately 120354524ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-05-22 15:57:02,374 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$702/2064598138@5442ed2b] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-e30a79fb-17da-4f0f-8b7c-18871dbe2f08: Detected pause in JVM or host machine (eg GC): pause of approximately 120632327ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-05-22 15:57:02,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:02,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:03,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:03,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:04,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:04,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:05,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:05,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:06,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:06,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:07,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:07,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:08,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:08,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:09,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:09,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:10,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:10,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:11,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:11,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:12,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:12,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:13,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:13,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:14,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:14,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:15,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:15,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:16,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:16,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:17,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:17,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:18,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:18,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:19,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:19,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:20,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:20,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:21,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:21,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:22,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:22,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:23,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:23,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:24,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:24,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:25,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:25,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:26,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:57:26,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:27,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:27,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:57:28,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:28,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:29,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:29,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:30,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:30,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:31,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:31,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:32,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:32,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:33,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:33,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:34,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:34,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:35,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:35,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:36,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:36,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:37,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:37,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:38,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:38,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:39,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:39,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:40,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:57:40,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:41,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:41,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:42,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:42,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:43,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:43,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:44,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:44,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:45,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:45,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:46,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:46,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:47,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:47,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:48,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:48,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:49,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:49,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:50,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:57:50,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:51,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:57:51,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:52,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:52,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:53,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:53,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:54,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:54,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:55,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:55,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:56,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:56,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:57,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:57,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:58,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:58,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:59,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:57:59,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:00,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:00,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:01,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:01,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:02,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:02,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:03,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:03,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:04,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:04,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:05,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:05,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:06,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:06,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:07,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:07,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:08,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:08,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:09,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:09,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:10,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:10,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:11,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:11,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:12,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:12,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:13,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:13,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:14,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:14,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:15,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:15,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:16,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:16,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:17,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:17,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:18,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:18,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:19,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:19,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:20,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:20,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:21,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:21,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:22,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:22,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:23,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:23,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:24,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:24,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:25,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:25,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:26,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:26,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:27,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:27,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:28,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:28,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:29,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:29,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:30,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:30,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:31,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:31,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:32,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:32,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:33,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:33,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:34,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:34,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:35,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:35,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:36,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:36,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:37,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:37,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:38,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:38,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:39,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:39,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:40,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:40,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:41,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:41,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:42,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:42,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:43,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:43,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:44,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:44,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:45,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:45,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:46,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:46,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:47,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:47,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:48,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:48,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:49,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:49,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:50,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:50,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:51,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:51,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:58:52,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:52,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:53,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:53,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:54,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:54,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:55,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:55,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:56,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:56,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:57,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:57,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:58,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:58,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:59,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:58:59,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:00,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:00,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:01,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:01,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:02,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:02,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:03,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:03,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:04,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:04,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:05,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:05,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:06,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:06,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:07,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:07,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:08,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:08,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:09,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:09,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:10,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:10,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:11,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:11,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:12,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:12,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:13,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:13,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:14,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:14,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:15,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:15,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:16,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:16,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:17,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:17,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:18,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:18,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:19,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:19,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:20,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:20,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:21,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:21,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:22,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:22,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:59:23,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:23,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:24,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:24,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:25,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:25,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:26,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:26,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:27,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:27,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:28,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:28,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:29,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:29,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:30,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:30,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:31,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:31,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:32,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:59:32,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:33,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:33,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:34,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:34,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:35,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:35,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:36,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:36,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:37,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:37,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:38,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:38,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:39,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:39,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:40,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 15:59:40,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:41,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:41,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:42,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:42,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:43,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:43,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:44,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:44,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:45,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:45,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:46,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:46,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:47,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:47,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:48,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:48,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:49,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:49,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:50,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:50,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:51,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:51,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:52,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:52,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:53,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:53,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:54,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:54,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:55,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:55,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:56,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:56,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:57,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:57,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:58,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:58,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:59,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 15:59:59,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:00,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:00,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:01,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:01,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:02,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:02,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:03,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:03,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:04,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:04,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:05,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:05,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:06,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:06,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:07,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:07,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:08,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:08,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:09,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:09,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:10,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:10,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:11,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:11,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:12,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:12,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:13,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:13,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:14,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:14,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:15,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:15,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:16,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:16,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:17,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:17,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:18,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:18,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:19,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:19,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:20,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:20,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:21,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:21,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:22,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:22,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:23,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:23,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:24,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:24,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:25,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:25,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:26,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:26,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:27,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:27,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:28,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:28,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:29,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:29,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:30,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:30,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:31,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:31,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:32,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:32,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:33,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:33,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:34,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:34,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:35,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:35,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:36,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:36,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:37,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:37,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:38,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:38,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:39,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:39,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:40,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:40,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:41,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:41,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:42,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:42,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:43,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:43,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:44,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:44,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:45,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:45,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:46,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:46,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:47,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:47,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:48,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:48,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:49,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:49,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:50,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:50,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:51,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:51,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:52,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:52,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:53,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:53,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:54,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:54,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:55,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:55,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:56,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:00:56,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:57,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:57,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:58,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:58,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:59,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:00:59,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:00,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:00,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:01,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:01,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:02,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:02,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:03,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:03,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:04,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:04,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:05,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:05,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:06,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:06,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:07,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:07,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:08,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:08,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:09,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:09,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:10,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:10,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:11,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:11,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:12,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:12,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:13,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:13,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:14,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:14,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:15,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:15,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:16,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:16,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:17,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:17,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:18,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:18,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:19,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:19,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:20,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:20,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:21,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:21,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:22,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:22,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:23,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:23,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:24,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:24,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:25,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:25,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:26,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:26,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:27,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:27,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:28,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:28,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:29,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:29,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:30,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:30,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:31,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:31,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:32,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:32,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:33,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:33,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:34,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:34,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:35,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:35,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:36,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:36,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:37,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:37,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:38,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:38,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:39,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:39,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:40,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:40,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:41,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:41,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:42,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:42,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:43,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:43,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:44,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:44,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:45,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:45,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:46,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:46,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:47,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:47,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:48,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:48,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:49,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:49,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:50,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:50,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:51,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:51,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:52,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:52,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:53,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:53,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:54,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:54,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:55,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:55,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:56,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:56,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:57,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:57,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:58,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:58,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:01:59,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:01:59,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:00,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:00,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:01,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:01,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:02,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:02,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:03,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:03,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:04,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:04,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:05,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:05,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:06,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:06,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:07,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:07,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:08,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:08,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:09,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:09,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:10,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:10,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:11,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:11,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:12,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:12,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:13,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:13,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:14,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:14,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:15,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:15,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:16,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:16,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:17,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:17,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:18,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:18,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:19,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:19,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:20,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:20,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:21,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:21,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:22,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:22,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:23,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:23,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:24,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:24,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:25,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:25,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:26,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:26,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:27,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:27,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:28,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:28,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:29,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:29,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:30,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:30,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:31,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:31,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:02:32,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:32,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:33,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:33,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:34,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:34,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:35,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:35,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:36,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:36,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:37,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:02:37,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:38,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:38,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:39,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:39,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:40,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:40,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:41,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:41,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:42,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:42,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:43,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:43,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:44,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:44,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:45,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:45,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:46,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:02:46,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:47,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:47,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:48,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:48,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:49,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:49,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:50,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:50,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:51,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:51,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:52,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:52,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:53,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:53,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:54,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:54,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:55,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:55,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:56,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:56,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:57,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:57,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:58,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:58,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:59,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:02:59,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:03:00,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:00,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:01,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:01,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:02,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:02,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:03,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:03,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:04,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:04,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:05,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:05,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:06,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:06,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:07,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:07,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:08,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:08,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:09,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:09,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:10,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:10,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:11,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:11,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:12,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:12,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:13,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:13,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:14,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:14,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:15,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:15,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:16,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:16,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:17,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:17,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:18,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:18,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:19,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:19,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:20,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:20,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:21,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:21,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:03:22,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:22,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:23,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:23,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:24,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:24,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:25,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:25,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:26,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:26,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:27,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:27,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:28,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:28,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:29,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:29,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:30,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:30,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:03:31,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:31,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:32,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:32,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:33,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:33,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:34,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:34,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:35,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:35,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:36,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:36,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:37,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:37,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:38,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:38,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:39,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:39,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:40,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:40,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:41,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:41,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:42,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:42,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:43,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:43,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:44,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:44,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:45,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:45,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:46,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:46,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:03:47,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:47,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:48,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:48,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:49,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:49,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:50,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:50,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:51,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:51,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:52,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:52,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:53,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:53,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:54,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:54,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:55,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:55,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:56,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:56,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:57,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:57,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:58,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:58,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:59,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:03:59,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:00,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:00,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:01,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:01,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:04:02,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:02,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:03,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:04,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:04,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:05,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:05,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:06,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:06,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:07,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:07,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:08,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:08,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:09,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:09,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:04:10,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:10,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:11,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:11,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:12,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:12,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:13,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:13,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:14,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:14,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:15,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:15,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:16,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:16,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:17,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:17,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:18,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:18,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:19,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:19,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:20,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:20,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:21,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:21,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:22,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:22,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:23,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:23,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:24,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:24,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:25,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:25,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:26,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:26,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:27,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:27,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:28,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:28,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:29,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:29,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:30,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:30,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:31,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:31,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:32,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:32,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:33,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:33,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:34,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:34,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:35,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:35,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:36,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:36,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:37,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:04:37,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:38,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:38,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:39,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:39,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:40,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:40,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:41,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:41,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:42,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:42,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:43,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:43,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:44,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:44,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:45,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:45,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:46,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:46,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:47,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:47,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:48,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:48,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:49,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:49,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:50,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:50,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:51,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:51,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:52,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:52,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:04:53,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:53,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:54,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:54,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:55,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:55,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:56,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:04:56,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:57,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:57,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:58,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:58,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:59,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:04:59,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:00,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:00,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:01,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:01,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:02,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:02,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:03,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:03,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:04,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:04,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:05,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:05,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:06,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:06,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:07,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:07,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:08,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:08,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:09,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:09,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:10,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:10,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:11,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:11,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:12,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:12,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:13,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:13,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:14,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:14,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:15,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:15,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:16,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:16,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:17,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:17,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:18,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:18,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:19,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:19,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:20,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:20,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:21,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:21,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:22,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:22,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:23,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:23,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:24,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:24,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:25,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:25,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:26,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:26,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:27,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:27,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:28,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:28,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:29,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:29,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:30,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:30,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:31,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:31,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:32,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:32,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:33,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:33,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:34,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:34,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:35,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:35,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:36,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:36,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:37,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:37,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:38,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:38,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:39,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:39,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:40,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:40,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:41,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:41,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:42,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:42,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:43,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:43,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:44,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:44,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:45,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:45,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:46,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:46,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:47,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:47,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:48,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:48,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:49,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:49,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:50,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:50,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:51,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:05:51,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:52,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:52,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:53,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:53,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:54,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:54,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:55,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:55,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:56,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:56,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:57,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:57,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:58,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:58,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:59,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:05:59,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:00,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:00,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:01,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:01,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:02,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:06:02,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:03,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:03,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:04,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:04,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:05,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:05,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:06,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:06,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:07,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:07,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:08,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:08,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:09,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:09,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:10,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:10,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:11,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:11,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:12,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:12,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:13,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:13,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:14,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:14,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:15,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:15,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:16,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:16,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:17,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:17,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:18,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:18,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:19,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:19,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:20,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:20,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:21,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:21,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:22,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:22,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:23,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:23,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:24,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:24,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:25,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:25,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:26,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:26,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:27,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:27,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:28,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:06:28,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:29,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:29,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:30,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:30,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:31,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:31,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:32,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:32,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:33,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:33,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:34,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:34,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:35,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:35,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:36,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:36,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:37,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:37,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:38,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:38,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:39,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:39,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:40,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:40,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:41,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:41,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:42,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:42,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:43,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:43,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:44,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:06:44,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:06:45,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:45,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:46,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:46,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:47,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:47,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:48,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:48,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:49,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:49,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:50,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:50,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:51,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:51,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:52,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:52,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:53,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:06:53,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:54,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:54,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:55,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:55,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:56,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:56,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:57,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:57,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:58,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:58,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:59,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:06:59,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:00,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:00,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:01,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:01,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:02,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:02,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:03,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:03,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:04,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:04,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:05,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:05,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:06,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:06,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:07,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:07,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:08,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:08,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:09,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:09,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:10,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:10,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:11,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:11,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:12,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:12,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:13,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:13,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:14,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:14,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:15,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:15,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:16,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:16,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:17,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:17,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:18,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:18,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:19,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:19,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:20,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:20,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:21,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:21,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:22,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:22,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:23,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:23,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:24,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:24,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:25,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:25,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:26,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:26,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:27,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:27,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:28,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:28,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:29,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:29,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:30,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:30,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:31,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:32,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:32,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:33,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:33,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:34,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:34,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:35,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:35,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:36,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:36,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:37,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:37,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:38,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:38,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:39,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:39,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:40,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:40,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:41,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:41,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:42,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:42,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:43,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:43,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:44,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:44,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:45,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:45,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:46,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:46,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:47,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:47,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:48,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:48,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:49,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:49,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:50,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:50,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:51,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:51,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:52,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:52,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:53,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:53,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:54,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:54,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:55,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:55,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:56,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:56,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:57,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:57,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:58,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:07:58,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:59,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:07:59,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:00,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:00,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:01,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:01,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:02,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:02,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:03,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:03,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:04,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:04,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:05,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:05,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:06,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:06,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:07,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:08:07,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:08,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:08,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:09,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:09,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:10,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:10,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:11,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:11,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:12,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:12,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:13,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:13,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:14,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:14,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:15,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:15,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:16,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:16,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:17,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:17,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:18,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:18,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:19,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:08:19,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:20,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:20,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:21,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:21,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:22,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:22,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:23,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:23,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:24,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:24,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:25,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:25,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:26,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:26,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:27,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:27,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:28,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:28,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:29,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:08:29,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:30,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:30,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:31,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:31,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:32,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:32,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:33,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:33,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:34,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:34,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:35,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:35,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:36,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:36,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:37,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:08:37,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:38,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:38,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:39,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:39,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:40,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:40,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:41,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:41,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:42,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:42,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:43,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:43,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:44,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:44,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:45,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:45,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:46,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:46,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:47,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:47,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:48,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:48,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:49,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:49,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:50,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:50,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:51,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 11 milliseconds for processing 0 containers.
2022-05-22 16:08:51,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:52,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:52,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:53,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:53,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:54,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:54,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:55,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:55,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:56,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:56,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:57,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:57,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:58,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:58,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:59,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:08:59,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:00,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:00,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:01,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:01,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:02,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:02,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:03,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:03,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:04,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:04,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:05,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:05,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:06,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:06,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:07,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:07,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:08,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:08,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:09,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:09,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:10,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:10,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:11,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:11,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:12,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:12,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:13,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:13,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:14,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:14,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:15,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:15,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:16,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:16,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:17,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:17,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:18,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:18,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:19,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:19,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:20,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:20,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:21,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:21,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:22,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:22,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:23,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:23,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:24,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:24,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:25,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:25,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:26,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:26,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:27,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:27,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:28,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:28,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:29,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:29,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:30,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:30,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:31,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:31,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:32,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:32,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:33,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:33,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:34,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:34,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:35,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:35,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:36,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:36,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:37,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:37,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:38,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:38,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:39,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:39,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:40,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:40,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:41,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:41,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:42,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:42,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:43,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:43,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:44,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:44,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:45,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:45,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:46,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:46,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:47,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:47,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:48,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:09:48,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:49,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:49,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:50,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:50,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:51,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:51,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:52,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:52,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:53,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:53,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:54,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:54,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:55,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:55,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:56,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:56,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:57,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:57,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:58,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:58,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:59,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:09:59,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:00,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:00,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:01,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:01,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:02,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:02,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:03,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:03,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:04,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:04,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:05,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:05,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:06,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:06,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:07,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:07,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:08,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:08,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:09,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:09,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:10,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:10,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:11,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:11,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:12,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:12,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:13,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:13,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:14,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:14,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:15,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:15,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:16,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:16,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:17,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:17,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:18,147 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:18,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:19,147 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:19,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:20,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:20,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:21,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:21,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:22,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:22,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:23,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:23,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:24,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:24,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:25,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:25,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:26,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:26,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:27,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:27,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:28,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:28,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:29,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:29,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:30,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:30,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:31,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:31,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:32,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:32,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:33,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:33,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:34,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:34,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:35,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:35,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:36,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:36,316 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:37,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:37,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:38,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:38,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:39,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:39,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:40,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:40,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:41,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:41,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:42,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:42,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:43,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:43,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:44,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:44,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:45,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:45,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:46,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:46,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:47,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:47,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:48,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:48,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:49,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:49,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:50,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:50,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:51,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:51,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:52,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:52,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:53,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:53,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:54,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:54,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:55,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:55,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:56,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:56,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:57,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:10:57,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:58,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:58,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:59,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:10:59,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:00,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:00,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:11:01,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:01,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:02,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:02,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:03,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:03,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:04,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:04,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:05,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:05,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:06,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:06,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:07,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:07,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:08,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:08,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:09,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:09,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:10,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:10,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:11,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:11,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:12,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:12,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:11:13,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:13,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:14,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:14,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:15,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:15,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:16,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:16,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:17,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:17,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:18,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:18,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:19,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:19,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:20,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:20,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:21,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:21,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:22,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:22,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:23,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:23,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:24,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:24,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:25,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:25,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:26,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:11:26,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:27,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:27,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:28,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:11:28,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:11:29,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:29,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:30,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:30,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:31,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:31,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:32,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:32,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:33,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:33,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:34,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:34,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:35,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:35,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:36,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:36,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:37,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:37,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:38,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:38,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:39,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:39,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:40,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:40,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:41,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:41,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:42,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:42,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:43,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:43,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:44,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:44,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:45,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:45,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:46,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:46,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:47,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:47,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:48,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:48,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:49,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:49,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:50,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:50,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:51,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:51,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:52,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:52,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:53,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:53,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:54,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:54,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:55,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:55,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:56,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:56,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:57,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:57,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:58,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:58,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:59,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:11:59,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:00,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:00,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:01,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:01,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:02,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:02,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:03,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:03,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:04,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:04,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:05,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:05,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:06,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:06,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:07,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:07,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:08,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:08,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:09,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:09,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:10,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:10,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:11,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:11,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:12,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:12,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:13,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:13,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:14,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:14,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:15,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:15,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:16,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:16,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:17,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:17,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:18,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:12:18,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:19,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:19,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:20,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:20,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:21,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:21,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:22,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:22,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:23,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:23,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:24,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:24,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:25,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:25,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:26,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:26,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:12:27,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:27,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:28,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:28,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:29,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:29,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:30,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:30,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:31,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:31,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:32,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:32,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:33,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:33,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:34,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:34,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:35,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:35,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:36,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:36,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:37,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:37,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:38,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:38,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:39,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:39,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:40,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:40,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:41,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:41,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:42,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:42,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:43,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:43,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:44,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:44,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:45,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:45,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:46,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:46,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:47,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:47,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:12:48,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:48,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:49,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:49,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:50,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:50,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:51,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:51,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:52,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:52,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:53,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:53,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:54,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:54,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:55,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:55,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:56,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:56,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:57,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:57,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:58,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:58,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:59,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:12:59,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:00,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:00,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:01,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:01,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:02,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:02,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:03,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:03,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:04,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:04,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:05,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:05,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:06,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:06,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:07,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:07,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:08,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:08,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:09,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:09,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:10,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:10,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:11,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:11,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:12,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:12,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:13,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:13,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:14,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:14,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:15,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:15,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:16,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:16,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:17,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:17,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:18,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:18,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:19,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:19,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:20,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:20,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:21,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:21,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:22,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:22,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:23,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:23,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:24,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:24,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:25,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:25,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:26,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:26,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:27,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:27,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:28,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:28,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:29,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:29,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:30,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:30,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:13:31,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:31,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:32,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:32,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:33,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:33,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:34,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:34,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:35,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:35,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:36,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:36,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:37,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:37,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:38,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:38,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:39,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:39,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:40,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:40,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:41,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:41,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:42,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:42,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:43,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:43,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:44,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:44,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:45,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:13:45,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:46,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:46,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:47,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:47,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:48,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:48,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:49,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:13:49,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:50,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:50,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:51,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:51,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:13:52,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:52,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:53,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:53,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:54,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:54,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:55,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:55,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:56,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:56,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:57,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:57,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:58,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:58,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:59,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:13:59,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:00,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:00,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:01,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:14:01,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:02,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:02,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:03,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:03,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:04,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:04,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:05,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:05,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:06,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:06,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:07,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:07,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:08,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:08,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:09,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:09,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:10,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:10,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:11,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:11,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:12,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:12,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:13,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:13,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:14,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:14,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:15,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:15,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:16,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:16,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:17,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:17,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:18,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:18,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:19,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:19,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:20,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:20,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:21,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:21,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:22,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:22,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:23,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:23,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:24,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:24,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:25,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:25,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:26,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:26,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:27,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:27,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:28,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:28,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:29,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:29,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:30,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:30,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:31,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:31,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:32,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:32,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:33,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:33,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:34,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:34,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:35,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:35,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:36,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:36,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:37,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:37,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:38,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:38,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:39,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:14:39,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:40,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:40,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:41,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:41,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:42,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:42,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:43,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:43,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:44,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:44,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:45,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:45,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:46,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:46,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:14:47,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:47,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:48,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:48,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:49,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:49,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:50,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:50,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:51,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:51,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:52,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:52,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:53,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:53,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:14:54,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:54,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:55,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:55,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:56,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:56,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:57,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:57,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:58,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:58,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:59,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:14:59,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:00,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:00,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:01,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:01,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:02,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:02,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:03,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:03,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:04,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:04,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:05,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:05,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:06,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:06,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:07,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:07,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:08,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:08,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:09,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:09,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:10,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:10,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:11,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:11,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:12,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:12,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:13,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:13,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:14,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:14,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:15,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:15,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:16,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:16,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:17,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:17,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:15:18,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:18,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:19,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:19,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:20,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:20,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:21,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:21,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:22,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:22,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:23,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:23,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:24,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:24,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:25,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:25,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:15:26,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:26,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:27,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:27,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:28,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:28,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:29,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:29,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:30,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:30,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:31,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:31,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:32,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:32,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:33,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:33,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:34,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:34,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:35,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:35,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:36,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:36,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:37,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:37,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:38,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:38,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:39,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:39,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:40,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:40,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:41,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:41,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:42,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:42,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:43,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:43,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:44,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:44,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:45,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:45,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:46,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:46,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:47,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:15:47,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:48,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:48,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:49,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:49,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:50,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:50,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:51,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:51,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:52,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:52,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:53,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:53,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:54,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:54,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:55,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:55,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:56,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:56,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:57,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:57,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:58,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:58,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:59,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:15:59,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:00,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:00,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:01,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:01,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:02,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:02,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:03,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:03,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:04,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:04,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:05,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:05,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:06,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:16:06,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:07,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:07,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:08,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:08,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:09,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:09,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:10,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:16:10,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:11,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:11,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:12,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:12,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:13,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:13,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:14,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:16:14,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:15,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:15,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:16,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:16,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:17,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:17,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:18,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:18,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:19,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:19,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:20,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:20,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:21,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:21,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:22,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:22,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:23,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:23,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:24,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:24,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:25,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:25,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:26,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:26,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:27,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:27,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:28,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:28,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:29,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:29,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:30,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:30,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:31,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:31,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:32,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:32,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:33,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:33,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:34,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:34,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:35,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:35,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:36,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:36,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:16:37,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:16:37,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:38,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:38,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:39,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:39,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:40,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:40,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:41,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:41,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:42,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:42,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:43,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:43,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:44,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:44,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:45,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:45,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:46,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:46,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:47,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:47,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:48,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:48,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:49,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:49,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:50,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:50,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:51,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:51,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:52,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:52,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:53,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:53,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:54,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:54,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:55,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:55,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:56,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:56,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:57,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:57,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 11 milliseconds for processing 0 containers.
2022-05-22 16:16:58,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:58,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:59,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:16:59,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:00,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:00,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:01,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:01,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:02,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:02,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:03,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:03,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:04,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:04,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:05,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:05,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:06,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:06,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:07,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:07,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:08,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:08,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:09,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:09,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:10,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:10,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:11,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:11,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:12,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:12,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:13,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:13,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:14,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:14,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:15,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:15,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:16,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:16,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:17,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:17,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:18,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:18,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:19,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:19,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:20,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:20,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:21,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:21,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:22,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:22,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:23,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:23,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:24,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:24,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:25,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:25,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:26,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:26,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:27,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:27,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:28,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:28,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:29,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:29,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:30,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:30,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:31,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:31,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:32,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:32,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:33,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:33,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:34,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:34,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:35,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:35,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:36,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:36,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:37,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:37,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:38,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:38,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:39,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:39,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:40,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:40,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:41,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:41,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:42,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:42,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:43,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:43,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:44,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:44,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:45,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:45,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:46,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:46,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:47,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:47,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:48,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:48,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:49,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:49,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:50,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:50,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:51,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:51,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:52,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:52,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:53,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:53,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:54,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:54,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:55,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:55,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:17:56,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:56,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:57,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:57,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:58,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:58,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:59,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:17:59,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:00,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:00,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:01,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:01,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:02,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:02,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:03,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:03,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:04,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:04,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:05,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:05,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:06,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:06,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:07,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:07,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:08,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:08,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:09,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:09,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:10,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:10,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:11,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:11,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:12,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:12,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:13,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:13,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:14,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:14,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:15,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:15,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:16,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:16,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:17,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:17,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:18,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:18,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:19,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:19,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:20,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:20,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:18:21,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:21,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:22,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:18:22,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:23,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:23,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:24,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:24,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:25,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:25,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:18:26,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:26,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:27,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:27,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:28,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:28,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:29,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:29,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:30,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:30,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:31,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:31,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:32,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:32,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:33,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:18:33,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:34,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:34,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:35,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:35,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:36,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:36,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:37,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:37,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:38,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:38,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:39,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:39,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:40,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:40,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:41,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:41,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:42,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:42,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:43,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:43,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:44,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:44,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:45,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:45,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:46,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:46,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:47,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:47,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:48,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:48,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:49,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:49,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:50,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:50,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:51,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:51,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:52,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:52,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:53,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:53,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:54,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:54,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:55,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:55,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:56,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:56,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:57,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:57,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:58,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:58,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:59,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:18:59,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:00,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:00,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:01,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:01,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:02,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:02,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:03,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:03,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:04,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:04,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:05,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:05,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:06,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:06,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:07,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:07,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:08,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:08,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:09,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:09,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:10,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:10,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:11,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:11,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:12,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:12,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:13,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:13,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:14,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:14,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:15,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:15,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:16,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:16,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:17,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:17,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:18,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:18,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:19,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:19,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:20,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:20,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:21,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:21,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:22,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:22,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:23,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:23,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:24,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:24,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:25,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:19:25,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:26,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:26,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:27,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:27,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:28,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:28,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:29,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:29,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:30,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:30,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:31,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:31,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:32,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:32,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:33,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:33,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:34,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:34,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:35,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:35,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:36,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:36,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:37,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:37,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:38,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:19:38,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:39,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:39,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:40,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:40,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:41,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:41,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:42,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:42,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:43,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:43,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:44,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:44,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:45,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:45,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:46,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:46,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:47,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:47,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:48,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:48,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:49,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:49,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:50,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:50,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:51,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:51,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:52,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:52,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:53,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:53,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:54,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:54,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:55,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:55,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:56,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:56,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:57,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:57,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:58,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:58,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:59,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:19:59,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:00,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:00,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:01,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:01,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:02,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:02,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:03,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:03,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:04,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:04,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:05,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:05,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:06,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:06,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:07,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:07,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:08,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:08,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:09,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:09,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:10,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:10,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:11,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:11,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:12,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:12,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:13,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:13,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:14,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:14,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:15,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:15,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:16,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:16,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:17,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:20:17,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:18,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:18,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:19,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:19,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:20,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:20,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:21,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:21,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:22,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:22,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:23,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:23,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:24,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:24,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:25,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:25,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:26,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:26,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:27,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:27,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:28,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:28,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:29,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:29,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:30,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:30,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:31,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:31,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:32,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:32,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:33,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:33,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:34,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:34,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:35,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:20:35,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:36,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:36,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:37,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:37,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:38,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:20:38,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:39,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:39,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:40,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:40,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:41,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:41,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:42,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:42,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:43,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:43,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:44,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:44,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:45,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:45,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:46,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:46,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:47,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:47,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:48,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:48,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:49,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:49,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:50,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:50,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:51,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:51,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:52,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:52,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:53,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:53,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:54,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:54,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:55,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:55,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:56,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:56,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:57,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:57,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:58,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:58,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:59,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:20:59,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:00,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:00,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:01,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:01,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:02,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:02,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:03,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:03,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:04,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:04,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:05,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:05,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:06,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:06,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:07,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:07,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:08,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:08,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:09,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:21:09,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:10,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:10,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:11,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:11,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:12,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:12,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:13,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:13,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:14,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:14,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:15,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:15,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:16,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:16,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:17,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:17,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:18,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:18,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:19,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:19,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:20,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:20,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:21,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:21,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:22,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:22,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:23,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:23,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:24,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:24,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:25,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:25,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:26,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:26,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:27,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:27,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:28,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:28,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:29,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:29,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:30,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:30,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:31,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:31,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:32,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:32,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:33,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:33,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:34,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:34,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:35,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:35,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:21:36,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:36,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:37,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:37,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:38,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:38,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:21:39,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:39,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:40,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:40,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:41,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:41,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:42,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:42,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:43,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:43,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:44,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:44,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:45,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:45,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:46,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:46,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:47,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:47,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:48,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:48,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:49,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:49,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:50,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:50,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:51,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:51,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:52,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:52,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:53,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:53,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:54,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:54,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:55,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:55,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:56,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:56,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:57,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:57,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:58,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:58,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:59,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:21:59,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:00,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:00,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:01,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:01,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:02,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:02,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:03,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:03,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:04,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:04,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:05,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:05,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:06,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:06,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:07,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:07,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:08,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:08,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:09,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:09,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:10,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:10,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:11,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:11,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:12,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:12,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:13,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:13,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:14,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:14,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:15,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:15,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:16,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:16,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:17,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:17,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:18,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:18,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:19,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:19,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:20,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:20,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:21,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:21,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:22,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:22,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:23,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:23,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:24,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:24,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:25,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:25,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:26,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:26,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:27,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:27,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:28,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:28,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:29,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:29,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:30,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:30,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:31,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:31,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:32,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:32,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:33,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:33,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:34,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:34,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:35,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:35,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:36,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:36,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:37,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:37,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:38,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:38,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:39,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:39,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:40,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:40,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:41,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:41,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:42,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:42,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:43,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:43,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:44,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:44,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:45,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:45,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:46,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:46,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:47,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:47,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:48,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:48,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:49,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:49,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:50,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:50,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:51,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:51,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:52,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:52,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:53,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:53,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:54,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:54,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:55,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:55,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:56,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:56,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:57,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:57,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:58,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:58,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:59,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:22:59,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:00,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:00,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:01,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:01,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:02,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:23:02,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:03,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:03,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:04,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:04,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:05,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:05,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:06,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:06,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:07,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:07,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:08,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:08,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:09,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:09,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:10,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:23:10,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:11,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:11,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:12,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:12,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:13,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:13,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:14,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:14,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:15,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:15,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:16,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:16,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:17,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:17,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:18,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:18,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:19,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:19,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:20,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:20,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:21,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:21,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:22,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:22,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:23,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:23:23,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:24,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:24,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:25,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:25,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:26,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:26,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:27,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:23:27,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:28,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:28,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:29,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:29,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:30,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:23:30,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:31,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:31,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:32,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:32,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:33,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:33,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:34,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:34,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:35,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:35,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:36,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:36,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:37,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:37,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:38,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:38,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:39,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:39,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:40,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:40,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:41,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:41,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:42,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:42,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:43,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:43,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:44,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:44,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:45,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:45,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:46,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:46,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:47,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:47,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:48,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:48,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:49,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:49,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:50,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:50,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:51,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:51,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:52,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:52,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:53,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:53,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:54,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:54,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:55,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:55,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:56,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:56,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:57,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:57,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:58,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:58,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:59,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:23:59,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:24:00,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:24:00,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:01,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:01,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:02,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:02,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:03,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:03,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:04,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:04,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:05,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:05,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:06,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:06,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:07,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:07,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:08,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:08,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:09,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:09,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:10,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:10,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:24:11,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:11,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:12,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:12,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:13,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:13,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:24:14,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:14,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:15,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:15,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:16,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:16,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:17,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:17,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:18,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:18,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:19,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:19,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:20,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:20,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:24:21,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:21,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:22,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:22,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:23,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:23,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:24,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:24,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:25,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:25,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:26,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:26,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:27,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:27,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:28,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:28,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:29,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:29,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:30,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:30,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:31,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:31,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:32,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:32,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:33,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:33,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:34,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:34,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:35,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:35,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:36,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:36,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:37,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:37,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:38,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:38,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:39,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:39,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:40,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:40,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:41,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:41,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:42,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:42,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:43,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:43,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:44,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:44,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:45,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:45,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 3 milliseconds for processing 0 containers.
2022-05-22 16:24:46,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:46,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:47,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:47,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:48,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:48,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:49,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:49,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:50,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:50,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:51,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:51,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:52,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:52,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:53,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:53,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:54,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:54,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:55,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:55,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:56,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:56,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:57,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:57,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:58,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:58,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:59,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:24:59,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:00,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:00,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:01,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:01,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:02,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:02,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:03,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:03,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:04,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:04,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:05,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:05,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:06,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:06,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:07,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:07,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:08,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:08,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:09,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:09,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:10,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:10,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:11,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:11,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:25:12,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:12,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:13,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:13,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:14,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:14,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:15,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:15,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:16,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:16,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:17,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:17,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:18,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:18,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:19,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:19,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:20,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:20,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:21,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:21,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:22,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:22,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:23,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:23,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:24,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:24,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:25,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:25,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:26,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:26,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:27,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:27,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:28,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:28,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:29,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:29,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:30,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:30,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:31,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:31,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:32,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:32,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:33,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:33,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:34,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:34,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:35,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:36,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:36,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:37,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:37,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:38,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:38,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:25:39,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:39,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:40,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:40,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:41,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:41,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:42,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:42,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:43,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:43,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:25:44,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:44,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:45,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:45,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:46,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:46,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:47,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:47,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:48,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:48,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:49,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:49,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:50,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:50,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:51,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:51,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:52,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:52,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:53,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:53,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:54,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:54,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:55,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:55,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:56,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:56,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:57,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:57,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:58,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:58,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:59,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:25:59,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:00,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:00,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:01,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:01,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:26:02,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:02,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:03,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:03,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:04,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:04,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:05,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:05,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:06,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:06,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:07,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:07,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:08,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:08,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:09,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:09,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:10,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:10,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:11,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:11,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:26:12,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:12,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:13,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:13,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:14,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:14,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:15,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:15,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:16,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:16,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:17,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:17,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:18,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:18,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:19,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:19,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:20,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:20,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:21,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:21,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:22,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:26:22,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:23,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:23,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:24,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:24,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:25,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:25,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:26,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:26,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:27,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:27,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:28,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:28,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:29,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:29,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:30,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:30,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:31,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:31,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:32,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:32,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:33,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:33,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:34,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:34,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:35,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:35,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:36,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:26:36,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:37,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:37,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:38,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:38,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:39,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:39,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:40,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:40,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:41,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:41,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:42,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:42,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:43,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:43,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:44,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:44,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:45,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:45,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:46,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:46,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:47,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:47,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:48,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:48,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:26:49,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:49,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:50,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:50,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:51,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:51,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:52,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:52,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:53,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:53,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:54,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:54,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:55,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:55,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:56,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:56,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:57,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:57,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:58,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:58,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:59,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:26:59,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:00,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:00,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:01,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:01,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:02,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:02,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:03,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:03,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:04,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:04,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:05,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:05,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:06,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:06,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:07,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:07,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:08,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:08,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:09,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:09,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:10,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:10,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:11,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:11,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:12,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:12,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:13,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:13,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:14,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:15,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:15,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:16,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:16,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:17,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:17,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:18,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:18,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:19,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:19,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:20,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:20,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:21,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:21,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:22,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:22,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:23,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:23,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:24,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:24,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:25,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:25,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:26,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:26,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:27,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:27,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:28,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:28,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:29,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:29,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:30,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:30,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:31,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 22 milliseconds for processing 0 containers.
2022-05-22 16:27:31,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:32,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:32,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:33,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:33,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:34,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:34,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:35,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:35,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:36,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:36,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:37,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:37,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:38,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:38,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:39,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:39,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:40,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:40,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:41,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:41,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:42,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:42,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:43,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:43,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:44,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:27:44,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:45,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:45,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:46,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:46,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:47,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:47,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:48,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:48,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:49,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:49,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:50,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:50,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:51,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:51,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:52,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:52,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:53,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:53,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:54,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:54,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:55,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:55,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:56,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:56,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:57,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:57,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:58,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:58,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:59,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:27:59,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:00,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:00,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:01,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:01,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:02,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:02,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:03,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:03,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:04,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:04,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:05,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:05,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:06,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:06,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:28:07,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:07,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:08,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:08,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:09,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:09,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:10,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:10,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:11,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:11,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:12,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:12,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:13,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:13,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:14,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:14,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:15,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:15,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:16,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:16,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:17,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:17,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:18,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:18,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:19,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:19,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:20,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:20,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:21,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:21,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:22,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:22,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:23,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:23,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:24,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:24,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:25,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:25,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:26,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:26,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:27,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:27,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:28,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:28,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:29,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:29,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:30,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:30,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:31,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:31,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:32,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:32,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:33,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:33,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:34,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:34,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:35,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:35,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:36,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:36,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:37,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:37,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:38,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:38,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:39,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:39,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:40,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:40,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:41,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:41,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:42,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:42,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:43,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:43,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:44,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:44,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:45,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:45,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:46,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:46,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:47,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:47,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:48,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:48,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:49,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:49,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:50,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:50,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:51,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:51,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:52,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:52,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:53,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:53,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:54,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:54,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:55,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:55,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:56,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:56,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:57,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:57,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:58,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:58,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:59,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:28:59,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:00,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:00,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:01,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:01,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:02,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:02,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:03,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:29:03,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:04,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:04,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:05,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:05,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:06,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:06,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:07,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:07,147 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:08,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:08,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:09,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:09,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:10,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:10,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:11,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:11,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:12,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:12,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:13,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:13,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:14,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:14,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:15,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:15,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:16,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:16,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:17,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:17,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:18,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:18,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:19,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:19,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:20,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:20,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:21,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:21,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:22,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:22,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:23,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:23,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:24,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:24,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:25,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:25,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:26,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:26,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:27,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:27,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:28,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:28,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:29,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:29,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:30,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:30,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:31,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:31,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:29:32,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:32,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:33,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:33,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:34,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:34,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:35,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:35,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:36,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:36,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:37,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:37,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:38,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:38,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:39,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:39,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:40,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:40,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:41,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 14 milliseconds for processing 0 containers.
2022-05-22 16:29:41,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:42,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:42,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:43,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:43,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:44,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:44,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:45,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:45,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:46,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:46,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:47,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:47,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:48,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:48,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:49,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:49,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:50,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:50,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:51,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:51,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:52,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:52,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:53,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:53,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:54,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:54,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:55,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:55,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:56,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:56,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:57,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:57,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:58,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:58,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:59,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:29:59,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:00,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:00,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:01,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:01,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:02,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:02,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:03,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:03,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:04,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:04,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:05,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:05,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:06,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:06,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:07,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:07,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:08,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:08,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:09,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:09,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:10,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:10,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:11,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:11,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:12,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:12,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:13,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:13,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:14,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:14,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:15,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:15,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:16,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:16,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:17,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:17,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:18,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:18,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:19,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:19,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:20,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:20,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:21,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:21,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:22,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:22,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:23,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:23,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:24,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:24,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:25,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:25,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:26,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:26,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:27,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:27,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:28,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:28,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:29,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:29,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:30,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:30,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:31,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:31,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:32,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:32,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:33,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:33,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:34,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:34,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:35,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:35,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:36,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:36,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:37,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:37,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:38,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:38,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:39,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:39,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:40,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:40,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:41,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:41,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:42,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:42,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:43,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:43,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:44,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:44,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:45,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:45,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:46,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:46,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:47,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:47,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:48,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:48,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:49,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:49,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:50,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:50,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:51,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:51,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:52,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:52,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:53,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:53,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:54,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:54,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:55,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:55,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:56,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:56,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:57,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:57,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:58,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:58,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:30:59,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:30:59,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:00,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:00,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:01,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:01,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:02,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:02,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:03,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:03,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:04,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:04,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:05,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:05,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:06,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:06,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:07,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:07,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:08,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:08,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:09,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:09,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:10,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:10,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:11,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:11,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:12,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:12,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:13,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:13,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:14,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:14,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:15,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:15,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:16,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:16,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:17,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:17,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:18,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:18,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:19,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:19,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:20,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:20,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:21,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:21,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:22,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:22,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:23,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:23,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:24,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:24,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:25,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:25,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:26,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:26,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:27,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:27,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:28,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:31:28,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:29,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:29,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:30,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:30,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:31,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:31,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:32,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:32,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:33,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:33,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:34,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:34,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:35,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:35,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:36,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:36,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:37,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:37,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:38,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:38,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:39,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:39,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:40,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:40,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:41,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:41,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:42,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:42,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:43,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:43,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:44,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:44,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:45,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:45,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:46,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:46,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:47,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:47,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:48,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:48,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:49,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:49,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:31:50,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:50,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:51,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:51,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:52,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:52,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:53,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:53,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:54,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:54,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 11 milliseconds for processing 0 containers.
2022-05-22 16:31:55,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:55,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:56,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:56,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:57,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:57,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:58,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:58,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:59,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:31:59,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:32:00,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:00,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:01,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:01,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:02,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:02,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:03,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:03,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:04,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:04,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:05,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:05,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:06,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:06,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:07,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:07,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:08,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:08,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:09,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:09,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:10,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:10,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:11,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:11,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:12,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:12,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:13,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:13,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:14,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:14,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:15,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:15,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:16,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:16,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:17,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:17,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:18,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:18,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:19,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:19,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:20,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:32:20,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:21,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:21,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:22,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:22,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:32:23,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:23,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:24,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:24,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:25,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:25,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:26,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:26,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:27,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:27,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:28,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:28,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:29,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:29,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:30,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:30,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:31,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:31,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:32,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:32,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:33,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:33,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:34,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:34,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:35,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:35,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:36,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:36,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:37,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:37,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:38,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:38,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:39,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:39,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:40,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:40,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:41,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:41,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:42,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:42,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:43,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:43,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:44,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:44,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:45,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:45,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:46,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:46,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:47,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:47,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:48,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:48,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:49,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:49,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:50,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:50,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:51,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:51,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:52,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:52,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:53,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:53,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:54,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:54,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:55,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:55,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:56,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:56,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:57,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:57,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:58,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:58,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:59,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:32:59,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:00,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:00,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:01,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:01,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:33:02,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:02,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:03,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:03,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:04,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:04,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:05,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:05,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:06,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:06,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:07,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:07,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:08,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:08,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:09,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:09,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:10,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:10,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:11,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:11,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:12,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:12,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:13,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:13,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:14,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:14,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:15,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:15,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:16,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:16,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:17,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:17,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:18,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:18,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:19,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:19,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:20,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:20,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:21,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:21,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:22,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:22,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:23,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:23,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:24,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:24,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:25,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:25,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:26,316 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:26,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:27,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:27,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:28,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:28,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:29,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:29,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:30,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:30,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:31,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:31,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:32,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:32,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:33,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:33,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:34,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:34,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:35,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:35,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:36,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:36,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:37,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:37,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:38,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:38,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:39,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:39,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:40,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:40,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:41,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:41,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:42,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:42,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:43,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:43,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:44,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:44,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:45,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:33:45,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:46,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:46,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:47,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:47,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:48,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:48,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:49,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:49,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:50,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:50,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:51,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:51,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:52,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:52,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:53,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:53,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:54,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:54,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:55,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:55,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:56,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:56,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:57,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:57,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:58,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:58,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:59,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:33:59,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:00,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:00,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:01,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:01,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:02,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:02,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:03,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:03,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:04,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:04,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:05,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:05,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:06,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:06,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:07,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:07,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:08,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:08,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:09,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:09,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:10,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:10,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:11,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:11,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:12,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:12,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:13,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:13,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:14,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:14,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:15,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:15,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:16,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:16,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:17,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:17,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:18,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:18,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:19,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:19,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:20,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:20,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:21,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:21,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:22,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:22,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:23,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:23,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:24,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:24,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:25,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:25,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:34:26,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:34:26,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:27,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:27,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:28,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:28,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:29,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:29,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:30,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:30,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:31,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:31,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:32,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:32,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:33,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:33,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:34,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:34,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:35,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:35,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:36,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:36,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:37,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:37,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:38,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:38,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:39,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:39,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:40,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:40,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:41,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:41,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:42,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:42,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:43,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:43,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:44,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:44,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:45,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:45,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:46,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:46,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:47,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:47,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:48,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:48,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:49,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:49,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:50,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:50,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:51,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:34:51,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:52,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:52,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:53,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:53,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:54,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:54,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:55,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:55,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:56,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:56,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:57,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:57,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:58,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:58,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:59,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:34:59,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:00,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:00,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:01,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:01,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:02,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:02,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:03,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:03,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:04,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:04,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:05,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:05,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:06,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:06,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:07,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:07,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:08,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:08,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:09,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:09,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:10,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:10,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:11,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:11,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:12,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:12,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:13,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:13,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:14,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:14,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:15,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:15,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:16,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:16,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:17,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:17,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:18,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:18,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:19,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:19,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:20,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:20,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-05-22 16:35:21,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:21,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:22,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:22,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:23,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:23,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:24,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:24,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:25,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:25,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:26,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:26,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:27,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:27,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:28,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:28,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:29,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:29,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:30,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:30,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:31,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:31,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:32,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:32,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:33,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:33,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:34,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:34,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:35,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:35,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:36,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:36,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:37,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:37,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:38,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:38,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:39,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:39,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:40,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:40,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:41,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-05-22 16:35:41,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
