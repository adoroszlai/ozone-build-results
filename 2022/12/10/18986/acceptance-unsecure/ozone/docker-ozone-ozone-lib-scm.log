Attaching to ozone_datanode_5, ozone_om_1, ozone_datanode_1, ozone_datanode_2, ozone_s3g_1, ozone_datanode_4, ozone_datanode_3, ozone_scm_1, ozone_recon_1
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2022-12-10 12:25:41,728 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = d9c349586e96/172.19.0.10
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_1  | STARTUP_MSG:   java = 11.0.14.1
datanode_1  | ************************************************************/
datanode_1  | 2022-12-10 12:25:41,826 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2022-12-10 12:25:42,220 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2022-12-10 12:25:43,029 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2022-12-10 12:25:44,397 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2022-12-10 12:25:44,405 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2022-12-10 12:25:45,254 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d9c349586e96 ip:172.19.0.10
datanode_1  | 2022-12-10 12:25:48,024 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1  | 2022-12-10 12:25:49,172 [main] INFO reflections.Reflections: Reflections took 891 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_1  | 2022-12-10 12:25:50,131 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_1  | 2022-12-10 12:25:51,715 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2022-12-10 12:25:51,917 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_1  | 2022-12-10 12:25:51,977 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2022-12-10 12:25:51,996 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2022-12-10 12:25:52,348 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2022-12-10 12:25:52,692 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2022-12-10 12:25:52,720 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_1  | 2022-12-10 12:25:52,722 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_1  | 2022-12-10 12:25:52,743 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_1  | 2022-12-10 12:25:52,744 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_1  | 2022-12-10 12:25:52,996 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2022-12-10 12:25:53,000 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 2022-12-10 12:26:02,707 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_1  | 2022-12-10 12:26:03,234 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2022-12-10 12:26:03,721 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_1  | 2022-12-10 12:26:05,171 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_1  | 2022-12-10 12:26:05,201 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_1  | 2022-12-10 12:26:05,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_1  | 2022-12-10 12:26:05,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1  | 2022-12-10 12:26:05,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_1  | 2022-12-10 12:26:05,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_1  | 2022-12-10 12:26:05,210 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2022-12-10 12:26:05,239 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 12:26:05,281 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2022-12-10 12:26:05,282 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-12-10 12:26:05,402 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_1  | 2022-12-10 12:26:05,414 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_1  | 2022-12-10 12:26:05,487 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_1  | 2022-12-10 12:26:07,163 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1  | 2022-12-10 12:26:07,165 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_1  | 2022-12-10 12:26:07,174 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_1  | 2022-12-10 12:26:07,185 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-12-10 12:26:07,185 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-12-10 12:26:07,190 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-12-10 12:26:07,340 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_1  | 2022-12-10 12:26:08,752 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2022-12-10 12:26:08,843 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2022-12-10 12:26:09,001 [main] INFO util.log: Logging initialized @39334ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2022-12-10 12:26:09,690 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_1  | 2022-12-10 12:26:09,847 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2022-12-10 12:26:09,949 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2022-12-10 12:26:09,951 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2022-12-10 12:25:41,842 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 6dce7f01dcdb/172.19.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_1  | 2022-12-10 12:26:09,979 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2022-12-10 12:26:09,979 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2022-12-10 12:26:10,347 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2022-12-10 12:26:10,367 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_1  | 2022-12-10 12:26:10,643 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2022-12-10 12:26:10,643 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2022-12-10 12:26:10,645 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2022-12-10 12:26:10,737 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@511a307e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2022-12-10 12:26:10,738 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@34c6b52e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2022-12-10 12:26:11,792 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1a0b4955{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-13923620539954048807/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2022-12-10 12:26:11,870 [main] INFO server.AbstractConnector: Started ServerConnector@4b4228cf{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2022-12-10 12:26:11,879 [main] INFO server.Server: Started @42211ms
datanode_1  | 2022-12-10 12:26:11,919 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2022-12-10 12:26:11,919 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2022-12-10 12:26:11,922 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2022-12-10 12:26:11,958 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_1  | 2022-12-10 12:26:12,085 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40ead8c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2022-12-10 12:26:13,162 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_1  | 2022-12-10 12:26:13,757 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2022-12-10 12:26:15,977 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:15,978 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:16,978 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:16,979 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:17,979 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:17,980 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:18,980 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:18,981 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:19,981 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:19,985 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:20,986 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:21,987 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:22,988 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:23,989 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:24,990 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:25,051 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From d9c349586e96/172.19.0.10 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.10:33450 remote=recon/172.19.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_2  | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | ************************************************************/
datanode_2  | 2022-12-10 12:25:41,906 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2022-12-10 12:25:42,409 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2022-12-10 12:25:43,153 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2022-12-10 12:25:44,459 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2022-12-10 12:25:44,459 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2022-12-10 12:25:45,308 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6dce7f01dcdb ip:172.19.0.4
datanode_2  | 2022-12-10 12:25:48,449 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_2  | 2022-12-10 12:25:49,639 [main] INFO reflections.Reflections: Reflections took 895 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_2  | 2022-12-10 12:25:50,561 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_2  | 2022-12-10 12:25:52,126 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2022-12-10 12:25:52,352 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_2  | 2022-12-10 12:25:52,379 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2022-12-10 12:25:52,380 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2022-12-10 12:25:52,622 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2022-12-10 12:25:52,951 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2022-12-10 12:25:52,984 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2  | 2022-12-10 12:25:53,003 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2  | 2022-12-10 12:25:53,004 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_2  | 2022-12-10 12:25:53,004 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_2  | 2022-12-10 12:25:53,365 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2022-12-10 12:25:53,373 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2022-12-10 12:26:02,932 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_2  | 2022-12-10 12:26:03,713 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2022-12-10 12:26:04,030 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_2  | 2022-12-10 12:26:05,100 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_2  | 2022-12-10 12:26:05,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_2  | 2022-12-10 12:26:05,256 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_2  | 2022-12-10 12:26:05,258 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_2  | 2022-12-10 12:26:05,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_2  | 2022-12-10 12:26:05,270 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_2  | 2022-12-10 12:26:05,303 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2022-12-10 12:26:05,309 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:05,310 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2022-12-10 12:26:05,323 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2022-12-10 12:26:05,448 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 2022-12-10 12:26:05,465 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_2  | 2022-12-10 12:26:05,488 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_2  | 2022-12-10 12:26:07,692 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_2  | 2022-12-10 12:26:07,702 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_2  | 2022-12-10 12:26:07,740 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2  | 2022-12-10 12:26:07,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-12-10 12:26:07,779 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-12-10 12:26:07,785 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-12-10 12:26:08,144 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_2  | 2022-12-10 12:26:09,984 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2022-12-10 12:26:10,193 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2022-12-10 12:26:10,476 [main] INFO util.log: Logging initialized @41830ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2022-12-10 12:26:11,291 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_2  | 2022-12-10 12:26:11,333 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2022-12-10 12:26:11,401 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2022-12-10 12:26:11,424 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2022-12-10 12:26:11,442 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2022-12-10 12:26:11,445 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2022-12-10 12:26:11,941 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2022-12-10 12:26:11,957 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_2  | 2022-12-10 12:26:12,311 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2022-12-10 12:26:12,311 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2022-12-10 12:26:12,312 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2022-12-10 12:26:12,416 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fd8b081{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2022-12-10 12:26:12,417 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7efba9b9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2022-12-10 12:26:13,069 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1f235a0a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-763829753227183640/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2022-12-10 12:26:13,159 [main] INFO server.AbstractConnector: Started ServerConnector@110318a7{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2  | 2022-12-10 12:26:13,159 [main] INFO server.Server: Started @44513ms
datanode_2  | 2022-12-10 12:26:13,189 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2022-12-10 12:26:13,189 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2022-12-10 12:26:13,198 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2022-12-10 12:26:13,261 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_2  | 2022-12-10 12:26:13,404 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71f774c2] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2022-12-10 12:26:14,207 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_2  | 2022-12-10 12:26:14,899 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2022-12-10 12:26:16,752 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:16,760 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:17,754 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:17,762 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:18,755 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:18,762 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:19,756 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:19,763 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:20,764 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:21,766 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:22,767 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:23,768 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:24,769 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:24,797 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 6dce7f01dcdb/172.19.0.4 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.4:49332 remote=recon/172.19.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_2  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.4:49332 remote=recon/172.19.0.3:9891]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_2  | 2022-12-10 12:26:25,770 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-12-10 12:26:30,779 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 6dce7f01dcdb/172.19.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.4:42698 remote=scm/172.19.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_2  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.4:42698 remote=scm/172.19.0.2:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.10:33450 remote=recon/172.19.0.3:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_1  | 2022-12-10 12:26:25,992 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-12-10 12:26:31,003 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From d9c349586e96/172.19.0.10 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.10:33758 remote=scm/172.19.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.10:33758 remote=scm/172.19.0.2:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_1  | 2022-12-10 12:26:32,220 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-009f15e1-2940-4364-bdaa-acac634d379c/container.db to cache
datanode_1  | 2022-12-10 12:26:32,222 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-009f15e1-2940-4364-bdaa-acac634d379c/container.db for volume DS-009f15e1-2940-4364-bdaa-acac634d379c
datanode_1  | 2022-12-10 12:26:32,228 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2022-12-10 12:26:32,239 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_1  | 2022-12-10 12:26:32,642 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_1  | 2022-12-10 12:26:32,812 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: eb6b06af-1f2c-4397-8743-5d103932e2bb: start RPC server
datanode_1  | 2022-12-10 12:26:32,822 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: eb6b06af-1f2c-4397-8743-5d103932e2bb: GrpcService started, listening on 9858
datanode_1  | 2022-12-10 12:26:32,832 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: eb6b06af-1f2c-4397-8743-5d103932e2bb: GrpcService started, listening on 9856
datanode_1  | 2022-12-10 12:26:32,836 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: eb6b06af-1f2c-4397-8743-5d103932e2bb: GrpcService started, listening on 9857
datanode_1  | 2022-12-10 12:26:32,861 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis eb6b06af-1f2c-4397-8743-5d103932e2bb is started using port 9858 for RATIS
datanode_1  | 2022-12-10 12:26:32,861 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis eb6b06af-1f2c-4397-8743-5d103932e2bb is started using port 9857 for RATIS_ADMIN
datanode_1  | 2022-12-10 12:26:32,862 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis eb6b06af-1f2c-4397-8743-5d103932e2bb is started using port 9856 for RATIS_SERVER
datanode_1  | 2022-12-10 12:26:32,864 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-eb6b06af-1f2c-4397-8743-5d103932e2bb: Started
datanode_1  | 2022-12-10 12:26:37,430 [Command processor thread] INFO server.RaftServer: eb6b06af-1f2c-4397-8743-5d103932e2bb: addNew group-977D25AA3D3C:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER] returns group-977D25AA3D3C:java.util.concurrent.CompletableFuture@478e9f35[Not completed]
datanode_1  | 2022-12-10 12:26:37,519 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb: new RaftServerImpl for group-977D25AA3D3C:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_1  | 2022-12-10 12:26:37,524 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2022-12-10 12:26:37,533 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2022-12-10 12:26:37,533 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2022-12-10 12:26:37,536 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-12-10 12:26:37,536 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-12-10 12:26:37,537 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2022-12-10 12:26:37,564 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: ConfigurationManager, init=-1: peers:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2022-12-10 12:26:37,567 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-12-10 12:26:37,592 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2022-12-10 12:26:37,593 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2022-12-10 12:26:37,626 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2022-12-10 12:26:37,633 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2022-12-10 12:26:37,644 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2022-12-10 12:26:37,836 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-12-10 12:26:37,839 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1  | 2022-12-10 12:26:37,842 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1  | 2022-12-10 12:26:37,852 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1  | 2022-12-10 12:26:37,855 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2022-12-10 12:26:37,855 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d792bf06-25f5-4ba9-821b-977d25aa3d3c does not exist. Creating ...
datanode_1  | 2022-12-10 12:26:37,884 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d792bf06-25f5-4ba9-821b-977d25aa3d3c/in_use.lock acquired by nodename 6@d9c349586e96
datanode_1  | 2022-12-10 12:26:37,914 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d792bf06-25f5-4ba9-821b-977d25aa3d3c has been successfully formatted.
datanode_1  | 2022-12-10 12:26:37,951 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-977D25AA3D3C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2022-12-10 12:26:37,982 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2022-12-10 12:26:38,041 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2022-12-10 12:26:38,067 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 12:26:38,068 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_4  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4  | 2022-12-10 12:25:42,304 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4  | /************************************************************
datanode_4  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4  | STARTUP_MSG:   host = c79f062f35ec/172.19.0.9
datanode_4  | STARTUP_MSG:   args = []
datanode_4  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_4  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_4  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_4  | STARTUP_MSG:   java = 11.0.14.1
datanode_4  | ************************************************************/
datanode_4  | 2022-12-10 12:25:42,408 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4  | 2022-12-10 12:25:42,827 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4  | 2022-12-10 12:25:43,620 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4  | 2022-12-10 12:25:44,817 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4  | 2022-12-10 12:25:44,817 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4  | 2022-12-10 12:25:45,680 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c79f062f35ec ip:172.19.0.9
datanode_4  | 2022-12-10 12:25:48,453 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_4  | 2022-12-10 12:25:49,463 [main] INFO reflections.Reflections: Reflections took 734 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_4  | 2022-12-10 12:25:50,611 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_4  | 2022-12-10 12:25:52,072 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4  | 2022-12-10 12:25:52,267 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_4  | 2022-12-10 12:25:52,301 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4  | 2022-12-10 12:25:52,307 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4  | 2022-12-10 12:25:52,698 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4  | 2022-12-10 12:25:52,969 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-12-10 12:25:53,028 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_4  | 2022-12-10 12:25:53,067 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_4  | 2022-12-10 12:25:53,071 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_4  | 2022-12-10 12:25:53,087 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_4  | 2022-12-10 12:25:53,432 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_4  | 2022-12-10 12:25:53,451 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_4  | 2022-12-10 12:26:02,903 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_4  | 2022-12-10 12:26:03,765 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-12-10 12:26:04,192 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_4  | 2022-12-10 12:26:05,153 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_4  | 2022-12-10 12:26:05,211 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_4  | 2022-12-10 12:26:05,221 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_4  | 2022-12-10 12:26:05,229 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_4  | 2022-12-10 12:26:05,239 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_4  | 2022-12-10 12:26:05,247 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_4  | 2022-12-10 12:26:05,248 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4  | 2022-12-10 12:26:05,255 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 12:26:05,327 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4  | 2022-12-10 12:26:05,349 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4  | 2022-12-10 12:26:05,525 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_4  | 2022-12-10 12:26:05,598 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_4  | 2022-12-10 12:26:05,649 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_4  | 2022-12-10 12:26:07,765 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_4  | 2022-12-10 12:26:07,768 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_4  | 2022-12-10 12:26:07,802 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_4  | 2022-12-10 12:26:07,802 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 12:26:07,807 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 12:26:07,810 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 12:26:08,088 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_4  | 2022-12-10 12:26:10,140 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4  | 2022-12-10 12:26:10,329 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4  | 2022-12-10 12:26:10,591 [main] INFO util.log: Logging initialized @40655ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4  | 2022-12-10 12:26:11,307 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_2  | 2022-12-10 12:26:32,197 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-587d5b2e-530e-49a3-9345-15e63c18256e/container.db to cache
datanode_2  | 2022-12-10 12:26:32,203 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-587d5b2e-530e-49a3-9345-15e63c18256e/container.db for volume DS-587d5b2e-530e-49a3-9345-15e63c18256e
datanode_2  | 2022-12-10 12:26:32,209 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2022-12-10 12:26:32,221 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_2  | 2022-12-10 12:26:32,729 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 12:26:32,911 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start RPC server
datanode_2  | 2022-12-10 12:26:32,924 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: c93c8eed-0198-45d8-87bc-3d7834e7dd79: GrpcService started, listening on 9858
datanode_2  | 2022-12-10 12:26:32,933 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: c93c8eed-0198-45d8-87bc-3d7834e7dd79: GrpcService started, listening on 9856
datanode_2  | 2022-12-10 12:26:32,942 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: c93c8eed-0198-45d8-87bc-3d7834e7dd79: GrpcService started, listening on 9857
datanode_2  | 2022-12-10 12:26:32,975 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c93c8eed-0198-45d8-87bc-3d7834e7dd79 is started using port 9858 for RATIS
datanode_2  | 2022-12-10 12:26:32,975 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c93c8eed-0198-45d8-87bc-3d7834e7dd79 is started using port 9857 for RATIS_ADMIN
datanode_2  | 2022-12-10 12:26:32,977 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c93c8eed-0198-45d8-87bc-3d7834e7dd79 is started using port 9856 for RATIS_SERVER
datanode_2  | 2022-12-10 12:26:32,977 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-c93c8eed-0198-45d8-87bc-3d7834e7dd79: Started
datanode_2  | 2022-12-10 12:26:41,727 [Command processor thread] INFO server.RaftServer: c93c8eed-0198-45d8-87bc-3d7834e7dd79: addNew group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] returns group-AF81ED93FE6E:java.util.concurrent.CompletableFuture@6bc06896[Not completed]
datanode_2  | 2022-12-10 12:26:41,864 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79: new RaftServerImpl for group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_2  | 2022-12-10 12:26:41,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2022-12-10 12:26:41,878 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2022-12-10 12:26:41,879 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2022-12-10 12:26:41,879 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-12-10 12:26:41,879 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-12-10 12:26:41,880 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2022-12-10 12:26:41,933 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: ConfigurationManager, init=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_2  | 2022-12-10 12:26:41,937 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-12-10 12:26:42,016 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2022-12-10 12:26:42,017 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2022-12-10 12:26:42,072 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2022-12-10 12:26:42,088 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2022-12-10 12:26:42,088 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2022-12-10 12:26:42,378 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-12-10 12:26:42,389 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2  | 2022-12-10 12:26:42,393 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2  | 2022-12-10 12:26:42,396 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2  | 2022-12-10 12:26:42,425 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 2022-12-10 12:26:42,430 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e does not exist. Creating ...
datanode_2  | 2022-12-10 12:26:42,460 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/in_use.lock acquired by nodename 6@6dce7f01dcdb
datanode_2  | 2022-12-10 12:26:42,516 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e has been successfully formatted.
datanode_2  | 2022-12-10 12:26:42,586 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2022-12-10 12:26:42,602 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2022-12-10 12:26:42,682 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2022-12-10 12:26:42,686 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:42,694 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2  | 2022-12-10 12:26:42,703 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_2  | 2022-12-10 12:26:42,724 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:42,798 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2022-12-10 12:26:42,805 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2022-12-10 12:26:42,848 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_1  | 2022-12-10 12:26:38,076 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_1  | 2022-12-10 12:26:38,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-12-10 12:26:38,181 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2022-12-10 12:26:38,186 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2022-12-10 12:26:38,243 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d792bf06-25f5-4ba9-821b-977d25aa3d3c
datanode_1  | 2022-12-10 12:26:38,245 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1  | 2022-12-10 12:26:38,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 12:26:38,264 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-12-10 12:26:38,265 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2022-12-10 12:26:38,267 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2022-12-10 12:26:38,269 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2022-12-10 12:26:38,271 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2022-12-10 12:26:38,274 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2022-12-10 12:26:38,331 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2022-12-10 12:26:38,333 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 12:26:38,417 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_1  | 2022-12-10 12:26:38,423 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_1  | 2022-12-10 12:26:38,435 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2022-12-10 12:26:38,515 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-12-10 12:26:38,515 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-12-10 12:26:38,535 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: start as a follower, conf=-1: peers:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 12:26:38,538 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2022-12-10 12:26:38,549 [pool-22-thread-1] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState
datanode_1  | 2022-12-10 12:26:38,569 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 12:26:38,572 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 12:26:38,646 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-977D25AA3D3C,id=eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_1  | 2022-12-10 12:26:38,657 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2022-12-10 12:26:38,763 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2022-12-10 12:26:38,766 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2022-12-10 12:26:38,783 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2022-12-10 12:26:38,973 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d792bf06-25f5-4ba9-821b-977d25aa3d3c
datanode_1  | 2022-12-10 12:26:38,980 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d792bf06-25f5-4ba9-821b-977d25aa3d3c.
datanode_1  | 2022-12-10 12:26:43,676 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5126750983ns, electionTimeout:5102ms
datanode_1  | 2022-12-10 12:26:43,678 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState
datanode_1  | 2022-12-10 12:26:43,678 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2022-12-10 12:26:43,683 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-12-10 12:26:43,684 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1
datanode_1  | 2022-12-10 12:26:43,714 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 12:26:43,716 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2022-12-10 12:26:43,722 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1
datanode_1  | 2022-12-10 12:26:43,727 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2022-12-10 12:26:43,730 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-977D25AA3D3C with new leaderId: eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_1  | 2022-12-10 12:26:43,733 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: change Leader from null to eb6b06af-1f2c-4397-8743-5d103932e2bb at term 1 for becomeLeader, leader elected after 6108ms
datanode_1  | 2022-12-10 12:26:43,801 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2022-12-10 12:26:43,871 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 12:26:43,882 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2022-12-10 12:25:40,983 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = d6dbe5575a0d/172.19.0.5
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_3  | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | ************************************************************/
datanode_3  | 2022-12-10 12:25:41,018 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2022-12-10 12:25:41,364 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2022-12-10 12:25:42,168 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2022-12-10 12:25:43,231 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2022-12-10 12:25:43,232 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2022-12-10 12:25:44,091 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d6dbe5575a0d ip:172.19.0.5
datanode_3  | 2022-12-10 12:25:46,940 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3  | 2022-12-10 12:25:47,949 [main] INFO reflections.Reflections: Reflections took 827 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_3  | 2022-12-10 12:25:48,725 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_3  | 2022-12-10 12:25:50,220 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2022-12-10 12:25:50,374 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_3  | 2022-12-10 12:25:50,404 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2022-12-10 12:25:50,419 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2022-12-10 12:25:50,759 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2022-12-10 12:25:51,085 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2022-12-10 12:25:51,109 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_3  | 2022-12-10 12:25:51,119 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_3  | 2022-12-10 12:25:51,127 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_3  | 2022-12-10 12:25:51,131 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_3  | 2022-12-10 12:25:51,491 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2022-12-10 12:25:51,492 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2022-12-10 12:26:00,883 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_3  | 2022-12-10 12:26:01,376 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2022-12-10 12:26:01,596 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2022-12-10 12:26:02,881 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2022-12-10 12:26:02,965 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_3  | 2022-12-10 12:26:02,978 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2022-12-10 12:26:03,007 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_3  | 2022-12-10 12:26:03,008 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_3  | 2022-12-10 12:26:03,013 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_3  | 2022-12-10 12:26:03,014 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2022-12-10 12:26:03,015 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 12:26:03,055 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2022-12-10 12:26:03,080 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2022-12-10 12:26:03,177 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_3  | 2022-12-10 12:26:03,223 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_3  | 2022-12-10 12:26:03,245 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_3  | 2022-12-10 12:26:05,444 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3  | 2022-12-10 12:26:05,446 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_3  | 2022-12-10 12:26:05,455 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_3  | 2022-12-10 12:26:05,465 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-12-10 12:26:05,466 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-12-10 12:26:05,473 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-12-10 12:26:05,685 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_3  | 2022-12-10 12:26:07,364 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2022-12-10 12:26:07,494 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2022-12-10 12:26:07,740 [main] INFO util.log: Logging initialized @38941ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2022-12-10 12:26:08,457 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_3  | 2022-12-10 12:26:08,546 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2022-12-10 12:26:08,620 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2022-12-10 12:26:08,623 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2022-12-10 12:26:43,919 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2022-12-10 12:26:43,920 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2022-12-10 12:26:43,921 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2022-12-10 12:26:44,000 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 12:26:44,016 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2022-12-10 12:26:44,026 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderStateImpl
datanode_1  | 2022-12-10 12:26:44,232 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2022-12-10 12:26:44,803 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-LeaderElection1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C: set configuration 0: peers:[eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 12:26:45,001 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-977D25AA3D3C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d792bf06-25f5-4ba9-821b-977d25aa3d3c/current/log_inprogress_0
datanode_1  | 2022-12-10 13:08:37,653 [grpc-default-executor-0] INFO server.RaftServer: eb6b06af-1f2c-4397-8743-5d103932e2bb: addNew group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER] returns group-18DDCF3CC495:java.util.concurrent.CompletableFuture@63f47fd7[Not completed]
datanode_1  | 2022-12-10 13:08:37,664 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb: new RaftServerImpl for group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_1  | 2022-12-10 13:08:37,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2022-12-10 13:08:37,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2022-12-10 13:08:37,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2022-12-10 13:08:37,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-12-10 13:08:37,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-12-10 13:08:37,668 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2022-12-10 13:08:37,668 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: ConfigurationManager, init=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2022-12-10 13:08:37,669 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-12-10 13:08:37,670 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2022-12-10 13:08:37,671 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2022-12-10 13:08:37,673 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2022-12-10 13:08:37,673 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2022-12-10 13:08:37,673 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2022-12-10 13:08:37,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-12-10 13:08:37,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1  | 2022-12-10 13:08:37,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1  | 2022-12-10 13:08:37,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1  | 2022-12-10 13:08:37,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2022-12-10 13:08:37,679 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 does not exist. Creating ...
datanode_1  | 2022-12-10 13:08:37,682 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/in_use.lock acquired by nodename 6@d9c349586e96
datanode_1  | 2022-12-10 13:08:37,689 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 has been successfully formatted.
datanode_1  | 2022-12-10 13:08:37,701 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-18DDCF3CC495: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2022-12-10 13:08:37,701 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2022-12-10 13:08:37,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2022-12-10 13:08:37,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 13:08:37,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2  | 2022-12-10 12:26:42,875 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2022-12-10 12:26:42,875 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:42,876 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:42,877 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2022-12-10 12:26:42,878 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2022-12-10 12:26:42,889 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2022-12-10 12:26:42,890 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2022-12-10 12:26:42,891 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2022-12-10 12:26:42,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:42,970 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:43,048 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2  | 2022-12-10 12:26:43,055 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2022-12-10 12:26:43,056 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2022-12-10 12:26:43,101 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-12-10 12:26:43,103 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-12-10 12:26:43,111 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: start as a follower, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:43,112 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2022-12-10 12:26:43,119 [pool-22-thread-1] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:43,130 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:43,132 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:43,166 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 12:26:43,182 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2022-12-10 12:26:43,183 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2022-12-10 12:26:43,184 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2022-12-10 12:26:43,187 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2022-12-10 12:26:43,331 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_2  | 2022-12-10 12:26:47,815 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e.
datanode_2  | 2022-12-10 12:26:47,835 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79: new RaftServerImpl for group-1150C0739B5C:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_2  | 2022-12-10 12:26:47,838 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2022-12-10 12:26:47,839 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2022-12-10 12:26:47,840 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2022-12-10 12:26:47,841 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-12-10 12:26:47,842 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-12-10 12:26:47,843 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2022-12-10 12:26:47,844 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: ConfigurationManager, init=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_2  | 2022-12-10 12:26:47,845 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-12-10 12:26:47,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2022-12-10 12:26:47,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2022-12-10 12:26:47,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2022-12-10 12:26:47,849 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2022-12-10 12:26:47,850 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2022-12-10 12:26:47,859 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-12-10 12:26:47,859 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2  | 2022-12-10 12:26:47,862 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2  | 2022-12-10 12:26:47,863 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4  | 2022-12-10 12:26:11,333 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4  | 2022-12-10 12:26:11,393 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4  | 2022-12-10 12:26:11,421 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4  | 2022-12-10 12:26:11,422 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4  | 2022-12-10 12:26:11,433 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4  | 2022-12-10 12:26:11,865 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4  | 2022-12-10 12:26:11,867 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_4  | 2022-12-10 12:26:12,120 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4  | 2022-12-10 12:26:12,120 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4  | 2022-12-10 12:26:12,122 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4  | 2022-12-10 12:26:12,278 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7aef8000{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4  | 2022-12-10 12:26:12,303 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f7c4e0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4  | 2022-12-10 12:26:13,105 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3435a4e5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-6163501143736012351/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4  | 2022-12-10 12:26:13,215 [main] INFO server.AbstractConnector: Started ServerConnector@7d216ee8{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_4  | 2022-12-10 12:26:13,215 [main] INFO server.Server: Started @43279ms
datanode_4  | 2022-12-10 12:26:13,221 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4  | 2022-12-10 12:26:13,221 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4  | 2022-12-10 12:26:13,225 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4  | 2022-12-10 12:26:13,239 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_4  | 2022-12-10 12:26:13,292 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6bd5f0df] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4  | 2022-12-10 12:26:14,351 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_4  | 2022-12-10 12:26:15,255 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4  | 2022-12-10 12:26:16,803 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:16,805 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:17,805 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:17,806 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:18,806 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:18,806 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:19,807 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:19,808 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:20,808 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:21,811 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:22,812 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:23,813 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:24,814 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:24,862 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_4  | java.net.SocketTimeoutException: Call From c79f062f35ec/172.19.0.9 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.9:42236 remote=recon/172.19.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_4  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_4  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.9:42236 remote=recon/172.19.0.3:9891]
datanode_4  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_4  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_4  | 2022-12-10 12:26:25,815 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-12-10 12:26:30,827 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4  | java.net.SocketTimeoutException: Call From c79f062f35ec/172.19.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.9:45070 remote=scm/172.19.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_4  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_4  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_2  | 2022-12-10 12:26:47,864 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 2022-12-10 12:26:47,878 [Command processor thread] INFO server.RaftServer: c93c8eed-0198-45d8-87bc-3d7834e7dd79: addNew group-1150C0739B5C:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER] returns      null c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C:t0, leader=null, voted=null, raftlog=UNINITIALIZED, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null NEW
datanode_2  | 2022-12-10 12:26:47,879 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d2f8c45a-a0b2-410a-969f-1150c0739b5c does not exist. Creating ...
datanode_2  | 2022-12-10 12:26:47,882 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d2f8c45a-a0b2-410a-969f-1150c0739b5c/in_use.lock acquired by nodename 6@6dce7f01dcdb
datanode_2  | 2022-12-10 12:26:47,891 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d2f8c45a-a0b2-410a-969f-1150c0739b5c has been successfully formatted.
datanode_2  | 2022-12-10 12:26:47,892 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-1150C0739B5C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2022-12-10 12:26:47,892 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2022-12-10 12:26:47,918 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2022-12-10 12:26:47,918 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:47,922 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2  | 2022-12-10 12:26:47,922 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_2  | 2022-12-10 12:26:47,926 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:47,927 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2022-12-10 12:26:47,927 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2022-12-10 12:26:47,927 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d2f8c45a-a0b2-410a-969f-1150c0739b5c
datanode_2  | 2022-12-10 12:26:47,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2022-12-10 12:26:47,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:47,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:47,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2022-12-10 12:26:47,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2022-12-10 12:26:47,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2022-12-10 12:26:47,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_5  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5  | 2022-12-10 12:25:41,472 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5  | /************************************************************
datanode_5  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5  | STARTUP_MSG:   host = cef178baecd7/172.19.0.8
datanode_5  | STARTUP_MSG:   args = []
datanode_5  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_5  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_5  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_5  | STARTUP_MSG:   java = 11.0.14.1
datanode_5  | ************************************************************/
datanode_5  | 2022-12-10 12:25:41,533 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5  | 2022-12-10 12:25:41,965 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5  | 2022-12-10 12:25:42,777 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5  | 2022-12-10 12:25:43,665 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5  | 2022-12-10 12:25:43,665 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5  | 2022-12-10 12:25:44,558 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:cef178baecd7 ip:172.19.0.8
datanode_5  | 2022-12-10 12:25:47,572 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_5  | 2022-12-10 12:25:48,826 [main] INFO reflections.Reflections: Reflections took 990 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_5  | 2022-12-10 12:25:49,715 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_5  | 2022-12-10 12:25:51,405 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5  | 2022-12-10 12:25:51,619 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_5  | 2022-12-10 12:25:51,657 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5  | 2022-12-10 12:25:51,711 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5  | 2022-12-10 12:25:52,003 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5  | 2022-12-10 12:25:52,363 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5  | 2022-12-10 12:25:52,377 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_5  | 2022-12-10 12:25:52,430 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_5  | 2022-12-10 12:25:52,439 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_5  | 2022-12-10 12:25:52,443 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_5  | 2022-12-10 12:25:52,807 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_5  | 2022-12-10 12:25:52,819 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_5  | 2022-12-10 12:26:03,184 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_5  | 2022-12-10 12:26:04,232 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5  | 2022-12-10 12:26:04,698 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_5  | 2022-12-10 12:26:05,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_5  | 2022-12-10 12:26:05,885 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_5  | 2022-12-10 12:26:05,891 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_5  | 2022-12-10 12:26:05,895 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_5  | 2022-12-10 12:26:05,895 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_5  | 2022-12-10 12:26:05,899 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_5  | 2022-12-10 12:26:05,900 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5  | 2022-12-10 12:26:05,911 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 12:26:05,991 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5  | 2022-12-10 12:26:05,992 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5  | 2022-12-10 12:26:06,108 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_5  | 2022-12-10 12:26:06,136 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_5  | 2022-12-10 12:26:06,159 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_5  | 2022-12-10 12:26:08,298 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_5  | 2022-12-10 12:26:08,324 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_5  | 2022-12-10 12:26:08,327 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_5  | 2022-12-10 12:26:08,328 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5  | 2022-12-10 12:26:08,379 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-12-10 12:26:08,416 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5  | 2022-12-10 12:26:08,796 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_5  | 2022-12-10 12:26:10,618 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5  | 2022-12-10 12:26:10,727 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5  | 2022-12-10 12:26:10,975 [main] INFO util.log: Logging initialized @41778ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5  | 2022-12-10 12:26:11,737 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_5  | 2022-12-10 12:26:11,778 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5  | 2022-12-10 12:26:11,844 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2022-12-10 12:26:47,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2022-12-10 12:26:47,935 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2022-12-10 12:26:47,937 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:48,726 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] WARN impl.FollowerState: Unexpected long sleep: sleep 5016ms but took extra 577753761ns (> threshold = 300ms)
datanode_2  | 2022-12-10 12:26:48,727 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-c93c8eed-0198-45d8-87bc-3d7834e7dd79: Detected pause in JVM or host machine (eg GC): pause of approximately 664389655ns.
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=91ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=723ms
datanode_2  | 2022-12-10 12:26:48,754 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2  | 2022-12-10 12:26:48,727 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:48,772 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:48,772 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2022-12-10 12:26:48,773 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2022-12-10 12:26:48,775 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-12-10 12:26:48,776 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-12-10 12:26:48,784 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: start as a follower, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:48,786 [pool-22-thread-1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2022-12-10 12:26:48,787 [pool-22-thread-1] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState
datanode_2  | 2022-12-10 12:26:48,793 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1150C0739B5C,id=c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 12:26:48,808 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2022-12-10 12:26:48,809 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2022-12-10 12:26:48,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2022-12-10 12:26:48,814 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2022-12-10 12:26:48,808 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:48,818 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:48,833 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d2f8c45a-a0b2-410a-969f-1150c0739b5c
datanode_2  | 2022-12-10 12:26:48,833 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d2f8c45a-a0b2-410a-969f-1150c0739b5c.
datanode_2  | 2022-12-10 12:26:48,979 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-AF81ED93FE6E, 1, (t:0, i:0))
datanode_2  | 2022-12-10 12:26:48,999 [grpc-default-executor-0] INFO impl.VoteContext: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_2  | 2022-12-10 12:26:49,001 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_2  | 2022-12-10 12:26:49,002 [grpc-default-executor-0] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:49,008 [grpc-default-executor-0] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:49,008 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState was interrupted
datanode_2  | 2022-12-10 12:26:49,038 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:49,051 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:49,103 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t1. Peer's state: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E:t1, leader=null, voted=null, raftlog=Memoized:c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:53,586 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: receive requestVote(ELECTION, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef, group-AF81ED93FE6E, 2, (t:0, i:0))
datanode_2  | 2022-12-10 12:26:53,586 [grpc-default-executor-0] INFO impl.VoteContext: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FOLLOWER: reject ELECTION from 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: our priority 1 > candidate's priority 0
datanode_2  | 2022-12-10 12:26:53,587 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_2  | 2022-12-10 12:26:53,587 [grpc-default-executor-0] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:53,587 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState was interrupted
datanode_2  | 2022-12-10 12:26:53,588 [grpc-default-executor-0] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:53,589 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:53,589 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:53,591 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E replies to ELECTION vote request: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t2. Peer's state: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E:t2, leader=null, voted=null, raftlog=Memoized:c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:53,901 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO impl.FollowerState: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113803753ns, electionTimeout:5081ms
datanode_2  | 2022-12-10 12:26:53,901 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState
datanode_2  | 2022-12-10 12:26:53,901 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2022-12-10 12:26:53,905 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2022-12-10 12:26:53,905 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-FollowerState] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1
datanode_2  | 2022-12-10 12:26:53,910 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO impl.LeaderElection: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:53,911 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO impl.LeaderElection: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_2  | 2022-12-10 12:26:53,912 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1
datanode_2  | 2022-12-10 12:26:53,912 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2022-12-10 12:26:53,912 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1150C0739B5C with new leaderId: c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 12:26:53,920 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: change Leader from null to c93c8eed-0198-45d8-87bc-3d7834e7dd79 at term 1 for becomeLeader, leader elected after 6064ms
datanode_2  | 2022-12-10 12:26:53,933 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2022-12-10 12:26:53,941 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:53,941 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_2  | 2022-12-10 12:26:53,959 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2022-12-10 12:26:53,960 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2022-12-10 12:26:53,962 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2022-12-10 12:26:53,983 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:53,987 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2  | 2022-12-10 12:26:53,994 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderStateImpl
datanode_2  | 2022-12-10 12:26:54,037 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2022-12-10 12:26:54,080 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-LeaderElection1] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:54,209 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-1150C0739B5C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d2f8c45a-a0b2-410a-969f-1150c0739b5c/current/log_inprogress_0
datanode_2  | 2022-12-10 12:26:58,620 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5032197344ns, electionTimeout:5031ms
datanode_2  | 2022-12-10 12:26:58,621 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState
datanode_2  | 2022-12-10 12:26:58,621 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_2  | 2022-12-10 12:26:58,622 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2022-12-10 12:26:58,622 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2
datanode_2  | 2022-12-10 12:26:58,628 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2 ELECTION round 0: submit vote requests at term 3 for -1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:58,646 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2022-12-10 12:26:58,646 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2022-12-10 12:26:58,647 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_2  | 2022-12-10 12:26:58,656 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_2  | 2022-12-10 12:26:58,744 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_2  | 2022-12-10 12:26:58,746 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection:   Response 0: c93c8eed-0198-45d8-87bc-3d7834e7dd79<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t3
datanode_2  | 2022-12-10 12:26:58,746 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2 ELECTION round 0: result PASSED
datanode_2  | 2022-12-10 12:26:58,749 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2
datanode_2  | 2022-12-10 12:26:58,749 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
datanode_2  | 2022-12-10 12:26:58,750 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AF81ED93FE6E with new leaderId: c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 12:26:58,759 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: change Leader from null to c93c8eed-0198-45d8-87bc-3d7834e7dd79 at term 3 for becomeLeader, leader elected after 16680ms
datanode_2  | 2022-12-10 12:26:58,759 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2022-12-10 12:26:58,760 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:58,760 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_2  | 2022-12-10 12:26:58,760 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2022-12-10 12:26:58,761 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2022-12-10 12:26:58,761 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2022-12-10 12:26:58,762 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-12-10 12:26:58,762 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2  | 2022-12-10 12:26:58,769 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: receive requestVote(ELECTION, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef, group-AF81ED93FE6E, 3, (t:0, i:0))
datanode_2  | 2022-12-10 12:26:58,817 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2022-12-10 12:26:58,817 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:58,817 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2022-12-10 12:26:58,827 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2022-12-10 12:26:58,827 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2022-12-10 12:26:58,827 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-12-10 12:26:58,827 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 2022-12-10 12:26:58,827 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 2022-12-10 12:26:58,838 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_2  | 2022-12-10 12:26:58,844 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: start c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderStateImpl
datanode_2  | 2022-12-10 12:26:58,846 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2022-12-10 12:26:58,849 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/current/log_inprogress_0
datanode_2  | 2022-12-10 12:26:58,852 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 12:26:58,852 [grpc-default-executor-0] INFO impl.VoteContext: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LEADER: reject ELECTION from 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: already has voted for c93c8eed-0198-45d8-87bc-3d7834e7dd79 at current term 3
datanode_2  | 2022-12-10 12:26:58,852 [grpc-default-executor-0] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E replies to ELECTION vote request: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t3. Peer's state: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E:t3, leader=c93c8eed-0198-45d8-87bc-3d7834e7dd79, voted=c93c8eed-0198-45d8-87bc-3d7834e7dd79, raftlog=Memoized:c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2022-12-10 13:05:13,999 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_2  | 2022-12-10 13:05:14,000 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_2  | 2022-12-10 13:05:14,021 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 3262.
datanode_2  | 2022-12-10 13:07:53,595 [grpc-default-executor-14] WARN server.GrpcClientProtocolService: 101-OrderedRequestStreamObserver101: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
datanode_2  | 2022-12-10 13:08:05,776 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
datanode_2  | 2022-12-10 13:08:05,778 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3274 -> 3273
datanode_2  | 2022-12-10 13:08:05,782 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
datanode_2  | 2022-12-10 13:08:05,782 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3273 -> 3272
datanode_2  | 2022-12-10 13:08:05,797 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:05,798 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3273 -> 3272
datanode_2  | 2022-12-10 13:08:05,799 [grpc-default-executor-18] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5  | 2022-12-10 12:26:11,860 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5  | 2022-12-10 12:26:11,878 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5  | 2022-12-10 12:26:11,879 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5  | 2022-12-10 12:26:12,209 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5  | 2022-12-10 12:26:12,212 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_5  | 2022-12-10 12:26:12,572 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5  | 2022-12-10 12:26:12,572 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5  | 2022-12-10 12:26:12,576 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5  | 2022-12-10 12:26:12,664 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fd8b081{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5  | 2022-12-10 12:26:12,710 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7efba9b9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5  | 2022-12-10 12:26:13,770 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1f235a0a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3342051410417490111/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5  | 2022-12-10 12:26:13,844 [main] INFO server.AbstractConnector: Started ServerConnector@110318a7{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_5  | 2022-12-10 12:26:13,846 [main] INFO server.Server: Started @44650ms
datanode_5  | 2022-12-10 12:26:13,866 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5  | 2022-12-10 12:26:13,867 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5  | 2022-12-10 12:26:13,868 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5  | 2022-12-10 12:26:13,886 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_5  | 2022-12-10 12:26:14,003 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b256830] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5  | 2022-12-10 12:26:14,847 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_5  | 2022-12-10 12:26:15,251 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5  | 2022-12-10 12:26:17,287 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:17,291 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:18,106 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_5  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:306)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:506)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	... 1 more
datanode_5  | 2022-12-10 12:26:18,288 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:18,292 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:19,289 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:19,292 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:20,109 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_5  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:306)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:506)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	... 1 more
datanode_5  | 2022-12-10 12:26:20,290 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:20,293 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:21,294 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:22,295 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:23,296 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:24,297 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:25,298 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:25,333 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_5  | java.net.SocketTimeoutException: Call From cef178baecd7/172.19.0.8 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.8:57622 remote=recon/172.19.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_5  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_5  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.8:57622 remote=recon/172.19.0.3:9891]
datanode_5  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_5  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_5  | 2022-12-10 12:26:26,299 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-12-10 12:26:31,310 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5  | java.net.SocketTimeoutException: Call From cef178baecd7/172.19.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.8:43828 remote=scm/172.19.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_5  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_5  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_3  | 2022-12-10 12:26:08,639 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2022-12-10 12:26:08,639 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2022-12-10 12:26:09,102 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2022-12-10 12:26:09,117 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 2022-12-10 12:26:09,458 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2022-12-10 12:26:09,459 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2022-12-10 12:26:09,460 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2022-12-10 12:26:09,577 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fe38b73{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2022-12-10 12:26:09,599 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b8cde43{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2022-12-10 12:26:10,403 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@75d402d4{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12578970633873064983/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2022-12-10 12:26:10,464 [main] INFO server.AbstractConnector: Started ServerConnector@42ac309{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2022-12-10 12:26:10,480 [main] INFO server.Server: Started @41680ms
datanode_3  | 2022-12-10 12:26:10,485 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2022-12-10 12:26:10,485 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2022-12-10 12:26:10,511 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2022-12-10 12:26:10,546 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3  | 2022-12-10 12:26:11,067 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c572e92] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2022-12-10 12:26:12,171 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_3  | 2022-12-10 12:26:12,749 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2022-12-10 12:26:14,814 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:14,866 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:15,821 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:15,869 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:16,822 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:16,870 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:17,823 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:17,871 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:18,823 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:18,871 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:19,824 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.19.0.3:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:19,878 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:20,879 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:21,880 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:22,881 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:23,882 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:24,859 [EndpointStateMachine task thread for recon/172.19.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From d6dbe5575a0d/172.19.0.5 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.5:42152 remote=recon/172.19.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 2022-12-10 13:08:37,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_1  | 2022-12-10 13:08:37,704 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-12-10 13:08:37,707 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2022-12-10 13:08:37,709 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2022-12-10 13:08:37,709 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495
datanode_1  | 2022-12-10 13:08:37,709 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1  | 2022-12-10 13:08:37,711 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 13:08:37,711 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-12-10 13:08:37,711 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2022-12-10 13:08:37,711 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2022-12-10 13:08:37,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2022-12-10 13:08:37,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2022-12-10 13:08:37,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2022-12-10 13:08:37,713 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2022-12-10 13:08:37,715 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 13:08:37,763 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_1  | 2022-12-10 13:08:37,765 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_1  | 2022-12-10 13:08:37,765 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2022-12-10 13:08:37,766 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-12-10 13:08:37,766 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-12-10 13:08:37,774 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: start as a follower, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:08:37,776 [pool-22-thread-1] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2022-12-10 13:08:37,776 [pool-22-thread-1] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:37,781 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18DDCF3CC495,id=eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_1  | 2022-12-10 13:08:37,782 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2022-12-10 13:08:37,784 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2022-12-10 13:08:37,785 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2022-12-10 13:08:37,785 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2022-12-10 13:08:37,786 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:37,804 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:08:38,869 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,869 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,877 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is closed with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,887 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,887 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,902 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is closed with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,930 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,930 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,949 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is closed with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,971 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,972 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:38,990 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is closed with bcsId 0.
datanode_1  | 2022-12-10 13:08:39,006 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:39,007 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_1  | 2022-12-10 13:08:39,024 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is closed with bcsId 0.
datanode_1  | 2022-12-10 13:08:42,565 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 1, (t:0, i:0))
datanode_1  | 2022-12-10 13:08:42,567 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_3  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.5:42152 remote=recon/172.19.0.3:9891]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_3  | 2022-12-10 12:26:24,883 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:25,884 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.19.0.2:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-12-10 12:26:30,896 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From d6dbe5575a0d/172.19.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.5:58536 remote=scm/172.19.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_3  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.5:58536 remote=scm/172.19.0.2:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2022-12-10 12:25:38,484 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = 967e10220715/172.19.0.3
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.3.23.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.3.23.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.3.23.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.3.23.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.3.23.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:08Z
recon_1     | STARTUP_MSG:   java = 11.0.14.1
recon_1     | ************************************************************/
recon_1     | 2022-12-10 12:25:38,584 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2022-12-10 12:25:43,398 [main] INFO reflections.Reflections: Reflections took 687 ms to scan 1 urls, producing 16 keys and 51 values 
recon_1     | 2022-12-10 12:25:49,607 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2022-12-10 12:25:52,366 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2022-12-10 12:26:01,510 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2022-12-10 12:26:03,754 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1     | 2022-12-10 12:26:03,795 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.04 seconds to initialized 0 records to KEY_CONTAINER table
recon_1     | 2022-12-10 12:26:03,846 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2022-12-10 12:26:04,066 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2022-12-10 12:26:04,095 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | 2022-12-10 12:26:11,166 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2022-12-10 12:26:11,260 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1     | 2022-12-10 12:26:11,349 [main] INFO util.log: Logging initialized @44190ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2022-12-10 12:26:12,108 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
recon_1     | 2022-12-10 12:26:12,158 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2022-12-10 12:26:12,195 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2022-12-10 12:26:12,197 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2022-12-10 12:26:12,197 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2022-12-10 12:26:12,219 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2022-12-10 12:26:13,586 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2022-12-10 12:26:15,482 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2022-12-10 12:26:15,515 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1     | 2022-12-10 12:26:15,537 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1     | 2022-12-10 12:26:15,605 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1     | 2022-12-10 12:26:15,605 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1     | 2022-12-10 12:26:17,483 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-12-10 12:26:17,940 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-12-10 12:26:18,079 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1     | 2022-12-10 12:26:18,082 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2022-12-10 12:26:18,308 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-12-10 12:26:18,642 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1     | 2022-12-10 12:26:18,782 [main] INFO reflections.Reflections: Reflections took 131 ms to scan 3 urls, producing 116 keys and 266 values 
recon_1     | 2022-12-10 12:26:18,931 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1     | 2022-12-10 12:26:18,998 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 60000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 60000.
recon_1     | 2022-12-10 12:26:19,012 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2022-12-10 12:26:19,022 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2022-12-10 12:26:19,041 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1     | 2022-12-10 12:26:19,101 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1     | 2022-12-10 12:26:19,169 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2022-12-10 12:26:19,297 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2022-12-10 12:26:19,405 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1     | 2022-12-10 12:26:19,689 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2022-12-10 12:26:19,689 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2022-12-10 12:26:19,923 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2022-12-10 12:26:19,963 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2022-12-10 12:26:19,964 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2022-12-10 12:26:20,723 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2022-12-10 12:26:20,724 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
recon_1     | 2022-12-10 12:26:20,806 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2022-12-10 12:26:20,806 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2022-12-10 12:26:20,815 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2022-12-10 12:26:20,856 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@39ac8c0c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2022-12-10 12:26:20,862 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78b8f818{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2022-12-10 12:26:24,523 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@58c4d427{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-11050612425243268394/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2022-12-10 12:26:24,558 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@1479ed5a{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1     | 2022-12-10 12:26:24,558 [Listener at 0.0.0.0/9891] INFO server.Server: Started @57399ms
recon_1     | 2022-12-10 12:26:24,568 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2022-12-10 12:26:24,568 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2022-12-10 12:26:24,570 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2022-12-10 12:26:24,570 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2022-12-10 12:26:24,587 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2022-12-10 12:26:24,599 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2022-12-10 12:26:24,600 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
datanode_2  | 2022-12-10 13:08:05,800 [grpc-default-executor-18] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3272 -> 3271
datanode_2  | 2022-12-10 13:08:06,313 [grpc-default-executor-18] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:06,314 [grpc-default-executor-18] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3271 -> 3270
datanode_2  | 2022-12-10 13:08:06,313 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:06,317 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3270 -> 3269
datanode_2  | 2022-12-10 13:08:06,323 [grpc-default-executor-19] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:06,325 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:06,334 [grpc-default-executor-19] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3270 -> 3269
datanode_2  | 2022-12-10 13:08:06,335 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3269 -> 3268
datanode_2  | 2022-12-10 13:08:07,564 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:07,564 [grpc-default-executor-19] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:07,565 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3268 -> 3267
datanode_2  | 2022-12-10 13:08:07,570 [grpc-default-executor-19] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3267 -> 3266
datanode_2  | 2022-12-10 13:08:07,575 [grpc-default-executor-19] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:07,576 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:07,578 [grpc-default-executor-19] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3267 -> 3266
datanode_2  | 2022-12-10 13:08:07,580 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3266 -> 3265
datanode_2  | 2022-12-10 13:08:37,080 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,083 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,088 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is closed with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,103 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,103 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,111 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is closed with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,151 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,152 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,158 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is closed with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,187 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-4] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_2  | 2022-12-10 13:08:37,187 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-4] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_2  | 2022-12-10 13:08:37,191 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-4] INFO keyvalue.KeyValueContainer: Container 9 is closed with bcsId 3272.
datanode_2  | 2022-12-10 13:08:37,197 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,197 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,209 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is closed with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,229 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,229 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_2  | 2022-12-10 13:08:37,255 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is closed with bcsId 0.
datanode_2  | 2022-12-10 13:08:38,452 [grpc-default-executor-18] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:38,452 [grpc-default-executor-18] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3266 -> 3265
datanode_2  | 2022-12-10 13:08:38,753 [grpc-default-executor-14] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_2  | 2022-12-10 13:08:38,753 [grpc-default-executor-14] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef: nextIndex: updateUnconditionally 3265 -> 3264
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.9:45070 remote=scm/172.19.0.2:9861]
datanode_4  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_4  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_4  | 2022-12-10 12:26:32,036 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db to cache
datanode_4  | 2022-12-10 12:26:32,044 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db for volume DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a
datanode_4  | 2022-12-10 12:26:32,051 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4  | 2022-12-10 12:26:32,064 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_4  | 2022-12-10 12:26:32,542 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 12:26:32,667 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start RPC server
datanode_4  | 2022-12-10 12:26:32,683 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9858
datanode_4  | 2022-12-10 12:26:32,693 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9856
datanode_4  | 2022-12-10 12:26:32,702 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9857
datanode_4  | 2022-12-10 12:26:32,721 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9858 for RATIS
datanode_4  | 2022-12-10 12:26:32,721 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9857 for RATIS_ADMIN
datanode_4  | 2022-12-10 12:26:32,721 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9856 for RATIS_SERVER
datanode_4  | 2022-12-10 12:26:32,722 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-85e9a0c6-8631-4fee-9b9c-0f8004d778ef: Started
datanode_4  | 2022-12-10 12:26:41,758 [Command processor thread] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: addNew group-D18C7B531924:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER] returns group-D18C7B531924:java.util.concurrent.CompletableFuture@530fb221[Not completed]
datanode_4  | 2022-12-10 12:26:41,881 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: new RaftServerImpl for group-D18C7B531924:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_4  | 2022-12-10 12:26:41,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-12-10 12:26:41,898 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-12-10 12:26:41,899 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-12-10 12:26:41,899 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 12:26:41,900 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 12:26:41,901 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2022-12-10 13:08:42,571 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:08:42,571 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:42,572 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:08:42,578 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:42,580 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:42,580 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:08:42,589 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t1. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t1, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:08:47,711 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5132775582ns, electionTimeout:5130ms
datanode_1  | 2022-12-10 13:08:47,715 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:47,716 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1  | 2022-12-10 13:08:47,717 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-12-10 13:08:47,717 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection2
datanode_1  | 2022-12-10 13:08:47,726 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 2, (t:0, i:0))
datanode_1  | 2022-12-10 13:08:47,731 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-CANDIDATE: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:08:47,731 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 2 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:08:47,731 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection2
datanode_1  | 2022-12-10 13:08:47,731 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:47,733 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection2] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection2: skip running since this is already CLOSING
datanode_1  | 2022-12-10 13:08:47,735 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t2. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t2, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:08:47,739 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:47,739 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:08:52,760 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 3, (t:0, i:0))
datanode_1  | 2022-12-10 13:08:52,761 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:08:52,761 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:08:52,761 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:52,761 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:52,767 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:08:52,776 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:52,776 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.19.0.8:43828 remote=scm/172.19.0.2:9861]
datanode_5  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_5  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
datanode_5  | 2022-12-10 12:26:32,117 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_5  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:306)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:506)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	... 1 more
datanode_5  | 2022-12-10 12:26:32,155 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-eac40ae2-c338-42ed-8b33-e8dcb8cdd30a/container.db to cache
datanode_5  | 2022-12-10 12:26:32,156 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-eac40ae2-c338-42ed-8b33-e8dcb8cdd30a/container.db for volume DS-eac40ae2-c338-42ed-8b33-e8dcb8cdd30a
datanode_5  | 2022-12-10 12:26:32,158 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5  | 2022-12-10 12:26:32,177 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_5  | 2022-12-10 12:26:32,533 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_5  | 2022-12-10 12:26:32,687 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start RPC server
datanode_5  | 2022-12-10 12:26:32,697 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: GrpcService started, listening on 9858
datanode_5  | 2022-12-10 12:26:32,702 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: GrpcService started, listening on 9856
datanode_5  | 2022-12-10 12:26:32,707 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: GrpcService started, listening on 9857
datanode_5  | 2022-12-10 12:26:32,726 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 is started using port 9858 for RATIS
datanode_5  | 2022-12-10 12:26:32,728 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 is started using port 9857 for RATIS_ADMIN
datanode_5  | 2022-12-10 12:26:32,731 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 is started using port 9856 for RATIS_SERVER
datanode_1  | 2022-12-10 13:08:52,777 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t3. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t3, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:08:52,932 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 3, (t:0, i:0))
datanode_1  | 2022-12-10 13:08:52,932 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:08:52,933 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:08:52,933 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:52,933 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:08:52,934 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:52,934 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t3. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t3, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:08:52,936 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:52,936 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:08:57,819 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 4, (t:0, i:0))
datanode_1  | 2022-12-10 13:08:57,819 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:08:57,819 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:08:57,819 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:57,820 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:08:57,820 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:08:57,820 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:08:57,821 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:08:57,831 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t4. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t4, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:02,889 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069239361ns, electionTimeout:5068ms
datanode_1  | 2022-12-10 13:09:02,889 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:02,889 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode_1  | 2022-12-10 13:09:02,889 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-12-10 13:09:02,889 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3
datanode_1  | 2022-12-10 13:09:02,894 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: submit vote requests at term 5 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:02,898 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:02,898 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:02,902 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3-1] INFO server.GrpcServerProtocolClient: Build channel for 44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:09:02,906 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3-2] INFO server.GrpcServerProtocolClient: Build channel for 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:09:02,984 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 5, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:02,984 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-CANDIDATE: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: already has voted for eb6b06af-1f2c-4397-8743-5d103932e2bb at current term 5
datanode_1  | 2022-12-10 13:09:02,985 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t5. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t5, leader=null, voted=eb6b06af-1f2c-4397-8743-5d103932e2bb, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:03,118 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_1  | 2022-12-10 13:09:03,118 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection:   Response 0: eb6b06af-1f2c-4397-8743-5d103932e2bb<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:FAIL-t5
datanode_1  | 2022-12-10 13:09:03,118 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection:   Response 1: eb6b06af-1f2c-4397-8743-5d103932e2bb<-213470ee-8924-4d24-82c9-a8e7505514cd#0:FAIL-t5
datanode_1  | 2022-12-10 13:09:03,118 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: result REJECTED
datanode_1  | 2022-12-10 13:09:03,119 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode_1  | 2022-12-10 13:09:03,119 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3
datanode_1  | 2022-12-10 13:09:03,119 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:03,123 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:03,123 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:08,103 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 6, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:08,103 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:08,103 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:09:08,103 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:08,104 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:08,106 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:08,110 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:08,110 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:08,111 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t6. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t6, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:13,181 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 7, (t:0, i:0))
datanode_2  | 2022-12-10 13:09:08,256 [Command processor thread] INFO server.RaftServer: c93c8eed-0198-45d8-87bc-3d7834e7dd79: remove    LEADER c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E:t3, leader=c93c8eed-0198-45d8-87bc-3d7834e7dd79, voted=c93c8eed-0198-45d8-87bc-3d7834e7dd79, raftlog=Memoized:c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c3275, conf=0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
datanode_2  | 2022-12-10 13:09:08,258 [Command processor thread] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: shutdown
datanode_2  | 2022-12-10 13:09:08,258 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_2  | 2022-12-10 13:09:08,259 [Command processor thread] INFO impl.RoleInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79: shutdown c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-LeaderStateImpl
datanode_2  | 2022-12-10 13:09:08,260 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2  | 2022-12-10 13:09:08,260 [Command processor thread] INFO impl.PendingRequests: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-PendingRequests: sendNotLeaderResponses
datanode_2  | 2022-12-10 13:09:08,263 [Command processor thread] INFO impl.StateMachineUpdater: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater: set stopIndex = 3275
datanode_2  | 2022-12-10 13:09:08,264 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Taking a snapshot at:(t:3, i:3275) file /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3275
datanode_2  | 2022-12-10 13:09:08,268 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2  | 2022-12-10 13:09:08,272 [grpc-default-executor-19] INFO server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 2022-12-10 13:09:08,286 [grpc-default-executor-19] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd: nextIndex: updateUnconditionally 3276 -> 3275
datanode_2  | 2022-12-10 13:09:08,299 [grpc-default-executor-19] INFO server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 2022-12-10 13:09:08,299 [grpc-default-executor-19] INFO leader.FollowerInfo: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->213470ee-8924-4d24-82c9-a8e7505514cd: nextIndex: updateUnconditionally 3275 -> 3274
datanode_2  | 2022-12-10 13:09:08,455 [grpc-default-executor-19] INFO server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender is already stopped
datanode_2  | 2022-12-10 13:09:08,470 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Finished taking a snapshot at:(t:3, i:3275) file:/data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3275 took: 207 ms
datanode_2  | 2022-12-10 13:09:08,472 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater: Took a snapshot at index 3275
datanode_2  | 2022-12-10 13:09:08,473 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3275
datanode_2  | 2022-12-10 13:09:08,476 [Command processor thread] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: closes. applyIndex: 3275
datanode_2  | 2022-12-10 13:09:08,478 [c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2022-12-10 13:09:08,478 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E-SegmentedRaftLogWorker close()
datanode_2  | 2022-12-10 13:09:08,489 [Command processor thread] INFO server.RaftServer$Division: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_2  | 2022-12-10 13:09:08,489 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e command on datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79.
datanode_2  | 2022-12-10 13:09:08,756 [grpc-default-executor-19] INFO server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender is already stopped
datanode_2  | 2022-12-10 13:09:39,700 [timer7] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31338,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:39,701 [timer0] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31339,entriesCount=1,lastEntry=(t:3, i:3264)
datanode_2  | 2022-12-10 13:09:40,952 [timer1] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31340,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:42,201 [timer0] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31341,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:43,451 [timer2] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31342,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:44,702 [timer1] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31343,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:45,952 [timer3] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31344,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:47,202 [timer2] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31345,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:48,452 [timer4] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31346,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:49,702 [timer3] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31347,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:50,954 [timer5] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31348,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:52,203 [timer4] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31349,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:53,454 [timer6] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31350,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:54,703 [timer5] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31351,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:55,953 [timer7] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31352,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:57,204 [timer6] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31353,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:58,454 [timer0] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31354,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:09:59,704 [timer7] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31355,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:00,954 [timer1] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31356,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:02,204 [timer0] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31357,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:03,455 [timer2] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31358,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:04,705 [timer1] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31359,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:05,955 [timer2] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31360,entriesCount=0,lastEntry=null
datanode_2  | 2022-12-10 13:10:07,205 [timer0] WARN server.GrpcLogAppender: c93c8eed-0198-45d8-87bc-3d7834e7dd79@group-AF81ED93FE6E->85e9a0c6-8631-4fee-9b9c-0f8004d778ef-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=31361,entriesCount=0,lastEntry=null
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2022-12-10 12:25:41,064 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = d61bd433dcf3/172.19.0.6
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_4  | 2022-12-10 12:26:41,964 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: ConfigurationManager, init=-1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-12-10 12:26:41,966 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 12:26:42,012 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4  | 2022-12-10 12:26:42,017 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4  | 2022-12-10 12:26:42,077 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-12-10 12:26:42,101 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-12-10 12:26:42,101 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-12-10 12:26:42,446 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-12-10 12:26:42,455 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4  | 2022-12-10 12:26:42,459 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4  | 2022-12-10 12:26:42,504 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4  | 2022-12-10 12:26:42,509 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4  | 2022-12-10 12:26:42,513 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924 does not exist. Creating ...
datanode_4  | 2022-12-10 12:26:42,556 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/in_use.lock acquired by nodename 7@c79f062f35ec
datanode_4  | 2022-12-10 12:26:42,587 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924 has been successfully formatted.
datanode_4  | 2022-12-10 12:26:42,645 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-D18C7B531924: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4  | 2022-12-10 12:26:42,666 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-12-10 12:26:42,706 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-12-10 12:26:42,713 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 12:26:42,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | 2022-12-10 12:26:42,749 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_4  | 2022-12-10 12:26:42,778 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:42,858 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-12-10 12:26:42,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-12-10 12:26:42,906 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924
datanode_4  | 2022-12-10 12:26:42,928 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-12-10 12:26:42,932 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 12:26:42,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:42,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-12-10 12:26:42,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-12-10 12:26:42,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-12-10 12:26:42,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-12-10 12:26:42,947 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-12-10 12:26:43,022 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:43,025 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 12:26:43,065 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4  | 2022-12-10 12:26:43,067 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_4  | 2022-12-10 12:26:43,072 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-12-10 12:26:43,093 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 12:26:43,102 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 12:26:43,116 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: start as a follower, conf=-1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:43,117 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4  | 2022-12-10 12:26:43,122 [pool-22-thread-1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState
datanode_4  | 2022-12-10 12:26:43,158 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:43,158 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:43,180 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D18C7B531924,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 12:26:43,182 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-12-10 12:26:43,183 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4  | 2022-12-10 12:26:43,188 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4  | 2022-12-10 12:26:43,190 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4  | 2022-12-10 12:26:43,274 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924
datanode_4  | 2022-12-10 12:26:43,279 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924.
datanode_4  | 2022-12-10 12:26:43,279 [Command processor thread] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: addNew group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] returns group-AF81ED93FE6E:java.util.concurrent.CompletableFuture@6f0adc4f[Not completed]
datanode_4  | 2022-12-10 12:26:43,293 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: new RaftServerImpl for group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_4  | 2022-12-10 12:26:43,294 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-12-10 12:26:43,295 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-12-10 12:26:43,296 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-12-10 12:26:43,296 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 12:26:43,297 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 12:26:43,297 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4  | 2022-12-10 12:26:43,297 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: ConfigurationManager, init=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-12-10 12:26:43,304 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 12:26:43,305 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4  | 2022-12-10 12:26:43,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4  | 2022-12-10 12:26:43,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-12-10 12:26:43,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-12-10 12:26:43,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-12-10 12:26:43,321 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-12-10 12:26:43,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4  | 2022-12-10 12:26:43,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4  | 2022-12-10 12:26:43,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:08Z
om_1        | STARTUP_MSG:   java = 11.0.14.1
om_1        | ************************************************************/
om_1        | 2022-12-10 12:25:41,171 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2022-12-10 12:25:49,455 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1        | 2022-12-10 12:25:52,975 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2022-12-10 12:25:53,724 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.19.0.6:9862
om_1        | 2022-12-10 12:25:53,724 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2022-12-10 12:25:53,725 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2022-12-10 12:25:54,119 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-12-10 12:25:56,430 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863]
om_1        | 2022-12-10 12:26:00,177 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:02,179 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:04,180 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:06,182 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:08,184 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:10,185 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:12,187 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:14,189 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:16,191 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:18,192 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:20,194 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:22,196 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:24,197 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From d61bd433dcf3/172.19.0.6 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:27,524 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:de14337a-ef52-472b-bd3f-7050a14dd151 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-12-10 12:26:29,529 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:de14337a-ef52-472b-bd3f-7050a14dd151 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863 after 15 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-200db308-9a00-4c02-aa1c-cee2a0f43436;layoutVersion=3
om_1        | 2022-12-10 12:26:32,836 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at d61bd433dcf3/172.19.0.6
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2022-12-10 12:26:39,516 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_4  | 2022-12-10 12:26:43,323 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4  | 2022-12-10 12:26:43,323 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e does not exist. Creating ...
datanode_4  | 2022-12-10 12:26:43,325 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/in_use.lock acquired by nodename 7@c79f062f35ec
datanode_4  | 2022-12-10 12:26:43,329 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e has been successfully formatted.
datanode_4  | 2022-12-10 12:26:43,330 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4  | 2022-12-10 12:26:43,350 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-12-10 12:26:43,352 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-12-10 12:26:43,353 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 12:26:43,354 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | 2022-12-10 12:26:43,354 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_4  | 2022-12-10 12:26:43,355 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:43,359 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-12-10 12:26:43,360 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-12-10 12:26:43,362 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_4  | 2022-12-10 12:26:43,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-12-10 12:26:43,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 12:26:43,366 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:43,366 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-12-10 12:26:43,366 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-12-10 12:26:43,367 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-12-10 12:26:43,368 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-12-10 12:26:43,369 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-12-10 12:26:43,376 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-12-10 12:26:43,384 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 12:26:44,133 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-85e9a0c6-8631-4fee-9b9c-0f8004d778ef: Detected pause in JVM or host machine (eg GC): pause of approximately 345597858ns.
datanode_4  | GC pool 'ParNew' had collection(s): count=1 time=51ms
datanode_4  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=691ms
datanode_4  | 2022-12-10 12:26:44,172 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4  | 2022-12-10 12:26:44,181 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_4  | 2022-12-10 12:26:44,182 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-12-10 12:26:44,182 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 12:26:44,183 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 12:26:44,183 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: start as a follower, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:44,184 [pool-22-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4  | 2022-12-10 12:26:44,185 [pool-22-thread-1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:44,192 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 12:26:44,195 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-12-10 12:26:44,202 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4  | 2022-12-10 12:26:44,203 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4  | 2022-12-10 12:26:44,204 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4  | 2022-12-10 12:26:44,220 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:44,227 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_4  | 2022-12-10 12:26:44,260 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:47,927 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-85e9a0c6-8631-4fee-9b9c-0f8004d778ef: Detected pause in JVM or host machine (eg GC): pause of approximately 256902139ns.
datanode_4  | GC pool 'ParNew' had collection(s): count=1 time=377ms
datanode_4  | 2022-12-10 12:26:48,181 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5059801416ns, electionTimeout:5017ms
recon_1     | 2022-12-10 12:26:24,601 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-12-10 12:26:24,601 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2022-12-10 12:26:24,607 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2022-12-10 12:26:27,693 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:de14337a-ef52-472b-bd3f-7050a14dd151 is not the leader. Could not determine the leader node.
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | , while invoking $Proxy44.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2022-12-10 12:26:29,698 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:de14337a-ef52-472b-bd3f-7050a14dd151 is not the leader. Could not determine the leader node.
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | , while invoking $Proxy44.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2022-12-10 12:26:34,223 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2022-12-10 12:26:34,223 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2022-12-10 12:26:34,223 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
recon_1     | 2022-12-10 12:26:34,227 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2022-12-10 12:26:34,239 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2022-12-10 12:26:34,344 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2022-12-10 12:26:34,448 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2022-12-10 12:26:34,448 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2022-12-10 12:26:34,475 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2022-12-10 12:26:34,475 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2022-12-10 12:26:34,608 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2022-12-10 12:26:34,612 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 65 milliseconds.
recon_1     | 2022-12-10 12:26:35,671 [IPC Server handler 11 on default port 9891] WARN ipc.Server: IPC Server handler 11 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.9:42236: output error
recon_1     | 2022-12-10 12:26:35,673 [IPC Server handler 11 on default port 9891] INFO ipc.Server: IPC Server handler 11 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_3  | 2022-12-10 12:26:32,295 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-070399b1-b030-4403-988f-f84f4a384114/container.db to cache
datanode_3  | 2022-12-10 12:26:32,299 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-070399b1-b030-4403-988f-f84f4a384114/container.db for volume DS-070399b1-b030-4403-988f-f84f4a384114
datanode_3  | 2022-12-10 12:26:32,302 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2022-12-10 12:26:32,318 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_3  | 2022-12-10 12:26:32,746 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 12:26:32,888 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: 213470ee-8924-4d24-82c9-a8e7505514cd: start RPC server
datanode_3  | 2022-12-10 12:26:32,898 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 213470ee-8924-4d24-82c9-a8e7505514cd: GrpcService started, listening on 9858
datanode_3  | 2022-12-10 12:26:32,906 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 213470ee-8924-4d24-82c9-a8e7505514cd: GrpcService started, listening on 9856
datanode_3  | 2022-12-10 12:26:32,912 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 213470ee-8924-4d24-82c9-a8e7505514cd: GrpcService started, listening on 9857
datanode_3  | 2022-12-10 12:26:32,928 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 213470ee-8924-4d24-82c9-a8e7505514cd is started using port 9858 for RATIS
datanode_3  | 2022-12-10 12:26:32,928 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 213470ee-8924-4d24-82c9-a8e7505514cd is started using port 9857 for RATIS_ADMIN
datanode_3  | 2022-12-10 12:26:32,928 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 213470ee-8924-4d24-82c9-a8e7505514cd is started using port 9856 for RATIS_SERVER
datanode_3  | 2022-12-10 12:26:32,929 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-213470ee-8924-4d24-82c9-a8e7505514cd: Started
datanode_3  | 2022-12-10 12:26:33,294 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_3  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:306)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:506)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.util.concurrent.TimeoutException
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	... 1 more
datanode_3  | 2022-12-10 12:26:41,531 [Command processor thread] INFO server.RaftServer: 213470ee-8924-4d24-82c9-a8e7505514cd: addNew group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] returns group-AF81ED93FE6E:java.util.concurrent.CompletableFuture@2825937b[Not completed]
datanode_3  | 2022-12-10 12:26:41,674 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd: new RaftServerImpl for group-AF81ED93FE6E:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_3  | 2022-12-10 12:26:41,682 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2022-12-10 12:26:41,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2022-12-10 12:26:41,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2022-12-10 12:26:41,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-12-10 12:26:41,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-12-10 12:26:41,696 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 2022-12-10 12:26:41,747 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: ConfigurationManager, init=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_3  | 2022-12-10 12:26:41,754 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-12-10 12:26:41,785 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2022-12-10 12:26:41,788 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2022-12-10 12:26:41,858 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2022-12-10 12:26:41,873 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2022-12-10 12:26:41,878 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2022-12-10 12:26:42,185 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2022-12-10 12:26:42,185 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3  | 2022-12-10 12:26:42,186 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3  | 2022-12-10 12:26:42,195 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2022-12-10 12:26:42,195 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3  | 2022-12-10 12:26:42,200 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e does not exist. Creating ...
datanode_3  | 2022-12-10 12:26:42,238 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/in_use.lock acquired by nodename 7@d6dbe5575a0d
datanode_3  | 2022-12-10 12:26:42,275 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e has been successfully formatted.
datanode_3  | 2022-12-10 12:26:42,369 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2022-12-10 12:26:42,384 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2022-12-10 12:26:42,504 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2022-12-10 12:26:42,507 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 12:26:42,536 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1        | STARTUP_MSG:   host = d61bd433dcf3/172.19.0.6
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_4  | 2022-12-10 12:26:48,184 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState
datanode_4  | 2022-12-10 12:26:48,190 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4  | 2022-12-10 12:26:48,218 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4  | 2022-12-10 12:26:48,218 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1
datanode_4  | 2022-12-10 12:26:48,328 [grpc-default-executor-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-AF81ED93FE6E, 1, (t:0, i:0))
datanode_4  | 2022-12-10 12:26:48,403 [grpc-default-executor-1] INFO impl.VoteContext: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_4  | 2022-12-10 12:26:48,405 [grpc-default-executor-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_4  | 2022-12-10 12:26:48,405 [grpc-default-executor-1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:48,406 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState was interrupted
datanode_4  | 2022-12-10 12:26:48,423 [grpc-default-executor-1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:48,425 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:48,441 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_4  | 2022-12-10 12:26:48,442 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1
datanode_4  | 2022-12-10 12:26:48,461 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:48,461 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:48,461 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4  | 2022-12-10 12:26:48,461 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D18C7B531924 with new leaderId: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 12:26:48,462 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: change Leader from null to 85e9a0c6-8631-4fee-9b9c-0f8004d778ef at term 1 for becomeLeader, leader elected after 6388ms
datanode_4  | 2022-12-10 12:26:48,509 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4  | 2022-12-10 12:26:48,579 [grpc-default-executor-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-85e9a0c6-8631-4fee-9b9c-0f8004d778ef#0:OK-t1. Peer's state: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E:t1, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:48,636 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 12:26:48,658 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_4  | 2022-12-10 12:26:48,762 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4  | 2022-12-10 12:26:48,796 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4  | 2022-12-10 12:26:48,801 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4  | 2022-12-10 12:26:48,856 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 12:26:48,899 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_4  | 2022-12-10 12:26:48,908 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderStateImpl
datanode_4  | 2022-12-10 12:26:48,996 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4  | 2022-12-10 12:26:49,075 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: set configuration 0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:49,129 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e.
recon_1     | 2022-12-10 12:26:35,679 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.8:57622: output error
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 8 on default port 9891] WARN ipc.Server: IPC Server handler 8 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.5:42152: output error
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 12 on default port 9891] WARN ipc.Server: IPC Server handler 12 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.4:49342: output error
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 10 on default port 9891] WARN ipc.Server: IPC Server handler 10 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.8:40630: output error
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 9 on default port 9891] WARN ipc.Server: IPC Server handler 9 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.4:58480: output error
recon_1     | 2022-12-10 12:26:35,703 [IPC Server handler 9 on default port 9891] INFO ipc.Server: IPC Server handler 9 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.4:49332: output error
recon_1     | 2022-12-10 12:26:35,707 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 13 on default port 9891] WARN ipc.Server: IPC Server handler 13 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.8:40628: output error
recon_1     | 2022-12-10 12:26:35,690 [IPC Server handler 14 on default port 9891] WARN ipc.Server: IPC Server handler 14 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.10:33564: output error
recon_1     | 2022-12-10 12:26:35,709 [IPC Server handler 14 on default port 9891] INFO ipc.Server: IPC Server handler 14 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
datanode_4  | 2022-12-10 12:26:49,337 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/current/log_inprogress_0
datanode_4  | 2022-12-10 12:26:53,497 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5038219497ns, electionTimeout:5035ms
datanode_4  | 2022-12-10 12:26:53,497 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:53,497 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_4  | 2022-12-10 12:26:53,497 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4  | 2022-12-10 12:26:53,497 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2
datanode_4  | 2022-12-10 12:26:53,500 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:53,514 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:53,514 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:53,516 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_4  | 2022-12-10 12:26:53,517 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_4  | 2022-12-10 12:26:53,618 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_4  | 2022-12-10 12:26:53,618 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection:   Response 0: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t2
datanode_4  | 2022-12-10 12:26:53,618 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2 ELECTION round 0: result REJECTED
datanode_4  | 2022-12-10 12:26:53,619 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode_4  | 2022-12-10 12:26:53,619 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2
datanode_4  | 2022-12-10 12:26:53,619 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection2] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:53,634 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:53,634 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:58,706 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086869280ns, electionTimeout:5072ms
datanode_4  | 2022-12-10 12:26:58,707 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:58,708 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_4  | 2022-12-10 12:26:58,708 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4  | 2022-12-10 12:26:58,708 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3
datanode_4  | 2022-12-10 12:26:58,717 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3 ELECTION round 0: submit vote requests at term 3 for -1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:58,727 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:58,727 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:58,768 [grpc-default-executor-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: receive requestVote(ELECTION, c93c8eed-0198-45d8-87bc-3d7834e7dd79, group-AF81ED93FE6E, 3, (t:0, i:0))
datanode_4  | 2022-12-10 12:26:58,772 [grpc-default-executor-1] INFO impl.VoteContext: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-CANDIDATE: reject ELECTION from c93c8eed-0198-45d8-87bc-3d7834e7dd79: already has voted for 85e9a0c6-8631-4fee-9b9c-0f8004d778ef at current term 3
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,699 [IPC Server handler 6 on default port 9891] WARN ipc.Server: IPC Server handler 6 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.5:50368: output error
recon_1     | 2022-12-10 12:26:35,691 [IPC Server handler 7 on default port 9891] WARN ipc.Server: IPC Server handler 7 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.10:33556: output error
recon_1     | 2022-12-10 12:26:35,691 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.10:33450: output error
recon_1     | 2022-12-10 12:26:35,691 [IPC Server handler 3 on default port 9891] WARN ipc.Server: IPC Server handler 3 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.9:42242: output error
recon_1     | 2022-12-10 12:26:35,690 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.5:42162: output error
recon_1     | 2022-12-10 12:26:35,690 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.19.0.9:33658: output error
recon_1     | 2022-12-10 12:26:35,714 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,710 [IPC Server handler 13 on default port 9891] INFO ipc.Server: IPC Server handler 13 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,707 [IPC Server handler 10 on default port 9891] INFO ipc.Server: IPC Server handler 10 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,703 [IPC Server handler 12 on default port 9891] INFO ipc.Server: IPC Server handler 12 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
datanode_3  | 2022-12-10 12:26:42,536 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2022-12-10 12:26:42,548 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:42,593 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2022-12-10 12:26:42,594 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2022-12-10 12:26:42,639 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_3  | 2022-12-10 12:26:42,640 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2022-12-10 12:26:42,642 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2022-12-10 12:26:42,643 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:42,643 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2022-12-10 12:26:42,643 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2022-12-10 12:26:42,676 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2022-12-10 12:26:42,676 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2022-12-10 12:26:42,676 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2022-12-10 12:26:42,719 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:42,720 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 12:26:42,803 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3  | 2022-12-10 12:26:42,806 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  | 2022-12-10 12:26:42,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2022-12-10 12:26:42,880 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 12:26:42,880 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 12:26:42,892 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: start as a follower, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:42,898 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2022-12-10 12:26:42,918 [pool-22-thread-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:42,958 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 12:26:42,959 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:42,973 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 12:26:42,983 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-12-10 12:26:42,989 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2022-12-10 12:26:42,993 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2022-12-10 12:26:43,000 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-12-10 12:26:43,094 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_3  | 2022-12-10 12:26:47,972 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5054956071ns, electionTimeout:5012ms
datanode_3  | 2022-12-10 12:26:47,973 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:47,975 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2022-12-10 12:26:48,007 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-12-10 12:26:48,007 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1
datanode_3  | 2022-12-10 12:26:48,019 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:48,085 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 12:26:48,085 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:48,086 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_3  | 2022-12-10 12:26:48,088 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_3  | 2022-12-10 12:26:49,112 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e.
datanode_3  | 2022-12-10 12:26:49,114 [Command processor thread] INFO server.RaftServer: 213470ee-8924-4d24-82c9-a8e7505514cd: addNew group-C785C98CE76D:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:1|startupRole:FOLLOWER] returns group-C785C98CE76D:java.util.concurrent.CompletableFuture@18de1505[Not completed]
datanode_3  | 2022-12-10 12:26:49,124 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd: new RaftServerImpl for group-C785C98CE76D:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_3  | 2022-12-10 12:26:49,124 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2022-12-10 12:26:49,126 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2022-12-10 12:26:49,126 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2022-12-10 12:26:49,126 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-12-10 12:26:49,126 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-12-10 12:26:49,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 2022-12-10 12:26:49,131 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: ConfigurationManager, init=-1: peers:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_3  | 2022-12-10 12:26:49,131 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-12-10 12:26:49,138 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2022-12-10 12:26:49,146 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2022-12-10 12:26:49,149 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2022-12-10 12:26:49,151 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2022-12-10 12:26:49,151 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2022-12-10 12:26:49,160 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3  | 2022-12-10 12:26:49,163 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t1
datanode_3  | 2022-12-10 12:26:49,163 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-85e9a0c6-8631-4fee-9b9c-0f8004d778ef#0:OK-t1
datanode_3  | 2022-12-10 12:26:49,166 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1 ELECTION round 0: result REJECTED
datanode_3  | 2022-12-10 12:26:49,168 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_3  | 2022-12-10 12:26:49,168 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1
datanode_3  | 2022-12-10 12:26:49,169 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-LeaderElection1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:49,177 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2022-12-10 12:26:49,183 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3  | 2022-12-10 12:26:49,184 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3  | 2022-12-10 12:26:49,185 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2022-12-10 12:26:49,185 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3  | 2022-12-10 12:26:49,185 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3c7dd0af-68a7-49be-9b83-c785c98ce76d does not exist. Creating ...
datanode_3  | 2022-12-10 12:26:49,192 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3c7dd0af-68a7-49be-9b83-c785c98ce76d/in_use.lock acquired by nodename 7@d6dbe5575a0d
datanode_3  | 2022-12-10 12:26:49,198 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3c7dd0af-68a7-49be-9b83-c785c98ce76d has been successfully formatted.
datanode_3  | 2022-12-10 12:26:49,199 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C785C98CE76D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2022-12-10 12:26:49,229 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2022-12-10 12:26:49,234 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2022-12-10 12:26:49,234 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 12:26:49,234 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 12:26:49,235 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:49,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3  | 2022-12-10 12:26:49,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2022-12-10 12:26:49,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:49,248 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2022-12-10 12:26:49,248 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2022-12-10 12:26:49,250 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/3c7dd0af-68a7-49be-9b83-c785c98ce76d
datanode_3  | 2022-12-10 12:26:49,250 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2022-12-10 12:26:49,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2022-12-10 12:26:49,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:49,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2022-12-10 12:26:49,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2022-12-10 12:26:49,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2022-12-10 12:26:49,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2022-12-10 12:26:49,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2022-12-10 12:26:49,263 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2022-12-10 12:26:49,265 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 12:26:49,803 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-213470ee-8924-4d24-82c9-a8e7505514cd: Detected pause in JVM or host machine (eg GC): pause of approximately 291230317ns.
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=77ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=446ms
datanode_3  | 2022-12-10 12:26:49,821 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3  | 2022-12-10 12:26:49,823 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  | 2022-12-10 12:26:49,830 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2022-12-10 12:26:49,832 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 12:26:49,833 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 12:26:49,834 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: start as a follower, conf=-1: peers:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:49,835 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2022-12-10 12:26:49,837 [pool-22-thread-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState
datanode_3  | 2022-12-10 12:26:49,838 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C785C98CE76D,id=213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 12:26:49,839 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-12-10 12:26:49,840 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2022-12-10 12:26:49,841 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2022-12-10 12:26:49,841 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-12-10 12:26:49,845 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:58,773 [grpc-default-executor-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E replies to ELECTION vote request: c93c8eed-0198-45d8-87bc-3d7834e7dd79<-85e9a0c6-8631-4fee-9b9c-0f8004d778ef#0:FAIL-t3. Peer's state: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E:t3, leader=null, voted=85e9a0c6-8631-4fee-9b9c-0f8004d778ef, raftlog=Memoized:85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:58,879 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_4  | 2022-12-10 12:26:58,879 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.LeaderElection:   Response 0: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-c93c8eed-0198-45d8-87bc-3d7834e7dd79#0:FAIL-t3
datanode_4  | 2022-12-10 12:26:58,880 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.LeaderElection:   Response 1: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-213470ee-8924-4d24-82c9-a8e7505514cd#0:FAIL-t3
datanode_4  | 2022-12-10 12:26:58,880 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3 ELECTION round 0: result REJECTED
datanode_4  | 2022-12-10 12:26:58,880 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode_4  | 2022-12-10 12:26:58,880 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3
datanode_4  | 2022-12-10 12:26:58,880 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-LeaderElection3] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 12:26:58,891 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 12:26:58,891 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 12:26:58,964 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AF81ED93FE6E with new leaderId: c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_4  | 2022-12-10 12:26:58,964 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-server-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: change Leader from null to c93c8eed-0198-45d8-87bc-3d7834e7dd79 at term 3 for appendEntries, leader elected after 15657ms
datanode_4  | 2022-12-10 12:26:59,017 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-server-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 12:26:59,026 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-server-thread1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4  | 2022-12-10 12:26:59,037 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/current/log_inprogress_0
datanode_4  | 2022-12-10 13:05:14,013 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_4  | 2022-12-10 13:05:14,013 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_4  | 2022-12-10 13:05:14,034 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-0] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 3262.
datanode_4  | 2022-12-10 13:08:05,680 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_4  | 2022-12-10 13:08:05,719 [shutdown-hook-0] INFO ozoneimpl.OzoneContainer: Attempting to stop container services.
datanode_4  | 2022-12-10 13:08:05,730 [shutdown-hook-0] INFO utils.DatanodeStoreCache: Removed db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db from cache
datanode_4  | 2022-12-10 13:08:05,730 [shutdown-hook-0] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db for volume DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a
datanode_4  | 2022-12-10 13:08:05,731 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_4  | /************************************************************
datanode_4  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at c79f062f35ec/172.19.0.9
datanode_4  | ************************************************************/
datanode_4  | 2022-12-10 13:08:05,740 [shutdown-hook-0] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: close
datanode_4  | 2022-12-10 13:08:05,745 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: shutdown
datanode_4  | 2022-12-10 13:08:05,747 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
datanode_4  | 2022-12-10 13:08:05,745 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D18C7B531924,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:08:05,751 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-LeaderStateImpl
datanode_4  | 2022-12-10 13:08:05,754 [shutdown-hook-0] INFO server.GrpcServerProtocolClient: c93c8eed-0198-45d8-87bc-3d7834e7dd79 Close channels
datanode_4  | 2022-12-10 13:08:05,756 [shutdown-hook-0] INFO server.GrpcServerProtocolClient: 213470ee-8924-4d24-82c9-a8e7505514cd Close channels
datanode_4  | 2022-12-10 13:08:05,756 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: shutdown
datanode_1  | 2022-12-10 13:09:13,181 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:13,182 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:09:13,182 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:13,182 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:13,185 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:13,192 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t7. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t7, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:13,193 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:13,194 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:18,250 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 8, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:18,255 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:18,255 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_1  | 2022-12-10 13:09:18,255 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:18,255 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:18,255 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:18,257 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:18,257 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:18,261 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t8. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t8, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:23,285 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 9, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:23,286 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:23,286 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 9 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:09:23,286 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:23,286 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:23,287 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:23,292 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:23,293 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:23,294 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t9. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t9, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:28,391 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 10, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:28,391 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:28,391 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:09:28,391 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:28,391 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:28,392 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:28,400 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:28,400 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:28,403 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t10. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t10, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:33,446 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 11, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:33,447 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:33,447 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:09:33,447 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:33,447 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:33,448 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:33,463 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:33,463 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:33,463 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t11. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t11, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:38,518 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 12, (t:0, i:0))
datanode_1  | 2022-12-10 13:09:38,518 [grpc-default-executor-0] INFO impl.VoteContext: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 1 > candidate's priority 0
datanode_1  | 2022-12-10 13:09:38,518 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 12 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_1  | 2022-12-10 13:09:38,518 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:38,518 [grpc-default-executor-0] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:38,519 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState was interrupted
datanode_1  | 2022-12-10 13:09:38,521 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:38,521 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:38,524 [grpc-default-executor-0] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t12. Peer's state: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495:t12, leader=null, voted=null, raftlog=Memoized:eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:43,532 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013392530ns, electionTimeout:5011ms
datanode_1  | 2022-12-10 13:09:43,532 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState
datanode_1  | 2022-12-10 13:09:43,533 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 12 for changeToCandidate
datanode_1  | 2022-12-10 13:09:43,533 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-12-10 13:09:43,533 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4
datanode_1  | 2022-12-10 13:09:43,539 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: submit vote requests at term 13 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2022-12-10 13:09:43,545 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2022-12-10 13:09:43,545 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2022-12-10 13:09:43,564 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_1  | 2022-12-10 13:09:43,565 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection:   Response 0: eb6b06af-1f2c-4397-8743-5d103932e2bb<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t13
datanode_1  | 2022-12-10 13:09:43,565 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: result PASSED
datanode_1  | 2022-12-10 13:09:43,565 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: shutdown eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4
datanode_1  | 2022-12-10 13:09:43,566 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: changes role from CANDIDATE to LEADER at term 13 for changeToLeader
datanode_1  | 2022-12-10 13:09:43,566 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18DDCF3CC495 with new leaderId: eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_1  | 2022-12-10 13:09:43,566 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: change Leader from null to eb6b06af-1f2c-4397-8743-5d103932e2bb at term 13 for becomeLeader, leader elected after 65895ms
datanode_1  | 2022-12-10 13:09:43,574 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2022-12-10 13:09:43,575 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 13:09:43,576 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1  | 2022-12-10 13:09:43,576 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2022-12-10 13:09:43,577 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2022-12-10 13:09:43,577 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2022-12-10 13:09:43,578 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-12-10 13:09:43,578 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2022-12-10 13:09:43,604 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2022-12-10 13:09:43,605 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-12-10 13:09:43,605 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2022-12-10 13:09:43,608 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2022-12-10 13:09:43,609 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-12-10 13:09:43,609 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-12-10 13:09:43,609 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_1  | 2022-12-10 13:09:43,609 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_1  | 2022-12-10 13:09:43,612 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2022-12-10 13:09:43,612 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 12:26:32,732 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-44877e3e-f8e0-4fab-9c03-bb94f29d2e65: Started
datanode_5  | 2022-12-10 12:26:34,136 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_5  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:306)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:506)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	... 1 more
datanode_5  | 2022-12-10 12:26:37,308 [Command processor thread] INFO server.RaftServer: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: addNew group-28C00CFC9A37:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:1|startupRole:FOLLOWER] returns group-28C00CFC9A37:java.util.concurrent.CompletableFuture@6458b9c8[Not completed]
datanode_5  | 2022-12-10 12:26:37,390 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: new RaftServerImpl for group-28C00CFC9A37:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_5  | 2022-12-10 12:26:37,397 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5  | 2022-12-10 12:26:37,398 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5  | 2022-12-10 12:26:37,403 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5  | 2022-12-10 12:26:37,404 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5  | 2022-12-10 12:26:37,405 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-12-10 12:26:37,405 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_5  | 2022-12-10 12:26:37,435 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: ConfigurationManager, init=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_5  | 2022-12-10 12:26:37,435 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5  | 2022-12-10 12:26:37,454 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5  | 2022-12-10 12:26:37,455 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5  | 2022-12-10 12:26:37,495 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5  | 2022-12-10 12:26:37,507 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5  | 2022-12-10 12:26:37,508 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5  | 2022-12-10 12:26:37,691 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5  | 2022-12-10 12:26:37,693 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_5  | 2022-12-10 12:26:37,697 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_5  | 2022-12-10 12:26:37,708 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_5  | 2022-12-10 12:26:37,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_5  | 2022-12-10 12:26:37,714 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37 does not exist. Creating ...
datanode_5  | 2022-12-10 12:26:37,735 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37/in_use.lock acquired by nodename 7@cef178baecd7
datanode_5  | 2022-12-10 12:26:37,746 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37 has been successfully formatted.
datanode_5  | 2022-12-10 12:26:37,761 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-28C00CFC9A37: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5  | 2022-12-10 12:26:37,773 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5  | 2022-12-10 12:26:37,792 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5  | 2022-12-10 12:26:37,792 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 12:26:37,795 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_5  | 2022-12-10 12:26:37,802 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_5  | 2022-12-10 12:26:37,812 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-12-10 12:26:37,830 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5  | 2022-12-10 12:26:37,830 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5  | 2022-12-10 12:26:37,844 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37
datanode_5  | 2022-12-10 12:26:37,846 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5  | 2022-12-10 12:26:37,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5  | 2022-12-10 12:26:37,849 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-12-10 12:26:37,849 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5  | 2022-12-10 12:26:37,850 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5  | 2022-12-10 12:26:37,853 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5  | 2022-12-10 12:26:37,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5  | 2022-12-10 12:26:37,858 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5  | 2022-12-10 12:26:37,913 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5  | 2022-12-10 12:26:37,924 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 12:26:37,967 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_5  | 2022-12-10 12:26:37,971 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,707 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,715 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,715 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:08Z
om_1        | STARTUP_MSG:   java = 11.0.14.1
om_1        | ************************************************************/
om_1        | 2022-12-10 12:26:39,530 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2022-12-10 12:26:43,032 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1        | 2022-12-10 12:26:45,928 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2022-12-10 12:26:46,392 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.19.0.6:9862
om_1        | 2022-12-10 12:26:46,393 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2022-12-10 12:26:46,395 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2022-12-10 12:26:46,590 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-12-10 12:26:46,746 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om_1        | 2022-12-10 12:26:47,958 [main] INFO reflections.Reflections: Reflections took 902 ms to scan 1 urls, producing 114 keys and 335 values [using 2 cores]
om_1        | 2022-12-10 12:26:48,150 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-12-10 12:26:50,385 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863]
om_1        | 2022-12-10 12:26:50,536 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.19.0.2:9863]
om_1        | 2022-12-10 12:26:51,883 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-12-10 12:26:52,253 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2022-12-10 12:26:52,257 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1        | 2022-12-10 12:26:52,985 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om_1        | 2022-12-10 12:26:53,318 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1        | 2022-12-10 12:26:53,744 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2022-12-10 12:26:53,747 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om_1        | 2022-12-10 12:26:53,811 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2022-12-10 12:26:53,822 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2022-12-10 12:26:53,948 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: om:9872
om_1        | 2022-12-10 12:26:53,991 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om_1        | 2022-12-10 12:26:54,196 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1        | 2022-12-10 12:26:54,366 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
om_1        | 2022-12-10 12:26:54,369 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
om_1        | 2022-12-10 12:26:54,372 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om_1        | 2022-12-10 12:26:54,373 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om_1        | 2022-12-10 12:26:54,374 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om_1        | 2022-12-10 12:26:54,374 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2022-12-10 12:26:54,374 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1        | 2022-12-10 12:26:54,381 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2022-12-10 12:26:54,382 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2022-12-10 12:26:54,384 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1        | 2022-12-10 12:26:54,406 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om_1        | 2022-12-10 12:26:54,432 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,715 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,715 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
datanode_4  | 2022-12-10 13:08:05,757 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:08:05,757 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 13:08:05,757 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
datanode_4  | 2022-12-10 13:08:05,757 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server GrpcServerProtocolService now
datanode_4  | 2022-12-10 13:08:05,757 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState was interrupted
datanode_4  | 2022-12-10 13:08:05,757 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Taking a snapshot at:(t:3, i:3273) file /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3273
datanode_4  | 2022-12-10 13:08:05,763 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO impl.PendingRequests: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-PendingRequests: sendNotLeaderResponses
datanode_4  | 2022-12-10 13:08:05,765 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-D18C7B531924: Taking a snapshot at:(t:1, i:0) file /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/sm/snapshot.1_0
datanode_4  | 2022-12-10 13:08:05,775 [grpc-default-executor-2] WARN server.GrpcServerProtocolService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: installSnapshot onError, lastRequest: c93c8eed-0198-45d8-87bc-3d7834e7dd79->85e9a0c6-8631-4fee-9b9c-0f8004d778ef#31042-t3,previous=(t:3, i:3272),leaderCommit=3272,initializing? true,entries: size=1, first=(t:3, i:3273), METADATAENTRY(c:3272): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
datanode_4  | 2022-12-10 13:08:05,782 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server GrpcServerProtocolService successfully
datanode_4  | 2022-12-10 13:08:05,783 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
datanode_4  | 2022-12-10 13:08:05,783 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater: set stopIndex = 0
datanode_4  | 2022-12-10 13:08:05,784 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater: set stopIndex = 3273
datanode_4  | 2022-12-10 13:08:05,785 [grpc-default-executor-3] WARN server.GrpcServerProtocolService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
datanode_4  | 2022-12-10 13:08:05,803 [shutdown-hook-0] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
datanode_4  | 2022-12-10 13:08:05,907 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-D18C7B531924: Finished taking a snapshot at:(t:1, i:0) file:/data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/sm/snapshot.1_0 took: 143 ms
datanode_4  | 2022-12-10 13:08:05,910 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater: Took a snapshot at index 0
datanode_4  | 2022-12-10 13:08:05,910 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Finished taking a snapshot at:(t:3, i:3273) file:/data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3273 took: 152 ms
datanode_4  | 2022-12-10 13:08:05,910 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
datanode_4  | 2022-12-10 13:08:05,911 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater: Took a snapshot at index 3273
datanode_4  | 2022-12-10 13:08:05,911 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3273
datanode_4  | 2022-12-10 13:08:05,915 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: closes. applyIndex: 0
datanode_4  | 2022-12-10 13:08:05,916 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_4  | 2022-12-10 13:08:05,918 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker close()
datanode_4  | 2022-12-10 13:08:05,919 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: closes. applyIndex: 3273
datanode_4  | 2022-12-10 13:08:05,921 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_4  | 2022-12-10 13:08:05,921 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread3] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker close()
datanode_4  | 2022-12-10 13:08:05,924 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-85e9a0c6-8631-4fee-9b9c-0f8004d778ef: Stopped
datanode_4  | 2022-12-10 13:08:07,980 [shutdown-hook-0] INFO utils.BackgroundService: Shutting down service BlockDeletingService
datanode_4  | 2022-12-10 13:08:07,982 [shutdown-hook-0] INFO utils.BackgroundService: Shutting down service StaleRecoveringContainerScrubbingService
datanode_4  | 2022-12-10 13:08:07,984 [shutdown-hook-0] INFO statemachine.DatanodeStateMachine: Ozone container server stopped.
datanode_4  | 2022-12-10 13:08:07,987 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.w.WebAppContext@3435a4e5{hddsDatanode,/,null,STOPPED}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4  | 2022-12-10 13:08:07,990 [shutdown-hook-0] INFO server.AbstractConnector: Stopped ServerConnector@7d216ee8{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_4  | 2022-12-10 13:08:07,990 [shutdown-hook-0] INFO server.session: node0 Stopped scavenging
datanode_4  | 2022-12-10 13:08:07,990 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@6f7c4e0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
datanode_4  | 2022-12-10 13:08:07,990 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@7aef8000{logs,/logs,file:///var/log/hadoop/,STOPPED}
datanode_4  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_4  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4  | 2022-12-10 13:09:31,424 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4  | /************************************************************
datanode_4  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4  | STARTUP_MSG:   host = c79f062f35ec/172.19.0.9
datanode_4  | STARTUP_MSG:   args = []
datanode_4  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_4  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_4  | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
datanode_4  | STARTUP_MSG:   java = 11.0.14.1
datanode_4  | ************************************************************/
datanode_4  | 2022-12-10 13:09:31,443 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4  | 2022-12-10 13:09:31,510 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4  | 2022-12-10 13:09:31,699 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4  | 2022-12-10 13:09:31,962 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2022-12-10 13:09:43,612 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2022-12-10 13:09:43,612 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2022-12-10 13:09:43,613 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-12-10 13:09:43,613 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-12-10 13:09:43,613 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_1  | 2022-12-10 13:09:43,613 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_1  | 2022-12-10 13:09:43,614 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: eb6b06af-1f2c-4397-8743-5d103932e2bb: start eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderStateImpl
datanode_1  | 2022-12-10 13:09:43,615 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2022-12-10 13:09:43,618 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/current/log_inprogress_0
datanode_1  | 2022-12-10 13:09:43,627 [eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServer$Division: eb6b06af-1f2c-4397-8743-5d103932e2bb@group-18DDCF3CC495: set configuration 0: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:31,962 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4  | 2022-12-10 13:09:32,315 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c79f062f35ec ip:172.19.0.9
datanode_4  | 2022-12-10 13:09:32,997 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_4  | 2022-12-10 13:09:33,436 [main] INFO reflections.Reflections: Reflections took 349 ms to scan 2 urls, producing 92 keys and 211 values 
datanode_4  | 2022-12-10 13:09:33,625 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_4  | 2022-12-10 13:09:33,947 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 390987635 at 2022-12-10T13:08:05.712Z
datanode_4  | 2022-12-10 13:09:33,961 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_4  | 2022-12-10 13:09:33,967 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4  | 2022-12-10 13:09:33,969 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4  | 2022-12-10 13:09:34,020 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4  | 2022-12-10 13:09:34,049 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-12-10 13:09:34,054 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-12-10T13:08:05.730Z
datanode_4  | 2022-12-10 13:09:34,055 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_4  | 2022-12-10 13:09:34,056 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_4  | 2022-12-10 13:09:34,056 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_4  | 2022-12-10 13:09:34,194 [main] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db to cache
datanode_4  | 2022-12-10 13:09:34,195 [main] INFO volume.HddsVolume: SchemaV3 db is loaded at /data/hdds/hdds/CID-200db308-9a00-4c02-aa1c-cee2a0f43436/DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a/container.db for volume DS-d01eff3d-1d96-4fc9-853e-09ddd7c9b76a
datanode_4  | 2022-12-10 13:09:34,233 [Thread-5] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_4  | 2022-12-10 13:09:34,452 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_4  | 2022-12-10 13:09:34,455 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_4  | 2022-12-10 13:09:36,741 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_4  | 2022-12-10 13:09:36,915 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-12-10 13:09:37,026 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_4  | 2022-12-10 13:09:37,270 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_4  | 2022-12-10 13:09:37,274 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_4  | 2022-12-10 13:09:37,275 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_4  | 2022-12-10 13:09:37,279 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_4  | 2022-12-10 13:09:37,279 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_4  | 2022-12-10 13:09:37,279 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_4  | 2022-12-10 13:09:37,282 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4  | 2022-12-10 13:09:37,290 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:37,291 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4  | 2022-12-10 13:09:37,293 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4  | 2022-12-10 13:09:37,327 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_4  | 2022-12-10 13:09:37,335 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_4  | 2022-12-10 13:09:37,337 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_4  | 2022-12-10 13:09:37,869 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_4  | 2022-12-10 13:09:37,872 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_4  | 2022-12-10 13:09:37,873 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_4  | 2022-12-10 13:09:37,873 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:37,873 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 13:09:37,876 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 13:09:37,879 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: found a subdirectory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_4  | 2022-12-10 13:09:37,884 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: addNew group-AF81ED93FE6E:[] returns group-AF81ED93FE6E:java.util.concurrent.CompletableFuture@54532f85[Not completed]
datanode_4  | 2022-12-10 13:09:37,885 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: found a subdirectory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924
datanode_4  | 2022-12-10 13:09:37,885 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: addNew group-D18C7B531924:[] returns group-D18C7B531924:java.util.concurrent.CompletableFuture@c6c8a8c[Not completed]
datanode_4  | 2022-12-10 13:09:37,940 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2022-12-10 12:25:40,822 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2022-12-10 12:25:40,823 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 2022-12-10 12:25:41,294 [main] INFO util.log: Logging initialized @12557ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2022-12-10 12:25:42,401 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
s3g_1       | 2022-12-10 12:25:42,684 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2022-12-10 12:25:43,027 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2022-12-10 12:25:43,063 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2022-12-10 12:25:43,063 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2022-12-10 12:25:43,091 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2022-12-10 12:25:44,132 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = a8268fa876cf/172.19.0.7
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.34.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:08Z
s3g_1       | STARTUP_MSG:   java = 11.0.14.1
s3g_1       | ************************************************************/
s3g_1       | 2022-12-10 12:25:44,202 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2022-12-10 12:25:44,438 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2022-12-10 12:25:45,229 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2022-12-10 12:25:46,454 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2022-12-10 12:25:46,454 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1       | 2022-12-10 12:25:46,781 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2022-12-10 12:25:46,812 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
s3g_1       | 2022-12-10 12:25:47,177 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2022-12-10 12:25:47,195 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2022-12-10 12:25:47,204 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2022-12-10 12:25:47,357 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@50eca7c6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2022-12-10 12:25:47,370 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ce3db41{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Dec 10, 2022 12:26:14 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
datanode_5  | 2022-12-10 12:26:37,973 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5  | 2022-12-10 12:26:37,985 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-12-10 12:26:37,991 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-12-10 12:26:37,993 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: start as a follower, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 12:26:37,994 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5  | 2022-12-10 12:26:37,995 [pool-22-thread-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState
datanode_5  | 2022-12-10 12:26:38,014 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-28C00CFC9A37,id=44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_5  | 2022-12-10 12:26:38,021 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 12:26:38,023 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 12:26:38,024 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5  | 2022-12-10 12:26:38,024 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5  | 2022-12-10 12:26:38,027 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5  | 2022-12-10 12:26:38,028 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5  | 2022-12-10 12:26:38,159 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37
datanode_5  | 2022-12-10 12:26:38,166 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37.
datanode_5  | 2022-12-10 12:26:43,138 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5142738031ns, electionTimeout:5113ms
datanode_5  | 2022-12-10 12:26:43,140 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState
datanode_5  | 2022-12-10 12:26:43,140 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5  | 2022-12-10 12:26:43,167 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 12:26:43,177 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1
datanode_5  | 2022-12-10 12:26:43,240 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 12:26:43,250 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_5  | 2022-12-10 12:26:43,255 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1
datanode_5  | 2022-12-10 12:26:43,260 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5  | 2022-12-10 12:26:43,263 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-28C00CFC9A37 with new leaderId: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_5  | 2022-12-10 12:26:43,274 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: change Leader from null to 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 at term 1 for becomeLeader, leader elected after 5768ms
datanode_5  | 2022-12-10 12:26:43,304 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5  | 2022-12-10 12:26:43,397 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5  | 2022-12-10 12:26:43,405 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_5  | 2022-12-10 12:26:43,461 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5  | 2022-12-10 12:26:43,470 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5  | 2022-12-10 12:26:43,478 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5  | 2022-12-10 12:26:43,558 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5  | 2022-12-10 12:26:43,582 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_5  | 2022-12-10 12:26:43,651 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderStateImpl
datanode_5  | 2022-12-10 12:26:44,120 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5  | 2022-12-10 12:26:44,594 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-LeaderElection1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37: set configuration 0: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 12:26:44,856 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-28C00CFC9A37-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37/current/log_inprogress_0
datanode_5  | 2022-12-10 13:08:37,429 [grpc-default-executor-0] INFO server.RaftServer: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: addNew group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER] returns group-18DDCF3CC495:java.util.concurrent.CompletableFuture@550564c1[Not completed]
datanode_5  | 2022-12-10 13:08:37,433 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: new RaftServerImpl for group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_5  | 2022-12-10 13:08:37,433 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_5  | 2022-12-10 13:08:37,434 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: ConfigurationManager, init=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_5  | 2022-12-10 13:08:37,435 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5  | 2022-12-10 13:08:37,436 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5  | 2022-12-10 13:08:37,437 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5  | 2022-12-10 13:08:37,437 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5  | 2022-12-10 13:08:37,438 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5  | 2022-12-10 13:08:37,439 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5  | 2022-12-10 13:08:37,442 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5  | 2022-12-10 13:08:37,445 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_5  | 2022-12-10 13:08:37,445 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_5  | 2022-12-10 13:08:37,446 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_5  | 2022-12-10 13:08:37,446 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_5  | 2022-12-10 13:08:37,447 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 does not exist. Creating ...
datanode_5  | 2022-12-10 13:08:37,459 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/in_use.lock acquired by nodename 7@cef178baecd7
datanode_5  | 2022-12-10 13:08:37,469 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 has been successfully formatted.
datanode_5  | 2022-12-10 13:08:37,469 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-18DDCF3CC495: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5  | 2022-12-10 13:08:37,474 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
s3g_1       | 2022-12-10 12:26:14,117 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1c43df76{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-808407873225362305/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2022-12-10 12:26:14,149 [main] INFO server.AbstractConnector: Started ServerConnector@5b970f7{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2022-12-10 12:26:14,154 [main] INFO server.Server: Started @45418ms
s3g_1       | 2022-12-10 12:26:14,162 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 2022-12-10 12:26:14,166 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 2022-12-10 12:26:14,168 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2022-12-10 12:48:41,202 [qtp1858015030-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1       | 2022-12-10 12:48:41,237 [qtp1858015030-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1       | 2022-12-10 12:48:41,258 [qtp1858015030-22] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
s3g_1       | 2022-12-10 12:48:41,259 [qtp1858015030-22] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
s3g_1       | 2022-12-10 12:48:43,267 [qtp1858015030-22] WARN erasurecode.ErasureCodeNative: ISA-L support is not available in your platform... using builtin-java codec where applicable
s3g_1       | 2022-12-10 12:48:43,420 [pool-7-thread-1] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1       | 2022-12-10 12:48:57,390 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-dcayyoezrw, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:00,325 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-otcrkxgvcm, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:10,009 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5761187386, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:10,647 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5525690288, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:11,275 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5525690288, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:12,788 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6990045147, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:23,623 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7317996626, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | Dec 10, 2022 12:49:40 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:665)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:129)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:72)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:112)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-12-10 13:08:37,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-12-10 13:08:37,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5  | 2022-12-10 13:08:37,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5  | 2022-12-10 13:08:37,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5  | 2022-12-10 13:08:37,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5  | 2022-12-10 13:08:37,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5  | 2022-12-10 13:08:37,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5  | 2022-12-10 13:08:37,481 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-12-10 13:08:37,520 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_5  | 2022-12-10 13:08:37,520 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_5  | 2022-12-10 13:08:37,520 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5  | 2022-12-10 13:08:37,522 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-12-10 13:08:37,522 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-12-10 13:08:37,529 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: start as a follower, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:08:37,530 [pool-22-thread-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5  | 2022-12-10 13:08:37,530 [pool-22-thread-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:37,534 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18DDCF3CC495,id=44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_5  | 2022-12-10 13:08:37,534 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5  | 2022-12-10 13:08:37,534 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5  | 2022-12-10 13:08:37,534 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5  | 2022-12-10 13:08:37,534 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5  | 2022-12-10 13:08:37,535 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:08:37,542 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:08:38,870 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,871 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,878 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is closed with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,899 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,905 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,926 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is closed with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,950 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,951 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,977 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is closed with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,992 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:38,992 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:39,025 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is closed with bcsId 0.
datanode_5  | 2022-12-10 13:08:39,048 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:39,048 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_5  | 2022-12-10 13:08:39,061 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is closed with bcsId 0.
datanode_5  | 2022-12-10 13:08:42,549 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5019285560ns, electionTimeout:5006ms
datanode_5  | 2022-12-10 13:08:42,550 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_4  | 2022-12-10 13:09:37,958 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: new RaftServerImpl for group-AF81ED93FE6E:[] with ContainerStateMachine:uninitialized
datanode_4  | 2022-12-10 13:09:37,966 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-12-10 13:09:37,970 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-12-10 13:09:37,970 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-12-10 13:09:37,970 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:37,971 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 13:09:37,972 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4  | 2022-12-10 13:09:37,989 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-12-10 13:09:37,996 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 13:09:38,019 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4  | 2022-12-10 13:09:38,021 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4  | 2022-12-10 13:09:38,065 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:38,073 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-12-10 13:09:38,073 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-12-10 13:09:38,254 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-12-10 13:09:38,255 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4  | 2022-12-10 13:09:38,256 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4  | 2022-12-10 13:09:38,256 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4  | 2022-12-10 13:09:38,258 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4  | 2022-12-10 13:09:38,272 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: new RaftServerImpl for group-D18C7B531924:[] with ContainerStateMachine:uninitialized
datanode_4  | 2022-12-10 13:09:38,274 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-12-10 13:09:38,274 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-12-10 13:09:38,275 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-12-10 13:09:38,275 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:38,275 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 13:09:38,277 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4  | 2022-12-10 13:09:38,278 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-12-10 13:09:38,279 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 13:09:38,280 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4  | 2022-12-10 13:09:38,281 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4  | 2022-12-10 13:09:38,282 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:38,283 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-12-10 13:09:38,283 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-12-10 13:09:38,288 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-12-10 13:09:38,290 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4  | 2022-12-10 13:09:38,290 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4  | 2022-12-10 13:09:38,291 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4  | 2022-12-10 13:09:38,292 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4  | 2022-12-10 13:09:38,425 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4  | 2022-12-10 13:09:38,455 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4  | 2022-12-10 13:09:38,517 [main] INFO util.log: Logging initialized @9471ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4  | 2022-12-10 13:09:38,734 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
datanode_4  | 2022-12-10 13:09:38,764 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4  | 2022-12-10 13:09:38,790 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4  | 2022-12-10 13:09:38,795 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4  | 2022-12-10 13:09:38,795 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4  | 2022-12-10 13:09:38,795 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4  | 2022-12-10 13:09:38,879 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4  | 2022-12-10 13:09:38,880 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_4  | 2022-12-10 13:09:38,927 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4  | 2022-12-10 13:09:38,927 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4  | 2022-12-10 13:09:38,931 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4  | 2022-12-10 13:09:38,961 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1fc386f8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 2022-12-10 12:26:54,433 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om_1        | 2022-12-10 12:26:54,742 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om_1        | 2022-12-10 12:26:54,745 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om_1        | 2022-12-10 12:26:54,746 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om_1        | 2022-12-10 12:26:54,746 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2022-12-10 12:26:54,746 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2022-12-10 12:26:54,752 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2022-12-10 12:26:54,764 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@41030c21[Not completed]
om_1        | 2022-12-10 12:26:54,764 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om_1        | 2022-12-10 12:26:54,847 [main] INFO om.OzoneManager: Creating RPC Server
om_1        | 2022-12-10 12:26:54,841 [pool-26-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
om_1        | 2022-12-10 12:26:54,921 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2022-12-10 12:26:54,922 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2022-12-10 12:26:54,922 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2022-12-10 12:26:54,923 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2022-12-10 12:26:54,923 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2022-12-10 12:26:54,923 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2022-12-10 12:26:54,995 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2022-12-10 12:26:54,997 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2022-12-10 12:26:55,022 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2022-12-10 12:26:55,023 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1        | 2022-12-10 12:26:55,094 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2022-12-10 12:26:55,112 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om_1        | 2022-12-10 12:26:55,114 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2022-12-10 12:26:55,414 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2022-12-10 12:26:55,415 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1        | 2022-12-10 12:26:55,416 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om_1        | 2022-12-10 12:26:55,417 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | 2022-12-10 12:26:55,419 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1        | 2022-12-10 12:26:55,996 [main] INFO reflections.Reflections: Reflections took 850 ms to scan 8 urls, producing 23 keys and 529 values [using 2 cores]
om_1        | 2022-12-10 12:26:56,301 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2022-12-10 12:26:56,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2022-12-10 12:26:57,320 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2022-12-10 12:26:57,391 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2022-12-10 12:26:57,391 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2022-12-10 12:26:57,556 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.19.0.6:9862
om_1        | 2022-12-10 12:26:57,558 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om_1        | 2022-12-10 12:26:57,564 [om1-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
om_1        | 2022-12-10 12:26:57,572 [om1-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 7@d61bd433dcf3
om_1        | 2022-12-10 12:26:57,612 [om1-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
om_1        | 2022-12-10 12:26:57,623 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2022-12-10 12:26:57,650 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2022-12-10 12:26:57,651 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2022-12-10 12:26:57,655 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1        | 2022-12-10 12:26:57,658 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | 2022-12-10 12:26:57,665 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2022-12-10 12:26:57,679 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2022-12-10 12:26:57,680 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | 2022-12-10 12:26:57,709 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
om_1        | 2022-12-10 12:26:57,710 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2022-12-10 12:26:57,714 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2022-12-10 12:26:57,719 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2022-12-10 12:26:57,720 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
datanode_4  | 2022-12-10 13:09:38,964 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78ab63b5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4  | 2022-12-10 13:09:39,200 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5bbc033f{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1602825237017264411/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4  | 2022-12-10 13:09:39,224 [main] INFO server.AbstractConnector: Started ServerConnector@4351d055{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_4  | 2022-12-10 13:09:39,224 [main] INFO server.Server: Started @10179ms
datanode_4  | 2022-12-10 13:09:39,235 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4  | 2022-12-10 13:09:39,236 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4  | 2022-12-10 13:09:39,238 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4  | 2022-12-10 13:09:39,251 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_4  | 2022-12-10 13:09:39,304 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b39ed92] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4  | 2022-12-10 13:09:39,494 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.19.0.3:9891
datanode_4  | 2022-12-10 13:09:39,537 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4  | 2022-12-10 13:09:41,573 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4  | 2022-12-10 13:09:41,577 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_4  | 2022-12-10 13:09:41,654 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:41,708 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/in_use.lock acquired by nodename 7@c79f062f35ec
datanode_4  | 2022-12-10 13:09:41,714 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/in_use.lock acquired by nodename 7@c79f062f35ec
datanode_4  | 2022-12-10 13:09:41,719 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=85e9a0c6-8631-4fee-9b9c-0f8004d778ef} from /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/current/raft-meta
datanode_4  | 2022-12-10 13:09:41,720 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=85e9a0c6-8631-4fee-9b9c-0f8004d778ef} from /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/current/raft-meta
datanode_4  | 2022-12-10 13:09:41,772 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: set configuration 0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:41,772 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:41,833 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Setting the last applied index to (t:3, i:3273)
datanode_4  | 2022-12-10 13:09:41,838 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO ratis.ContainerStateMachine: group-D18C7B531924: Setting the last applied index to (t:1, i:0)
datanode_4  | 2022-12-10 13:09:42,099 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-12-10 13:09:42,103 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-12-10 13:09:42,106 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-12-10 13:09:42,107 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:42,108 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | 2022-12-10 13:09:42,109 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_4  | 2022-12-10 13:09:42,111 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-12-10 13:09:42,111 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:42,111 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | 2022-12-10 13:09:42,111 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_4  | 2022-12-10 13:09:42,112 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,112 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,140 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-12-10 13:09:42,140 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-12-10 13:09:42,142 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-12-10 13:09:42,142 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-12-10 13:09:42,162 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924
datanode_4  | 2022-12-10 13:09:42,163 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-12-10 13:09:42,163 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 13:09:42,164 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,164 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-12-10 13:09:42,166 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-12-10 13:09:42,166 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-12-10 13:09:42,168 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-12-10 13:09:42,168 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-12-10 13:09:42,170 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO segmented.SegmentedRaftLogWorker: new 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_4  | 2022-12-10 13:09:42,171 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-12-10 13:09:42,171 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 13:09:42,171 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,171 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-12-10 13:09:42,172 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-12-10 13:09:42,172 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-12-10 13:09:42,172 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-12-10 13:09:42,172 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-12-10 13:09:42,179 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,180 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:42,181 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:42,183 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:42,404 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:42,405 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:42,405 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:42,420 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:42,421 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:42,421 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:42,458 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:42,459 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: set configuration 0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:42,459 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924/current/log_inprogress_0
datanode_4  | 2022-12-10 13:09:42,470 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode_4  | 2022-12-10 13:09:42,470 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 13:09:42,722 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: start as a follower, conf=0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:42,722 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_4  | 2022-12-10 13:09:42,729 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState
datanode_4  | 2022-12-10 13:09:42,736 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D18C7B531924,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:42,737 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 13:09:42,743 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:35,715 [IPC Server handler 3 on default port 9891] INFO ipc.Server: IPC Server handler 3 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:26:36,219 [IPC Server handler 20 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/44877e3e-f8e0-4fab-9c03-bb94f29d2e65
recon_1     | 2022-12-10 12:26:36,281 [IPC Server handler 26 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/eb6b06af-1f2c-4397-8743-5d103932e2bb
recon_1     | 2022-12-10 12:26:36,288 [IPC Server handler 26 on default port 9891] INFO node.SCMNodeManager: Registered Data node : eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:36,281 [IPC Server handler 20 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:36,632 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node eb6b06af-1f2c-4397-8743-5d103932e2bb to Node DB.
recon_1     | 2022-12-10 12:26:36,648 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 to Node DB.
recon_1     | 2022-12-10 12:26:37,901 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_5.ozone_default
recon_1     | 2022-12-10 12:26:37,904 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:38,044 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:44877e3e-f8e0-4fab-9c03-bb94f29d2e65, CreationTimestamp2022-12-10T12:26:36.053Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:38,138 [IPC Server handler 28 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_1.ozone_default
recon_1     | 2022-12-10 12:26:38,640 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:44877e3e-f8e0-4fab-9c03-bb94f29d2e65, CreationTimestamp2022-12-10T12:26:36.053Z[UTC]].
recon_1     | 2022-12-10 12:26:38,760 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d792bf06-25f5-4ba9-821b-977d25aa3d3c. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:38,841 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d792bf06-25f5-4ba9-821b-977d25aa3d3c, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:eb6b06af-1f2c-4397-8743-5d103932e2bb, CreationTimestamp2022-12-10T12:26:35.950Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:38,843 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d792bf06-25f5-4ba9-821b-977d25aa3d3c, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:eb6b06af-1f2c-4397-8743-5d103932e2bb, CreationTimestamp2022-12-10T12:26:35.950Z[UTC]].
recon_1     | 2022-12-10 12:26:40,347 [IPC Server handler 43 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/213470ee-8924-4d24-82c9-a8e7505514cd
recon_1     | 2022-12-10 12:26:40,348 [IPC Server handler 43 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:40,349 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 213470ee-8924-4d24-82c9-a8e7505514cd to Node DB.
datanode_4  | 2022-12-10 13:09:42,744 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:42,745 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4  | 2022-12-10 13:09:42,745 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4  | 2022-12-10 13:09:42,748 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4  | 2022-12-10 13:09:42,758 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO segmented.LogSegment: Successfully read 3274 entries from segment file /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/current/log_inprogress_0
datanode_4  | 2022-12-10 13:09:42,765 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 3273
datanode_4  | 2022-12-10 13:09:42,765 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 13:09:42,767 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO raftlog.RaftLog: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLog: commitIndex: updateToMax old=3273, new=3272, updated? false
datanode_4  | 2022-12-10 13:09:42,767 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: start as a follower, conf=0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:42,767 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: changes role from      null to FOLLOWER at term 3 for startAsFollower
datanode_4  | 2022-12-10 13:09:42,767 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 13:09:42,773 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:42,773 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:42,773 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4  | 2022-12-10 13:09:42,773 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4  | 2022-12-10 13:09:42,773 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef-impl-thread2] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4  | 2022-12-10 13:09:42,777 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start RPC server
datanode_4  | 2022-12-10 13:09:42,786 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9858
datanode_4  | 2022-12-10 13:09:42,787 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9856
datanode_4  | 2022-12-10 13:09:42,788 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO server.GrpcService: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: GrpcService started, listening on 9857
datanode_4  | 2022-12-10 13:09:42,792 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9858 for RATIS
datanode_4  | 2022-12-10 13:09:42,792 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9857 for RATIS_ADMIN
datanode_4  | 2022-12-10 13:09:42,792 [EndpointStateMachine task thread for scm/172.19.0.2:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 85e9a0c6-8631-4fee-9b9c-0f8004d778ef is started using port 9856 for RATIS_SERVER
datanode_4  | 2022-12-10 13:09:42,792 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-85e9a0c6-8631-4fee-9b9c-0f8004d778ef: Started
datanode_4  | 2022-12-10 13:09:42,796 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 13:09:42,797 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 13:09:46,903 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,904 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,912 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,929 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 8 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,929 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 8 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,942 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 8 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,956 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,956 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,972 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,981 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,982 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:46,996 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,174 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,174 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,183 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,202 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2022-12-10 12:25:47,349 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 2beb09acc4d8/172.19.0.2
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
scm_1       | STARTUP_MSG:   java = 11.0.14.1
scm_1       | ************************************************************/
scm_1       | 2022-12-10 12:25:47,528 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2022-12-10 12:25:48,936 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-12-10 12:25:49,787 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2022-12-10 12:25:50,119 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2022-12-10 12:25:53,426 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1       | 2022-12-10 12:25:54,569 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | 2022-12-10 12:25:54,616 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm_1       | 2022-12-10 12:25:54,639 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm_1       | 2022-12-10 12:25:54,644 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm_1       | 2022-12-10 12:25:54,662 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | 2022-12-10 12:25:54,671 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1       | 2022-12-10 12:25:54,671 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1       | 2022-12-10 12:25:54,676 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2022-12-10 12:25:54,715 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2022-12-10 12:25:54,724 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm_1       | 2022-12-10 12:25:54,894 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm_1       | 2022-12-10 12:25:54,985 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm_1       | 2022-12-10 12:25:55,001 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1       | 2022-12-10 12:25:59,226 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm_1       | 2022-12-10 12:25:59,298 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1       | 2022-12-10 12:25:59,326 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1       | 2022-12-10 12:25:59,326 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2022-12-10 12:25:59,335 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2022-12-10 12:25:59,427 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2022-12-10 12:25:59,609 [main] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: addNew group-CEE2A0F43436:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|priority:0|startupRole:FOLLOWER] returns group-CEE2A0F43436:java.util.concurrent.CompletableFuture@66ba7e45[Not completed]
scm_1       | 2022-12-10 12:26:00,132 [pool-2-thread-1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151: new RaftServerImpl for group-CEE2A0F43436:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
scm_1       | 2022-12-10 12:26:00,178 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1       | 2022-12-10 12:26:00,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2022-12-10 12:26:00,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2022-12-10 12:26:00,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2022-12-10 12:26:00,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2022-12-10 12:26:00,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1       | 2022-12-10 12:26:00,330 [pool-2-thread-1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: ConfigurationManager, init=-1: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
scm_1       | 2022-12-10 12:26:00,379 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2022-12-10 12:26:00,425 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2022-12-10 12:26:00,487 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm_1       | 2022-12-10 12:26:00,887 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2022-12-10 12:26:00,893 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1       | 2022-12-10 12:26:00,931 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1       | 2022-12-10 12:26:01,311 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2022-12-10 12:26:03,778 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2022-12-10 12:26:03,781 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       | 2022-12-10 12:26:03,788 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1       | 2022-12-10 12:26:03,789 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1       | 2022-12-10 12:26:03,790 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1       | 2022-12-10 12:26:03,860 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436 does not exist. Creating ...
scm_1       | 2022-12-10 12:26:03,895 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/in_use.lock acquired by nodename 12@2beb09acc4d8
scm_1       | 2022-12-10 12:26:03,987 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436 has been successfully formatted.
scm_1       | 2022-12-10 12:26:04,082 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2022-12-10 12:26:04,298 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2022-12-10 12:26:04,344 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2022-12-10 12:26:04,365 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1       | 2022-12-10 12:26:04,386 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm_1       | 2022-12-10 12:26:04,402 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1       | 2022-12-10 12:26:04,623 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2022-12-10 12:26:04,635 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1       | 2022-12-10 12:26:04,719 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436
scm_1       | 2022-12-10 12:26:04,721 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1       | 2022-12-10 12:26:04,742 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1       | 2022-12-10 12:26:04,787 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1       | 2022-12-10 12:26:04,792 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm_1       | 2022-12-10 12:26:04,796 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2022-12-10 12:26:04,811 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2022-12-10 12:26:04,819 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2022-12-10 12:26:04,842 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2022-12-10 12:26:40,450 [IPC Server handler 99 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c93c8eed-0198-45d8-87bc-3d7834e7dd79
recon_1     | 2022-12-10 12:26:40,453 [IPC Server handler 99 on default port 9891] INFO node.SCMNodeManager: Registered Data node : c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:40,453 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node c93c8eed-0198-45d8-87bc-3d7834e7dd79 to Node DB.
recon_1     | 2022-12-10 12:26:40,522 [IPC Server handler 20 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/85e9a0c6-8631-4fee-9b9c-0f8004d778ef
recon_1     | 2022-12-10 12:26:40,522 [IPC Server handler 20 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:40,523 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 85e9a0c6-8631-4fee-9b9c-0f8004d778ef to Node DB.
recon_1     | 2022-12-10 12:26:42,457 [IPC Server handler 99 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_3.ozone_default
recon_1     | 2022-12-10 12:26:42,459 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:42,463 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:42,464 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]].
recon_1     | 2022-12-10 12:26:42,465 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:42,750 [IPC Server handler 28 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_2.ozone_default
recon_1     | 2022-12-10 12:26:42,752 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:42,768 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_5.ozone_default
recon_1     | 2022-12-10 12:26:42,843 [IPC Server handler 43 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_4.ozone_default
recon_1     | 2022-12-10 12:26:42,844 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:42,862 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:42,863 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]].
recon_1     | 2022-12-10 12:26:42,864 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 reported by 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om_1        | 2022-12-10 12:26:57,720 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2022-12-10 12:26:57,724 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2022-12-10 12:26:57,725 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2022-12-10 12:26:57,727 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2022-12-10 12:26:57,763 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om_1        | 2022-12-10 12:26:57,763 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2022-12-10 12:26:57,793 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om_1        | 2022-12-10 12:26:57,795 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
om_1        | 2022-12-10 12:26:57,796 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1        | 2022-12-10 12:26:57,806 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2022-12-10 12:26:57,806 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2022-12-10 12:26:57,808 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2022-12-10 12:26:57,816 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2022-12-10 12:26:57,817 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
om_1        | 2022-12-10 12:26:57,837 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1        | 2022-12-10 12:26:57,839 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2022-12-10 12:26:57,839 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 2022-12-10 12:26:57,856 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2022-12-10 12:26:57,864 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1        | 2022-12-10 12:26:57,866 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om_1        | 2022-12-10 12:26:57,867 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om_1        | 2022-12-10 12:26:57,872 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
om_1        | 2022-12-10 12:26:57,933 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om_1        | 2022-12-10 12:26:57,946 [Listener at om/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om_1        | 2022-12-10 12:26:57,948 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1        | 2022-12-10 12:26:58,019 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2022-12-10 12:26:58,019 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2022-12-10 12:26:58,078 [Listener at om/9862] INFO util.log: Logging initialized @24326ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2022-12-10 12:26:58,334 [Listener at om/9862] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
om_1        | 2022-12-10 12:26:58,361 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2022-12-10 12:26:58,382 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2022-12-10 12:26:58,387 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2022-12-10 12:26:58,388 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2022-12-10 12:26:58,388 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2022-12-10 12:26:58,520 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2022-12-10 12:26:58,524 [Listener at om/9862] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
om_1        | 2022-12-10 12:26:58,651 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2022-12-10 12:26:58,654 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2022-12-10 12:26:58,665 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2022-12-10 12:26:58,814 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54e9d42e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2022-12-10 12:26:58,815 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@34ded59f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2022-12-10 12:26:59,293 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5a050bf9{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-15408751241364457912/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2022-12-10 12:26:59,339 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@a25c653{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1        | 2022-12-10 12:26:59,340 [Listener at om/9862] INFO server.Server: Started @25588ms
om_1        | 2022-12-10 12:26:59,363 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2022-12-10 12:26:59,363 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2022-12-10 12:26:59,367 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2022-12-10 12:26:59,375 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2022-12-10 12:26:59,387 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2022-12-10 12:26:59,650 [Listener at om/9862] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1       | 	... 114 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2022-12-10 12:49:48,116 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg1, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,119 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg2, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,120 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg3, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,126 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg7, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,157 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg6, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,168 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg8, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,180 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg0, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,188 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg9, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,192 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg4, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,192 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg5, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,239 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg10, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,246 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg11, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,247 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg12, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,299 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg14, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,301 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg17, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,301 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg15, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,302 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg20, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,305 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg18, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,312 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg21, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,325 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg16, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,339 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg13, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,394 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg19, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,396 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg24, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,406 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg26, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,442 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg25, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,444 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg30, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,442 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg23, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,445 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg28, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,494 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg31, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,496 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg34, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,502 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg33, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,506 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg36, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,514 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg29, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,523 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg22, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_4  | 2022-12-10 13:09:47,204 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,215 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is closed with bcsId 0.
datanode_4  | 2022-12-10 13:09:47,237 [Command processor thread] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: remove  FOLLOWER 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924:t1, leader=null, voted=85e9a0c6-8631-4fee-9b9c-0f8004d778ef, raftlog=Memoized:85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLog:OPENED:c0, conf=0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
datanode_4  | 2022-12-10 13:09:47,243 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: shutdown
datanode_4  | 2022-12-10 13:09:47,244 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D18C7B531924,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:47,244 [Command processor thread] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState
datanode_4  | 2022-12-10 13:09:47,245 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-FollowerState was interrupted
datanode_4  | 2022-12-10 13:09:47,248 [Command processor thread] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-StateMachineUpdater: set stopIndex = 0
datanode_4  | 2022-12-10 13:09:47,249 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: closes. applyIndex: 0
datanode_4  | 2022-12-10 13:09:47,250 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_4  | 2022-12-10 13:09:47,261 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924-SegmentedRaftLogWorker close()
datanode_4  | 2022-12-10 13:09:47,286 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-D18C7B531924: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/914e75cc-e1b0-4c3b-bff3-d18c7b531924
datanode_4  | 2022-12-10 13:09:47,288 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 command on datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef.
datanode_4  | 2022-12-10 13:09:47,292 [Command processor thread] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: remove  FOLLOWER 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E:t3, leader=null, voted=85e9a0c6-8631-4fee-9b9c-0f8004d778ef, raftlog=Memoized:85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c3273, conf=0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
datanode_4  | 2022-12-10 13:09:47,293 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: shutdown
datanode_4  | 2022-12-10 13:09:47,293 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:47,293 [Command processor thread] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState
datanode_4  | 2022-12-10 13:09:47,294 [Command processor thread] INFO impl.StateMachineUpdater: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-StateMachineUpdater: set stopIndex = 3273
datanode_4  | 2022-12-10 13:09:47,293 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-FollowerState was interrupted
datanode_4  | 2022-12-10 13:09:47,298 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: closes. applyIndex: 3273
datanode_4  | 2022-12-10 13:09:47,300 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_4  | 2022-12-10 13:09:47,305 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E-SegmentedRaftLogWorker close()
datanode_4  | 2022-12-10 13:09:47,312 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_4  | 2022-12-10 13:09:47,313 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_4  | 2022-12-10 13:09:47,347 [Command processor thread] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-AF81ED93FE6E: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
datanode_4  | 2022-12-10 13:09:47,347 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e command on datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef.
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: new RaftServerImpl for group-F3435B17AA3B:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-12-10 13:09:53,439 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4  | 2022-12-10 13:09:53,443 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: ConfigurationManager, init=-1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-12-10 13:09:53,443 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-12-10 13:09:53,446 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2022-12-10 12:26:59,654 [Listener at om/9862] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
om_1        | 2022-12-10 12:26:59,991 [Listener at om/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om_1        | 2022-12-10 12:27:00,015 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ed5cb12] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2022-12-10 12:27:02,854 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037085319ns, electionTimeout:5014ms
om_1        | 2022-12-10 12:27:02,855 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1        | 2022-12-10 12:27:02,856 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2022-12-10 12:27:02,870 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2022-12-10 12:27:02,870 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
om_1        | 2022-12-10 12:27:02,886 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2022-12-10 12:27:02,887 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
om_1        | 2022-12-10 12:27:02,888 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
om_1        | 2022-12-10 12:27:02,890 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2022-12-10 12:27:02,890 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 7796ms
om_1        | 2022-12-10 12:27:02,905 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2022-12-10 12:27:02,917 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2022-12-10 12:27:02,918 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om_1        | 2022-12-10 12:27:02,924 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1        | 2022-12-10 12:27:02,925 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2022-12-10 12:27:02,925 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2022-12-10 12:27:02,963 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2022-12-10 12:27:02,966 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2022-12-10 12:27:02,975 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
om_1        | 2022-12-10 12:27:03,035 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2022-12-10 12:27:03,185 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:om:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2022-12-10 12:27:03,339 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
om_1        | 2022-12-10 12:27:03,572 [om1@group-C5BA1605619E-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om_1        | [id: "om1"
om_1        | address: "om:9872"
om_1        | startupRole: FOLLOWER
om_1        | ]
om_1        | 2022-12-10 12:27:22,802 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hadoop
om_1        | 2022-12-10 12:27:25,414 [qtp1120630217-47] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om_1        | 2022-12-10 12:27:25,435 [qtp1120630217-47] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1670675245419 in 15 milliseconds
om_1        | 2022-12-10 12:27:25,535 [qtp1120630217-47] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 98 milliseconds
om_1        | 2022-12-10 12:27:25,535 [qtp1120630217-47] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1670675245419
om_1        | 2022-12-10 12:27:33,101 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:09,589 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:28:36,818 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser0 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:36,833 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser1 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:36,842 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser2 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:36,849 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser3 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:36,859 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser4 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:28:42,537 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 12:29:27,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:27,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:29:43,329 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:89652-source for user:hadoop
datanode_3  | 2022-12-10 12:26:49,848 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=3c7dd0af-68a7-49be-9b83-c785c98ce76d
datanode_3  | 2022-12-10 12:26:49,848 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=3c7dd0af-68a7-49be-9b83-c785c98ce76d.
datanode_3  | 2022-12-10 12:26:49,851 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:53,639 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: receive requestVote(ELECTION, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef, group-AF81ED93FE6E, 2, (t:0, i:0))
datanode_3  | 2022-12-10 12:26:53,642 [grpc-default-executor-1] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FOLLOWER: accept ELECTION from 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: our priority 0 <= candidate's priority 0
datanode_3  | 2022-12-10 12:26:53,642 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_3  | 2022-12-10 12:26:53,642 [grpc-default-executor-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:53,642 [grpc-default-executor-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:53,642 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState was interrupted
datanode_3  | 2022-12-10 12:26:53,646 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 12:26:53,647 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:53,653 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E replies to ELECTION vote request: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t2. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E:t2, leader=null, voted=85e9a0c6-8631-4fee-9b9c-0f8004d778ef, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:54,871 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5034514676ns, electionTimeout:5020ms
datanode_3  | 2022-12-10 12:26:54,872 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState
datanode_3  | 2022-12-10 12:26:54,872 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2022-12-10 12:26:54,872 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-12-10 12:26:54,872 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2
datanode_3  | 2022-12-10 12:26:54,905 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:54,905 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_3  | 2022-12-10 12:26:54,906 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2
datanode_3  | 2022-12-10 12:26:54,906 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2022-12-10 12:26:54,906 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C785C98CE76D with new leaderId: 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 12:26:54,906 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: change Leader from null to 213470ee-8924-4d24-82c9-a8e7505514cd at term 1 for becomeLeader, leader elected after 5757ms
datanode_3  | 2022-12-10 12:26:54,981 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2022-12-10 12:26:54,988 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2022-12-10 12:26:54,990 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3  | 2022-12-10 12:26:54,998 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2022-12-10 12:26:54,998 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2022-12-10 12:26:55,000 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2022-12-10 12:26:55,012 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2022-12-10 12:26:55,020 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | 2022-12-10 12:26:55,026 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderStateImpl
datanode_3  | 2022-12-10 12:26:55,078 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-12-10 12:26:55,142 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-LeaderElection2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D: set configuration 0: peers:[213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:55,280 [213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-C785C98CE76D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3c7dd0af-68a7-49be-9b83-c785c98ce76d/current/log_inprogress_0
datanode_3  | 2022-12-10 12:26:58,722 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: receive requestVote(ELECTION, c93c8eed-0198-45d8-87bc-3d7834e7dd79, group-AF81ED93FE6E, 3, (t:0, i:0))
datanode_3  | 2022-12-10 12:26:58,722 [grpc-default-executor-1] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FOLLOWER: accept ELECTION from c93c8eed-0198-45d8-87bc-3d7834e7dd79: our priority 0 <= candidate's priority 1
datanode_3  | 2022-12-10 12:26:58,722 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_3  | 2022-12-10 12:26:58,723 [grpc-default-executor-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:58,723 [grpc-default-executor-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
datanode_3  | 2022-12-10 12:26:58,723 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState was interrupted
datanode_3  | 2022-12-10 12:26:58,724 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 12:26:58,724 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 12:26:58,726 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E replies to ELECTION vote request: c93c8eed-0198-45d8-87bc-3d7834e7dd79<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t3. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E:t3, leader=null, voted=c93c8eed-0198-45d8-87bc-3d7834e7dd79, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:58,768 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: receive requestVote(ELECTION, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef, group-AF81ED93FE6E, 3, (t:0, i:0))
datanode_3  | 2022-12-10 12:26:58,769 [grpc-default-executor-1] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FOLLOWER: reject ELECTION from 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: already has voted for c93c8eed-0198-45d8-87bc-3d7834e7dd79 at current term 3
datanode_3  | 2022-12-10 12:26:58,769 [grpc-default-executor-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E replies to ELECTION vote request: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef<-213470ee-8924-4d24-82c9-a8e7505514cd#0:FAIL-t3. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E:t3, leader=null, voted=c93c8eed-0198-45d8-87bc-3d7834e7dd79, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:58,984 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AF81ED93FE6E with new leaderId: c93c8eed-0198-45d8-87bc-3d7834e7dd79
datanode_3  | 2022-12-10 12:26:58,987 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: change Leader from null to c93c8eed-0198-45d8-87bc-3d7834e7dd79 at term 3 for appendEntries, leader elected after 17132ms
datanode_3  | 2022-12-10 12:26:59,005 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: set configuration 0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 12:26:59,007 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-12-10 12:26:59,013 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/current/log_inprogress_0
datanode_3  | 2022-12-10 13:05:14,037 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-7] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_3  | 2022-12-10 13:05:14,038 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-7] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 3262.
datanode_3  | 2022-12-10 13:05:14,046 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-7] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 3262.
datanode_3  | 2022-12-10 13:08:37,119 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,120 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,133 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 7 is closed with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,138 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,138 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,146 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 5 is closed with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,153 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,153 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,163 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 3 is closed with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,188 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,188 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,196 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-9] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_3  | 2022-12-10 13:08:37,197 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-9] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_3  | 2022-12-10 13:08:37,202 [ContainerOp-c0524777-5948-4be0-b34b-af81ed93fe6e-9] INFO keyvalue.KeyValueContainer: Container 9 is closed with bcsId 3272.
datanode_3  | 2022-12-10 13:08:37,222 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 6 is closed with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,236 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,238 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is synced with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,245 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 4 is closed with bcsId 0.
datanode_3  | 2022-12-10 13:08:37,259 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd: new RaftServerImpl for group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
s3g_1       | 2022-12-10 12:49:48,526 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg27, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,535 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg37, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,537 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg32, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,567 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg38, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,560 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg39, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,574 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg35, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,585 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg41, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,593 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg40, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,593 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg44, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,651 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg49, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,657 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg46, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,666 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg45, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,666 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg48, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,681 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg42, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,706 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg47, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,708 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg43, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,710 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg51, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,729 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg53, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,737 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg50, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,745 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg52, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,777 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg58, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,786 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg60, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,788 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg61, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,790 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg55, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,792 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg63, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,794 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg56, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,796 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg59, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,801 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg54, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,801 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg57, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,804 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg62, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,840 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg64, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,875 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg71, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,876 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg66, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,879 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg73, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:26:42,864 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] moved to OPEN state
recon_1     | 2022-12-10 12:26:42,957 [IPC Server handler 44 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_1.ozone_default
recon_1     | 2022-12-10 12:26:43,370 [IPC Server handler 45 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_4.ozone_default
recon_1     | 2022-12-10 12:26:43,372 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:47,373 [IPC Server handler 58 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_3.ozone_default
recon_1     | 2022-12-10 12:26:47,377 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:47,635 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_2.ozone_default
recon_1     | 2022-12-10 12:26:47,636 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:47,897 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:47,897 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d2f8c45a-a0b2-410a-969f-1150c0739b5c. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:47,959 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d2f8c45a-a0b2-410a-969f-1150c0739b5c, Nodes: c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.976Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:47,972 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d2f8c45a-a0b2-410a-969f-1150c0739b5c, Nodes: c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.976Z[UTC]].
recon_1     | 2022-12-10 12:26:47,975 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d2f8c45a-a0b2-410a-969f-1150c0739b5c reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:47,975 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d2f8c45a-a0b2-410a-969f-1150c0739b5c, Nodes: c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.976Z[UTC]] moved to OPEN state
recon_1     | 2022-12-10 12:26:48,407 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:48,492 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:49,231 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:49,231 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=3c7dd0af-68a7-49be-9b83-c785c98ce76d. Trying to get from SCM.
recon_1     | 2022-12-10 12:26:49,238 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 3c7dd0af-68a7-49be-9b83-c785c98ce76d, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:36.003Z[UTC]] to Recon pipeline metadata.
recon_1     | 2022-12-10 12:26:49,239 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 3c7dd0af-68a7-49be-9b83-c785c98ce76d, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:36.003Z[UTC]].
recon_1     | 2022-12-10 12:26:49,240 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=3c7dd0af-68a7-49be-9b83-c785c98ce76d reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:49,240 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 3c7dd0af-68a7-49be-9b83-c785c98ce76d, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:213470ee-8924-4d24-82c9-a8e7505514cd, CreationTimestamp2022-12-10T12:26:36.003Z[UTC]] moved to OPEN state
recon_1     | 2022-12-10 12:26:53,922 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:54,909 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:58,783 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e reported by c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:26:58,783 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] moved to OPEN state
recon_1     | 2022-12-10 12:27:24,604 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:27:24,604 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2022-12-10 12:27:25,632 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1670675244605
recon_1     | 2022-12-10 12:27:25,641 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:27:25,645 [pool-27-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:27:25,823 [pool-27-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1670675244605.
recon_1     | 2022-12-10 12:27:25,933 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2022-12-10 12:27:25,969 [pool-49-thread-2] INFO tasks.NSSummaryTaskWithLegacy: Completed a reprocess run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:27:25,972 [pool-49-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a reprocess run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:27:26,493 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1     | 2022-12-10 12:27:26,493 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2022-12-10 12:27:26,494 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1     | 2022-12-10 12:27:26,494 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
recon_1     | 2022-12-10 12:27:26,498 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2022-12-10 12:27:26,499 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.005 seconds to process 0 keys.
recon_1     | 2022-12-10 12:27:26,524 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1     | 2022-12-10 12:27:26,525 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:28:02,471 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-12-10 12:28:02,605 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2022-12-10 12:28:26,536 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
datanode_4  | 2022-12-10 13:09:53,448 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4  | 2022-12-10 13:09:53,448 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-12-10 13:09:53,449 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-12-10 13:09:53,449 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-12-10 13:09:53,452 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-12-10 13:09:53,453 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4  | 2022-12-10 13:09:53,454 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4  | 2022-12-10 13:09:53,454 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4  | 2022-12-10 13:09:53,454 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4  | 2022-12-10 13:09:53,457 [Command processor thread] INFO server.RaftServer: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: addNew group-F3435B17AA3B:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER] returns      null 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B:t0, leader=null, voted=null, raftlog=UNINITIALIZED, conf=-1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null NEW
datanode_4  | 2022-12-10 13:09:53,461 [pool-26-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4bdf5060-2d04-4557-9c86-f3435b17aa3b does not exist. Creating ...
datanode_4  | 2022-12-10 13:09:53,465 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4bdf5060-2d04-4557-9c86-f3435b17aa3b/in_use.lock acquired by nodename 7@c79f062f35ec
datanode_4  | 2022-12-10 13:09:53,495 [pool-26-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4bdf5060-2d04-4557-9c86-f3435b17aa3b has been successfully formatted.
datanode_4  | 2022-12-10 13:09:53,508 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-F3435B17AA3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4  | 2022-12-10 13:09:53,508 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:53,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4bdf5060-2d04-4557-9c86-f3435b17aa3b
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-12-10 13:09:53,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-12-10 13:09:53,513 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-12-10 13:09:53,515 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-12-10 13:09:53,517 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:53,546 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:53,546 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_4  | 2022-12-10 13:09:53,546 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:53,546 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 13:09:53,547 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-12-10 13:09:53,547 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: start as a follower, conf=-1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_4  | 2022-12-10 13:09:53,550 [pool-26-thread-1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4  | 2022-12-10 13:09:53,550 [pool-26-thread-1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState
datanode_4  | 2022-12-10 13:09:53,574 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 13:09:53,579 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 13:09:53,580 [pool-26-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F3435B17AA3B,id=85e9a0c6-8631-4fee-9b9c-0f8004d778ef
datanode_4  | 2022-12-10 13:09:53,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-12-10 13:09:53,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5  | 2022-12-10 13:08:42,550 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5  | 2022-12-10 13:08:42,550 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 13:08:42,550 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection2
datanode_5  | 2022-12-10 13:08:42,577 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 1, (t:0, i:0))
datanode_5  | 2022-12-10 13:08:42,584 [grpc-default-executor-0] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-CANDIDATE: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_5  | 2022-12-10 13:08:42,587 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 1 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:08:42,587 [grpc-default-executor-0] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection2
datanode_5  | 2022-12-10 13:08:42,587 [grpc-default-executor-0] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:42,591 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:08:42,592 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:08:42,606 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t1. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t1, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:08:47,713 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 2, (t:0, i:0))
datanode_5  | 2022-12-10 13:08:47,713 [grpc-default-executor-0] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_5  | 2022-12-10 13:08:47,714 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:08:47,714 [grpc-default-executor-0] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:47,714 [grpc-default-executor-0] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:47,714 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
datanode_5  | 2022-12-10 13:08:47,721 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:08:47,721 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:08:47,722 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t2. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t2, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:08:52,747 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5025651890ns, electionTimeout:5024ms
datanode_5  | 2022-12-10 13:08:52,747 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:52,747 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_5  | 2022-12-10 13:08:52,748 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 13:08:52,748 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3
datanode_5  | 2022-12-10 13:08:52,751 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: submit vote requests at term 3 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 13:08:37,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2022-12-10 13:08:37,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2022-12-10 13:08:37,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2022-12-10 13:08:37,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-12-10 13:08:37,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-12-10 13:08:37,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 2022-12-10 13:08:37,260 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: ConfigurationManager, init=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_3  | 2022-12-10 13:08:37,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-12-10 13:08:37,261 [Command processor thread] INFO server.RaftServer: 213470ee-8924-4d24-82c9-a8e7505514cd: addNew group-18DDCF3CC495:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER] returns group-18DDCF3CC495:java.util.concurrent.CompletableFuture@8f27bf[Not completed]
datanode_3  | 2022-12-10 13:08:37,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2022-12-10 13:08:37,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2022-12-10 13:08:37,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2022-12-10 13:08:37,263 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2022-12-10 13:08:37,263 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2022-12-10 13:08:37,265 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2022-12-10 13:08:37,265 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3  | 2022-12-10 13:08:37,265 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3  | 2022-12-10 13:08:37,266 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2022-12-10 13:08:37,266 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3  | 2022-12-10 13:08:37,266 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 does not exist. Creating ...
datanode_3  | 2022-12-10 13:08:37,269 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/in_use.lock acquired by nodename 7@d6dbe5575a0d
datanode_3  | 2022-12-10 13:08:37,273 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495 has been successfully formatted.
datanode_3  | 2022-12-10 13:08:37,273 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-18DDCF3CC495: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2022-12-10 13:08:37,284 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2022-12-10 13:08:37,285 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2022-12-10 13:08:37,286 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 13:08:37,286 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3  | 2022-12-10 13:08:37,286 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2022-12-10 13:08:37,286 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-12-10 13:08:37,289 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2022-12-10 13:08:37,291 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2022-12-10 13:08:37,291 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495
datanode_3  | 2022-12-10 13:08:37,292 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2022-12-10 13:08:37,292 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2022-12-10 13:08:37,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:28:26,540 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 5 
recon_1     | 2022-12-10 12:28:26,607 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4, SequenceNumber diff: 10, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:28:26,607 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 10 records
recon_1     | 2022-12-10 12:28:26,616 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:28:26,619 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:28:26,929 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:28:26,956 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-12-10 12:28:27,017 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:29:27,028 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:29:27,029 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:29:27,029 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 15 
recon_1     | 2022-12-10 12:29:27,259 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 209, SequenceNumber diff: 625, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:29:27,260 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 625 records
recon_1     | 2022-12-10 12:29:27,267 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:29:27,275 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:29:27,521 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:29:27,545 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 101 OM DB update event(s).
recon_1     | 2022-12-10 12:29:27,564 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:30:27,585 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:30:27,585 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:30:27,585 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 640 
recon_1     | 2022-12-10 12:30:27,620 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 28, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:30:27,620 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 28 records
recon_1     | 2022-12-10 12:30:27,637 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:30:27,637 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:30:27,873 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:30:27,878 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
recon_1     | 2022-12-10 12:30:27,893 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:31:27,904 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:31:27,905 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:31:27,905 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 668 
recon_1     | 2022-12-10 12:31:27,917 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:31:27,917 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
recon_1     | 2022-12-10 12:31:27,920 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:31:27,921 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:31:28,095 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:31:28,101 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-12-10 12:31:28,131 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:31:34,516 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 48 milliseconds to process 0 existing database records.
recon_1     | 2022-12-10 12:31:34,531 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 14 milliseconds for processing 1 containers.
recon_1     | 2022-12-10 12:31:35,024 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-12-10 12:31:35,048 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 36 milliseconds.
recon_1     | 2022-12-10 12:32:28,138 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:32:28,138 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:32:28,139 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 679 
recon_1     | 2022-12-10 12:32:28,149 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12, SequenceNumber diff: 30, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:32:28,149 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 30 records
recon_1     | 2022-12-10 12:32:28,165 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:32:28,166 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:32:28,440 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:32:28,441 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-12-10 12:32:28,450 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:33:28,459 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:33:28,460 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2022-12-10 13:08:37,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2022-12-10 13:08:37,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2022-12-10 13:08:37,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2022-12-10 13:08:37,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2022-12-10 13:08:37,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2022-12-10 13:08:37,300 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2022-12-10 13:08:37,302 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-12-10 13:08:37,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3  | 2022-12-10 13:08:37,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  | 2022-12-10 13:08:37,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2022-12-10 13:08:37,318 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 13:08:37,319 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-12-10 13:08:37,322 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: start as a follower, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 13:08:37,325 [pool-22-thread-1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2022-12-10 13:08:37,326 [pool-22-thread-1] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:08:37,326 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:08:37,338 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18DDCF3CC495,id=213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 13:08:37,338 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:08:37,339 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-12-10 13:08:37,339 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2022-12-10 13:08:37,340 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2022-12-10 13:08:37,340 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-12-10 13:08:37,340 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495
datanode_3  | 2022-12-10 13:08:37,882 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495.
datanode_3  | 2022-12-10 13:08:42,510 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184477856ns, electionTimeout:5172ms
datanode_3  | 2022-12-10 13:08:42,511 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:08:42,511 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2022-12-10 13:08:42,512 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-12-10 13:08:42,512 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3
datanode_3  | 2022-12-10 13:08:42,516 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 13:08:42,518 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3-1] INFO server.GrpcServerProtocolClient: Build channel for 44877e3e-f8e0-4fab-9c03-bb94f29d2e65
datanode_3  | 2022-12-10 13:08:42,522 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:08:42,540 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:08:42,529 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3-2] INFO server.GrpcServerProtocolClient: Build channel for eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t1
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: result REJECTED
scm_1       | 2022-12-10 12:26:04,998 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1       | 2022-12-10 12:26:04,998 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2022-12-10 12:26:05,219 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2022-12-10 12:26:05,228 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2022-12-10 12:26:05,236 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1       | 2022-12-10 12:26:05,371 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2022-12-10 12:26:05,371 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2022-12-10 12:26:05,406 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: start as a follower, conf=-1: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:05,442 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2022-12-10 12:26:05,480 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState
scm_1       | 2022-12-10 12:26:05,667 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:05,668 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:05,718 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CEE2A0F43436,id=de14337a-ef52-472b-bd3f-7050a14dd151
scm_1       | 2022-12-10 12:26:05,721 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2022-12-10 12:26:05,811 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm_1       | 2022-12-10 12:26:05,848 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1       | 2022-12-10 12:26:05,868 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2022-12-10 12:26:06,047 [main] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: start RPC server
scm_1       | 2022-12-10 12:26:07,136 [main] INFO server.GrpcService: de14337a-ef52-472b-bd3f-7050a14dd151: GrpcService started, listening on 9894
scm_1       | 2022-12-10 12:26:07,283 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-de14337a-ef52-472b-bd3f-7050a14dd151: Started
scm_1       | 2022-12-10 12:26:10,743 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.FollowerState: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5263427331ns, electionTimeout:5055ms
scm_1       | 2022-12-10 12:26:10,744 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState
scm_1       | 2022-12-10 12:26:10,767 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2022-12-10 12:26:10,770 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:10,770 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1
scm_1       | 2022-12-10 12:26:10,884 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.LeaderElection: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:10,885 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.LeaderElection: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm_1       | 2022-12-10 12:26:10,935 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1
scm_1       | 2022-12-10 12:26:10,936 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 2022-12-10 12:26:10,937 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: change Leader from null to de14337a-ef52-472b-bd3f-7050a14dd151 at term 1 for becomeLeader, leader elected after 10049ms
scm_1       | 2022-12-10 12:26:11,342 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2022-12-10 12:26:11,432 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2022-12-10 12:26:11,451 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2022-12-10 12:26:11,610 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2022-12-10 12:26:11,644 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2022-12-10 12:26:11,644 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2022-12-10 12:26:11,702 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2022-12-10 12:26:11,821 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm_1       | 2022-12-10 12:26:11,856 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderStateImpl
scm_1       | 2022-12-10 12:26:12,160 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2022-12-10 12:26:12,705 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: set configuration 0: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:13,120 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/log_inprogress_0
scm_1       | 2022-12-10 12:26:13,350 [main] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: close
scm_1       | 2022-12-10 12:26:13,363 [main] INFO server.GrpcService: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown server GrpcServerProtocolService now
scm_1       | 2022-12-10 12:26:13,367 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: shutdown
scm_1       | 2022-12-10 12:26:13,367 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CEE2A0F43436,id=de14337a-ef52-472b-bd3f-7050a14dd151
scm_1       | 2022-12-10 12:26:13,368 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderStateImpl
scm_1       | 2022-12-10 12:26:13,396 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO impl.PendingRequests: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-PendingRequests: sendNotLeaderResponses
scm_1       | 2022-12-10 12:26:13,516 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO impl.StateMachineUpdater: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater: Took a snapshot at index 0
scm_1       | 2022-12-10 12:26:13,526 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO impl.StateMachineUpdater: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm_1       | 2022-12-10 12:26:13,536 [main] INFO server.GrpcService: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown server GrpcServerProtocolService successfully
scm_1       | 2022-12-10 12:26:13,535 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO impl.StateMachineUpdater: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater: set stopIndex = 0
scm_1       | 2022-12-10 12:26:13,550 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: closes. applyIndex: 0
scm_1       | 2022-12-10 12:26:13,574 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1       | 2022-12-10 12:26:13,575 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker close()
scm_1       | 2022-12-10 12:26:13,600 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-de14337a-ef52-472b-bd3f-7050a14dd151: Stopped
scm_1       | 2022-12-10 12:26:13,600 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-12-10 12:26:13,644 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-200db308-9a00-4c02-aa1c-cee2a0f43436; layoutVersion=4; scmId=de14337a-ef52-472b-bd3f-7050a14dd151
scm_1       | 2022-12-10 12:26:13,678 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 2beb09acc4d8/172.19.0.2
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2022-12-10 12:26:19,325 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 2beb09acc4d8/172.19.0.2
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
om_1        | 2022-12-10 12:29:47,459 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:89652-target for user:hadoop
om_1        | 2022-12-10 12:29:51,751 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 89652-target
om_1        | 2022-12-10 12:30:00,532 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 89652-target
datanode_5  | 2022-12-10 13:08:52,757 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/a9bb08889c2c75fc8d30ed3847593a5184917f30 ; compiled by 'runner' on 2022-12-10T12:07Z
recon_1     | 2022-12-10 12:33:28,460 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 709 
datanode_5  | 2022-12-10 13:08:52,757 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_4  | 2022-12-10 13:09:53,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
recon_1     | 2022-12-10 12:33:28,469 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
datanode_5  | 2022-12-10 13:08:52,767 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 3, (t:0, i:0))
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3
recon_1     | 2022-12-10 12:33:28,469 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
om_1        | 2022-12-10 12:30:04,730 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 89652-source
om_1        | 2022-12-10 12:31:01,229 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_5  | 2022-12-10 13:08:52,769 [grpc-default-executor-0] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-CANDIDATE: reject ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: already has voted for 44877e3e-f8e0-4fab-9c03-bb94f29d2e65 at current term 3
datanode_5  | 2022-12-10 13:08:52,769 [grpc-default-executor-0] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:FAIL-t3. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t3, leader=null, voted=44877e3e-f8e0-4fab-9c03-bb94f29d2e65, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:33:28,472 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2022-12-10 12:31:01,230 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,231 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_5  | 2022-12-10 13:08:52,776 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3-1] INFO server.GrpcServerProtocolClient: Build channel for 213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:08:52,779 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3-2] INFO server.GrpcServerProtocolClient: Build channel for eb6b06af-1f2c-4397-8743-5d103932e2bb
recon_1     | 2022-12-10 12:33:28,472 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_4  | 2022-12-10 13:09:53,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
s3g_1       | 2022-12-10 12:49:48,893 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg68, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_5  | 2022-12-10 13:08:52,943 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_5  | 2022-12-10 13:08:52,943 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection:   Response 0: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t3
datanode_3  | 2022-12-10 13:08:42,592 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
om_1        | 2022-12-10 12:31:01,231 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:49:48,913 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg70, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:33:28,587 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_5  | 2022-12-10 13:08:52,943 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3 ELECTION round 0: result REJECTED
datanode_5  | 2022-12-10 13:08:52,945 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
om_1        | 2022-12-10 12:31:01,232 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,232 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,232 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,232 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,233 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,234 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,235 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,235 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,235 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:49:48,919 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg65, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,917 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg72, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,914 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg67, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,936 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg69, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_5  | 2022-12-10 13:08:52,946 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3
datanode_5  | 2022-12-10 13:08:52,946 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection3] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:08:52,949 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 2022-12-10 12:49:48,939 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg76, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,950 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg74, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,956 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg77, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:48,967 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg75, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:31:01,235 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,235 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,236 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:01,236 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:49:48,970 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg78, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:33:28,587 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 2022-12-10 12:31:01,236 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:31:29,023 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 89652-target
om_1        | 2022-12-10 12:31:33,246 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:89652-target
s3g_1       | 2022-12-10 12:49:48,981 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg79, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_5  | 2022-12-10 13:08:52,949 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:08:42,595 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
datanode_5  | 2022-12-10 13:08:57,823 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 4, (t:0, i:0))
datanode_3  | 2022-12-10 13:08:42,595 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 2022-12-10 12:49:49,010 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg80, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 2022-12-10 12:49:49,069 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg88, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_5  | 2022-12-10 13:08:57,823 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_3  | 2022-12-10 13:08:47,701 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109170284ns, electionTimeout:5106ms
scm_1       | STARTUP_MSG:   java = 11.0.14.1
scm_1       | ************************************************************/
s3g_1       | 2022-12-10 12:49:49,075 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg83, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,077 [qtp1858015030-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg87, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,090 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg84, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_3  | 2022-12-10 13:08:47,701 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:19,372 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2022-12-10 12:26:19,515 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 2022-12-10 12:49:49,089 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg85, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,117 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg90, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,100 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg86, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_3  | 2022-12-10 13:08:47,702 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm_1       | 2022-12-10 12:26:19,597 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2022-12-10 12:26:19,657 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
s3g_1       | 2022-12-10 12:49:49,098 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg81, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,094 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg82, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,139 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg89, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_5  | 2022-12-10 13:08:57,823 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 13:08:47,702 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
s3g_1       | 2022-12-10 12:49:49,191 [qtp1858015030-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg94, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:33:28,587 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_4  | 2022-12-10 13:09:53,587 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4bdf5060-2d04-4557-9c86-f3435b17aa3b
datanode_5  | 2022-12-10 13:08:57,824 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:08:47,702 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4
scm_1       | 2022-12-10 12:26:20,920 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 2022-12-10 12:49:49,194 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg96, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,197 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg91, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode_4  | 2022-12-10 13:09:53,588 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=4bdf5060-2d04-4557-9c86-f3435b17aa3b.
datanode_5  | 2022-12-10 13:08:57,824 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
datanode_3  | 2022-12-10 13:08:47,709 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:21,346 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4  | 2022-12-10 13:09:58,661 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO impl.FollowerState: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5111020490ns, electionTimeout:5081ms
datanode_5  | 2022-12-10 13:08:57,824 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:08:47,720 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:21,805 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:31:37,794 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 89652-target
recon_1     | 2022-12-10 12:34:28,594 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_4  | 2022-12-10 13:09:58,663 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState
datanode_3  | 2022-12-10 13:08:47,721 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:08:57,825 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2022-12-10 12:31:41,715 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:89652-target
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1     | 2022-12-10 12:34:28,595 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_4  | 2022-12-10 13:09:58,663 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2022-12-10 12:26:21,807 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_3  | 2022-12-10 13:08:47,738 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
recon_1     | 2022-12-10 12:34:28,595 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 724 
datanode_4  | 2022-12-10 13:09:58,667 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:21,940 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2022-12-10 13:08:47,738 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t2
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
recon_1     | 2022-12-10 12:34:28,615 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 23, SequenceNumber Lag from OM 0.
datanode_4  | 2022-12-10 13:09:58,667 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-FollowerState] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1
scm_1       | 2022-12-10 12:26:21,965 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:de14337a-ef52-472b-bd3f-7050a14dd151
datanode_3  | 2022-12-10 13:08:47,738 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t2
s3g_1       | 2022-12-10 12:49:49,221 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg92, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,223 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg95, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:34:28,616 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 23 records
datanode_4  | 2022-12-10 13:09:58,672 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:22,091 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2022-12-10 13:08:47,738 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: result REJECTED
datanode_5  | 2022-12-10 13:08:57,826 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 2022-12-10 12:49:49,227 [qtp1858015030-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg93, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4  | 2022-12-10 13:09:58,673 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO impl.LeaderElection: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm_1       | 2022-12-10 12:26:22,308 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2022-12-10 13:08:47,739 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode_5  | 2022-12-10 13:08:57,827 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t4. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t4, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 2022-12-10 12:49:49,240 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg97, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4  | 2022-12-10 13:09:58,673 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: shutdown 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1
scm_1       | 2022-12-10 12:26:22,309 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
datanode_3  | 2022-12-10 13:08:47,739 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4
datanode_5  | 2022-12-10 13:09:02,834 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 2022-12-10 12:49:49,242 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg99, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:49:49,271 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg98, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-12-10 12:34:28,620 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_4  | 2022-12-10 13:09:58,673 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2022-12-10 13:08:47,740 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:02,834 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 2022-12-10 12:51:03,454 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-05520, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 2022-12-10 12:34:28,621 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_4  | 2022-12-10 13:09:58,673 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F3435B17AA3B with new leaderId: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 12:26:22,314 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2022-12-10 13:08:47,746 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 2022-12-10 12:51:05,764 [qtp1858015030-20] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 2022-12-10 12:52:15,024 [qtp1858015030-21] WARN server.HttpChannel: /erasure/ozone-test-3785280973/putobject/custom-metadata/key2
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:31:45,623 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 89652-target
om_1        | 2022-12-10 12:31:49,890 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 89652-target
datanode_5  | 2022-12-10 13:09:02,972 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 5, (t:0, i:0))
datanode_5  | 2022-12-10 13:09:02,974 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_5  | 2022-12-10 13:09:02,974 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:09:02,974 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_4  | 2022-12-10 13:09:58,674 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: change Leader from null to 85e9a0c6-8631-4fee-9b9c-0f8004d778ef at term 1 for becomeLeader, leader elected after 5225ms
recon_1     | 2022-12-10 12:34:28,724 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2022-12-10 12:31:54,100 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 89652-target
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
datanode_3  | 2022-12-10 13:08:47,747 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:09:02,974 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:22,315 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
datanode_4  | 2022-12-10 13:09:58,682 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
recon_1     | 2022-12-10 12:34:28,727 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | 2022-12-10 12:32:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_3  | 2022-12-10 13:08:52,751 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5011069942ns, electionTimeout:5004ms
datanode_5  | 2022-12-10 13:09:02,974 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
datanode_5  | 2022-12-10 13:09:02,976 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_4  | 2022-12-10 13:09:58,688 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2022-12-10 12:34:28,749 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
datanode_3  | 2022-12-10 13:08:52,751 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:02,976 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:22,315 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_4  | 2022-12-10 13:09:58,689 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
recon_1     | 2022-12-10 12:35:28,765 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_3  | 2022-12-10 13:08:52,751 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_5  | 2022-12-10 13:09:02,977 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t5. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t5, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:22,315 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
datanode_4  | 2022-12-10 13:09:58,695 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 2022-12-10 12:35:28,766 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:52,751 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 13:09:03,090 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, eb6b06af-1f2c-4397-8743-5d103932e2bb, group-18DDCF3CC495, 5, (t:0, i:0))
scm_1       | 2022-12-10 12:26:22,316 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
datanode_4  | 2022-12-10 13:09:58,695 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 2022-12-10 12:35:28,766 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 747 
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:52,751 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5
datanode_5  | 2022-12-10 13:09:03,091 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: reject ELECTION from eb6b06af-1f2c-4397-8743-5d103932e2bb: already has voted for 213470ee-8924-4d24-82c9-a8e7505514cd at current term 5
scm_1       | 2022-12-10 12:26:22,318 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-12-10 13:09:58,696 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 2022-12-10 12:35:28,776 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 21, SequenceNumber Lag from OM 0.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:52,754 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:03,091 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: eb6b06af-1f2c-4397-8743-5d103932e2bb<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:FAIL-t5. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t5, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:22,321 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode_4  | 2022-12-10 13:09:58,703 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2022-12-10 12:35:28,776 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 21 records
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
datanode_3  | 2022-12-10 13:08:52,755 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:08,018 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:26:22,323 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
recon_1     | 2022-12-10 12:35:28,782 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_5  | 2022-12-10 13:09:08,019 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
datanode_4  | 2022-12-10 13:09:58,706 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | 2022-12-10 13:08:52,755 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:26:22,342 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
recon_1     | 2022-12-10 12:35:28,783 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_5  | 2022-12-10 13:09:08,098 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 6, (t:0, i:0))
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
datanode_4  | 2022-12-10 13:09:58,708 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO impl.RoleInfo: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef: start 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderStateImpl
datanode_3  | 2022-12-10 13:08:52,780 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:26:22,347 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
recon_1     | 2022-12-10 12:35:28,912 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_5  | 2022-12-10 13:09:08,100 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_5  | 2022-12-10 13:09:08,100 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:09:08,100 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_4  | 2022-12-10 13:09:58,714 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:FAIL-t3
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
datanode_5  | 2022-12-10 13:09:08,100 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_4  | 2022-12-10 13:09:58,721 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4bdf5060-2d04-4557-9c86-f3435b17aa3b/current/log_inprogress_0
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t3
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:26:22,350 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1       | 2022-12-10 12:26:22,667 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_5  | 2022-12-10 13:09:08,100 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode_4  | 2022-12-10 13:09:58,729 [85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B-LeaderElection1] INFO server.RaftServer$Division: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef@group-F3435B17AA3B: set configuration 0: peers:[85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5 ELECTION round 0: result REJECTED
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:32:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:35:28,913 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
datanode_5  | 2022-12-10 13:09:08,107 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
datanode_4  | 2022-12-10 13:11:54,681 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 12:26:22,669 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1       | 2022-12-10 12:26:22,670 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1       | 2022-12-10 12:26:22,670 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2022-12-10 12:26:22,671 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2022-12-10 12:26:22,675 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5
datanode_5  | 2022-12-10 13:09:08,107 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:22,679 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: found a subdirectory /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436
scm_1       | 2022-12-10 12:26:22,684 [main] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: addNew group-CEE2A0F43436:[] returns group-CEE2A0F43436:java.util.concurrent.CompletableFuture@5d1b1c2a[Not completed]
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
datanode_3  | 2022-12-10 13:08:52,781 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection5] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:08,109 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t6. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t6, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:22,707 [pool-16-thread-1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151: new RaftServerImpl for group-CEE2A0F43436:[] with SCMStateMachine:uninitialized
datanode_4  | 2022-12-10 13:11:54,681 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 9 is synced with bcsId 3272.
datanode_5  | 2022-12-10 13:09:13,179 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 7, (t:0, i:0))
datanode_3  | 2022-12-10 13:08:52,787 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:22,708 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1       | 2022-12-10 12:26:22,711 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2022-12-10 12:26:22,711 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2022-12-10 12:26:22,711 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | 2022-12-10 13:09:13,180 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
datanode_3  | 2022-12-10 13:08:52,788 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:22,712 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
datanode_5  | 2022-12-10 13:09:13,180 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_3  | 2022-12-10 13:08:52,938 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 3, (t:0, i:0))
scm_1       | 2022-12-10 12:26:22,712 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_4  | 2022-12-10 13:11:54,685 [Command processor thread] INFO keyvalue.KeyValueContainer: Container 9 is closed with bcsId 3272.
datanode_5  | 2022-12-10 13:09:13,180 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:26:22,732 [pool-16-thread-1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:35:28,918 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:36:28,927 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2022-12-10 13:08:52,938 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: reject ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: already has voted for 213470ee-8924-4d24-82c9-a8e7505514cd at current term 3
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
datanode_3  | 2022-12-10 13:08:52,938 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:FAIL-t3. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t3, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
datanode_3  | 2022-12-10 13:08:57,813 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031336364ns, electionTimeout:5025ms
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
datanode_3  | 2022-12-10 13:08:57,813 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:13,181 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
datanode_5  | 2022-12-10 13:09:13,182 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:13,182 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:13,183 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | 2022-12-10 13:08:57,813 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode_5  | 2022-12-10 13:09:13,184 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t7. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t7, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
datanode_3  | 2022-12-10 13:08:57,814 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 13:09:18,248 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, 213470ee-8924-4d24-82c9-a8e7505514cd, group-18DDCF3CC495, 8, (t:0, i:0))
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
datanode_3  | 2022-12-10 13:08:57,814 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6
datanode_5  | 2022-12-10 13:09:18,248 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 213470ee-8924-4d24-82c9-a8e7505514cd: our priority 0 <= candidate's priority 0
scm_1       | 2022-12-10 12:26:22,733 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
recon_1     | 2022-12-10 12:36:28,927 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 2022-12-10 12:32:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
datanode_3  | 2022-12-10 13:08:57,816 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:18,248 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:213470ee-8924-4d24-82c9-a8e7505514cd
datanode_5  | 2022-12-10 13:09:18,248 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
recon_1     | 2022-12-10 12:36:28,927 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 768 
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
datanode_3  | 2022-12-10 13:08:57,817 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:22,761 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5  | 2022-12-10 13:09:18,248 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
recon_1     | 2022-12-10 12:36:28,934 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 26, SequenceNumber Lag from OM 0.
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_3  | 2022-12-10 13:08:57,817 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:22,762 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5  | 2022-12-10 13:09:18,249 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
datanode_5  | 2022-12-10 13:09:18,257 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t8. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t8, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_5  | 2022-12-10 13:09:18,259 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2022-12-10 12:36:28,935 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 26 records
scm_1       | 2022-12-10 12:26:22,811 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2022-12-10 12:26:22,835 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1       | 2022-12-10 12:26:22,837 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t4
datanode_5  | 2022-12-10 13:09:18,259 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2022-12-10 12:36:28,940 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:26:23,100 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6 ELECTION round 0: result REJECTED
datanode_5  | 2022-12-10 13:09:23,272 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5014174316ns, electionTimeout:5012ms
recon_1     | 2022-12-10 12:36:28,940 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:26:23,101 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode_5  | 2022-12-10 13:09:23,273 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
recon_1     | 2022-12-10 12:36:29,084 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:26:23,104 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6
datanode_5  | 2022-12-10 13:09:23,273 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
recon_1     | 2022-12-10 12:36:29,086 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2022-12-10 12:36:29,087 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
datanode_3  | 2022-12-10 13:08:57,833 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection6] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:23,274 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:23,105 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
recon_1     | 2022-12-10 12:36:34,532 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
datanode_3  | 2022-12-10 13:08:57,834 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:23,274 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4
scm_1       | 2022-12-10 12:26:23,107 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
recon_1     | 2022-12-10 12:36:34,535 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
datanode_5  | 2022-12-10 13:09:23,276 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: submit vote requests at term 9 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2022-12-10 13:08:57,840 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:02,958 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5124565239ns, electionTimeout:5118ms
recon_1     | 2022-12-10 12:36:35,060 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
datanode_5  | 2022-12-10 13:09:23,281 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:02,958 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:09:02,958 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
recon_1     | 2022-12-10 12:36:35,070 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 15 milliseconds.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
datanode_5  | 2022-12-10 13:09:23,281 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:02,959 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:23,115 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
recon_1     | 2022-12-10 12:37:29,095 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
datanode_3  | 2022-12-10 13:09:02,959 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7
scm_1       | 2022-12-10 12:26:23,116 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
recon_1     | 2022-12-10 12:37:29,095 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3  | 2022-12-10 13:09:02,966 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:23,117 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
recon_1     | 2022-12-10 12:37:29,096 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 794 
recon_1     | 2022-12-10 12:37:29,105 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 16, SequenceNumber Lag from OM 0.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:32:02,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 89652-target
datanode_3  | 2022-12-10 13:09:02,982 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:02,982 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2022-12-10 12:37:29,105 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 16 records
recon_1     | 2022-12-10 12:37:29,108 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2022-12-10 12:32:32,505 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 89652-target
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection:   Response 0: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t9
datanode_3  | 2022-12-10 13:09:02,986 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3  | 2022-12-10 13:09:02,986 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t5
datanode_3  | 2022-12-10 13:09:02,986 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t5
recon_1     | 2022-12-10 12:37:29,108 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 2022-12-10 12:32:36,625 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:89652-target
om_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
datanode_3  | 2022-12-10 13:09:02,986 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7 ELECTION round 0: result REJECTED
scm_1       | 2022-12-10 12:26:23,184 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm_1       | 2022-12-10 12:26:23,523 [main] INFO reflections.Reflections: Reflections took 260 ms to scan 3 urls, producing 116 keys and 266 values 
recon_1     | 2022-12-10 12:37:29,214 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection:   Response 1: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t9
datanode_3  | 2022-12-10 13:09:02,986 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
scm_1       | 2022-12-10 12:26:23,648 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm_1       | 2022-12-10 12:26:23,652 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
recon_1     | 2022-12-10 12:37:29,215 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4 ELECTION round 0: result REJECTED
datanode_3  | 2022-12-10 13:09:02,987 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7
recon_1     | 2022-12-10 12:37:29,222 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
recon_1     | 2022-12-10 12:38:29,231 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:26:23,660 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
recon_1     | 2022-12-10 12:38:29,232 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
datanode_3  | 2022-12-10 13:09:02,987 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection7] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:26:23,663 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1       | 2022-12-10 12:26:23,833 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 60000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 60000.
datanode_5  | 2022-12-10 13:09:23,298 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4
datanode_3  | 2022-12-10 13:09:02,995 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
datanode_5  | 2022-12-10 13:09:23,299 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection4] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
om_1        | 2022-12-10 12:32:49,008 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:58828-without-scheme for user:hadoop
om_1        | 2022-12-10 12:32:57,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:23,859 [main] INFO node.SCMNodeManager: Entering startup safe mode.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
datanode_5  | 2022-12-10 13:09:23,308 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:03,005 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2022-12-10 12:38:29,233 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 810 
recon_1     | 2022-12-10 12:38:29,248 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 24, SequenceNumber Lag from OM 0.
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_5  | 2022-12-10 13:09:23,309 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:03,097 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, eb6b06af-1f2c-4397-8743-5d103932e2bb, group-18DDCF3CC495, 5, (t:0, i:0))
scm_1       | 2022-12-10 12:26:23,901 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1     | 2022-12-10 12:38:29,248 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 24 records
recon_1     | 2022-12-10 12:38:29,254 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:38:29,254 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_3  | 2022-12-10 13:09:03,098 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: reject ELECTION from eb6b06af-1f2c-4397-8743-5d103932e2bb: already has voted for 213470ee-8924-4d24-82c9-a8e7505514cd at current term 5
scm_1       | 2022-12-10 12:26:23,911 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
recon_1     | 2022-12-10 12:38:29,372 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:38:29,373 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2022-12-10 12:38:29,376 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2022-12-10 13:09:03,099 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: eb6b06af-1f2c-4397-8743-5d103932e2bb<-213470ee-8924-4d24-82c9-a8e7505514cd#0:FAIL-t5. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t5, leader=null, voted=213470ee-8924-4d24-82c9-a8e7505514cd, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:23,932 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1     | 2022-12-10 12:39:29,381 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_5  | 2022-12-10 13:09:28,382 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082871033ns, electionTimeout:5073ms
datanode_5  | 2022-12-10 13:09:28,382 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:24,042 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
recon_1     | 2022-12-10 12:39:29,381 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:39:29,382 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 834 
recon_1     | 2022-12-10 12:39:29,392 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:26:24,044 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1     | 2022-12-10 12:39:29,392 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
datanode_5  | 2022-12-10 13:09:28,382 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
datanode_5  | 2022-12-10 13:09:28,382 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:24,058 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
recon_1     | 2022-12-10 12:39:29,398 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:39:29,458 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:39:29,459 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
datanode_3  | 2022-12-10 13:09:08,079 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092201041ns, electionTimeout:5074ms
scm_1       | 2022-12-10 12:26:24,058 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
datanode_5  | 2022-12-10 13:09:28,382 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:26:24,062 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_5  | 2022-12-10 13:09:28,386 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5 ELECTION round 0: submit vote requests at term 10 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:28,389 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:24,063 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
datanode_3  | 2022-12-10 13:09:08,079 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:09:08,079 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode_3  | 2022-12-10 13:09:08,079 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:26:24,072 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_3  | 2022-12-10 13:09:08,079 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8
datanode_3  | 2022-12-10 13:09:08,089 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8 ELECTION round 0: submit vote requests at term 6 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:28,389 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:26:24,072 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_3  | 2022-12-10 13:09:08,100 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:26:24,129 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:39:29,467 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2022-12-10 13:09:08,101 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:08,118 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8: ELECTION REJECTED received 2 response(s) and 0 exception(s):
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2022-12-10 12:26:24,160 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om_1        | 2022-12-10 12:32:57,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:39:29,469 [pool-27-thread-1] ERROR tasks.ReconTaskControllerImpl: Unexpected error : 
datanode_3  | 2022-12-10 13:09:08,118 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t6
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection:   Response 0: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t10
scm_1       | 2022-12-10 12:26:24,282 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
om_1        | 2022-12-10 12:32:57,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:32:57,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_3  | 2022-12-10 13:09:08,118 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t6
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5 ELECTION round 0: result REJECTED
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
scm_1       | 2022-12-10 12:26:24,343 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
om_1        | 2022-12-10 12:32:57,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:32:57,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
datanode_3  | 2022-12-10 13:09:08,118 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8 ELECTION round 0: result REJECTED
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5
datanode_5  | 2022-12-10 13:09:28,409 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection5] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:24,344 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2022-12-10 12:32:57,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | java.util.concurrent.ExecutionException: java.lang.NullPointerException
scm_1       | 2022-12-10 12:26:24,369 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om_1        | 2022-12-10 12:33:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
datanode_5  | 2022-12-10 13:09:28,422 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:28,422 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:08,119 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
scm_1       | 2022-12-10 12:26:24,377 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_5  | 2022-12-10 13:09:33,437 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5028150968ns, electionTimeout:5015ms
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 2022-12-10 13:09:08,119 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8
scm_1       | 2022-12-10 12:26:24,383 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
recon_1     | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_5  | 2022-12-10 13:09:33,438 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
datanode_3  | 2022-12-10 13:09:08,119 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection8] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:25,465 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1     | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.processTaskResults(ReconTaskControllerImpl.java:247)
datanode_3  | 2022-12-10 13:09:08,124 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:25,496 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:09:08,125 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:25,537 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2022-12-10 12:26:25,587 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2022-12-10 12:26:25,596 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
datanode_3  | 2022-12-10 13:09:08,270 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 213470ee-8924-4d24-82c9-a8e7505514cd: Completed APPEND_ENTRIES, lastRequest: c93c8eed-0198-45d8-87bc-3d7834e7dd79->213470ee-8924-4d24-82c9-a8e7505514cd#31756-t3,previous=(t:3, i:3274),leaderCommit=3274,initializing? true,entries: size=1, first=(t:3, i:3275), METADATAENTRY(c:3274)
scm_1       | 2022-12-10 12:26:25,597 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
datanode_5  | 2022-12-10 13:09:33,438 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 10 for changeToCandidate
datanode_3  | 2022-12-10 13:09:08,272 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 213470ee-8924-4d24-82c9-a8e7505514cd: Completed APPEND_ENTRIES, lastRequest: null
scm_1       | 2022-12-10 12:26:25,651 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2022-12-10 12:26:25,664 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2022-12-10 12:26:25,664 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
datanode_5  | 2022-12-10 13:09:33,439 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-12-10 13:09:08,276 [Command processor thread] INFO server.RaftServer: 213470ee-8924-4d24-82c9-a8e7505514cd: remove  FOLLOWER 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E:t3, leader=c93c8eed-0198-45d8-87bc-3d7834e7dd79, voted=c93c8eed-0198-45d8-87bc-3d7834e7dd79, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLog:OPENED:c3275, conf=0: peers:[c93c8eed-0198-45d8-87bc-3d7834e7dd79|rpc:172.19.0.4:9856|admin:172.19.0.4:9857|client:172.19.0.4:9858|dataStream:|priority:1|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, 85e9a0c6-8631-4fee-9b9c-0f8004d778ef|rpc:172.19.0.9:9856|admin:172.19.0.9:9857|client:172.19.0.9:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
scm_1       | 2022-12-10 12:26:25,778 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
datanode_3  | 2022-12-10 13:09:08,277 [Command processor thread] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: shutdown
scm_1       | 2022-12-10 12:26:25,781 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1       | Container Balancer status:
scm_1       | Key                            Value
datanode_5  | 2022-12-10 13:09:33,439 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | Running                        true
scm_1       | Container Balancer Configuration values:
scm_1       | Key                                                Value
datanode_5  | 2022-12-10 13:09:33,442 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6 ELECTION round 0: submit vote requests at term 11 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:33,443 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:08,278 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AF81ED93FE6E,id=213470ee-8924-4d24-82c9-a8e7505514cd
scm_1       | Threshold                                          10
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
datanode_5  | 2022-12-10 13:09:33,443 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
datanode_3  | 2022-12-10 13:09:08,278 [Command processor thread] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState
scm_1       | Max Datanodes to Involve per Iteration(percent)    20
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.consumeOMEvents(ReconTaskControllerImpl.java:118)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
datanode_3  | 2022-12-10 13:09:08,278 [Command processor thread] INFO impl.StateMachineUpdater: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater: set stopIndex = 3275
scm_1       | Max Size to Move per Iteration                     500GB
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:503)
datanode_5  | 2022-12-10 13:09:33,468 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3  | 2022-12-10 13:09:08,278 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-FollowerState was interrupted
scm_1       | Max Size Entering Target per Iteration             26GB
om_1        | 2022-12-10 12:33:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:258)
datanode_5  | 2022-12-10 13:09:33,468 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection:   Response 0: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t11
datanode_5  | 2022-12-10 13:09:33,468 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection:   Response 1: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t11
datanode_3  | 2022-12-10 13:09:08,279 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Taking a snapshot at:(t:3, i:3275) file /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3275
scm_1       | Max Size Leaving Source per Iteration              26GB
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
datanode_5  | 2022-12-10 13:09:33,471 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6 ELECTION round 0: result REJECTED
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 2022-12-10 13:09:33,472 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 11 for REJECTED
datanode_5  | 2022-12-10 13:09:33,472 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6
datanode_3  | 2022-12-10 13:09:08,625 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-AF81ED93FE6E: Finished taking a snapshot at:(t:3, i:3275) file:/data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e/sm/snapshot.3_3275 took: 346 ms
datanode_3  | 2022-12-10 13:09:08,635 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater: Took a snapshot at index 3275
datanode_3  | 2022-12-10 13:09:08,639 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater] INFO impl.StateMachineUpdater: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3275
datanode_3  | 2022-12-10 13:09:08,642 [Command processor thread] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: closes. applyIndex: 3275
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_3  | 2022-12-10 13:09:08,648 [213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:09:08,648 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E-SegmentedRaftLogWorker close()
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | Caused by: java.lang.NullPointerException
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTaskWithLegacy.processWithLegacy(NSSummaryTaskWithLegacy.java:107)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
datanode_3  | 2022-12-10 13:09:08,656 [Command processor thread] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-AF81ED93FE6E: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/c0524777-5948-4be0-b34b-af81ed93fe6e
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
datanode_5  | 2022-12-10 13:09:33,474 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection6] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:33,476 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:08,657 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e command on datanode 213470ee-8924-4d24-82c9-a8e7505514cd.
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTask.process(NSSummaryTask.java:99)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
datanode_5  | 2022-12-10 13:09:33,476 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:09:38,510 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5035337902ns, electionTimeout:5033ms
datanode_3  | 2022-12-10 13:09:13,161 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041809525ns, electionTimeout:5035ms
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.lambda$consumeOMEvents$0(ReconTaskControllerImpl.java:113)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
datanode_3  | 2022-12-10 13:09:13,161 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 2022-12-10 12:26:25,782 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1       | 2022-12-10 12:26:25,789 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1     | 	... 3 more
scm_1       | 2022-12-10 12:26:25,799 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm_1       | 2022-12-10 12:26:25,808 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/in_use.lock acquired by nodename 6@2beb09acc4d8
scm_1       | 2022-12-10 12:26:25,814 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=de14337a-ef52-472b-bd3f-7050a14dd151} from /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/raft-meta
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:52:15,026 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
recon_1     | 2022-12-10 12:40:29,470 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:26:25,876 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: set configuration 0: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:40:29,470 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:40:29,471 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 859 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
om_1        | 2022-12-10 12:33:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
recon_1     | 2022-12-10 12:40:29,486 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:40:29,486 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
scm_1       | 2022-12-10 12:26:25,885 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1     | 2022-12-10 12:40:29,489 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2022-12-10 13:09:13,161 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode_3  | 2022-12-10 13:09:13,161 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_5  | 2022-12-10 13:09:38,510 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:38,510 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_5  | 2022-12-10 13:09:38,510 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-12-10 13:09:38,511 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
datanode_3  | 2022-12-10 13:09:13,161 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9
datanode_5  | 2022-12-10 13:09:38,514 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7 ELECTION round 0: submit vote requests at term 12 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:40:29,489 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:26:25,912 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2022-12-10 12:26:25,912 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2022-12-10 12:26:25,916 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
datanode_3  | 2022-12-10 13:09:13,170 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9 ELECTION round 0: submit vote requests at term 7 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:38,515 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:38,515 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:26:25,917 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_5  | 2022-12-10 13:09:38,527 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7: ELECTION REJECTED received 1 response(s) and 0 exception(s):
scm_1       | 2022-12-10 12:26:25,923 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
datanode_5  | 2022-12-10 13:09:38,527 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection:   Response 0: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t12
datanode_5  | 2022-12-10 13:09:38,527 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.LeaderElection: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7 ELECTION round 0: result REJECTED
scm_1       | 2022-12-10 12:26:25,937 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
datanode_5  | 2022-12-10 13:09:38,527 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
datanode_5  | 2022-12-10 13:09:38,528 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode_3  | 2022-12-10 13:09:13,177 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2022-12-10 12:40:29,565 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
recon_1     | 2022-12-10 12:40:29,565 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
recon_1     | 2022-12-10 12:40:29,565 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:26:25,937 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5  | 2022-12-10 13:09:38,528 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-LeaderElection7] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:38,528 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:13,178 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2022-12-10 12:41:29,577 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_5  | 2022-12-10 13:09:38,529 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:41:29,577 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:41:29,577 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 884 
scm_1       | 2022-12-10 12:26:25,964 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
recon_1     | 2022-12-10 12:41:29,586 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 21, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:41:29,586 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 21 records
scm_1       | 2022-12-10 12:26:25,965 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1     | 2022-12-10 12:41:29,595 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:41:29,595 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:26:25,966 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1     | 2022-12-10 12:41:29,682 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2022-12-10 12:33:09,267 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 58828-without-scheme
scm_1       | 2022-12-10 12:26:25,967 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9: ELECTION REJECTED received 2 response(s) and 0 exception(s):
recon_1     | 2022-12-10 12:41:29,683 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-12-10 12:41:29,686 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t7
datanode_5  | 2022-12-10 13:09:43,543 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: receive requestVote(ELECTION, eb6b06af-1f2c-4397-8743-5d103932e2bb, group-18DDCF3CC495, 13, (t:0, i:0))
datanode_5  | 2022-12-10 13:09:43,543 [grpc-default-executor-1] INFO impl.VoteContext: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FOLLOWER: accept ELECTION from eb6b06af-1f2c-4397-8743-5d103932e2bb: our priority 0 <= candidate's priority 1
scm_1       | 2022-12-10 12:26:25,971 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm_1       | 2022-12-10 12:26:25,971 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
datanode_5  | 2022-12-10 13:09:43,543 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_5  | 2022-12-10 13:09:43,543 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: shutdown 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:25,972 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2022-12-10 12:26:25,972 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t7
datanode_5  | 2022-12-10 13:09:43,544 [grpc-default-executor-1] INFO impl.RoleInfo: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: start 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState
datanode_5  | 2022-12-10 13:09:43,544 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9 ELECTION round 0: result REJECTED
recon_1     | 2022-12-10 12:41:34,536 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 0 milliseconds to process 0 existing database records.
recon_1     | 2022-12-10 12:41:34,541 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 2022-12-10 12:26:25,974 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2022-12-10 12:41:35,095 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-12-10 12:41:35,110 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 26 milliseconds.
om_1        | 2022-12-10 12:34:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
recon_1     | 2022-12-10 12:42:29,694 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:42:29,694 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
datanode_5  | 2022-12-10 13:09:43,559 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_5  | 2022-12-10 13:09:43,561 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_5  | 2022-12-10 13:09:43,562 [grpc-default-executor-1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495 replies to ELECTION vote request: eb6b06af-1f2c-4397-8743-5d103932e2bb<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t13. Peer's state: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495:t13, leader=null, voted=eb6b06af-1f2c-4397-8743-5d103932e2bb, raftlog=Memoized:44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:42:29,694 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 905 
scm_1       | 2022-12-10 12:26:25,984 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode_5  | 2022-12-10 13:09:43,688 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18DDCF3CC495 with new leaderId: eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_5  | 2022-12-10 13:09:43,688 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65-server-thread1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: change Leader from null to eb6b06af-1f2c-4397-8743-5d103932e2bb at term 13 for appendEntries, leader elected after 66250ms
recon_1     | 2022-12-10 12:42:29,723 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_5  | 2022-12-10 13:09:43,691 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65-server-thread1] INFO server.RaftServer$Division: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495: set configuration 0: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_5  | 2022-12-10 13:09:43,692 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65-server-thread1] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9
datanode_3  | 2022-12-10 13:09:13,194 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection9] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
recon_1     | 2022-12-10 12:42:29,723 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
datanode_5  | 2022-12-10 13:09:43,695 [44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65@group-18DDCF3CC495-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/current/log_inprogress_0
datanode_3  | 2022-12-10 13:09:13,222 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2022-12-10 13:09:13,226 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2022-12-10 13:09:18,240 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045910980ns, electionTimeout:5014ms
recon_1     | 2022-12-10 12:42:29,725 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
recon_1     | 2022-12-10 12:42:29,725 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
datanode_3  | 2022-12-10 13:09:18,240 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
datanode_3  | 2022-12-10 13:09:18,240 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
recon_1     | 2022-12-10 12:42:29,799 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
datanode_3  | 2022-12-10 13:09:18,241 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2022-12-10 12:26:25,985 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2022-12-10 12:42:29,799 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
datanode_3  | 2022-12-10 13:09:18,241 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10
scm_1       | 2022-12-10 12:26:26,001 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
recon_1     | 2022-12-10 12:42:29,803 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
datanode_3  | 2022-12-10 13:09:18,245 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10 ELECTION round 0: submit vote requests at term 8 for -1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2022-12-10 12:26:26,002 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
recon_1     | 2022-12-10 12:43:29,807 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
datanode_3  | 2022-12-10 13:09:18,246 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:26,003 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
recon_1     | 2022-12-10 12:43:29,808 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
datanode_3  | 2022-12-10 13:09:18,246 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2022-12-10 12:26:26,036 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: set configuration 0: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:43:29,808 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 924 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
datanode_3  | 2022-12-10 13:09:18,262 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10: ELECTION REJECTED received 2 response(s) and 0 exception(s):
scm_1       | 2022-12-10 12:26:26,037 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/log_inprogress_0
recon_1     | 2022-12-10 12:43:29,820 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
datanode_3  | 2022-12-10 13:09:18,262 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.LeaderElection:   Response 0: 213470ee-8924-4d24-82c9-a8e7505514cd<-44877e3e-f8e0-4fab-9c03-bb94f29d2e65#0:OK-t8
scm_1       | 2022-12-10 12:26:26,044 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
recon_1     | 2022-12-10 12:43:29,820 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
datanode_3  | 2022-12-10 13:09:18,262 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.LeaderElection:   Response 1: 213470ee-8924-4d24-82c9-a8e7505514cd<-eb6b06af-1f2c-4397-8743-5d103932e2bb#0:FAIL-t8
scm_1       | 2022-12-10 12:26:26,045 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
recon_1     | 2022-12-10 12:43:29,832 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
datanode_3  | 2022-12-10 13:09:18,263 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.LeaderElection: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10 ELECTION round 0: result REJECTED
scm_1       | 2022-12-10 12:26:26,103 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: start as a follower, conf=0: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:43:29,832 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
datanode_3  | 2022-12-10 13:09:18,267 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from CANDIDATE to FOLLOWER at term 8 for REJECTED
scm_1       | 2022-12-10 12:26:26,104 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from      null to FOLLOWER at term 1 for startAsFollower
recon_1     | 2022-12-10 12:43:29,934 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2022-12-10 12:34:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
datanode_3  | 2022-12-10 13:09:18,267 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10
scm_1       | 2022-12-10 12:26:26,106 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState
recon_1     | 2022-12-10 12:43:29,936 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_3  | 2022-12-10 13:09:18,267 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-LeaderElection10] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:26,109 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
scm_1       | 2022-12-10 12:26:26,110 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:26:26,111 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CEE2A0F43436,id=de14337a-ef52-472b-bd3f-7050a14dd151
recon_1     | 2022-12-10 12:43:29,936 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:44:29,944 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2022-12-10 13:09:18,278 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:44:29,944 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:26:26,116 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-12-10 13:09:18,279 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:44:29,944 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 935 
scm_1       | 2022-12-10 12:26:26,116 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
datanode_3  | 2022-12-10 13:09:23,280 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 9, (t:0, i:0))
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:44:29,957 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 27, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:26:26,117 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
datanode_3  | 2022-12-10 13:09:23,280 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 0 <= candidate's priority 0
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 12:44:29,962 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 27 records
scm_1       | 2022-12-10 12:26:26,118 [de14337a-ef52-472b-bd3f-7050a14dd151-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-12-10 13:09:23,281 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 9 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:26:26,120 [Listener at 0.0.0.0/9860] INFO server.RaftServer: de14337a-ef52-472b-bd3f-7050a14dd151: start RPC server
datanode_3  | 2022-12-10 13:09:23,281 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:26:26,175 [Listener at 0.0.0.0/9860] INFO server.GrpcService: de14337a-ef52-472b-bd3f-7050a14dd151: GrpcService started, listening on 9894
datanode_3  | 2022-12-10 13:09:23,281 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:44:29,991 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:26:26,189 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-de14337a-ef52-472b-bd3f-7050a14dd151: Started
datanode_3  | 2022-12-10 13:09:23,281 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:44:29,992 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:44:30,073 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | 2022-12-10 13:09:23,283 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 2022-12-10 12:44:30,075 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
scm_1       | 2022-12-10 12:26:26,192 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
datanode_3  | 2022-12-10 13:09:23,284 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:44:30,087 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:26:26,193 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
datanode_3  | 2022-12-10 13:09:23,287 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t9. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t9, leader=null, voted=44877e3e-f8e0-4fab-9c03-bb94f29d2e65, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 2022-12-10 12:34:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:45:30,092 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:26:26,340 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2022-12-10 13:09:28,390 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 10, (t:0, i:0))
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
recon_1     | 2022-12-10 12:45:30,093 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:26:26,359 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2022-12-10 13:09:28,390 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 0 <= candidate's priority 0
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-12-10 12:45:30,093 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 962 
scm_1       | 2022-12-10 12:26:26,359 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_3  | 2022-12-10 13:09:28,390 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:45:30,101 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 23, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:26:26,878 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_3  | 2022-12-10 13:09:28,390 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:45:30,104 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 23 records
scm_1       | 2022-12-10 12:26:26,880 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2022-12-10 13:09:28,390 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:45:30,106 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:26:26,883 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
datanode_3  | 2022-12-10 13:09:28,390 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	... 17 more
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 12:45:30,187 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:26:27,031 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_3  | 2022-12-10 13:09:28,400 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t10. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t10, leader=null, voted=44877e3e-f8e0-4fab-9c03-bb94f29d2e65, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 12:45:30,187 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
scm_1       | 2022-12-10 12:26:27,035 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_3  | 2022-12-10 13:09:28,409 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:45:30,192 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:26:27,043 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2022-12-10 13:09:28,409 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:45:30,192 [pool-27-thread-1] ERROR tasks.ReconTaskControllerImpl: Unexpected error : 
scm_1       | 2022-12-10 12:26:27,046 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3  | 2022-12-10 13:09:33,445 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 11, (t:0, i:0))
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | java.util.concurrent.ExecutionException: java.lang.NullPointerException
scm_1       | 2022-12-10 12:26:27,210 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@57eb2555] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2022-12-10 13:09:33,445 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 0 <= candidate's priority 0
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
scm_1       | 2022-12-10 12:26:27,250 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_3  | 2022-12-10 13:09:33,445 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:26:27,252 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2022-12-10 13:09:33,445 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.processTaskResults(ReconTaskControllerImpl.java:247)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:26:27,347 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @11256ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2022-12-10 13:09:33,445 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.consumeOMEvents(ReconTaskControllerImpl.java:118)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:35:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
datanode_3  | 2022-12-10 13:09:33,446 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
scm_1       | 2022-12-10 12:26:27,662 [Listener at 0.0.0.0/9860] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
scm_1       | 2022-12-10 12:26:27,674 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:503)
datanode_3  | 2022-12-10 13:09:33,451 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t11. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t11, leader=null, voted=44877e3e-f8e0-4fab-9c03-bb94f29d2e65, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:258)
datanode_3  | 2022-12-10 13:09:33,453 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:26:27,693 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 2022-12-10 13:09:33,453 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:26:27,695 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
recon_1     | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
datanode_3  | 2022-12-10 13:09:38,522 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, 44877e3e-f8e0-4fab-9c03-bb94f29d2e65, group-18DDCF3CC495, 12, (t:0, i:0))
scm_1       | 2022-12-10 12:26:27,695 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
datanode_3  | 2022-12-10 13:09:38,522 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: accept ELECTION from 44877e3e-f8e0-4fab-9c03-bb94f29d2e65: our priority 0 <= candidate's priority 0
scm_1       | 2022-12-10 12:26:27,695 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
datanode_3  | 2022-12-10 13:09:38,522 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 12 for candidate:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
scm_1       | 2022-12-10 12:26:27,815 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
datanode_3  | 2022-12-10 13:09:38,522 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:27,817 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
scm_1       | 2022-12-10 12:26:27,849 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
datanode_3  | 2022-12-10 13:09:38,522 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
scm_1       | 2022-12-10 12:26:27,849 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
datanode_3  | 2022-12-10 13:09:38,523 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState was interrupted
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:27,852 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
datanode_3  | 2022-12-10 13:09:38,524 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | Caused by: java.lang.NullPointerException
scm_1       | 2022-12-10 12:26:27,863 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@11703cc8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
datanode_3  | 2022-12-10 13:09:38,525 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t12. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t12, leader=null, voted=44877e3e-f8e0-4fab-9c03-bb94f29d2e65, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTaskWithLegacy.processWithLegacy(NSSummaryTaskWithLegacy.java:107)
scm_1       | 2022-12-10 12:26:27,864 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6ade4ac6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
datanode_3  | 2022-12-10 13:09:38,526 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTask.process(NSSummaryTask.java:99)
scm_1       | 2022-12-10 12:26:27,970 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7bc46dde{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-986342232057660229/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:35:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.lambda$consumeOMEvents$0(ReconTaskControllerImpl.java:113)
scm_1       | 2022-12-10 12:26:27,980 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@17e2ad13{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
datanode_3  | 2022-12-10 13:09:43,551 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: receive requestVote(ELECTION, eb6b06af-1f2c-4397-8743-5d103932e2bb, group-18DDCF3CC495, 13, (t:0, i:0))
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 2022-12-10 12:26:27,980 [Listener at 0.0.0.0/9860] INFO server.Server: Started @11888ms
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
datanode_3  | 2022-12-10 13:09:43,552 [grpc-default-executor-2] INFO impl.VoteContext: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FOLLOWER: accept ELECTION from eb6b06af-1f2c-4397-8743-5d103932e2bb: our priority 0 <= candidate's priority 1
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
recon_1     | 	... 3 more
scm_1       | 2022-12-10 12:26:27,984 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2022-12-10 13:09:43,552 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:eb6b06af-1f2c-4397-8743-5d103932e2bb
s3g_1       | 	... 51 more
recon_1     | 2022-12-10 12:46:12,270 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #2 got from ozone_datanode_2.ozone_default.
scm_1       | 2022-12-10 12:26:27,984 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:09:43,552 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: shutdown 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | 2022-12-10 12:52:15,566 [qtp1858015030-21] WARN server.HttpChannel: /erasure/ozone-test-3785280973/putobject/custom-metadata/key2
recon_1     | 2022-12-10 12:46:12,281 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
scm_1       | 2022-12-10 12:26:27,986 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:09:43,552 [grpc-default-executor-2] INFO impl.RoleInfo: 213470ee-8924-4d24-82c9-a8e7505514cd: start 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:26:31,151 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.FollowerState: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045524783ns, electionTimeout:5040ms
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-12-10 13:09:43,553 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO impl.FollowerState: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState was interrupted
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:26:31,152 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState
datanode_3  | 2022-12-10 13:09:43,559 [grpc-default-executor-2] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495 replies to ELECTION vote request: eb6b06af-1f2c-4397-8743-5d103932e2bb<-213470ee-8924-4d24-82c9-a8e7505514cd#0:OK-t13. Peer's state: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495:t13, leader=null, voted=eb6b06af-1f2c-4397-8743-5d103932e2bb, raftlog=Memoized:213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1     | 2022-12-10 12:46:30,198 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:26:31,153 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_3  | 2022-12-10 13:09:43,560 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
recon_1     | 2022-12-10 12:46:30,198 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:26:31,156 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
datanode_3  | 2022-12-10 13:09:43,560 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
recon_1     | 2022-12-10 12:46:30,198 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 985 
scm_1       | 2022-12-10 12:26:31,156 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-FollowerState] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
datanode_3  | 2022-12-10 13:09:43,642 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18DDCF3CC495 with new leaderId: eb6b06af-1f2c-4397-8743-5d103932e2bb
datanode_3  | 2022-12-10 13:09:43,643 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: change Leader from null to eb6b06af-1f2c-4397-8743-5d103932e2bb at term 13 for appendEntries, leader elected after 66380ms
datanode_3  | 2022-12-10 13:09:43,699 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO server.RaftServer$Division: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495: set configuration 0: peers:[44877e3e-f8e0-4fab-9c03-bb94f29d2e65|rpc:172.19.0.8:9856|admin:172.19.0.8:9857|client:172.19.0.8:9858|dataStream:|priority:0|startupRole:FOLLOWER, 213470ee-8924-4d24-82c9-a8e7505514cd|rpc:172.19.0.5:9856|admin:172.19.0.5:9857|client:172.19.0.5:9858|dataStream:|priority:0|startupRole:FOLLOWER, eb6b06af-1f2c-4397-8743-5d103932e2bb|rpc:172.19.0.10:9856|admin:172.19.0.10:9857|client:172.19.0.10:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:46:30,216 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:26:31,172 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.LeaderElection: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
recon_1     | 2022-12-10 12:46:30,216 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
recon_1     | 2022-12-10 12:46:30,221 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:46:30,222 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:26:31,173 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.LeaderElection: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1 ELECTION round 0: result PASSED (term=2)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
datanode_3  | 2022-12-10 13:09:43,699 [213470ee-8924-4d24-82c9-a8e7505514cd-server-thread1] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-12-10 13:09:43,702 [213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 213470ee-8924-4d24-82c9-a8e7505514cd@group-18DDCF3CC495-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/283d1058-72b4-45d6-919c-18ddcf3cc495/current/log_inprogress_0
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:46:30,274 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:35:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 2022-12-10 12:26:31,173 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: shutdown de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1
recon_1     | 2022-12-10 12:46:30,277 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-12-10 12:46:30,285 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:26:31,174 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm_1       | 2022-12-10 12:26:31,174 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
recon_1     | 2022-12-10 12:46:34,542 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-12-10 12:46:34,544 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
scm_1       | 2022-12-10 12:26:31,174 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm_1       | 2022-12-10 12:26:31,179 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: change Leader from null to de14337a-ef52-472b-bd3f-7050a14dd151 at term 2 for becomeLeader, leader elected after 8362ms
scm_1       | 2022-12-10 12:26:31,185 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:26:31,190 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2022-12-10 12:26:31,191 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2022-12-10 12:26:31,196 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2022-12-10 12:26:31,196 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 2022-12-10 12:46:35,125 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:26:31,196 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2022-12-10 12:26:31,204 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2022-12-10 12:26:31,211 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
recon_1     | 2022-12-10 12:46:35,128 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 13 milliseconds.
recon_1     | 2022-12-10 12:47:30,295 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:26:31,222 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO impl.RoleInfo: de14337a-ef52-472b-bd3f-7050a14dd151: start de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderStateImpl
recon_1     | 2022-12-10 12:47:30,295 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:31,231 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
recon_1     | 2022-12-10 12:47:30,295 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1010 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:26:31,237 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/log_inprogress_0 to /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/log_0-0
recon_1     | 2022-12-10 12:47:30,304 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12, SequenceNumber diff: 34, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
scm_1       | 2022-12-10 12:26:31,248 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-LeaderElection1] INFO server.RaftServer$Division: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436: set configuration 1: peers:[de14337a-ef52-472b-bd3f-7050a14dd151|rpc:2beb09acc4d8:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2022-12-10 12:47:30,304 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 34 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:26:31,265 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/200db308-9a00-4c02-aa1c-cee2a0f43436/current/log_inprogress_1
recon_1     | 2022-12-10 12:47:30,307 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:26:31,271 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm_1       | 2022-12-10 12:26:31,271 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 2022-12-10 12:26:31,280 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2022-12-10 12:47:30,307 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
recon_1     | 2022-12-10 12:47:30,391 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1     | 2022-12-10 12:47:30,393 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:26:31,281 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
recon_1     | 2022-12-10 12:47:30,395 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm_1       | 2022-12-10 12:26:31,282 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
recon_1     | 2022-12-10 12:48:30,400 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:26:31,282 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
recon_1     | 2022-12-10 12:48:30,401 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:26:31,290 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2022-12-10 12:48:30,401 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1044 
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:26:31,290 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
recon_1     | 2022-12-10 12:48:30,415 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:26:31,513 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.19.0.10:33758: output error
recon_1     | 2022-12-10 12:48:30,415 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:26:31,514 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
recon_1     | 2022-12-10 12:48:30,420 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | java.nio.channels.ClosedChannelException
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:30,421 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:30,486 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:30,486 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 2022-12-10 12:35:00,041 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:30,488 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,317 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_4.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,335 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,340 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_3.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,340 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,344 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,344 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,651 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_1.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,657 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,657 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 2022-12-10 12:35:00,042 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2022-12-10 12:48:44,845 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_2.ozone_default.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:48:44,849 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
recon_1     | 2022-12-10 12:48:44,851 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1     | 2022-12-10 12:48:45,528 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_5.ozone_default.
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:31,528 [IPC Server handler 5 on default port 9861] WARN ipc.Server: IPC Server handler 5 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.19.0.8:43828: output error
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:31,530 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861 caught an exception
recon_1     | 2022-12-10 12:48:45,531 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | java.nio.channels.ClosedChannelException
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 2022-12-10 12:35:00,043 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 2022-12-10 12:48:45,531 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
s3g_1       | 	... 17 more
om_1        | 2022-12-10 12:35:00,044 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 2022-12-10 12:48:46,514 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_2.ozone_default.
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 2022-12-10 12:35:00,044 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
recon_1     | 2022-12-10 12:48:46,526 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 2022-12-10 12:35:00,044 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
recon_1     | 2022-12-10 12:48:46,532 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 4 not found!
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
recon_1     | 2022-12-10 12:48:46,573 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_3.ozone_default.
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 2022-12-10 12:35:00,045 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
recon_1     | 2022-12-10 12:48:46,579 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2022-12-10 12:35:00,045 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:35:00,045 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
om_1        | 2022-12-10 12:35:00,045 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2022-12-10 12:35:45,682 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:58828-without-scheme for user:hadoop
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
om_1        | 2022-12-10 12:35:57,947 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 58828-without-scheme
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
recon_1     | 2022-12-10 12:48:46,583 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 4 not found!
om_1        | 2022-12-10 12:36:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
recon_1     | 2022-12-10 12:48:46,595 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2022-12-10 12:48:46,598 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2022-12-10 12:48:46,598 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_1.ozone_default.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2022-12-10 12:48:46,611 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1     | 2022-12-10 12:48:46,613 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 4 not found!
recon_1     | 2022-12-10 12:48:46,663 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_5.ozone_default.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 2022-12-10 12:48:46,668 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2022-12-10 12:48:46,670 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 4 not found!
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 12:26:31,555 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.19.0.5:58536: output error
recon_1     | 2022-12-10 12:48:46,689 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_4.ozone_default.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 12:26:31,556 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
recon_1     | 2022-12-10 12:48:46,703 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | java.nio.channels.ClosedChannelException
recon_1     | 2022-12-10 12:48:46,703 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 4 not found!
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 2022-12-10 12:48:49,618 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_2.ozone_default.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:48:49,623 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
recon_1     | 2022-12-10 12:48:49,623 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 5 not found!
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:36:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 12:48:49,634 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_3.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 12:48:49,637 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:48:49,638 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 5 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:48:49,690 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_5.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
s3g_1       | 	... 51 more
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:48:49,694 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
s3g_1       | 2022-12-10 12:52:15,566 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:48:49,694 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 5 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:48:49,798 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_1.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:48:49,801 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 2022-12-10 12:36:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:48:49,801 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 5 not found!
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
recon_1     | 2022-12-10 12:48:49,806 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_4.ozone_default.
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-12-10 12:48:49,808 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:48:49,809 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 5 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:48:57,567 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_3.ozone_default.
scm_1       | 2022-12-10 12:26:31,572 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.19.0.9:45070: output error
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:48:57,571 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 2022-12-10 12:26:31,581 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 12:48:57,577 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 6 not found!
scm_1       | java.nio.channels.ClosedChannelException
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 12:48:57,614 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_5.ozone_default.
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:48:57,619 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:48:57,619 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 6 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:48:57,622 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_2.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:48:57,626 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:48:57,628 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 6 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 2022-12-10 12:48:57,689 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_4.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:48:57,693 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 2022-12-10 12:36:21,131 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-with-host for user:hadoop
recon_1     | 2022-12-10 12:48:57,693 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 6 not found!
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:36:41,379 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 99047-with-host
recon_1     | 2022-12-10 12:48:57,699 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_1.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 2022-12-10 12:37:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:48:57,704 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
recon_1     | 2022-12-10 12:48:57,704 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 6 not found!
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-12-10 12:48:57,830 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-12-10 12:48:57,836 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
recon_1     | 2022-12-10 12:48:57,836 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:48:57,841 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-12-10 12:48:57,843 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_4.ozone_default.
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2022-12-10 12:26:31,602 [IPC Server handler 6 on default port 9861] WARN ipc.Server: IPC Server handler 6 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.19.0.4:42698: output error
scm_1       | 2022-12-10 12:26:31,611 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861 caught an exception
recon_1     | 2022-12-10 12:48:57,847 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm_1       | java.nio.channels.ClosedChannelException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 2022-12-10 12:48:57,847 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-12-10 12:48:57,851 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:48:57,853 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-12-10 12:48:57,900 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_3.ozone_default.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:37:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:48:57,905 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
recon_1     | 2022-12-10 12:48:57,906 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:48:57,910 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-12-10 12:48:57,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:48:57,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-12-10 12:49:12,916 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:26:33,861 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 12:26:33,863 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c93c8eed-0198-45d8-87bc-3d7834e7dd79
scm_1       | 2022-12-10 12:26:33,912 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
recon_1     | 2022-12-10 12:49:12,916 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
scm_1       | 2022-12-10 12:26:33,920 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/213470ee-8924-4d24-82c9-a8e7505514cd
scm_1       | 2022-12-10 12:26:33,881 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 12:26:33,940 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:49:12,917 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
recon_1     | 2022-12-10 12:49:12,917 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 2022-12-10 12:26:34,019 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 2022-12-10 12:49:12,917 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
scm_1       | 2022-12-10 12:26:34,063 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:34,049 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
recon_1     | 2022-12-10 12:49:12,918 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:26:34,069 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-12-10 12:26:34,093 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om_1        | 2022-12-10 12:37:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:49:12,919 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:12,919 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:34,093 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
scm_1       | 2022-12-10 12:26:34,095 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 to datanode:85e9a0c6-8631-4fee-9b9c-0f8004d778ef
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:49:12,919 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:12,920 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:34,097 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
om_1        | 2022-12-10 12:37:17,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:34,097 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:49:30,494 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:49:30,495 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:49:30,495 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1069 
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:34,332 [IPC Server handler 21 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/44877e3e-f8e0-4fab-9c03-bb94f29d2e65
scm_1       | 2022-12-10 12:26:34,338 [IPC Server handler 21 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 12:26:34,352 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
recon_1     | 2022-12-10 12:49:30,564 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 63, SequenceNumber diff: 174, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:49:30,564 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 174 records
scm_1       | 2022-12-10 12:26:34,360 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
scm_1       | 2022-12-10 12:26:34,419 [IPC Server handler 21 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/eb6b06af-1f2c-4397-8743-5d103932e2bb
scm_1       | 2022-12-10 12:26:34,422 [IPC Server handler 21 on default port 9861] INFO node.SCMNodeManager: Registered Data node : eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 12:49:30,591 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:26:34,427 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-12-10 12:26:34,428 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
scm_1       | 2022-12-10 12:26:34,428 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
recon_1     | 2022-12-10 12:49:30,592 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:49:30,669 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:26:34,432 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2022-12-10 12:26:34,432 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:49:30,700 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 12 OM DB update event(s).
recon_1     | 2022-12-10 12:49:30,722 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:34,434 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:35,492 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm_1       | 2022-12-10 12:26:35,530 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:49:32,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | 2022-12-10 12:26:35,583 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:35,752 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]].
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:26:35,766 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-12-10 12:26:35,909 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e to datanode:85e9a0c6-8631-4fee-9b9c-0f8004d778ef
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:35,917 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e to datanode:213470ee-8924-4d24-82c9-a8e7505514cd
scm_1       | 2022-12-10 12:26:35,917 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e to datanode:c93c8eed-0198-45d8-87bc-3d7834e7dd79
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 12:26:35,947 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]].
scm_1       | 2022-12-10 12:26:35,947 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:26:35,950 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d792bf06-25f5-4ba9-821b-977d25aa3d3c to datanode:eb6b06af-1f2c-4397-8743-5d103932e2bb
scm_1       | 2022-12-10 12:26:35,965 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d792bf06-25f5-4ba9-821b-977d25aa3d3c, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.950Z[UTC]].
scm_1       | 2022-12-10 12:26:35,965 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:26:35,966 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:26:35,976 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d2f8c45a-a0b2-410a-969f-1150c0739b5c to datanode:c93c8eed-0198-45d8-87bc-3d7834e7dd79
scm_1       | 2022-12-10 12:26:36,000 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d2f8c45a-a0b2-410a-969f-1150c0739b5c, Nodes: c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:35.976Z[UTC]].
scm_1       | 2022-12-10 12:26:36,000 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2022-12-10 12:49:32,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
recon_1     | 2022-12-10 12:49:32,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 2022-12-10 12:26:36,003 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3c7dd0af-68a7-49be-9b83-c785c98ce76d to datanode:213470ee-8924-4d24-82c9-a8e7505514cd
scm_1       | 2022-12-10 12:26:36,049 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 3c7dd0af-68a7-49be-9b83-c785c98ce76d, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:36.003Z[UTC]].
scm_1       | 2022-12-10 12:26:36,049 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2022-12-10 12:49:32,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
recon_1     | 2022-12-10 12:49:32,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
scm_1       | 2022-12-10 12:26:36,053 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37 to datanode:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:26:36,059 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:26:36.053Z[UTC]].
scm_1       | 2022-12-10 12:26:36,060 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-12-10 12:26:36,062 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:26:36,221 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
recon_1     | 2022-12-10 12:49:32,913 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:36,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:37,894 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:37,897 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6585fdfb-0dfe-4a3b-af4f-28c00cfc9a37, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:44877e3e-f8e0-4fab-9c03-bb94f29d2e65, CreationTimestamp2022-12-10T12:26:36.053Z[UTC]] moved to OPEN state
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1     | 2022-12-10 12:49:32,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:49:32,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:32,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:37:17,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:38:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
recon_1     | 2022-12-10 12:49:32,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:37,827 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:26:37,916 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:49:37,827 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
recon_1     | 2022-12-10 12:49:37,828 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:26:37,925 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-12-10 12:26:38,078 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:38,086 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d792bf06-25f5-4ba9-821b-977d25aa3d3c, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:eb6b06af-1f2c-4397-8743-5d103932e2bb, CreationTimestamp2022-12-10T12:26:35.950Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:26:38,092 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-12-10 12:26:38,098 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-12-10 12:26:40,365 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:49:37,828 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
recon_1     | 2022-12-10 12:49:37,828 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
scm_1       | 2022-12-10 12:26:40,460 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:40,540 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 12:26:42,499 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:42,774 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:42,790 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:42,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:49:37,828 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:37,828 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:42,865 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] moved to OPEN state
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:42,927 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-12-10 12:26:42,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 12:26:42,967 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:43,339 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:38:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
recon_1     | 2022-12-10 12:49:37,835 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:37,835 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:26:43,344 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2022-12-10 12:49:37,835 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:26:43,359 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2022-12-10 12:49:57,856 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 12:26:43,366 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:49:57,856 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:49:57,856 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
recon_1     | 2022-12-10 12:49:57,857 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:26:43,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm_1       | 2022-12-10 12:26:43,765 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-12-10 12:26:47,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:47,642 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:49:57,857 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
recon_1     | 2022-12-10 12:49:57,858 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:47,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:26:47,903 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d2f8c45a-a0b2-410a-969f-1150c0739b5c, Nodes: c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.976Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:26:47,913 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-12-10 12:26:47,919 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2022-12-10 12:49:57,858 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 2022-12-10 12:38:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:26:48,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:48,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:48,538 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:48,547 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 12:26:48,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 2022-12-10 12:26:49,244 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:49:57,858 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:49:57,858 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:49:57,858 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:27,828 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:52:16,272 [qtp1858015030-21] WARN server.HttpChannel: /erasure/ozone-test-3785280973/putobject/custom-metadata/key2
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:50:27,828 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:26:49,246 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 3c7dd0af-68a7-49be-9b83-c785c98ce76d, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:213470ee-8924-4d24-82c9-a8e7505514cd, CreationTimestamp2022-12-10T12:26:36.003Z[UTC]] moved to OPEN state
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:39:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:26:49,268 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:26:49,276 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-12-10 12:26:52,899 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:53,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
scm_1       | 2022-12-10 12:26:53,473 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
scm_1       | 2022-12-10 12:26:53,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:53,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:26:53,927 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-12-10 12:26:54,212 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:54,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:54,935 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:26:58,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:58,465 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:58,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:26:58,790 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:26:58,790 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] moved to OPEN state
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
scm_1       | 2022-12-10 12:26:58,800 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:26:58,801 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:58,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:26:58,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:39:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:50:27,829 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:27,830 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:26:58,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2022-12-10 12:26:58,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1       | 2022-12-10 12:26:58,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1       | 2022-12-10 12:26:58,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1       | 2022-12-10 12:26:58,810 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1       | 2022-12-10 12:26:58,830 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1       | 2022-12-10 12:26:59,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 12:50:27,830 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:27,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
scm_1       | 2022-12-10 12:27:03,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 12:50:27,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
recon_1     | 2022-12-10 12:50:27,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
scm_1       | 2022-12-10 12:27:03,471 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:03,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:50:27,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
recon_1     | 2022-12-10 12:50:27,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:27:03,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:50:27,913 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:27,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:27:04,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:27:06,077 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
recon_1     | 2022-12-10 12:50:27,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:27,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 2022-12-10 12:39:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:27:08,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:08,467 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:08,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:27:08,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:09,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:50:27,914 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:27:13,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:50:30,726 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:50:30,727 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 12:50:30,727 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1243 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
recon_1     | 2022-12-10 12:50:30,908 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 179, SequenceNumber diff: 504, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:27:13,481 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 12:50:30,911 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 504 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:50:30,922 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:50:30,923 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:50:31,112 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:50:31,118 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2022-12-10 12:50:31,138 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:27:13,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:13,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
om_1        | 2022-12-10 12:39:17,232 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-with-host for user:hadoop
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:50:47,830 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:27:14,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:18,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:50:47,831 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm_1       | 2022-12-10 12:27:18,474 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:18,742 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:50:47,831 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:50:47,831 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:27:18,770 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:07,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 not found. Cannot add container #3
recon_1     | 2022-12-10 12:51:07,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 not found. Cannot add container #4
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:19,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:07,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e not found. Cannot add container #5
recon_1     | 2022-12-10 12:51:07,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 not found. Cannot add container #6
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:23,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:23,475 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:23,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:23,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 2022-12-10 12:39:30,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:24,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:39:30,179 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:28,277 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:39:30,179 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:28,474 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:28,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
recon_1     | 2022-12-10 12:51:07,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 not found. Cannot add container #7
recon_1     | 2022-12-10 12:51:07,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:51:07,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 4 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 2022-12-10 12:39:30,179 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:07,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 5 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-12-10 12:51:07,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 6 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
recon_1     | 2022-12-10 12:51:07,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:39:30,179 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:39:30,180 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 99047-with-host
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 2022-12-10 12:39:30,180 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:39:30,180 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:39:30,180 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1     | 2022-12-10 12:51:31,161 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:51:31,161 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:27:28,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:31,161 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1747 
recon_1     | 2022-12-10 12:51:31,196 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 74, SequenceNumber diff: 219, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:51:31,196 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 219 records
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:31,199 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:27:29,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:33,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:31,200 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:27:33,474 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:33,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:31,237 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:27:33,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:34,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:31,244 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 17 OM DB update event(s).
scm_1       | 2022-12-10 12:27:36,079 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:27:38,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:31,258 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:51:34,545 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:27:38,470 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:38,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:38,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
recon_1     | 2022-12-10 12:51:34,551 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
scm_1       | 2022-12-10 12:27:39,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:43,277 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:43,467 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:43,742 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:35,149 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-12-10 12:51:35,151 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85 from SCM.
scm_1       | 2022-12-10 12:27:43,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:35,155 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]].
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 12:51:35,156 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e from SCM.
recon_1     | 2022-12-10 12:51:35,163 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]].
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 2022-12-10 12:51:35,167 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7 from SCM.
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:27:44,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:48,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:48,468 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:48,742 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:48,769 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:49,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:53,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:35,168 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]].
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:27:53,474 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1     | 2022-12-10 12:51:35,173 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14 from SCM.
scm_1       | 2022-12-10 12:27:53,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:53,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm_1       | 2022-12-10 12:27:54,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:35,176 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]].
om_1        | 2022-12-10 12:39:30,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1     | 2022-12-10 12:51:35,181 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545 from SCM.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 2022-12-10 12:27:58,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:39:54,209 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-with-errors for user:hadoop
recon_1     | 2022-12-10 12:51:35,189 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]].
recon_1     | 2022-12-10 12:51:35,191 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 59 milliseconds.
scm_1       | 2022-12-10 12:27:58,477 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:40:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 12:51:47,920 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1     | 2022-12-10 12:51:47,921 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
scm_1       | 2022-12-10 12:27:58,719 [IPC Server handler 35 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
recon_1     | 2022-12-10 12:51:47,922 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #5 to Recon.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-12-10 12:51:47,923 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #6 to Recon.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:27:58,741 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:51:47,926 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #7 to Recon.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1     | 2022-12-10 12:52:31,291 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:52:31,291 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 12:27:58,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:27:58,791 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
recon_1     | 2022-12-10 12:52:31,291 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1966 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:27:58,800 [IPC Server handler 35 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:52:16,273 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 12:52:31,312 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 22, SequenceNumber diff: 72, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:27:59,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:02,483 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:28:02,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:52:31,313 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 72 records
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:52:31,317 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:52:31,317 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:28:03,313 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:28:03,432 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:03,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
recon_1     | 2022-12-10 12:52:31,390 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:28:06,081 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:28:07,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:52:31,392 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 11 OM DB update event(s).
recon_1     | 2022-12-10 12:52:31,395 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:53:31,399 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:53:31,399 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:40:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
recon_1     | 2022-12-10 12:53:31,399 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2038 
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
recon_1     | 2022-12-10 12:53:31,439 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 87, SequenceNumber diff: 223, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:28:07,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:08,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1     | 2022-12-10 12:53:31,442 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 223 records
scm_1       | 2022-12-10 12:28:08,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:08,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
recon_1     | 2022-12-10 12:53:31,447 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1     | 2022-12-10 12:53:31,447 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 12:53:31,570 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:53:31,573 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 12 OM DB update event(s).
recon_1     | 2022-12-10 12:53:31,588 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:54:31,595 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:54:31,595 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:28:12,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:12,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:54:31,595 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2261 
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 12:54:31,680 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 217, SequenceNumber diff: 391, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:54:31,680 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 391 records
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
recon_1     | 2022-12-10 12:54:31,682 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:28:13,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:54:31,682 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
recon_1     | 2022-12-10 12:54:31,716 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:54:31,719 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
scm_1       | 2022-12-10 12:28:13,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:13,748 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:28:17,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1     | 2022-12-10 12:54:31,727 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 12:55:31,731 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:55:31,732 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:55:31,732 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2652 
recon_1     | 2022-12-10 12:55:31,812 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 88, SequenceNumber diff: 238, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:28:17,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:18,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:28:18,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 12:55:31,813 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 238 records
recon_1     | 2022-12-10 12:55:31,817 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:28:18,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:40:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:28:22,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:55:31,818 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:55:31,864 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:28:22,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:55:31,867 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:28:23,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:55:31,882 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 12:56:31,891 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:56:31,891 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 12:56:31,891 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2890 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 12:56:31,917 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 23, SequenceNumber diff: 75, SequenceNumber Lag from OM 0.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:28:23,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:23,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:56:31,917 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 75 records
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:28:27,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:27,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:56:31,920 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1     | 2022-12-10 12:56:31,924 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 12:56:31,994 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:28:28,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:28,396 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1     | 2022-12-10 12:56:31,995 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 12 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 12:28:28,748 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:32,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
recon_1     | 2022-12-10 12:56:32,011 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:40:04,069 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 99047-with-errors
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
recon_1     | 2022-12-10 12:56:34,554 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 0 milliseconds to process 0 existing database records.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 12:28:32,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:33,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | 2022-12-10 12:40:22,286 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-acls for user:hadoop
scm_1       | 2022-12-10 12:28:33,396 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:56:34,558 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 7 containers.
recon_1     | 2022-12-10 12:56:35,213 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 11 pipelines in house.
om_1        | 2022-12-10 12:40:55,052 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 99047-acls
recon_1     | 2022-12-10 12:56:35,217 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 25 milliseconds.
recon_1     | 2022-12-10 12:57:32,027 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:28:33,741 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:36,083 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:41:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
recon_1     | 2022-12-10 12:57:32,028 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:57:32,028 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2965 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:28:37,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:37,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:57:32,086 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 231, SequenceNumber diff: 449, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 12:57:32,086 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 449 records
scm_1       | 2022-12-10 12:28:38,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:38,397 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:38,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:57:32,090 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:57:32,090 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:28:42,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:57:32,145 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:28:42,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:43,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:43,397 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:43,740 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:28:47,432 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:28:47,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:57:32,147 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 14 OM DB update event(s).
recon_1     | 2022-12-10 12:57:32,164 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:28:48,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:58:32,168 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:58:32,168 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2022-12-10 12:41:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 12:28:48,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:48,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:52,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 12:58:32,169 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3414 
recon_1     | 2022-12-10 12:58:32,208 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 155, SequenceNumber diff: 396, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:28:52,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:58:32,208 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 396 records
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:28:53,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:28:53,398 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:28:53,741 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:57,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:58:32,215 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 12:58:32,215 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:28:57,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:58,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:58,397 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:28:58,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:02,413 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:58:32,264 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 2022-12-10 12:29:02,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:29:03,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:58:32,265 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 14 OM DB update event(s).
recon_1     | 2022-12-10 12:58:32,284 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:29:03,396 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:29:03,741 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 2022-12-10 12:29:06,085 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:29:07,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
recon_1     | 2022-12-10 12:59:32,289 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 12:59:32,293 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 12:59:32,293 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3810 
recon_1     | 2022-12-10 12:59:32,311 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 34, SequenceNumber diff: 106, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:29:07,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 12:59:32,312 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 106 records
recon_1     | 2022-12-10 12:59:32,315 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:29:08,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:08,398 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:08,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:29:12,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:12,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:13,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:29:13,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:13,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:17,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:52:17,624 [qtp1858015030-21] WARN server.HttpChannel: /erasure/ozone-test-3785280973/putobject/custom-metadata/key2
recon_1     | 2022-12-10 12:59:32,315 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 12:59:32,368 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 12:59:32,370 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 2022-12-10 12:59:32,377 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:41:02,943 [OM StateMachine ApplyTransaction Thread - 0] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /99047-acls/bb1 failed, because acl already exist
om_1        | 2022-12-10 12:41:40,648 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:00:32,381 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:29:17,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:18,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:18,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:00:32,382 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:29:18,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:29:22,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:00:32,382 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3916 
recon_1     | 2022-12-10 13:00:32,402 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 24, SequenceNumber diff: 69, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:29:22,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:23,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:23,398 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:00:32,402 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 69 records
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:29:23,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:29:27,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:29:27,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:40,649 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:29:28,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
recon_1     | 2022-12-10 13:00:32,403 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:29:28,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:28,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:32,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:00:32,404 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:29:32,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:00:32,431 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:29:33,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:33,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:33,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:36,087 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:00:32,432 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
recon_1     | 2022-12-10 13:00:32,433 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,650 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
recon_1     | 2022-12-10 13:00:38,623 [qtp2116006444-42] INFO impl.Tools: Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
scm_1       | 2022-12-10 12:29:37,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:38,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1     | 2022-12-10 13:01:32,436 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:29:38,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:38,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:41:40,651 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:42:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 13:01:32,436 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 13:01:32,436 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3985 
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:01:32,457 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 21, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 13:01:32,457 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 21 records
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:01:32,463 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 13:01:32,463 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 13:01:32,498 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:29:42,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:42,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:43,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:01:32,499 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:29:43,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:43,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:47,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:01:32,499 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:29:47,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:48,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:48,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:29:48,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:52,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:52,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:01:34,559 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-12-10 13:01:34,561 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 7 containers.
scm_1       | 2022-12-10 12:29:53,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:53,398 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:53,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:01:35,224 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 11 pipelines in house.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:29:57,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:57,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:58,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:01:35,236 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 18 milliseconds.
recon_1     | 2022-12-10 13:02:32,505 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:29:58,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:29:58,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:02,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:02,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:03,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:03,398 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:03,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:06,088 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:30:07,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:02:32,505 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 13:02:32,505 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4006 
scm_1       | 2022-12-10 12:30:07,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:08,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:08,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:02:32,512 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 14, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 13:02:32,512 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 14 records
scm_1       | 2022-12-10 12:30:08,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:12,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:02:32,513 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 2022-12-10 12:42:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:02:32,514 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 13:02:32,562 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:42:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 13:02:32,563 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:02:32,566 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 13:03:32,571 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:30:12,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:13,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
recon_1     | 2022-12-10 13:03:32,572 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:30:13,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1     | 2022-12-10 13:03:32,572 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4020 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:30:13,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:30:17,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1     | 2022-12-10 13:03:32,631 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 228, SequenceNumber diff: 693, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:30:17,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
recon_1     | 2022-12-10 13:03:32,631 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 693 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:30:18,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
recon_1     | 2022-12-10 13:03:32,635 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1     | 2022-12-10 13:03:32,670 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:30:18,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
recon_1     | 2022-12-10 13:03:32,673 [pool-28-thread-1] ERROR tasks.FileSizeCountTask: Unexpected exception while processing key /voltest/buckettest/performanceTest/182be0c.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:30:18,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1     | java.lang.ClassCastException: class org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo cannot be cast to class org.apache.hadoop.ozone.om.helpers.OmKeyInfo (org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo and org.apache.hadoop.ozone.om.helpers.OmKeyInfo are in unnamed module of loader 'app')
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:30:22,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.FileSizeCountTask.process(FileSizeCountTask.java:144)
om_1        | 2022-12-10 12:42:40,509 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-without-host for user:hadoop
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.lambda$consumeOMEvents$0(ReconTaskControllerImpl.java:113)
om_1        | 2022-12-10 12:43:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
scm_1       | 2022-12-10 12:30:22,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:23,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:23,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:23,743 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:27,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:27,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:28,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:28,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:30:28,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:30:32,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:32,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
recon_1     | 2022-12-10 13:03:32,673 [pool-27-thread-1] ERROR tasks.ReconTaskControllerImpl: Unexpected error : 
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1     | java.util.concurrent.ExecutionException: java.lang.ClassCastException: class org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo cannot be cast to class org.apache.hadoop.ozone.om.helpers.OmKeyInfo (org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo and org.apache.hadoop.ozone.om.helpers.OmKeyInfo are in unnamed module of loader 'app')
recon_1     | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
recon_1     | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.processTaskResults(ReconTaskControllerImpl.java:247)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.consumeOMEvents(ReconTaskControllerImpl.java:118)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:30:33,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:503)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:30:33,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:258)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 12:30:33,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm_1       | 2022-12-10 12:30:36,091 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:30:37,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | Caused by: java.lang.ClassCastException: class org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo cannot be cast to class org.apache.hadoop.ozone.om.helpers.OmKeyInfo (org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo and org.apache.hadoop.ozone.om.helpers.OmKeyInfo are in unnamed module of loader 'app')
scm_1       | 2022-12-10 12:30:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:38,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTaskWithLegacy.processWithLegacy(NSSummaryTaskWithLegacy.java:93)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTask.process(NSSummaryTask.java:99)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 2022-12-10 12:43:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:30:38,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.lambda$consumeOMEvents$0(ReconTaskControllerImpl.java:113)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 12:30:38,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:42,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 	... 3 more
recon_1     | 2022-12-10 13:04:32,674 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:30:42,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:43,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 12:30:43,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:04:32,674 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-12-10 13:04:32,674 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4713 
recon_1     | 2022-12-10 13:04:32,687 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 29, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:04:32,689 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 29 records
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
recon_1     | 2022-12-10 13:04:32,691 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:30:43,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:47,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1     | 2022-12-10 13:04:32,692 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 13:04:32,728 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
recon_1     | 2022-12-10 13:04:32,730 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
scm_1       | 2022-12-10 12:30:47,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:52:17,624 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 13:04:32,737 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:30:48,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:48,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:04:33,530 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-12-10 13:04:33,542 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767 not found. Cannot add container #8
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 13:04:33,545 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-12-10 13:04:58,537 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767 not found. Cannot add container #8
recon_1     | 2022-12-10 13:04:58,537 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1     | 2022-12-10 13:05:13,951 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:30:48,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:05:14,035 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:30:52,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:05:32,744 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:30:52,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:05:32,744 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
recon_1     | 2022-12-10 13:05:32,744 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4742 
om_1        | 2022-12-10 12:43:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:30:53,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:53,406 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1     | 2022-12-10 13:05:32,752 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1, SequenceNumber diff: 1, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 13:05:32,752 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 1 records
scm_1       | 2022-12-10 12:30:53,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:57,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:05:32,753 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 13:05:32,753 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:30:57,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1     | 2022-12-10 13:05:32,797 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1     | 2022-12-10 13:05:32,797 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:05:32,797 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 13:06:32,805 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
recon_1     | 2022-12-10 13:06:32,806 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:30:58,081 [IPC Server handler 2 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm_1       | 2022-12-10 12:30:58,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
recon_1     | 2022-12-10 13:06:32,806 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4743 
scm_1       | 2022-12-10 12:30:58,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:30:58,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
recon_1     | 2022-12-10 13:06:32,813 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1, SequenceNumber diff: 1, SequenceNumber Lag from OM 0.
scm_1       | 2022-12-10 12:31:02,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:02,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1     | 2022-12-10 13:06:32,814 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 1 records
recon_1     | 2022-12-10 13:06:32,816 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:31:03,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:06:32,816 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:31:03,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 13:06:32,897 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 13:06:32,897 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 13:06:32,897 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:31:03,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 13:06:34,562 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
scm_1       | 2022-12-10 12:31:06,094 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 13:06:34,568 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 7 containers.
scm_1       | 2022-12-10 12:31:07,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 2022-12-10 13:06:35,249 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 11 pipelines in house.
scm_1       | 2022-12-10 12:31:07,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:06:35,250 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=96ebd449-ccfc-4faf-8e5b-cb01ba603b2a from SCM.
scm_1       | 2022-12-10 12:31:08,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 2022-12-10 12:43:00,641 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 99047-without-host
recon_1     | 2022-12-10 13:06:35,250 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 96ebd449-ccfc-4faf-8e5b-cb01ba603b2a, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T13:05:58.122Z[UTC]].
scm_1       | 2022-12-10 12:31:08,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:43:37,522 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:06:35,251 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767 from SCM.
scm_1       | 2022-12-10 12:31:08,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:06:35,251 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]].
scm_1       | 2022-12-10 12:31:12,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:06:35,265 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 26 milliseconds.
scm_1       | 2022-12-10 12:31:12,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:06:49,052 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #8 to Recon.
scm_1       | 2022-12-10 12:31:13,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,907 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:31:13,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,908 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2022-12-10 12:31:13,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,908 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4744 
scm_1       | 2022-12-10 12:31:17,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,914 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 3, SequenceNumber diff: 7, SequenceNumber Lag from OM 0.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,914 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 7 records
scm_1       | 2022-12-10 12:31:17,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 2022-12-10 12:43:37,523 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,916 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2022-12-10 12:31:18,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,916 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:31:18,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,951 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 13:07:32,951 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2022-12-10 12:31:18,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:32,951 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 13:07:36,084 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_4.ozone_default.
scm_1       | 2022-12-10 12:31:22,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:36,103 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_2.ozone_default.
scm_1       | 2022-12-10 12:31:22,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:23,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:36,106 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #9 to Recon.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:31:23,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:07:36,127 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #9 to Recon.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:08:31,207 [EventQueue-StaleNodeForStaleNodeHandler] INFO node.StaleNodeHandler: Datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924, PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767, PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e, PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7, PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e, PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14, PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545]
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:31:23,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,524 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:08:31,211 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] moved to CLOSED state
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:31:24,350 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:08:31,212 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #7 closed for pipeline=PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 12:31:27,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	... 17 more
recon_1     | 2022-12-10 13:08:31,213 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 12:31:27,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 13:08:31,215 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #8 closed for pipeline=PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767
scm_1       | 2022-12-10 12:31:28,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
recon_1     | 2022-12-10 13:08:31,215 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 12:31:28,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
recon_1     | 2022-12-10 13:08:31,217 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #5 closed for pipeline=PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e
scm_1       | 2022-12-10 12:31:28,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
recon_1     | 2022-12-10 13:08:31,219 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 12:31:32,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 2022-12-10 13:08:31,220 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #3 closed for pipeline=PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7
scm_1       | 2022-12-10 12:31:32,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:33,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,525 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 2022-12-10 13:08:31,222 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 12:31:33,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:43:37,526 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:08:31,224 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #9 closed for pipeline=PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e
scm_1       | 2022-12-10 12:31:33,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om_1        | 2022-12-10 12:43:37,526 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:08:31,224 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] moved to CLOSED state
recon_1     | 2022-12-10 13:08:31,225 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #6 closed for pipeline=PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 2022-12-10 12:44:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:31:36,096 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
recon_1     | 2022-12-10 13:08:31,231 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]] moved to CLOSED state
recon_1     | 2022-12-10 13:08:31,232 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #4 closed for pipeline=PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545
recon_1     | 2022-12-10 13:08:31,233 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7, current state: CLOSING
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
scm_1       | 2022-12-10 12:31:37,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:31,238 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]] moved to CLOSED state
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:08:31,255 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8, current state: CLOSING
recon_1     | 2022-12-10 13:08:31,255 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5, current state: CLOSING
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:31:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:31:38,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:31:38,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:31:38,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:31,255 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3, current state: CLOSING
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:31:42,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:31,255 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9, current state: CLOSING
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:31:42,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:31:43,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 2022-12-10 12:44:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:31:43,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:43,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:47,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
recon_1     | 2022-12-10 13:08:31,255 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6, current state: CLOSING
scm_1       | 2022-12-10 12:31:47,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:48,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:48,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:48,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:31,256 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4, current state: CLOSING
recon_1     | 2022-12-10 13:08:32,959 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2022-12-10 12:31:52,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:52,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
recon_1     | 2022-12-10 13:08:32,960 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:31:53,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:32,960 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4751 
recon_1     | 2022-12-10 13:08:32,966 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 3, SequenceNumber diff: 7, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 13:08:32,966 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 7 records
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:31:53,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:32,969 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:08:32,969 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2022-12-10 13:08:33,025 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:31:53,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:57,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:57,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:31:58,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 12:31:58,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:31:58,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:02,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm_1       | 2022-12-10 12:32:02,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:32:03,281 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:32:03,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:03,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:32:06,099 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:32:07,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:07,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:32:08,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:08,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 2022-12-10 12:52:23,710 [qtp1858015030-20] WARN server.HttpChannel: /erasure/ozone-test-3785280973/putobject/custom-metadata/key2
recon_1     | 2022-12-10 13:08:33,028 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
om_1        | 2022-12-10 12:44:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-12-10 13:08:33,031 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-12-10 13:08:37,091 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #7 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:32:08,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:12,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:12,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:13,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 13:08:37,116 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #5 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:32:13,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 13:08:37,160 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #3 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:32:13,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 13:08:37,209 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #9 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1     | 2022-12-10 13:08:37,228 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #6 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:32:17,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:08:37,251 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #4 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 12:32:17,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 2022-12-10 12:45:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:32:18,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:18,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:18,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:08:37,279 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495. Trying to get from SCM.
recon_1     | 2022-12-10 13:08:37,296 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 283d1058-72b4-45d6-919c-18ddcf3cc495, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:08:36.251Z[UTC]] to Recon pipeline metadata.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:32:22,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:22,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:32:23,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:37,297 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 283d1058-72b4-45d6-919c-18ddcf3cc495, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:08:36.251Z[UTC]].
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:32:23,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:08:37,298 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:32:23,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:24,343 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
recon_1     | 2022-12-10 13:08:37,476 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:08:37,696 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 13:09:01,208 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO node.DeadNodeHandler: A dead datanode is detected. 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 13:09:01,210 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] removed.
recon_1     | 2022-12-10 13:09:01,211 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]] removed.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
recon_1     | 2022-12-10 13:09:01,211 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]] removed.
recon_1     | 2022-12-10 13:09:01,211 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]] removed.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
recon_1     | 2022-12-10 13:09:01,212 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]] removed.
recon_1     | 2022-12-10 13:09:01,212 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] removed.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm_1       | 2022-12-10 12:32:24,349 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:32:27,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm_1       | 2022-12-10 12:32:27,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:28,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm_1       | 2022-12-10 12:32:28,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:28,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:32:32,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:32,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
recon_1     | 2022-12-10 13:09:01,212 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]] removed.
recon_1     | 2022-12-10 13:09:01,213 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]] removed.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:32:33,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
recon_1     | 2022-12-10 13:09:01,217 [EventQueue-DeadNodeForReconDeadNodeHandler] INFO net.NetworkTopologyImpl: Removed a node: /default-rack/85e9a0c6-8631-4fee-9b9c-0f8004d778ef
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:32:33,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1     | 2022-12-10 13:09:04,065 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 12:32:33,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:32:36,113 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:32:37,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1     | 2022-12-10 13:09:07,279 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e. Trying to get from SCM.
scm_1       | 2022-12-10 12:32:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:32:38,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:32:38,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1     | 2022-12-10 13:09:07,286 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler: Could not find pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e at SCM.
scm_1       | 2022-12-10 12:32:38,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:32:42,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
recon_1     | 2022-12-10 13:09:07,287 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not find pipeline id: "c0524777-5948-4be0-b34b-af81ed93fe6e"
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:32:42,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:43,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | uuid128 {
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 12:32:43,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     |   mostSigBits: -4588526492412523552
recon_1     |   leastSigBits: -5527131145095610770
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:32:43,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | }
recon_1     | 
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:32:47,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:47,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:48,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:07,287 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-12-10 13:09:33,035 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 13:09:33,035 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2022-12-10 12:45:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-12-10 13:09:33,035 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4758 
recon_1     | 2022-12-10 13:09:33,041 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1, SequenceNumber diff: 1, SequenceNumber Lag from OM 0.
recon_1     | 2022-12-10 13:09:33,041 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 1 records
scm_1       | 2022-12-10 12:32:48,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
recon_1     | 2022-12-10 13:09:33,043 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 13:09:33,043 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:32:48,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:32:52,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:09:33,132 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1     | 2022-12-10 13:09:33,132 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:32:52,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:53,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:53,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:33,133 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:32:53,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:54,343 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:32:54,349 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
recon_1     | 2022-12-10 13:09:42,950 [IPC Server handler 0 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for c79f062f35ec
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:32:57,435 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:57,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:32:58,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:32:58,407 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm_1       | 2022-12-10 12:32:58,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:02,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:02,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 13:09:42,951 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924. Trying to get from SCM.
scm_1       | 2022-12-10 12:33:03,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:33:03,406 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:42,966 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler: Could not find pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 at SCM.
recon_1     | 2022-12-10 13:09:42,966 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not find pipeline id: "914e75cc-e1b0-4c3b-bff3-d18c7b531924"
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:33:03,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:33:06,115 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:33:07,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:07,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | uuid128 {
recon_1     |   mostSigBits: -7976308367206364101
scm_1       | 2022-12-10 12:33:08,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:52:23,711 [qtp1858015030-20] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 12:33:08,407 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:08,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     |   leastSigBits: -4615114791829956316
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:33:12,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:12,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:13,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:45:36,307 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:99047-without-host for user:hadoop
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:45:49,284 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 99047-without-host
om_1        | 2022-12-10 12:45:57,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
recon_1     | }
recon_1     | 
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:42,967 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e. Trying to get from SCM.
scm_1       | 2022-12-10 12:33:13,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:13,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:17,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:33:17,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:18,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
recon_1     | 2022-12-10 13:09:42,976 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler: Could not find pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e at SCM.
recon_1     | 2022-12-10 13:09:42,976 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not find pipeline id: "c0524777-5948-4be0-b34b-af81ed93fe6e"
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:33:18,401 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | uuid128 {
recon_1     |   mostSigBits: -4588526492412523552
scm_1       | 2022-12-10 12:33:18,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:22,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:22,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:23,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     |   leastSigBits: -5527131145095610770
recon_1     | }
scm_1       | 2022-12-10 12:33:23,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:23,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:24,344 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:33:24,349 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:33:27,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:27,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 
recon_1     | 2022-12-10 13:09:43,572 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 reported by eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 12:33:28,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:28,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:43,572 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 283d1058-72b4-45d6-919c-18ddcf3cc495, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:eb6b06af-1f2c-4397-8743-5d103932e2bb, CreationTimestamp2022-12-10T13:08:36.251Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:33:28,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:32,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:32,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:33:33,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:33:33,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:43,914 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924. Trying to get from SCM.
scm_1       | 2022-12-10 12:33:33,754 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:36,116 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:33:37,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:33:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:38,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:38,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:38,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:42,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:33:42,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:43,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:43,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:43,918 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler: Could not find pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 at SCM.
scm_1       | 2022-12-10 12:33:43,754 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:47,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:47,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:33:48,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:43,919 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not find pipeline id: "914e75cc-e1b0-4c3b-bff3-d18c7b531924"
recon_1     | uuid128 {
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
recon_1     |   mostSigBits: -7976308367206364101
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:33:48,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     |   leastSigBits: -4615114791829956316
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:33:48,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:33:52,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | }
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 
scm_1       | 2022-12-10 12:33:52,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:45:57,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:43,919 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e. Trying to get from SCM.
scm_1       | 2022-12-10 12:33:53,283 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
recon_1     | 2022-12-10 13:09:43,929 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler: Could not find pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e at SCM.
om_1        | 2022-12-10 12:45:57,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:45:57,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:33:53,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:45:57,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 2022-12-10 13:09:43,930 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not find pipeline id: "c0524777-5948-4be0-b34b-af81ed93fe6e"
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:33:53,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:46:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | uuid128 {
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:33:54,344 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
scm_1       | 2022-12-10 12:33:54,350 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     |   mostSigBits: -4588526492412523552
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:33:57,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     |   leastSigBits: -5527131145095610770
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 12:33:57,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | }
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:33:58,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:33:58,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:09:46,947 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #8 to CLOSED state, datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 12:33:58,754 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 13:09:53,501 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=4bdf5060-2d04-4557-9c86-f3435b17aa3b. Trying to get from SCM.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 12:34:02,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2022-12-10 13:09:53,503 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 4bdf5060-2d04-4557-9c86-f3435b17aa3b, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:09:51.080Z[UTC]] to Recon pipeline metadata.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:34:02,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:53,504 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4bdf5060-2d04-4557-9c86-f3435b17aa3b, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:09:51.080Z[UTC]].
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:34:03,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:53,505 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=4bdf5060-2d04-4557-9c86-f3435b17aa3b reported by 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:34:03,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:09:53,505 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4bdf5060-2d04-4557-9c86-f3435b17aa3b, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T13:09:51.080Z[UTC]] moved to OPEN state
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:34:03,754 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:06,117 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:34:07,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,139 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:34:07,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,140 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2022-12-10 12:46:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:34:08,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,140 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4759 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 12:34:08,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,148 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11, SequenceNumber diff: 31, SequenceNumber Lag from OM 0.
s3g_1       | 	... 17 more
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:34:08,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,148 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 31 records
recon_1     | 2022-12-10 13:10:33,150 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:34:12,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:12,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:10:33,151 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:34:13,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:10:33,229 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:34:13,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:10:33,229 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:34:13,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:10:33,229 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:34:17,431 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 13:11:04,328 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_1.ozone_default.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:34:17,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2022-12-10 13:11:04,342 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #10 to Recon.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
recon_1     | 2022-12-10 13:11:33,235 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm_1       | 2022-12-10 12:34:18,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1     | 2022-12-10 13:11:33,236 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:34:18,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:46:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:34:18,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:22,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:11:33,236 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4790 
recon_1     | 2022-12-10 13:11:33,249 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 27, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:34:22,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:23,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1     | 2022-12-10 13:11:33,249 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 27 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1     | 2022-12-10 13:11:33,251 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:34:23,402 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:34:23,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1     | 2022-12-10 13:11:33,251 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1     | 2022-12-10 13:11:33,296 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:34:24,344 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:34:24,350 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
recon_1     | 2022-12-10 13:11:33,296 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 2022-12-10 12:46:29,905 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:bphle for user:hadoop
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1     | 2022-12-10 13:11:33,296 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2022-12-10 12:46:33,803 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket1 of layout LEGACY in volume: bphle
scm_1       | 2022-12-10 12:34:27,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 2022-12-10 12:46:57,606 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket2 of layout LEGACY in volume: bphle
scm_1       | 2022-12-10 12:34:27,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 2022-12-10 12:47:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
recon_1     | 2022-12-10 13:11:34,569 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-12-10 13:11:34,571 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 10 containers.
s3g_1       | 2022-12-10 12:53:12,675 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-ijdtptzqau, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:14,907 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-zcszkppsvn, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | Dec 10, 2022 12:53:43 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
scm_1       | 2022-12-10 12:34:28,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:11:35,278 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:11:35,279 [PipelineSyncTask] INFO scm.ReconPipelineManager: Removing invalid pipeline PipelineID=96ebd449-ccfc-4faf-8e5b-cb01ba603b2a from Recon.
recon_1     | 2022-12-10 13:11:35,281 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 96ebd449-ccfc-4faf-8e5b-cb01ba603b2a, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T13:05:58.122Z[UTC]] removed.
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-12-10 13:11:35,283 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 10 milliseconds.
scm_1       | 2022-12-10 12:34:28,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:34:28,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:32,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
recon_1     | 2022-12-10 13:12:33,300 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 13:12:33,302 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-12-10 13:12:33,303 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4817 
recon_1     | 2022-12-10 13:12:33,314 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11, SequenceNumber diff: 32, SequenceNumber Lag from OM 0.
om_1        | 2022-12-10 12:47:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
scm_1       | 2022-12-10 12:34:32,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:33,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
recon_1     | 2022-12-10 13:12:33,314 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 32 records
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
scm_1       | 2022-12-10 12:34:33,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:33,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:665)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
recon_1     | 2022-12-10 13:12:33,317 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 13:12:33,318 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
recon_1     | 2022-12-10 13:12:33,395 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-12-10 12:34:36,119 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
om_1        | 2022-12-10 12:47:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:34:37,434 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:37,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 2022-12-10 12:34:38,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:12:33,399 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:129)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:72)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:112)
recon_1     | 2022-12-10 13:12:33,401 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:34:38,406 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
recon_1     | 2022-12-10 13:13:33,406 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 13:13:33,406 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:13:33,406 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4849 
recon_1     | 2022-12-10 13:13:33,420 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 20, SequenceNumber diff: 69, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:34:38,754 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:42,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:34:42,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:43,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:47:19,793 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket3 of layout LEGACY in volume: bphle
om_1        | 2022-12-10 12:47:43,319 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket4 of layout LEGACY in volume: bphle
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
om_1        | 2022-12-10 12:48:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:34:43,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:43,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:47,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:47,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:34:48,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:48,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-12-10 13:13:33,420 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 69 records
recon_1     | 2022-12-10 13:13:33,473 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:34:48,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:52,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:52,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
scm_1       | 2022-12-10 12:34:53,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:53,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2022-12-10 13:13:33,473 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2022-12-10 13:13:33,474 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:34:53,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:54,345 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
recon_1     | 2022-12-10 13:13:33,474 [pool-27-thread-1] ERROR tasks.ReconTaskControllerImpl: Unexpected error : 
recon_1     | java.util.concurrent.ExecutionException: java.lang.ClassCastException: class org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo cannot be cast to class org.apache.hadoop.ozone.om.helpers.OmKeyInfo (org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo and org.apache.hadoop.ozone.om.helpers.OmKeyInfo are in unnamed module of loader 'app')
scm_1       | 2022-12-10 12:34:54,350 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:34:57,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:34:57,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
scm_1       | 2022-12-10 12:34:58,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:34:58,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:34:58,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.processTaskResults(ReconTaskControllerImpl.java:247)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:48:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:35:02,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:02,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:03,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:03,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.consumeOMEvents(ReconTaskControllerImpl.java:118)
scm_1       | 2022-12-10 12:35:03,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:503)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:258)
om_1        | 2022-12-10 12:48:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:35:06,120 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:35:07,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:07,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:08,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
scm_1       | 2022-12-10 12:35:08,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:08,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:12,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | Caused by: java.lang.ClassCastException: class org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo cannot be cast to class org.apache.hadoop.ozone.om.helpers.OmKeyInfo (org.apache.hadoop.ozone.om.helpers.RepeatedOmKeyInfo and org.apache.hadoop.ozone.om.helpers.OmKeyInfo are in unnamed module of loader 'app')
scm_1       | 2022-12-10 12:35:12,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:13,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:13,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:13,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:17,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:17,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
scm_1       | 2022-12-10 12:35:18,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:18,406 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:18,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:22,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:22,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTaskWithFSO.processWithFSO(NSSummaryTaskWithFSO.java:90)
scm_1       | 2022-12-10 12:35:23,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:23,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:23,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.NSSummaryTask.process(NSSummaryTask.java:97)
recon_1     | 	at org.apache.hadoop.ozone.recon.tasks.ReconTaskControllerImpl.lambda$consumeOMEvents$0(ReconTaskControllerImpl.java:113)
scm_1       | 2022-12-10 12:35:24,345 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:35:24,350 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	... 3 more
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1     | 2022-12-10 13:14:33,475 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-12-10 13:14:33,475 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
recon_1     | 2022-12-10 13:14:33,476 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4918 
recon_1     | 2022-12-10 13:14:33,485 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 19, SequenceNumber diff: 61, SequenceNumber Lag from OM 0.
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:35:27,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:27,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:14:33,485 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 61 records
recon_1     | 2022-12-10 13:14:33,493 [pool-28-thread-1] ERROR tasks.NSSummaryTaskDbEventHandler: The namespace table is not correctly populated.
scm_1       | 2022-12-10 12:35:28,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:28,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:28,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:14:33,494 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2022-12-10 13:14:33,494 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2022-12-10 12:35:32,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:32,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:33,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:33,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
recon_1     | 2022-12-10 13:14:33,536 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-12-10 13:14:33,536 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2022-12-10 12:35:33,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:36,121 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm_1       | 2022-12-10 12:35:37,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:38,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
recon_1     | 2022-12-10 13:14:33,536 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2022-12-10 12:35:38,403 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:38,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:42,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:35:42,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:43,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:43,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:35:43,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:47,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:35:47,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:35:48,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:35:48,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:35:48,755 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:35:52,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:35:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:35:53,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:35:53,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
scm_1       | 2022-12-10 12:35:53,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:35:54,345 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 12:35:54,350 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:35:57,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:35:57,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 12:35:58,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 12:35:58,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
scm_1       | 2022-12-10 12:35:58,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 12:36:02,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:36:02,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm_1       | 2022-12-10 12:36:03,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm_1       | 2022-12-10 12:36:03,404 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:36:03,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:36:06,122 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 12:36:07,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:36:07,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:36:08,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:48:07,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:48:34,158 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: erasure of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:48:57,403 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-dcayyoezrw of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:36:08,406 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:36:08,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:36:12,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:36:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:36:13,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:36:13,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:36:13,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:36:17,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:36:17,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:36:18,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm_1       | 2022-12-10 12:36:18,405 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
scm_1       | 2022-12-10 12:36:18,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
scm_1       | 2022-12-10 12:36:22,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:36:22,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:36:23,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
scm_1       | 2022-12-10 12:36:23,407 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
scm_1       | 2022-12-10 12:36:23,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
scm_1       | 2022-12-10 12:36:24,346 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
scm_1       | 2022-12-10 12:36:24,351 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
scm_1       | 2022-12-10 12:36:24,351 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
scm_1       | 2022-12-10 12:36:27,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	... 114 more
scm_1       | 2022-12-10 12:36:27,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 
scm_1       | 2022-12-10 12:36:28,286 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 
scm_1       | 2022-12-10 12:36:28,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 2022-12-10 12:53:50,796 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg2, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:28,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 2022-12-10 12:53:50,796 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg0, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:32,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 2022-12-10 12:53:50,797 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg7, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:36:32,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,798 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg3, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:36:33,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,799 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg5, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:36:33,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,800 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg4, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:36:33,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,800 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg1, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:36,124 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:49:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 2022-12-10 12:53:50,800 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg8, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:37,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
s3g_1       | 2022-12-10 12:53:50,804 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg6, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:50,832 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg9, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:37,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 2022-12-10 12:53:50,871 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg10, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:38,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 2022-12-10 12:53:50,882 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg12, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:38,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 2022-12-10 12:53:50,900 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg11, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 2022-12-10 12:53:50,901 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg16, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:38,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 2022-12-10 12:53:50,902 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg15, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:42,433 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 2022-12-10 12:53:50,905 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg17, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:42,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 2022-12-10 12:53:50,906 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg14, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:43,287 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 2022-12-10 12:53:50,919 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg13, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:43,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | 2022-12-10 12:53:50,937 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg21, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:43,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,945 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg18, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:36:47,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,947 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg22, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:36:47,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,949 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg23, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:36:48,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,952 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg20, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:36:48,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,955 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg19, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:00,329 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-otcrkxgvcm of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:36:48,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,962 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg25, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:52,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,985 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg26, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:50,995 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg27, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:53,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,001 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg24, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:53,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,011 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg29, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:53,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,032 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg36, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,032 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg35, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,040 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg34, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:54,346 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 2022-12-10 12:53:51,041 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg33, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,061 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg30, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,060 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg31, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,056 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg32, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,044 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg37, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:54,351 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 2022-12-10 12:53:51,065 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg28, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:49:01,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,083 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg39, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,097 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg41, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:57,431 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,105 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg44, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:57,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,125 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg49, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:01,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:36:58,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:01,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,139 [qtp1858015030-683] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg50, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:36:58,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:01,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:53:51,141 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg45, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,143 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg38, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:10,013 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5761187386 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:10,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5525690288 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:36:58,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,144 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg43, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:11,278 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-5525690288 in volume:s3v
scm_1       | 2022-12-10 12:37:02,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,151 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg48, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 2022-12-10 12:53:51,152 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg42, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:37:02,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 2022-12-10 12:53:51,155 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg40, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:49:12,791 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6990045147 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,156 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg46, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:23,628 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7317996626 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:24,835 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-0090083056 in volume:s3v
scm_1       | 2022-12-10 12:37:03,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:03,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,158 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg47, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:03,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:06,125 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:37:07,431 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:07,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,165 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg51, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:08,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:08,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:08,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:12,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:129)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 2022-12-10 12:53:51,172 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg52, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:37:12,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:37:13,288 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,189 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg53, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:37:13,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,214 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg57, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:37:13,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,216 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg58, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:49:48,124 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:17,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,224 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg56, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,132 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:17,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,233 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg59, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,141 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,145 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:18,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:18,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:18,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,234 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg55, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:22,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:22,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:23,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:23,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,236 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg61, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:23,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:24,347 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:37:24,351 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:37:27,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,235 [qtp1858015030-683] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg60, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:27,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:28,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:28,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:28,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,235 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg54, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:32,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:32,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:33,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:37:33,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,251 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg64, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:33,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,159 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:36,129 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 2022-12-10 12:53:51,277 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg69, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,174 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:37,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,277 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg67, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,193 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:37,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,282 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg71, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,196 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,282 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg68, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,201 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,214 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:38,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,248 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,285 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg65, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,286 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg63, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,291 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg66, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,295 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg70, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,297 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg62, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,326 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg77, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,335 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg78, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,350 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg72, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,352 [qtp1858015030-683] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg80, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,353 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg76, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,356 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg75, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,357 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg74, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,356 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg81, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,356 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg73, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,357 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg79, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,367 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg83, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,255 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:38,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,261 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,311 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,315 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:38,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,318 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,319 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,326 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,334 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:42,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,342 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,405 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,407 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,413 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,449 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,370 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg82, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:42,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,453 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,392 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg85, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:43,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,456 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,404 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg86, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,459 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,511 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,405 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg87, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,411 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg84, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:43,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:53:51,419 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg92, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:53:51,430 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg88, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,515 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,518 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:43,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,525 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,538 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,543 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,416 [qtp1858015030-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg90, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,546 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,412 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg91, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:47,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,557 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,438 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg95, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:47,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,595 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,434 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg93, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:48,289 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,600 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,602 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,639 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:48,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,671 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,432 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg89, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,676 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,682 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:48,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,683 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,459 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg96, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,696 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,463 [qtp1858015030-683] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg94, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:52,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,700 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,479 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg97, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:52,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,713 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,496 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg99, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:49:48,716 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,723 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:53,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,724 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,733 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,741 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:53:51,503 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg98, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:53,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,751 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:55:08,344 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-49142, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:37:53,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,787 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
s3g_1       | 2022-12-10 12:56:21,288 [qtp1858015030-182] WARN server.HttpChannel: /link/ozone-test-8026277223/putobject/custom-metadata/key2
scm_1       | 2022-12-10 12:37:54,347 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:49:48,812 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:37:54,351 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:49:48,817 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:37:57,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,827 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,834 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,837 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,839 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:37:57,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:37:58,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:37:58,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:37:58,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 2022-12-10 12:49:48,841 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:02,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 2022-12-10 12:49:48,850 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:02,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 2022-12-10 12:49:48,852 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:03,290 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 2022-12-10 12:49:48,855 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:03,407 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:49:48,883 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,892 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 2022-12-10 12:49:48,903 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 2022-12-10 12:49:48,913 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:03,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm_1       | 2022-12-10 12:38:06,130 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:49:48,931 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm_1       | 2022-12-10 12:38:07,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,987 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:38:07,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,988 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm_1       | 2022-12-10 12:38:08,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:48,991 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:48,991 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:08,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,012 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:38:08,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,015 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:38:12,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,018 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:38:12,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,021 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:38:13,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,026 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:38:13,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,033 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 12:38:13,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,069 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:49,088 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:49:49,094 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:38:17,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,096 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:38:17,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,122 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:38:18,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,129 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:38:18,408 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:49:49,130 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:18,756 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:22,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
scm_1       | 2022-12-10 12:38:22,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2022-12-10 12:49:49,158 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:23,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:23,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:23,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 2022-12-10 12:49:49,166 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:24,348 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:49:49,170 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:24,351 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:38:27,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:38:27,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:49:49,174 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:28,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:28,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:28,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 2022-12-10 12:49:49,210 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:32,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 2022-12-10 12:49:49,217 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:32,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:33,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:33,413 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,226 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:33,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 12:38:36,133 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:38:37,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,233 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:37,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:38:38,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 2022-12-10 12:49:49,238 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:38,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 2022-12-10 12:49:49,240 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:38,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:38:42,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:38:42,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:43,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:49:49,254 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:38:43,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:43,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
om_1        | 2022-12-10 12:49:49,265 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 2022-12-10 12:49:49,286 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om_1        | 2022-12-10 12:50:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm_1       | 2022-12-10 12:38:47,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:38:47,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 2022-12-10 12:38:48,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:38:48,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:48,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 12:38:52,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:38:52,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:53,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:53,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:53,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:38:54,348 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:38:54,352 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:38:57,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:57,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:38:58,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:38:58,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:38:58,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:02,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:02,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:03,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:39:03,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:03,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:56:21,289 [qtp1858015030-182] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 12:39:06,133 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:39:07,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:07,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:08,291 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:08,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:08,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:12,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:39:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 2022-12-10 12:50:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:39:13,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:13,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:39:13,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 12:39:17,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:39:17,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:39:18,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:18,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:39:18,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:22,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:39:22,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:23,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:39:23,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:23,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:24,348 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 12:39:24,352 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:39:27,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:27,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:39:28,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:28,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:28,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:39:32,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:39:32,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 12:39:33,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 12:39:33,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 12:39:33,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:36,138 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 2022-12-10 12:39:37,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:37,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:38,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:38,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:39:38,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:39:42,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:42,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:43,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:43,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:43,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:39:47,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:47,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:48,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:48,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:39:48,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:52,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:39:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:53,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm_1       | 2022-12-10 12:39:53,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:53,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm_1       | 2022-12-10 12:39:54,348 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:39:54,352 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:39:57,432 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:39:57,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:58,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:58,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:39:58,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 12:40:02,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:40:02,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:40:03,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:40:03,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:40:03,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 2022-12-10 12:56:22,043 [qtp1858015030-21] WARN server.HttpChannel: /link/ozone-test-8026277223/putobject/custom-metadata/key2
scm_1       | 2022-12-10 12:40:06,140 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:40:07,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:40:07,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,738 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:40:08,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,738 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:40:08,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,738 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:40:08,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:40:12,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:40:12,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:40:13,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:40:13,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:40:13,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:40:17,430 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,739 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:17,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:40:18,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:40:18,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:18,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm_1       | 2022-12-10 12:40:22,431 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
scm_1       | 2022-12-10 12:40:22,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
scm_1       | 2022-12-10 12:40:23,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 12:40:23,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:50:06,740 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:23,757 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:24,351 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:24,353 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:27,432 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:27,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:28,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:28,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:28,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 2022-12-10 12:50:06,741 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:32,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 2022-12-10 12:50:06,742 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:32,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 2022-12-10 12:50:06,742 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:33,293 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 2022-12-10 12:50:06,742 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:33,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:50:06,742 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:33,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:50:06,742 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:36,141 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 2022-12-10 12:50:06,743 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:37,434 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 2022-12-10 12:50:06,743 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:37,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:38,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:38,409 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:38,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:42,434 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:42,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:43,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:43,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 2022-12-10 12:50:06,744 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:43,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 2022-12-10 12:50:06,745 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:47,433 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 2022-12-10 12:50:06,746 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:47,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:50:06,746 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,746 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 2022-12-10 12:50:06,746 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:48,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:50:06,746 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:48,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:48,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:52,435 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:53,294 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:53,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:53,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:40:54,351 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 12:40:54,353 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:50:06,747 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:40:57,435 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:40:57,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:40:58,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:40:58,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2022-12-10 12:40:58,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:41:02,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:41:02,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,748 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 12:41:03,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm_1       | 2022-12-10 12:41:03,410 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:41:03,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:06,142 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:07,434 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:07,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:08,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 2022-12-10 12:50:06,749 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:08,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,750 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:08,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 2022-12-10 12:50:06,750 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:12,434 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 2022-12-10 12:41:13,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:13,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,750 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,750 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 2022-12-10 12:50:06,751 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,752 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,752 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:13,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 2022-12-10 12:50:06,752 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:17,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 2022-12-10 12:50:06,752 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:17,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,753 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:18,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 2022-12-10 12:50:06,754 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:18,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om_1        | 2022-12-10 12:50:06,754 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:18,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,754 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:22,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,754 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,755 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:41:22,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:23,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,755 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:56:22,043 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 12:41:23,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:23,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:24,351 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:41:24,352 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:41:24,353 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:41:27,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:41:27,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:28,301 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:28,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:28,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:32,441 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:32,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:41:33,300 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:33,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:33,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:36,143 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:41:37,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:37,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:38,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:38,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,757 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 2022-12-10 12:50:06,758 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,759 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,759 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:41:38,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:50:06,760 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 2022-12-10 12:50:12,856 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/erasure/ozone-test-8939756019/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2022-12-10 12:50:12,857 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8939756019/multipartKey2 in Volume/Bucket s3v/erasure
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-8939756019/multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:41:42,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:41:42,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:43,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:43,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:43,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:41:47,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:47,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:48,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:48,413 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm_1       | 2022-12-10 12:41:48,774 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:52,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:53,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:41:53,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:41:53,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 2022-12-10 12:50:14,310 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/erasure/ozone-test-0323064274/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
scm_1       | 2022-12-10 12:41:54,351 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | partName: "etag1"
om_1        | , partNumber: 2
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | partName: "etag2"
om_1        | ]
scm_1       | 2022-12-10 12:41:54,353 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:41:57,435 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:57,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:58,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:14,312 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0323064274/multipartKey3 in Volume/Bucket s3v/erasure
scm_1       | 2022-12-10 12:41:58,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:41:58,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
scm_1       | 2022-12-10 12:42:02,435 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:02,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:03,303 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:03,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:42:03,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0323064274/multipartKey3
scm_1       | 2022-12-10 12:42:06,144 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:42:07,442 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 2022-12-10 12:42:07,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:50:15,025 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/erasure/ozone-test-0323064274/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
scm_1       | 2022-12-10 12:42:08,301 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | partName: "etag1"
scm_1       | 2022-12-10 12:42:08,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-12-10 12:50:15,026 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0323064274/multipartKey3 in Volume/Bucket s3v/erasure
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:42:08,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:12,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:12,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:13,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm_1       | 2022-12-10 12:42:13,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:13,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:17,441 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:17,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:42:18,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:18,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:18,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0323064274/multipartKey3
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:42:22,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:42:22,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:42:23,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:23,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:23,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:42:24,352 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 12:42:24,353 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:42:27,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:27,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:28,301 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:42:28,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:42:28,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:50:18,577 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0323064274/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0323064274/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/erasure/ozone-test-0323064274/multipartKey3-74f257c7-f146-4f66-a1ba-a4f94857682f-109489462546661526-1
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:42:32,449 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:50:19,210 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0323064274/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0323064274/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/erasure/ozone-test-0323064274/multipartKey3-74f257c7-f146-4f66-a1ba-a4f94857682f-109489462546661526-2
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:42:32,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:42:33,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:33,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:33,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:42:36,146 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:42:37,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:37,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:38,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 12:42:38,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:42:38,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:42,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:42:42,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:42:43,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:43,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:50:19,846 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/erasure/ozone-test-0323064274/multipartKey3
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:50:19,847 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0323064274/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0323064274/multipartKey3 because parts are in Invalid order.
scm_1       | 2022-12-10 12:42:43,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:47,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:47,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 12:42:48,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
scm_1       | 2022-12-10 12:42:48,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:42:48,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:52,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:52,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 2022-12-10 12:50:23,371 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-6992105015/multipartKey5 in VolumeName/Bucket s3v/erasure
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: erasurekey: ozone-test-6992105015/multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
scm_1       | 2022-12-10 12:42:53,296 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:42:53,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:42:53,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:54,352 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:42:54,354 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:42:57,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:57,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:42:58,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:58,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:42:58,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:02,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 17 more
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:50:24,027 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:erasure, Key:ozone-test-0670393396/multipartKey. 
scm_1       | 2022-12-10 12:43:02,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:03,295 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
scm_1       | 2022-12-10 12:43:03,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:03,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:43:06,147 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:43:07,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:07,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:08,301 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:43:08,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:08,760 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2022-12-10 12:43:12,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:13,304 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:13,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:43:13,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:43:17,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:17,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:18,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:43:18,414 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:43:18,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:22,436 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:43:22,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:23,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:23,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:23,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 12:43:24,353 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:43:24,354 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm_1       | 2022-12-10 12:43:27,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:27,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:28,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 12:43:28,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:28,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 2022-12-10 12:43:32,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:32,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:43:33,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 2022-12-10 12:51:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 12:43:33,416 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 12:43:33,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:43:36,149 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 12:43:37,437 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:43:37,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 12:43:38,303 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:43:38,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
s3g_1       | 2022-12-10 12:56:23,059 [qtp1858015030-182] WARN server.HttpChannel: /link/ozone-test-8026277223/putobject/custom-metadata/key2
scm_1       | 2022-12-10 12:43:38,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:43:42,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:43:42,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:43:43,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:43:43,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:43:43,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:43:47,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:43:47,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:43:48,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:43:48,415 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:43:48,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:43:52,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 12:43:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 12:43:53,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:43:53,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:43:53,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm_1       | 2022-12-10 12:43:54,353 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:43:54,354 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 2022-12-10 12:51:03,458 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-05520 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:43:57,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:21,091 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:erasure, Key:thereisnosuchfile.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
scm_1       | 2022-12-10 12:43:57,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:43:58,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:43:58,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:43:58,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:02,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:02,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:23,638 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:erasure, Key:ozone-test-3766570291/deletetestapidir/key=value/.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
scm_1       | 2022-12-10 12:44:03,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:44:03,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:44:03,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:26,984 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:erasure, Key:ozone-test-3766570291/deletetestapiprefix/key=value/file.
scm_1       | 2022-12-10 12:44:06,151 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:56:23,059 [qtp1858015030-182] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:51:47,815 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:erasure, Key:ozone-test-5303481112/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:51:56,809 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=3, localID=109611004723200210}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key ozone-test-3785280973/putobject/key=value/zerobyte.
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:56:26,951 [qtp1858015030-21] WARN server.HttpChannel: /link/ozone-test-8026277223/putobject/custom-metadata/key2
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:44:07,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:07,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:08,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:08,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:08,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:12,441 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:12,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:13,301 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:13,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:13,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:17,442 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:17,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:18,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:18,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:18,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:22,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:22,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:23,300 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:23,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:23,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:24,353 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:44:24,355 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:44:27,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:27,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:28,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:28,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:28,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:32,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:32,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:33,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:33,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:33,761 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:36,153 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:44:37,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:37,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:38,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:38,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:38,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:42,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:42,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:43,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:43,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:43,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:47,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:47,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:48,297 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:48,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:48,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:52,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:52,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:53,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:53,421 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:53,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:54,354 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:44:54,355 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:44:57,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:57,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:58,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:58,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:44:58,762 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:02,441 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:02,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:03,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:03,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:03,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:06,154 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:45:07,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:07,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:08,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:08,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:08,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:12,441 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:13,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:13,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:13,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:17,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:17,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:18,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:18,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:18,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:22,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:22,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:23,304 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:23,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:23,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:24,354 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:45:24,355 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:45:27,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:27,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:28,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:28,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:28,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:32,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:32,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:33,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:33,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:33,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:36,158 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:45:37,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:37,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:38,305 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:38,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:38,763 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:42,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:51:57,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:52:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:52:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:52:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:52:46,670 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:legacy for user:hadoop
om_1        | 2022-12-10 12:52:50,973 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: source-bucket of layout LEGACY in volume: legacy
om_1        | 2022-12-10 12:52:55,114 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:53:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 12:45:42,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:43,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:43,419 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:43,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:47,442 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:47,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:48,303 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:48,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:48,764 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:52,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:52,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:53,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:53,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:53,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:54,354 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:45:54,355 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:45:57,442 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:57,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:58,303 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:58,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:45:58,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:02,442 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:02,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:03,304 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:03,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:03,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:06,159 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:46:07,440 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:07,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:08,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:08,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:08,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:12,271 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:13,302 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:56:26,951 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:46:13,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:13,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:17,268 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:17,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:18,305 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:18,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:18,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:22,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:22,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:23,306 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:23,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:23,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:24,353 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm_1       | 2022-12-10 12:46:24,355 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:46:24,355 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:46:27,266 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:27,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:28,305 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:28,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:28,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:32,266 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:32,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:33,306 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:33,420 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:33,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:36,161 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:46:37,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:37,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:38,305 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:38,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:38,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:42,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:42,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:43,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:43,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:56:27,907 [qtp1858015030-21] WARN server.HttpChannel: /link/ozone-test-8026277223/putobject/custom-metadata/key2
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:46:43,769 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:47,269 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:47,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:48,319 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:48,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:48,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:52,270 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:52,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:53,310 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:53,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:53,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:54,355 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:46:54,356 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:46:57,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:57,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:58,309 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:58,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:46:58,769 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:02,268 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:02,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:03,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:03,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:03,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:06,162 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:47:07,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:07,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:08,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:08,423 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:08,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:12,266 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:12,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:13,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:13,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:13,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:17,268 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:17,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:12,679 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ijdtptzqau of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:53:14,849 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,849 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,850 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:47:18,309 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:18,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:18,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:22,269 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:22,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:23,309 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:23,422 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:23,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:24,355 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:47:24,356 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:47:27,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:27,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:28,312 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:28,427 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:28,772 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:32,274 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:32,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:33,310 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:33,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:33,771 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:36,163 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:47:37,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:37,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:38,312 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:38,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:38,774 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:42,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:42,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:43,310 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:43,428 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:43,766 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:47,275 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:47,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:48,307 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:48,429 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,851 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:47:48,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:52,273 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:52,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:53,313 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:53,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:53,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:54,356 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:47:54,356 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:47:57,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:57,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:58,313 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:58,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:47:58,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:02,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:02,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:03,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:03,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:03,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:06,167 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:48:07,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:07,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:08,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:08,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:08,765 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:12,270 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:12,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:13,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:13,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:13,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:17,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:17,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:18,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:18,425 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:18,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:22,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:56:27,908 [qtp1858015030-21] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:48:22,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:23,310 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:23,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:23,768 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:24,356 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:48:24,356 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:48:27,277 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:27,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:28,307 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:28,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:28,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:32,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:32,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:33,307 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:33,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:33,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:36,168 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:48:37,274 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:37,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:38,308 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:38,426 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:38,769 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:42,272 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:42,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:43,127 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]].
scm_1       | 2022-12-10 12:48:43,132 [IPC Server handler 17 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:48:43,306 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:43,424 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:43,767 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:44,316 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:44,330 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:44,655 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:44,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:45,525 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:46,367 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]].
scm_1       | 2022-12-10 12:48:46,377 [IPC Server handler 3 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:48:46,514 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:46,529 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:46,578 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:46,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:46,690 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 12:48:49,540 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]].
scm_1       | 2022-12-10 12:48:49,545 [IPC Server handler 43 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:48:49,618 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:49,640 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:49,690 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:49,797 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:49,805 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:54,357 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:48:54,364 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:48:54,618 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:54,637 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:54,691 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:54,803 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:54,803 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,445 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]].
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,852 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,853 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,854 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,855 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,856 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,857 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,858 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,858 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,858 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:48:57,465 [IPC Server handler 65 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:48:57,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,615 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,621 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,689 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,699 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,757 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]].
scm_1       | 2022-12-10 12:48:57,762 [IPC Server handler 7 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]] moved to OPEN state
scm_1       | 2022-12-10 12:48:57,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,899 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:48:57,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:02,814 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:56:36,899 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6889642163, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:49:02,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:02,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:02,898 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:02,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:06,169 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:49:07,814 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:07,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:07,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:07,897 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:07,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:12,817 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:12,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:12,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:12,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:17,815 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:17,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:17,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:17,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:17,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:22,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:22,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:22,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:22,897 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:22,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:24,365 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:49:24,367 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:49:27,815 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:27,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:27,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:27,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:27,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:32,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:32,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:32,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:32,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:36,174 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:49:37,815 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:37,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:37,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:37,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:37,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:42,815 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:42,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:42,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:42,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:42,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:47,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:47,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:47,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:47,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:47,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:52,817 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:52,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:52,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:52,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:52,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:54,366 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:49:54,367 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:49:57,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:57,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:57,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:57,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:49:57,903 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:02,817 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:02,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:02,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:02,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:02,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:56:39,781 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9004868281, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:56:47,360 [qtp1858015030-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4583828019, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:56:47,866 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-fpfawftzmc, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:56:51,854 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ufbnnznpsv, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:56:56,452 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9014437795, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:56:57,074 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3239661225, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:00,501 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5855071661, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:03,943 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0634222470, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | Dec 10, 2022 12:57:05 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:665)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:129)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:72)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:112)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1       | 	... 114 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2022-12-10 12:57:13,056 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg9, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,056 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg2, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,058 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg3, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg1, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg5, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg0, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg7, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:50:06,177 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:50:07,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:07,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:07,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:07,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:07,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:12,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:12,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:12,898 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:12,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:17,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:17,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:17,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:17,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:17,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:22,818 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:22,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:22,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:22,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:22,903 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:24,366 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:50:24,367 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:50:27,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:27,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:27,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:27,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:27,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:32,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:32,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:32,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:32,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:32,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:36,179 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:50:37,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:37,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:37,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:37,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:37,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:42,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:42,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:42,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:42,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:42,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:47,818 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:47,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:47,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:47,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:47,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:52,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:52,823 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:52,899 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:52,903 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:54,366 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:50:54,367 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:50:57,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:57,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:57,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:57,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:50:57,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:02,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:02,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:02,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:02,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:02,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:06,182 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:51:07,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:07,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:07,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:07,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg4, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,057 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg8, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,056 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg6, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,153 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg11, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,163 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg14, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,166 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg10, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,185 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg18, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,191 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg17, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,193 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg20, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,200 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg12, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,201 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg19, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,207 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg21, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,207 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg13, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,208 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg15, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,210 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg16, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,225 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg23, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,226 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg24, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,251 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg22, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,272 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg33, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,274 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg29, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,274 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg25, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,274 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg32, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,274 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg26, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,279 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg30, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,279 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg27, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,295 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg28, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,296 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg31, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,346 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg35, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,352 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg40, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,356 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg38, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,362 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg41, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,363 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg34, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,370 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg37, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,372 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg36, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm_1       | 2022-12-10 12:51:07,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:12,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:12,825 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:12,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:12,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:17,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:17,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:17,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:17,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:17,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:22,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:22,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:22,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:22,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:22,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:24,361 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 7 milliseconds for processing 7 containers.
scm_1       | 2022-12-10 12:51:24,368 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:51:24,368 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:51:27,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:27,825 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:27,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:27,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:27,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:32,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:32,825 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:32,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:32,899 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:32,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:36,186 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:51:37,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:37,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:37,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:37,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:37,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:57:13,362 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg43, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,376 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg45, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,362 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg39, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,374 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg42, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,395 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg47, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,399 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg50, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,403 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg49, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,403 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg48, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,407 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg51, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,408 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg44, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,409 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg46, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,427 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg52, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,438 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg53, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,449 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg54, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,452 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg57, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,454 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg58, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,455 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg56, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,456 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg55, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,456 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg61, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,450 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg59, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,457 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg60, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,462 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg62, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,500 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg64, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,501 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg68, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,513 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg70, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,514 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg67, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,514 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg65, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,529 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg63, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,536 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg69, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,546 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg74, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,543 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg75, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,552 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg71, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,557 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg73, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,557 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg72, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 2022-12-10 12:57:13,560 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg66, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,567 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg79, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,568 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg77, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,582 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg81, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,584 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg80, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,592 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg76, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,605 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg84, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,607 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg78, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,649 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg87, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,668 [qtp1858015030-1068] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg83, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,669 [qtp1858015030-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg85, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,671 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg86, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,672 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg82, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,679 [qtp1858015030-187] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg88, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,679 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg89, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,679 [qtp1858015030-184] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg90, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,698 [qtp1858015030-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg94, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,706 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg93, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,712 [qtp1858015030-182] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg91, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,723 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg92, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,724 [qtp1858015030-682] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg97, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,730 [qtp1858015030-681] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg96, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,734 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg99, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,735 [qtp1858015030-185] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg98, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:13,741 [qtp1858015030-183] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg95, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:57:16,674 [qtp1858015030-186] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2919117940, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:19,486 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0993215277, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:20,136 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-35103, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:29,673 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6565274452, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:44,150 [qtp1858015030-1067] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4337905199, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:49,774 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9689348547, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:58:56,224 [qtp1858015030-188] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2995952554, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-12-10 12:59:16,444 [qtp1858015030-1067] WARN server.HttpChannel: /bucket-ozone-test-2995952554/ozone-test-7527826492/putobject/custom-metadata/key2
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:51:42,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:42,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:42,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:42,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:42,908 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:47,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:47,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:47,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:47,900 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:47,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:52,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:52,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:52,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:52,902 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:52,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:51:54,368 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm_1       | 2022-12-10 12:51:54,368 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 2022-12-10 12:51:57,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 12:51:57,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 12:51:57,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 12:51:57,903 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:51:57,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:02,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:02,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
s3g_1       | 2022-12-10 12:59:16,445 [qtp1858015030-1067] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 12:52:02,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:02,904 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:02,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 2022-12-10 12:53:14,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:06,189 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:52:07,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 2022-12-10 12:53:14,896 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:07,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 2022-12-10 12:53:14,897 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:07,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:52:07,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,898 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,898 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,905 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,905 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 12:52:07,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:14,906 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,906 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:53:14,914 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-zcszkppsvn of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:53:27,302 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: to-be-deleted of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 12:52:12,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,806 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg2 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:52:12,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:52:12,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:52:12,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,814 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg7 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:52:12,908 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:52:17,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:52:17,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:52:17,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 2022-12-10 12:52:17,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,816 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg0 in volume:s3v
scm_1       | 2022-12-10 12:52:17,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:52:22,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:52:22,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:52:22,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:22,901 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:52:22,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:24,368 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:52:24,369 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:52:27,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 12:52:27,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:27,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:27,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:27,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:52:32,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:32,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:32,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 12:52:32,908 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:32,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:36,190 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:52:37,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:52:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:37,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:37,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:37,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:52:42,819 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:52:42,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:42,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:42,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 2022-12-10 12:53:50,818 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg5 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:52:42,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:52:47,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:47,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:47,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:52:47,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,822 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg4 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:52:47,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:52:52,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 12:52:52,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 12:52:52,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
scm_1       | 2022-12-10 12:52:52,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 12:52:52,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:52:54,369 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm_1       | 2022-12-10 12:52:54,369 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:53:50,823 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg1 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm_1       | 2022-12-10 12:52:57,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 12:52:57,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2022-12-10 12:52:57,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 12:52:57,927 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 12:52:57,927 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:53:02,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:53:02,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:53:02,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,826 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg8 in volume:s3v
scm_1       | 2022-12-10 12:53:02,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2022-12-10 12:53:02,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:53:06,191 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 12:53:07,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 12:53:07,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:53:07,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:07,908 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm_1       | 2022-12-10 12:53:07,909 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:12,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:12,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:53:12,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 2022-12-10 12:53:50,831 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg3 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:53:12,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:53:12,908 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:53:17,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:53:17,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,844 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg6 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:53:17,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:53:17,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:53:17,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:22,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:22,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:22,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 2022-12-10 12:53:22,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:22,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:24,369 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:53:24,370 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 12:53:27,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:53:27,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:27,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:27,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:27,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:53:32,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:53:32,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 2022-12-10 12:53:50,847 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg9 in volume:s3v
scm_1       | 2022-12-10 12:53:32,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:53:32,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:32,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:53:36,194 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:53:37,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
om_1        | 2022-12-10 12:53:50,876 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg10 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:53:37,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:53:37,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:37,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 2022-12-10 12:59:16,812 [qtp1858015030-188] WARN server.HttpChannel: /bucket-ozone-test-2995952554/ozone-test-7527826492/putobject/custom-metadata/key2
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:53:37,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,886 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg12 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:53:42,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:42,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:53:42,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:42,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:53:42,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,905 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg15 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:53:47,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:47,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:53:47,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 2022-12-10 12:53:50,909 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg17 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:53:47,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:47,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:53:52,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:52,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:53:52,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:52,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:52,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:54,369 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:53:50,924 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg14 in volume:s3v
scm_1       | 2022-12-10 12:53:54,370 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:53:57,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:57,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:57,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:57,907 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:53:57,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:54:02,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:02,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:02,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:02,906 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:54:02,910 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:06,195 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:54:07,821 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:07,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:54:07,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:07,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:07,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:12,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:54:12,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:12,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:12,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:12,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:17,823 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:17,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:54:17,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:17,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:17,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 2022-12-10 12:53:50,926 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg13 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:54:22,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:22,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:22,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:22,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:22,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:24,370 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:54:24,370 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:54:27,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:27,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:27,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:54:27,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:27,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:32,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:32,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:54:32,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:32,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 12:54:32,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 12:54:36,198 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:54:37,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,936 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg16 in volume:s3v
scm_1       | 2022-12-10 12:54:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:37,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:54:37,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:37,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:42,823 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:42,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm_1       | 2022-12-10 12:54:42,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:42,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:42,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:54:47,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:54:47,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:47,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:54:47,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:47,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:52,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:52,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:54:52,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:52,911 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 2022-12-10 12:53:50,940 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg11 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 12:54:52,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:54,370 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:54:54,370 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:54:57,822 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:57,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:54:57,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 2022-12-10 12:59:16,812 [qtp1858015030-188] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:54:57,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:54:57,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:02,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:02,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:02,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:55:02,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:02,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:06,199 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:55:07,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:07,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:07,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 2022-12-10 12:53:50,949 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg18 in volume:s3v
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:55:07,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:55:07,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:55:12,824 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:12,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:12,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:12,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:55:12,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:17,823 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:17,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:55:17,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm_1       | 2022-12-10 12:55:17,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:17,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:22,823 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:55:22,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:55:22,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 12:55:22,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:55:22,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:53:50,958 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg23 in volume:s3v
scm_1       | 2022-12-10 12:55:24,371 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:55:24,371 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:55:27,829 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:55:27,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:55:27,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:55:27,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:55:27,915 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:55:32,825 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:55:32,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 12:55:32,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 2022-12-10 12:53:50,965 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg25 in volume:s3v
scm_1       | 2022-12-10 12:55:32,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:55:32,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:55:36,200 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:55:37,825 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
scm_1       | 2022-12-10 12:55:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:55:37,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:37,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 12:55:37,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:55:42,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:55:42,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:55:42,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,969 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg21 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 12:55:42,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 12:55:42,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
scm_1       | 2022-12-10 12:55:47,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 12:55:47,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:55:47,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:50,985 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg20 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:55:47,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm_1       | 2022-12-10 12:55:47,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm_1       | 2022-12-10 12:55:52,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:55:52,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:52,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 12:55:52,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:52,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:55:54,371 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:55:54,371 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 2022-12-10 12:53:50,988 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg19 in volume:s3v
scm_1       | 2022-12-10 12:55:57,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:55:57,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:50,992 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg22 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:55:57,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:55:57,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:55:57,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:02,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:02,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 12:56:02,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:02,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:02,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:06,202 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	... 51 more
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:56:07,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:07,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:59:18,682 [qtp1858015030-1067] WARN server.HttpChannel: /bucket-ozone-test-2995952554/ozone-test-7527826492/putobject/custom-metadata/key2
scm_1       | 2022-12-10 12:56:07,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:56:07,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:07,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,000 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg27 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:56:12,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:56:12,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:56:12,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:56:12,912 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:56:12,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:56:17,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:56:17,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:56:17,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om_1        | 2022-12-10 12:53:51,008 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg24 in volume:s3v
scm_1       | 2022-12-10 12:56:17,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:56:17,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:56:22,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:56:22,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:56:22,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:56:22,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:22,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 2022-12-10 12:53:51,025 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg29 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
scm_1       | 2022-12-10 12:56:24,364 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 7 containers.
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
scm_1       | 2022-12-10 12:56:24,371 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:56:24,372 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:56:27,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:56:27,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:27,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:56:27,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:27,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:56:32,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:32,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:56:32,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:32,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:32,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:36,204 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 2022-12-10 12:53:51,046 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg34 in volume:s3v
scm_1       | 2022-12-10 12:56:37,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 12:56:37,830 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:56:37,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:37,913 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:56:37,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:56:42,828 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:42,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:56:42,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:56:42,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:42,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm_1       | 2022-12-10 12:56:47,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:47,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:47,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:47,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm_1       | 2022-12-10 12:56:47,927 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:52,826 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:52,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:56:52,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:56:52,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:56:52,924 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
scm_1       | 2022-12-10 12:56:54,372 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:56:54,372 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm_1       | 2022-12-10 12:56:57,827 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:56:57,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,052 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg36 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:56:57,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:56:57,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:56:57,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:57:02,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:57:02,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:57:02,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:57:02,914 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 12:57:02,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:57:06,205 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:57:07,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:57:07,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:07,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:07,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,057 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg35 in volume:s3v
scm_1       | 2022-12-10 12:57:07,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:12,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:12,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:12,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,068 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg33 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:57:12,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:57:12,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:17,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:17,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:17,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,072 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg26 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:57:17,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:57:17,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:57:22,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,085 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg37 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:57:22,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:22,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:57:22,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:22,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:57:24,372 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:57:24,372 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 2022-12-10 12:53:51,086 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg32 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:57:27,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:27,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:57:27,856 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:27,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:27,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 12:57:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:32,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,088 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg31 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:57:32,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:32,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:36,206 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:57:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:37,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:37,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:37,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:37,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:42,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:42,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:42,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:42,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 2022-12-10 12:53:51,091 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg39 in volume:s3v
scm_1       | 2022-12-10 12:57:42,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:57:47,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:57:47,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 12:57:47,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 2022-12-10 12:59:18,683 [qtp1858015030-1067] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 12:57:47,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:57:47,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:57:52,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:52,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:57:52,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:52,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:57:52,924 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:54,372 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 12:57:54,373 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:57:57,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:57:57,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:57,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:57,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:57:57,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:58:02,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:02,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,097 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg28 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:58:02,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:02,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:02,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:58:06,208 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:58:07,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:07,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,108 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg30 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,109 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg41 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:58:07,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:07,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:58:07,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:12,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:12,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:58:12,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:12,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:12,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:17,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
scm_1       | 2022-12-10 12:58:17,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:17,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,113 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg44 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:58:17,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,145 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg50 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:58:17,927 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:58:22,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,162 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg49 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:58:22,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:58:22,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:58:22,918 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:58:22,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | 2022-12-10 12:53:51,171 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg40 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:58:24,372 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:58:24,373 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:58:27,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:58:27,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:53:51,180 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg42 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:58:27,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:58:27,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:58:27,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:32,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:32,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:32,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:58:32,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:32,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:36,210 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 12:58:37,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 12:58:37,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:37,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:37,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:37,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:42,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:42,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:42,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:42,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:58:42,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:47,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:47,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:47,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:58:47,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:47,934 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm_1       | 2022-12-10 12:58:52,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:52,919 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:52,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:54,372 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:58:54,373 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 12:58:57,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:57,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:58:57,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:58:57,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg43 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 12:58:57,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:59:02,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:02,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:59:02,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 12:59:02,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 12:59:02,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:59:06,211 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:59:07,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:07,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 2022-12-10 12:53:51,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg38 in volume:s3v
scm_1       | 2022-12-10 12:59:07,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:59:07,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:59:07,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:12,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:59:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:59:12,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	... 17 more
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:59:12,920 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:12,936 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:59:17,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,189 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg51 in volume:s3v
scm_1       | 2022-12-10 12:59:17,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:59:17,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:59:17,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:17,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:59:22,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:59:22,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:59:22,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:59:22,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:59:22,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:24,373 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | 2022-12-10 12:53:51,193 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg47 in volume:s3v
scm_1       | 2022-12-10 12:59:24,373 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:59:27,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:59:27,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:27,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:59:27,927 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 12:59:27,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 12:59:32,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 12:59:32,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:32,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om_1        | 2022-12-10 12:53:51,193 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg45 in volume:s3v
scm_1       | 2022-12-10 12:59:32,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 12:59:32,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 12:59:36,221 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 12:59:37,831 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:37,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	... 51 more
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 12:59:37,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 2022-12-10 12:59:20,810 [qtp1858015030-188] WARN server.HttpChannel: /bucket-ozone-test-2995952554/ozone-test-7527826492/putobject/custom-metadata/key2
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 12:59:37,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 12:59:37,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 12:59:42,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 12:59:42,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 12:59:42,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,196 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg46 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 12:59:42,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 12:59:42,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 12:59:47,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 12:59:47,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 12:59:47,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm_1       | 2022-12-10 12:59:47,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 12:59:47,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 12:59:52,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 12:59:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,197 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg48 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm_1       | 2022-12-10 12:59:52,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 12:59:52,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:52,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:54,373 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:53:51,204 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg52 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 12:59:54,373 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm_1       | 2022-12-10 12:59:57,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 12:59:57,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 12:59:57,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 12:59:57,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 12:59:57,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg53 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm_1       | 2022-12-10 13:00:02,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 13:00:02,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 13:00:02,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 13:00:02,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:02,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,220 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg57 in volume:s3v
scm_1       | 2022-12-10 13:00:06,223 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:00:07,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:07,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,231 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg58 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:00:07,853 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:07,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 13:00:07,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
scm_1       | 2022-12-10 13:00:12,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:00:12,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 2022-12-10 12:53:51,243 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg59 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:00:12,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:00:12,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:12,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,245 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg56 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:00:17,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:17,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,255 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg55 in volume:s3v
scm_1       | 2022-12-10 13:00:17,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:17,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 13:00:17,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm_1       | 2022-12-10 13:00:22,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 2022-12-10 13:00:22,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 13:00:22,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 13:00:22,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,256 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg61 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:00:22,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:00:24,373 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 13:00:24,374 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	... 51 more
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 2022-12-10 12:59:20,811 [qtp1858015030-188] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 13:00:27,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:00:27,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 13:00:27,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:27,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 2022-12-10 12:53:51,260 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg60 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 13:00:27,933 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 13:00:32,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm_1       | 2022-12-10 13:00:32,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:00:32,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm_1       | 2022-12-10 13:00:32,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:00:32,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 13:00:36,224 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:37,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 13:00:37,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 13:00:37,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm_1       | 2022-12-10 13:00:37,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 13:00:37,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,264 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg54 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:00:42,833 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:42,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,265 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg64 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:00:42,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:00:42,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,293 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg67 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:00:42,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:47,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,296 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg65 in volume:s3v
scm_1       | 2022-12-10 13:00:47,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:00:47,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,297 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg71 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 13:00:47,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm_1       | 2022-12-10 13:00:47,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 13:00:52,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 13:00:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 13:00:52,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 13:00:52,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
scm_1       | 2022-12-10 13:00:52,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2022-12-10 13:00:54,374 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	... 17 more
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
scm_1       | 2022-12-10 13:00:54,374 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 13:00:57,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 13:00:57,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 13:00:57,863 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:00:57,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om_1        | 2022-12-10 12:53:51,298 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg68 in volume:s3v
scm_1       | 2022-12-10 13:00:57,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:01:02,832 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 13:01:02,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 13:01:02,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,300 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg69 in volume:s3v
scm_1       | 2022-12-10 13:01:02,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:01:02,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:01:06,225 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,312 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg63 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm_1       | 2022-12-10 13:01:07,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 13:01:07,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 13:01:07,854 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 51 more
scm_1       | 2022-12-10 13:01:07,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 2022-12-10 12:59:24,133 [qtp1858015030-1067] WARN server.HttpChannel: /bucket-ozone-test-2995952554/ozone-test-7527826492/putobject/custom-metadata/key2
scm_1       | 2022-12-10 13:01:07,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,316 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg62 in volume:s3v
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:01:12,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
scm_1       | 2022-12-10 13:01:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:01:12,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:01:12,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:01:12,933 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
om_1        | 2022-12-10 12:53:51,319 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg70 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
scm_1       | 2022-12-10 13:01:17,834 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:01:17,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:01:17,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 13:01:17,923 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:17,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,327 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg66 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 13:01:22,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:22,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:01:22,856 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:01:22,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg77 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm_1       | 2022-12-10 13:01:22,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:24,365 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 7 containers.
scm_1       | 2022-12-10 13:01:24,374 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:01:24,375 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:01:27,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:27,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
scm_1       | 2022-12-10 13:01:27,856 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:27,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:01:27,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:32,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm_1       | 2022-12-10 13:01:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:32,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:32,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:32,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm_1       | 2022-12-10 13:01:36,226 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:01:37,835 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:01:37,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:37,856 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:37,921 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:37,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,338 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg78 in volume:s3v
scm_1       | 2022-12-10 13:01:42,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:42,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:42,868 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm_1       | 2022-12-10 13:01:42,924 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:42,933 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm_1       | 2022-12-10 13:01:47,836 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:47,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,361 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg72 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:01:47,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:47,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm_1       | 2022-12-10 13:01:47,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:52,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:52,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm_1       | 2022-12-10 13:01:52,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:01:52,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:52,941 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,362 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg75 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:01:54,374 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:01:54,375 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:01:57,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:57,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:57,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	... 17 more
scm_1       | 2022-12-10 13:01:57,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:01:57,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:02:02,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:02:02,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,364 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg80 in volume:s3v
scm_1       | 2022-12-10 13:02:02,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:02:02,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:02:02,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:02:06,228 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:02:07,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:02:07,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:07,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:07,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:07,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2022-12-10 13:02:12,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:12,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:12,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:12,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm_1       | 2022-12-10 13:02:12,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:02:17,837 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:17,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,368 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg76 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:02:17,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:17,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:17,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 13:02:22,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,370 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg83 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:02:22,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:22,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 13:02:22,924 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:22,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:24,375 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:02:24,375 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:02:27,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:27,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:02:27,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm_1       | 2022-12-10 13:02:27,924 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm_1       | 2022-12-10 13:02:27,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm_1       | 2022-12-10 13:02:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 13:02:32,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm_1       | 2022-12-10 13:02:32,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,382 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg79 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm_1       | 2022-12-10 13:02:32,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 13:02:32,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm_1       | 2022-12-10 13:02:36,229 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm_1       | 2022-12-10 13:02:37,838 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm_1       | 2022-12-10 13:02:37,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	... 51 more
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 2022-12-10 12:59:24,134 [qtp1858015030-1067] WARN server.HttpChannelState: unhandled due to prior sendError
scm_1       | 2022-12-10 13:02:37,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:02:37,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm_1       | 2022-12-10 13:02:37,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
scm_1       | 2022-12-10 13:02:42,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,386 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg74 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
scm_1       | 2022-12-10 13:02:42,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:02:42,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2022-12-10 13:02:42,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm_1       | 2022-12-10 13:02:42,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:02:47,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:02:47,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:02:47,863 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm_1       | 2022-12-10 13:02:47,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:02:47,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,388 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg81 in volume:s3v
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm_1       | 2022-12-10 13:02:52,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm_1       | 2022-12-10 13:02:52,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:02:52,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | Caused by: javax.servlet.ServletException: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:02:52,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:02:52,937 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:410)
scm_1       | 2022-12-10 13:02:54,375 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:02:54,376 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm_1       | 2022-12-10 13:02:57,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm_1       | 2022-12-10 13:02:57,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm_1       | 2022-12-10 13:02:57,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:02:57,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:02:57,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om_1        | 2022-12-10 12:53:51,389 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg82 in volume:s3v
scm_1       | 2022-12-10 13:03:02,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:02,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:02,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:03:02,925 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
om_1        | 2022-12-10 12:53:51,391 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg73 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1681)
scm_1       | 2022-12-10 13:03:02,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm_1       | 2022-12-10 13:03:06,230 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 13:03:07,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
scm_1       | 2022-12-10 13:03:07,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
scm_1       | 2022-12-10 13:03:07,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2022-12-10 13:03:07,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om_1        | 2022-12-10 12:53:51,397 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg85 in volume:s3v
scm_1       | 2022-12-10 13:03:07,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:12,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:12,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:03:12,858 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:12,926 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:03:12,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm_1       | 2022-12-10 13:03:17,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | Caused by: java.lang.IllegalArgumentException: Illegal user defined metadata. Combined size cannot exceed 2KB.
scm_1       | 2022-12-10 13:03:17,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getCustomMetadataFromHeaders(EndpointBase.java:291)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:214)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
scm_1       | 2022-12-10 13:03:17,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2022-12-10 12:53:51,420 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg86 in volume:s3v
scm_1       | 2022-12-10 13:03:17,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:17,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm_1       | 2022-12-10 13:03:22,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm_1       | 2022-12-10 13:03:22,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm_1       | 2022-12-10 13:03:22,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,435 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg87 in volume:s3v
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:22,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm_1       | 2022-12-10 13:03:22,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm_1       | 2022-12-10 13:03:24,376 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm_1       | 2022-12-10 13:03:24,376 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm_1       | 2022-12-10 13:03:27,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:27,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 51 more
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,447 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg92 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:03:27,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:27,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:03:27,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,458 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg84 in volume:s3v
scm_1       | 2022-12-10 13:03:32,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:32,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:32,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:03:32,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:03:32,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:36,232 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:03:37,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:03:37,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:03:37,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,467 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg88 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:37,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:37,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:03:42,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:03:42,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:42,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:03:42,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:03:42,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:03:47,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,469 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg91 in volume:s3v
scm_1       | 2022-12-10 13:03:47,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:03:47,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:47,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:47,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:03:52,840 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:52,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:03:52,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:03:52,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,475 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg95 in volume:s3v
scm_1       | 2022-12-10 13:03:52,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:03:54,376 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:03:54,376 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:03:57,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:03:57,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:03:57,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:03:57,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:03:57,938 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:02,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:02,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:02,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:02,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:04:02,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,477 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg90 in volume:s3v
scm_1       | 2022-12-10 13:04:06,236 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:04:07,839 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:04:07,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:07,859 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:07,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:07,950 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:04:12,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,484 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg89 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:12,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:12,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:12,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:04:12,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:04:17,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:04:17,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,488 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg93 in volume:s3v
scm_1       | 2022-12-10 13:04:17,861 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:17,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:04:17,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:04:22,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:22,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:22,862 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:04:22,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:22,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:24,377 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,495 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg96 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:04:24,377 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:04:27,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:27,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:27,860 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:04:27,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:04:27,947 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:04:31,544 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]].
om_1        | 2022-12-10 12:53:51,497 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg97 in volume:s3v
scm_1       | 2022-12-10 13:04:32,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:04:32,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:04:32,861 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:04:32,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:04:32,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:33,537 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:36,237 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:04:37,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:04:37,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:04:37,932 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,507 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg99 in volume:s3v
scm_1       | 2022-12-10 13:04:37,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:04:38,531 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:04:42,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:04:42,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:04:42,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:53:51,510 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg98 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2022-12-10 13:04:42,939 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
scm_1       | 2022-12-10 13:04:43,534 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:04:47,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:04:47,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:53:51,513 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg94 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:04:47,929 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:04:47,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:04:48,531 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:52,841 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:04:52,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 13:04:52,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:52,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 13:04:53,533 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:54,377 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:04:54,377 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:04:57,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:57,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:57,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:57,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:04:58,534 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:02,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:02,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:02,931 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:02,941 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:03,532 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:06,240 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:05:07,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:07,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 13:05:07,930 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:07,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:08,527 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1, current state: OPEN
scm_1       | 2022-12-10 13:05:08,532 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:12,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 13:05:12,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:12,940 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:05:12,941 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:13,532 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:13,963 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:05:14,009 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 13:05:14,021 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 13:05:14,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:13,086 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /legacy/source-bucket/ozone-test-2623936947/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
scm_1       | 2022-12-10 13:05:14,040 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
om_1        | 2022-12-10 12:54:13,086 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2623936947/multipartKey2 in Volume/Bucket legacy/source-bucket
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-2623936947/multipartKey2. Entity too small.
scm_1       | 2022-12-10 13:05:14,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
scm_1       | 2022-12-10 13:05:14,072 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:05:17,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:05:17,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:14,379 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/ozone-test-3841979385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-12-10 12:54:14,379 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3841979385/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-3841979385/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
scm_1       | 2022-12-10 13:05:19,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:19,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:19,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:05:22,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:22,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:05:24,036 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:24,037 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:05:24,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:24,377 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:05:24,378 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:05:27,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:27,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:05:29,032 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:29,037 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:05:29,048 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:32,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:32,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:14,993 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/ozone-test-3841979385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
scm_1       | 2022-12-10 13:05:34,037 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:34,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | partName: "etag1"
scm_1       | 2022-12-10 13:05:34,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:36,241 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | , partNumber: 1
scm_1       | 2022-12-10 13:05:37,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:37,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:39,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:39,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | partName: "etag2"
scm_1       | 2022-12-10 13:05:39,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:42,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | ]
scm_1       | 2022-12-10 13:05:42,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:44,033 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:14,994 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3841979385/multipartKey3 in Volume/Bucket legacy/source-bucket
scm_1       | 2022-12-10 13:05:44,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:44,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-3841979385/multipartKey3
scm_1       | 2022-12-10 13:05:47,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:47,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
scm_1       | 2022-12-10 13:05:49,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:49,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:05:49,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:52,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:05:52,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:54,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:05:54,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:54,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:05:54,378 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:05:54,378 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:05:57,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:05:57,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:58,125 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 96ebd449-ccfc-4faf-8e5b-cb01ba603b2a, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:05:58.122Z[UTC]].
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:05:59,035 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:05:59,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:05:59,048 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:02,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:02,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:18,418 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3841979385/multipartKey3 in Volume/Bucket legacy/source-bucket
scm_1       | 2022-12-10 13:06:04,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:04,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-3841979385/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /legacy/source-bucket/ozone-test-3841979385/multipartKey3-1324e2e0-70b9-42cd-bec1-22093144d049-109489478285983966-1
scm_1       | 2022-12-10 13:06:04,054 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:06,242 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:06:07,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:07,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
scm_1       | 2022-12-10 13:06:09,035 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:09,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
scm_1       | 2022-12-10 13:06:09,055 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:12,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:06:12,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:14,036 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:06:14,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:14,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:06:17,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:17,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:06:19,035 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:06:19,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:19,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:22,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:22,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:24,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:06:24,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:24,051 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:06:24,372 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 7 milliseconds for processing 8 containers.
om_1        | 2022-12-10 12:54:19,004 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3841979385/multipartKey3 in Volume/Bucket legacy/source-bucket
scm_1       | 2022-12-10 13:06:24,378 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-3841979385/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /legacy/source-bucket/ozone-test-3841979385/multipartKey3-1324e2e0-70b9-42cd-bec1-22093144d049-109489478285983966-2
scm_1       | 2022-12-10 13:06:24,378 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
scm_1       | 2022-12-10 13:06:25,618 [IPC Server handler 1 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 96ebd449-ccfc-4faf-8e5b-cb01ba603b2a, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:05:58.122Z[UTC]] moved to CLOSED state
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
scm_1       | 2022-12-10 13:06:27,842 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:06:27,857 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:06:29,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:06:29,043 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:06:29,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:06:32,843 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:06:32,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:19,603 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /legacy/source-bucket/ozone-test-3841979385/multipartKey3
scm_1       | 2022-12-10 13:06:34,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:19,604 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-3841979385/multipartKey3 in Volume/Bucket legacy/source-bucket
scm_1       | 2022-12-10 13:06:34,040 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-3841979385/multipartKey3 because parts are in Invalid order.
scm_1       | 2022-12-10 13:06:34,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
scm_1       | 2022-12-10 13:06:36,246 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
scm_1       | 2022-12-10 13:06:37,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:06:37,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:06:39,033 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:06:39,040 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:06:39,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:23,020 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0986383548/multipartKey5 in VolumeName/Bucket legacy/source-bucket
scm_1       | 2022-12-10 13:06:42,657 [IPC Server handler 3 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: linkkey: ozone-test-0986383548/multipartKey5
scm_1       | 2022-12-10 13:06:42,658 [Over Replicated Processor] WARN replication.OverReplicatedProcessor: Over Replicated Processor interrupted. Exiting...
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
scm_1       | 2022-12-10 13:06:42,658 [Under Replicated Processor] WARN replication.UnderReplicatedProcessor: Under Replicated Processor interrupted. Exiting...
scm_1       | 2022-12-10 13:06:42,660 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:06:42,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:42,849 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:06:44,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:44,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:06:44,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:47,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:06:47,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:49,035 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:06:49,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:49,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:06:49,892 [IPC Server handler 13 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2022-12-10 13:06:49,901 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:06:49,901 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:54:23,648 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:link, Key:ozone-test-7203867991/multipartKey. 
scm_1       | 2022-12-10 13:06:49,903 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 8 containers.
scm_1       | 2022-12-10 13:06:52,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
scm_1       | 2022-12-10 13:06:52,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:54,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
scm_1       | 2022-12-10 13:06:54,040 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:54,049 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
scm_1       | 2022-12-10 13:06:57,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:57,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
scm_1       | 2022-12-10 13:06:59,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:06:59,041 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
scm_1       | 2022-12-10 13:06:59,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:02,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:07:02,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:04,033 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:07:04,041 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:04,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:07:06,247 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:07:07,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2022-12-10 13:07:07,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:09,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:09,039 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:09,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:07:12,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:12,855 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2022-12-10 13:07:14,044 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:14,045 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:14,050 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:54:32,279 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:17,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:17,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:19,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:19,041 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:19,059 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,280 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:19,903 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:07:19,903 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:22,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:22,850 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:24,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:24,041 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:24,052 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:27,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:27,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:29,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:29,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:29,051 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:32,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:32,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:34,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:34,042 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:34,051 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:36,087 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:36,088 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:36,114 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:36,249 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:37,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:37,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,281 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:41,076 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:41,085 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,282 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:41,114 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:42,845 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,282 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:42,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:46,075 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,282 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:46,085 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:46,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:47,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:47,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:49,903 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:49,903 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:07:51,076 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:51,088 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:51,116 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:52,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:52,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:56,083 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:56,087 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:56,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:07:57,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:07:57,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:01,077 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:01,086 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:01,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:02,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:02,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:06,076 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,283 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:06,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:06,250 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:54:32,284 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:07,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:07,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,284 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:11,077 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:11,114 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:12,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:12,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:16,079 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:16,116 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:17,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:17,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:19,903 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:08:19,903 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:08:21,077 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:21,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:22,848 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:22,856 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:26,077 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:26,114 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,290 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:27,847 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:27,851 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:31,078 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:31,115 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:32,846 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:32,852 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:33,067 [EventQueue-StaleNodeForStaleNodeHandler] INFO node.StaleNodeHandler: Datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924, PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767, PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e, PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7, PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e, PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14, PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545]
scm_1       | 2022-12-10 13:08:33,076 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 13:08:33,079 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #7 closed for pipeline=PipelineID=b8bc09df-dadd-4e20-b0dd-aa5dd3091f85
scm_1       | 2022-12-10 13:08:33,079 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7, current state: CLOSING
scm_1       | 2022-12-10 13:08:33,095 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 13:08:33,105 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8, current state: CLOSING
scm_1       | 2022-12-10 13:08:33,105 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #8 closed for pipeline=PipelineID=10b214c8-c2b7-46b6-bfa5-db40a75ae767
scm_1       | 2022-12-10 13:08:33,124 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]] moved to CLOSED state
om_1        | 2022-12-10 12:54:32,291 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,128 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #5 closed for pipeline=PipelineID=7677adbd-518e-490d-92bc-3540511fbb8e
scm_1       | 2022-12-10 13:08:33,128 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5, current state: CLOSING
om_1        | 2022-12-10 12:54:32,291 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,135 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]] moved to CLOSED state
om_1        | 2022-12-10 12:54:32,291 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,138 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #3 closed for pipeline=PipelineID=8945e1f8-547e-4f81-890c-99f15b8e2cc7
scm_1       | 2022-12-10 13:08:33,138 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3, current state: CLOSING
om_1        | 2022-12-10 12:54:32,292 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,142 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 13:08:33,145 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #9 closed for pipeline=PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e
scm_1       | 2022-12-10 13:08:33,145 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9, current state: CLOSING
scm_1       | 2022-12-10 13:08:33,148 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] moved to CLOSED state
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,151 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #6 closed for pipeline=PipelineID=499f4c46-a7d5-4149-8020-68a055ba8e14
scm_1       | 2022-12-10 13:08:33,151 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6, current state: CLOSING
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,156 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 13:08:33,160 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Container #4 closed for pipeline=PipelineID=44471292-fff8-4b43-a7f8-42cd8111e545
scm_1       | 2022-12-10 13:08:33,160 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4, current state: CLOSING
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:33,168 [EventQueue-StaleNodeForStaleNodeHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]] moved to CLOSED state
scm_1       | 2022-12-10 13:08:36,077 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:36,116 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:36,251 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 to datanode:44877e3e-f8e0-4fab-9c03-bb94f29d2e65
scm_1       | 2022-12-10 13:08:36,253 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 to datanode:eb6b06af-1f2c-4397-8743-5d103932e2bb
scm_1       | 2022-12-10 13:08:36,253 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=283d1058-72b4-45d6-919c-18ddcf3cc495 to datanode:213470ee-8924-4d24-82c9-a8e7505514cd
om_1        | 2022-12-10 12:54:32,293 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:36,256 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 283d1058-72b4-45d6-919c-18ddcf3cc495, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:08:36.251Z[UTC]].
scm_1       | 2022-12-10 13:08:36,257 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,084 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,094 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,094 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #7 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:08:37,103 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,127 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,127 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,127 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #5 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:08:37,157 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,167 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,167 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #3 to CLOSED state, datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:08:37,172 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,178 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,201 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,202 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,211 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,211 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #9 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:08:37,226 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,226 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,226 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #6 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:08:37,230 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,235 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,239 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,255 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,256 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #4 to CLOSED state, datanode 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:37,265 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,476 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:37,694 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,864 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:38,870 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,886 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,893 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,899 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,905 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,928 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,952 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,953 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,965 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,965 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:38,979 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,981 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:38,998 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:39,021 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,294 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:39,021 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:39,032 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:39,038 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:39,053 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:39,067 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:42,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:42,282 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:44,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:44,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:47,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:47,276 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:49,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:49,064 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:49,904 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,295 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,296 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,296 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,296 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,296 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,296 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:08:49,904 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:08:52,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:52,277 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:54,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:54,064 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:57,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:57,276 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:59,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:08:59,064 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:02,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,297 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,297 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,297 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,298 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,298 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,298 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:02,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:03,069 [EventQueue-DeadNodeForDeadNodeHandler] INFO node.DeadNodeHandler: A dead datanode is detected. 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 13:09:03,071 [EventQueue-DeadNodeForDeadNodeHandler] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 close command to datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 13:09:03,083 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 914e75cc-e1b0-4c3b-bff3-d18c7b531924, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T12:26:34.094Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,086 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: b8bc09df-dadd-4e20-b0dd-aa5dd3091f85, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:57.752Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,090 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 10b214c8-c2b7-46b6-bfa5-db40a75ae767, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T13:04:31.539Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,095 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 7677adbd-518e-490d-92bc-3540511fbb8e, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:49.537Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,097 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 8945e1f8-547e-4f81-890c-99f15b8e2cc7, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:43.118Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,099 [EventQueue-DeadNodeForDeadNodeHandler] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e close command to datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 13:09:03,100 [EventQueue-DeadNodeForDeadNodeHandler] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e close command to datanode 213470ee-8924-4d24-82c9-a8e7505514cd
scm_1       | 2022-12-10 13:09:03,101 [EventQueue-DeadNodeForDeadNodeHandler] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e close command to datanode c93c8eed-0198-45d8-87bc-3d7834e7dd79
scm_1       | 2022-12-10 13:09:03,104 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: c0524777-5948-4be0-b34b-af81ed93fe6e, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:c93c8eed-0198-45d8-87bc-3d7834e7dd79, CreationTimestamp2022-12-10T12:26:35.909Z[UTC]] removed.
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,299 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:03,108 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 499f4c46-a7d5-4149-8020-68a055ba8e14, Nodes: 213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:57.441Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,113 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 44471292-fff8-4b43-a7f8-42cd8111e545, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}c93c8eed-0198-45d8-87bc-3d7834e7dd79{ip: 172.19.0.4, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T12:48:46.364Z[UTC]] removed.
scm_1       | 2022-12-10 13:09:03,116 [EventQueue-DeadNodeForDeadNodeHandler] INFO net.NetworkTopologyImpl: Removed a node: /default-rack/85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 13:09:04,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:04,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:06,258 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1       | 2022-12-10 13:09:07,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:07,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:07,280 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e is not found
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:07,280 [IPC Server handler 20 on default port 9860] INFO ipc.Server: IPC Server handler 20 on default port 9860, call Call#103 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.19.0.3:35586
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e not found
om_1        | 2022-12-10 12:54:32,300 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:157)
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:139)
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2022-12-10 12:54:32,301 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,302 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,302 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,302 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,302 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,304 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,305 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,305 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,305 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,305 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,305 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:87)
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:72)
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at com.sun.proxy.$Proxy18.getPipeline(Unknown Source)
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,306 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:274)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:693)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:870)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:583)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:09,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:09,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:12,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:12,277 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,307 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:14,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:14,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:17,263 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:17,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:19,034 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:19,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:19,904 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:09:19,904 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:09:22,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:54:32,308 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:54:32,308 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 13:09:22,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:24,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:24,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:27,257 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:27,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:29,027 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:29,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:32,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:32,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:34,030 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:34,069 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:36,259 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:09:37,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:37,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:39,029 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 13:09:39,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 13:09:42,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:42,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 13:09:42,961 [IPC Server handler 18 on default port 9860] INFO ipc.Server: IPC Server handler 18 on default port 9860, call Call#105 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.19.0.3:45264
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 not found
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:157)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:139)
scm_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:72)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 	at com.sun.proxy.$Proxy18.getPipeline(Unknown Source)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:274)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:693)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:870)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:583)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 2022-12-10 12:55:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 13:09:42,969 [IPC Server handler 72 on default port 9860] INFO ipc.Server: IPC Server handler 72 on default port 9860, call Call#106 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.19.0.3:45264
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e not found
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:157)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:139)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
scm_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:87)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:72)
scm_1       | 	at com.sun.proxy.$Proxy18.getPipeline(Unknown Source)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:274)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:693)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:870)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:583)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 2022-12-10 12:55:08,346 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-49142 of layout LEGACY in volume: s3v
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2022-12-10 13:09:43,573 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:43,583 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 283d1058-72b4-45d6-919c-18ddcf3cc495, Nodes: 44877e3e-f8e0-4fab-9c03-bb94f29d2e65{ip: 172.19.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}213470ee-8924-4d24-82c9-a8e7505514cd{ip: 172.19.0.5, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:eb6b06af-1f2c-4397-8743-5d103932e2bb, CreationTimestamp2022-12-10T13:08:36.251Z[UTC]] moved to OPEN state
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:43,866 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 is not found
scm_1       | 2022-12-10 13:09:43,867 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e is not found
scm_1       | 2022-12-10 13:09:43,915 [IPC Server handler 18 on default port 9860] INFO ipc.Server: IPC Server handler 18 on default port 9860, call Call#107 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.19.0.3:45264
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:157)
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:139)
scm_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:72)
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at com.sun.proxy.$Proxy18.getPipeline(Unknown Source)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:274)
om_1        | 2022-12-10 12:55:24,813 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:693)
om_1        | 2022-12-10 12:55:24,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:870)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:583)
om_1        | 2022-12-10 12:55:24,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
om_1        | 2022-12-10 12:55:24,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 2022-12-10 12:55:24,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 2022-12-10 12:55:24,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2022-12-10 13:09:43,920 [IPC Server handler 72 on default port 9860] INFO ipc.Server: IPC Server handler 72 on default port 9860, call Call#108 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.19.0.3:45264
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e not found
om_1        | 2022-12-10 12:55:24,816 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:157)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:139)
om_1        | 2022-12-10 12:55:24,816 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
scm_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:87)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:72)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at com.sun.proxy.$Proxy18.getPipeline(Unknown Source)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:274)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:693)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:870)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:583)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2022-12-10 12:55:24,817 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:44,067 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:45,844 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:45,845 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=914e75cc-e1b0-4c3b-bff3-d18c7b531924 is not found
scm_1       | 2022-12-10 13:09:45,845 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=c0524777-5948-4be0-b34b-af81ed93fe6e is not found
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:46,890 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:46,922 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:46,933 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:46,952 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:46,952 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #8 to CLOSED state, datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-12-10 13:09:46,959 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:46,981 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:46,989 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,818 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:47,008 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:47,017 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:47,162 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:47,189 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:47,206 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:47,226 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:47,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:47,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:47,344 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:48,078 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:48,080 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 13:09:48,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:49,067 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:49,904 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:49,904 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:09:51,079 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1       | 2022-12-10 13:09:51,079 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-12-10 13:09:51,080 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4bdf5060-2d04-4557-9c86-f3435b17aa3b to datanode:85e9a0c6-8631-4fee-9b9c-0f8004d778ef
scm_1       | 2022-12-10 13:09:51,084 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4bdf5060-2d04-4557-9c86-f3435b17aa3b, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-12-10T13:09:51.080Z[UTC]].
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:51,087 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:09:52,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:52,278 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:52,337 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:53,501 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:53,508 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4bdf5060-2d04-4557-9c86-f3435b17aa3b, Nodes: 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:85e9a0c6-8631-4fee-9b9c-0f8004d778ef, CreationTimestamp2022-12-10T13:09:51.080Z[UTC]] moved to OPEN state
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:53,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:54,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:57,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:57,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:58,500 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,819 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:58,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:09:58,679 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:09:59,064 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:02,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:02,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:03,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:03,677 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:04,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:07,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:07,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:08,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:08,679 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:09,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:12,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:12,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:13,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:13,680 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:14,067 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:17,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,820 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:17,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:18,571 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:18,677 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:19,070 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:19,904 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:19,906 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:21,090 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,821 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:22,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:22,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:23,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:23,681 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:24,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:27,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:27,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:28,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:28,677 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,822 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:29,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:32,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:32,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:33,572 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:33,678 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:34,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:37,258 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:37,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:38,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:38,678 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:39,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:42,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:42,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:43,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:43,679 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,823 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:44,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:47,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:47,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:48,568 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:48,679 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:49,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:49,906 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:10:49,906 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:51,092 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:52,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:52,280 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:53,569 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:53,683 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,824 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:54,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:57,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:57,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:58,568 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:10:58,683 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:10:59,066 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:02,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:02,279 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:03,570 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,825 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:03,683 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,826 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:04,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,827 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:04,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:04,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:04,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:07,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:08,686 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:09,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:09,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:09,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,828 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:12,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:13,684 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:14,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,829 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,830 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:14,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:14,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:17,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:18,682 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:24,831 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:11:19,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:55:25,471 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:thereisnosuchfile.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm_1       | 2022-12-10 13:11:19,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 2022-12-10 13:11:19,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:11:19,906 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:11:19,906 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:55:28,108 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:ozone-test-8533783628/deletetestapidir/key=value/.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm_1       | 2022-12-10 13:11:21,093 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
scm_1       | 2022-12-10 13:11:22,259 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
scm_1       | 2022-12-10 13:11:23,681 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:24,075 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=96ebd449-ccfc-4faf-8e5b-cb01ba603b2a since it stays at CLOSED stage.
scm_1       | 2022-12-10 13:11:24,078 [de14337a-ef52-472b-bd3f-7050a14dd151@group-CEE2A0F43436-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 96ebd449-ccfc-4faf-8e5b-cb01ba603b2a, Nodes: eb6b06af-1f2c-4397-8743-5d103932e2bb{ip: 172.19.0.10, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-12-10T13:05:58.122Z[UTC]] removed.
scm_1       | 2022-12-10 13:11:24,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:24,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:24,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
scm_1       | 2022-12-10 13:11:27,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2022-12-10 13:11:28,685 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:55:31,413 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:ozone-test-8533783628/deletetestapiprefix/key=value/file.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:55:53,662 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:ozone-test-4426936352/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:56:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 13:11:29,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 13:11:29,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 13:11:29,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 13:11:32,266 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:33,686 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:34,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:34,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:34,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:37,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:38,684 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 13:11:39,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:39,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:11:39,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:42,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:43,685 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:44,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:44,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:44,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:47,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:48,683 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 13:11:49,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:49,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:11:49,906 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:11:49,932 [ReplicationMonitor] INFO replication.LegacyReplicationManager: Sending delete container command for container #8 to datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-12-10 13:11:49,925 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:11:49,941 [ReplicationMonitor] INFO replication.LegacyReplicationManager: Sending close container command for container #9 to datanode 85e9a0c6-8631-4fee-9b9c-0f8004d778ef{ip: 172.19.0.9, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
scm_1       | 2022-12-10 13:11:49,941 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 37 milliseconds for processing 10 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:11:51,094 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:11:52,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2022-12-10 13:11:53,684 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 13:11:54,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 13:11:54,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 13:11:54,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:56:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-12-10 13:11:54,689 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2022-12-10 13:11:54,710 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2022-12-10 13:11:57,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2022-12-10 13:11:59,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2022-12-10 13:11:59,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2022-12-10 13:11:59,389 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
scm_1       | 2022-12-10 13:11:59,713 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:02,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
scm_1       | 2022-12-10 13:12:04,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:04,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
scm_1       | 2022-12-10 13:12:04,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:04,708 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:07,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
scm_1       | 2022-12-10 13:12:09,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:09,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2022-12-10 13:12:09,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:09,709 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:12,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:14,329 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:02,965 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=1, localID=109611004723200401}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key ozone-test-8026277223/putobject/key=value/zerobyte.
scm_1       | 2022-12-10 13:12:14,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:14,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:14,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:36,903 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6889642163 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 13:12:17,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:19,334 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:39,784 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9004868281 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 13:12:19,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:19,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,363 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4583828019 of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 13:12:19,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:19,934 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:56:47,872 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-fpfawftzmc of layout LEGACY in volume: s3v
scm_1       | 2022-12-10 13:12:19,936 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:12:21,096 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:12:22,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:24,327 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:24,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:24,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:24,709 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:27,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:29,329 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:29,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:29,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:29,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:32,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:34,327 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:34,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:34,386 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:34,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:37,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:39,327 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:39,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:39,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:39,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:42,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:44,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:44,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:44,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:44,713 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:47,260 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:49,329 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:49,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:49,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:49,935 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:49,936 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:12:51,098 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:52,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:54,329 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:54,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:54,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:54,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:57,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:59,330 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:59,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:12:59,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:12:59,717 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:02,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:04,330 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:04,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:04,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:04,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:07,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:09,331 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:09,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:09,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:09,713 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:12,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:14,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:14,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:14,387 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:14,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:17,267 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:19,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:19,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:19,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:19,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:19,935 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:13:19,937 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:13:21,099 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:22,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:24,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:24,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:24,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:24,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:27,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:29,335 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:29,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:29,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:29,719 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:32,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:34,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:34,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:34,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:34,717 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:37,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:39,335 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:39,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:39,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:39,719 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:42,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:44,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:44,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:44,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:44,722 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:47,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:49,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:49,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:49,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:49,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:49,936 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1       | 2022-12-10 13:13:49,937 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:51,100 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2022-12-10 13:13:52,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:54,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:54,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:54,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:54,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:57,261 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:59,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:59,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:13:59,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:13:59,717 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:02,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:04,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:04,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:04,386 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:04,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:07,262 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:09,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:09,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:09,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:09,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:12,263 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:14,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:14,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:14,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:14,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:17,265 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:19,339 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:19,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:19,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:19,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:19,936 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:19,937 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1       | 2022-12-10 13:14:21,101 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:22,263 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:24,333 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:24,386 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:24,388 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:24,716 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:27,263 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:29,334 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:29,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:29,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:29,718 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:32,264 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:34,332 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:34,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:34,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:34,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:37,263 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:39,334 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:39,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
scm_1       | 2022-12-10 13:14:39,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
scm_1       | 2022-12-10 13:14:39,718 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,952 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:47,953 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:56:51,856 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ufbnnznpsv of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:56:56,455 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9014437795 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:56:57,078 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3239661225 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:57:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:00,504 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5855071661 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:57:03,946 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0634222470 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:57:13,062 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg9 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,063 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg2 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,069 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg7 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,077 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg0 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,079 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg4 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,080 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg1 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,083 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg6 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,086 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg5 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,087 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg8 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,091 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg3 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,156 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg11 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,170 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg14 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,171 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg10 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,187 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg18 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,198 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg20 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg12 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,210 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg21 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,214 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg19 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,215 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg15 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,216 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg13 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,216 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg16 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,217 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg17 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,230 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg24 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,237 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg23 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,253 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg22 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,278 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg32 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,281 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg29 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,284 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg26 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,284 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg25 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,287 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg33 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,287 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg30 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,289 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg27 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,303 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg28 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,303 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg31 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,348 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg35 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,355 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg40 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,360 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg38 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,368 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg34 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,369 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg41 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,373 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg37 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,377 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg36 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,382 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg45 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,386 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg39 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,393 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg43 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,394 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg42 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,397 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg47 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,413 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg50 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,414 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg51 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,417 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg48 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,418 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg49 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,419 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg46 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,420 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg44 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,440 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg52 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,462 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg53 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,465 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg57 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,465 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg54 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,468 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg61 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,469 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg55 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,470 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg56 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,471 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg58 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,472 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg60 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,473 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg59 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,474 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg62 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,505 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg68 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,507 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg64 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,518 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg70 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,524 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg67 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,525 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg65 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,535 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg63 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,553 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg69 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,554 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg74 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,560 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg75 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,563 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg73 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,567 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg71 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,568 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg72 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,573 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg66 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,575 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg79 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,587 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg81 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,592 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg77 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:57:13,650 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg76 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,652 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg80 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,659 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg78 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,671 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg84 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,674 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg87 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,680 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg83 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,684 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg82 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,685 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg86 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,685 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg88 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,692 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg85 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,694 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg90 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,700 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg89 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,709 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg94 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,713 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg93 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,719 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg91 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,728 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg92 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,732 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg97 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,736 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg96 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,737 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg99 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,742 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg98 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:13,744 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:s3bg95 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:16,676 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2919117940 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:57:33,337 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-2919117940/ozone-test-9363149768/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2022-12-10 12:57:33,338 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9363149768/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-9363149768/multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:34,662 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-2919117940/ozone-test-5620804415/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-12-10 12:57:34,663 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5620804415/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-5620804415/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:35,276 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-2919117940/ozone-test-5620804415/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-12-10 12:57:35,277 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5620804415/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-5620804415/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:38,491 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5620804415/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-5620804415/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-2919117940/ozone-test-5620804415/multipartKey3-64655cb3-83aa-46dd-bf02-90bfd0dcb86a-109489491410420006-1
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:39,132 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5620804415/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-5620804415/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-2919117940/ozone-test-5620804415/multipartKey3-64655cb3-83aa-46dd-bf02-90bfd0dcb86a-109489491410420006-2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:39,790 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-2919117940/ozone-test-5620804415/multipartKey3
om_1        | 2022-12-10 12:57:39,790 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5620804415/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-2919117940
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-2919117940 key: ozone-test-5620804415/multipartKey3 because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:42,995 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-7111626634/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-2919117940
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-2919117940key: ozone-test-7111626634/multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:57:43,643 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-2919117940, Key:ozone-test-6878833136/multipartKey. 
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:19,489 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0993215277 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:20,138 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-35103 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:29,675 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6565274452 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:33,695 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6565274452, Key:thereisnosuchfile.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:35,637 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,638 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,639 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,640 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,641 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,642 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,643 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,644 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:35,645 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 12:58:36,249 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6565274452, Key:ozone-test-5117798640/deletetestapidir/key=value/.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:39,558 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6565274452, Key:ozone-test-5117798640/deletetestapiprefix/key=value/file.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:44,153 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4337905199 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:49,777 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9689348547 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:52,982 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-9689348547, Key:ozone-test-2683479503/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:311)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:58:56,226 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2995952554 of layout LEGACY in volume: s3v
om_1        | 2022-12-10 12:58:58,152 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=1, localID=109611004723200592}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key ozone-test-7527826492/putobject/key=value/zerobyte.
om_1        | 2022-12-10 12:59:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:59:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:59:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 12:59:33,904 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:recon for user:hadoop
om_1        | 2022-12-10 12:59:33,947 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: api of layout LEGACY in volume: recon
om_1        | 2022-12-10 13:00:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:00:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:00:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,024 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,025 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,026 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:00:42,695 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol-pjped for user:hadoop
om_1        | 2022-12-10 13:00:46,750 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: buc-mqnkx of layout FILE_SYSTEM_OPTIMIZED in volume: vol-pjped
om_1        | 2022-12-10 13:01:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:01:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:01:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:01:47,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:02:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:02:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:02:32,291 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=1, localID=109611004723200608}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key omkg/0.
om_1        | 2022-12-10 13:02:37,373 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 13:02:42,655 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:voltest for user:hadoop
om_1        | 2022-12-10 13:02:42,690 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: buckettest of layout LEGACY in volume: voltest
om_1        | 2022-12-10 13:02:47,174 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,175 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,177 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,178 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,181 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,182 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,183 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,184 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,185 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,186 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,186 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,186 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,187 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,188 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,189 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,190 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,191 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,192 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,192 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,192 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,192 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:02:47,193 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:03:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:03:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:03:37,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,431 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,432 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:37,433 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:03:43,514 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om_1        | 2022-12-10 13:04:00,000 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:04:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:04:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:05:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:05:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:05:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,413 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:05:27,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:06:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:06:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:06:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:07:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:07:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:07:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:07:25,636 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:cli-debug-volume18304 for user:hadoop
om_1        | 2022-12-10 13:07:29,787 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: cli-debug-bucket of layout LEGACY in volume: cli-debug-volume18304
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,661 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,662 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,663 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,664 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,665 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,666 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,667 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,668 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,669 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,670 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,671 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,672 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,673 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,674 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,675 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,676 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,676 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,677 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,678 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,678 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,678 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,678 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,679 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,679 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,679 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,679 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:07:31,679 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:08:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:08:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:08:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:09:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:09:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:09:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:09:22,144 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,144 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,145 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,146 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,147 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,148 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,149 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,150 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,151 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,151 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,151 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,151 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,152 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,152 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,153 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,153 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,154 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,155 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,156 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,157 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,158 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,159 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,160 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,161 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,162 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,163 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,164 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,165 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,166 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,167 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,168 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,169 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,170 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:22,171 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:09:54,835 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:fstest1 for user:hadoop
om_1        | 2022-12-10 13:09:58,851 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:fstest2 for user:hadoop
om_1        | 2022-12-10 13:10:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:10:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:10:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:10:03,039 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:fstest1-src for user:hadoop
om_1        | 2022-12-10 13:10:07,095 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:fstest2-src for user:hadoop
om_1        | 2022-12-10 13:10:10,657 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link1-ofs-src of layout FILE_SYSTEM_OPTIMIZED in volume: fstest1-src
om_1        | 2022-12-10 13:10:14,778 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link2-ofs-src of layout FILE_SYSTEM_OPTIMIZED in volume: fstest1-src
om_1        | 2022-12-10 13:10:19,034 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link3-ofs-src of layout FILE_SYSTEM_OPTIMIZED in volume: fstest2-src
om_1        | 2022-12-10 13:10:22,527 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link1-ofs of layout LEGACY in volume: fstest1
om_1        | 2022-12-10 13:10:26,784 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link2-ofs of layout LEGACY in volume: fstest1
om_1        | 2022-12-10 13:10:30,798 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: 31947-link3-ofs of layout LEGACY in volume: fstest2
om_1        | 2022-12-10 13:11:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:11:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:11:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:11:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,027 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,028 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,029 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,030 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,031 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:00,032 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:11:32,342 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:zhvfxfwg for user:hadoop
om_1        | 2022-12-10 13:11:36,227 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ikxtmrpw of layout LEGACY in volume: zhvfxfwg
om_1        | 2022-12-10 13:12:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:12:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:12:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:12:07,858 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,858 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,859 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,860 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,861 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,862 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,863 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,864 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,865 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,866 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,867 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,868 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,869 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,870 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,871 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,872 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,873 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,874 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,875 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,876 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,877 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,878 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,879 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,880 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,881 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,882 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,883 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,884 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,885 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,886 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,887 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,888 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,889 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,890 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,891 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:07,892 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:12:42,869 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=10, localID=109611004723200728}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key test/ofs/dir/TOUCHFILE-ofs.txt.
om_1        | 2022-12-10 13:12:51,894 [OM StateMachine ApplyTransaction Thread - 0] INFO key.OMKeyRequest: Detect allocated but uncommitted blocks [{blockID={containerID=10, localID=109611004723200729}, length=1048576, offset=0, token=null, pipeline=null, createVersion=0, partNumber=0}] in key test/ofs/dir/testFile.txt.
om_1        | 2022-12-10 13:12:58,016 [DirectoryDeletingService#0] INFO service.DirectoryDeletingService: Number of dirs deleted: 1, Number of sub-dir deleted: 0, Number of sub-files moved: 0 to DeletedTable, Number of sub-dirs moved 0 to DeletedDirectoryTable, iteration elapsed: 8ms, totalRunCount: 46
om_1        | 2022-12-10 13:13:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:13:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:13:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,414 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,415 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,416 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,417 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,418 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,419 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,420 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,421 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,422 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,423 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,424 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,425 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,426 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,427 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,428 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,429 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:17,430 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:13:58,011 [DirectoryDeletingService#0] INFO service.DirectoryDeletingService: Number of dirs deleted: 1, Number of sub-dir deleted: 0, Number of sub-files moved: 0 to DeletedTable, Number of sub-dirs moved 0 to DeletedDirectoryTable, iteration elapsed: 3ms, totalRunCount: 47
om_1        | 2022-12-10 13:14:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:14:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:14:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 89652-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:280)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:336)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:316)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:311)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,405 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,406 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,407 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,408 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,409 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,410 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,411 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
om_1        | 2022-12-10 13:14:37,412 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
