rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test in ozone-csi
Removing network ozone-csi_default
Network ozone-csi_default not found.
Creating network "ozone-csi_default" with the default driver
Pulling datanode (apache/ozone-runner:20220623-1)...
20220623-1: Pulling from apache/ozone-runner
Digest: sha256:ba2ed07322bc8f888150fa2a1ec0523fca85e09c8eb9779445f8bca0d58cff97
Status: Downloaded newer image for apache/ozone-runner:20220623-1
Creating ozone-csi_csi_1 ... 
Creating ozone-csi_scm_1 ... 
Creating ozone-csi_datanode_1 ... 
Creating ozone-csi_datanode_2 ... 
Creating ozone-csi_datanode_3 ... 
Creating ozone-csi_om_1       ... 
Creating ozone-csi_scm_1      ... done
Creating ozone-csi_csi_1      ... done
Creating ozone-csi_datanode_3 ... done
Creating ozone-csi_datanode_2 ... done
Creating ozone-csi_om_1       ... done
Creating ozone-csi_datanode_1 ... done
SECONDS: 42
com.google.protobuf.ServiceException: java.net.ConnectException: Call From dcd6a7d5fb5a/172.18.0.2 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From dcd6a7d5fb5a/172.18.0.2 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From dcd6a7d5fb5a/172.18.0.2 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:405a3d2c-9766-4143-85ca-9a3f4c160689 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:405a3d2c-9766-4143-85ca-9a3f4c160689 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:405a3d2c-9766-4143-85ca-9a3f4c160689 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.2:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=1) >= required datanodes (=1) validated:true, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=0) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 58
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Csi :: Smoketest Ozone CSI service                                            
==============================================================================
Check if CSI server is started                                        | PASS |
------------------------------------------------------------------------------
Test CSI identity service                                             | PASS |
------------------------------------------------------------------------------
Csi :: Smoketest Ozone CSI service                                    | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-csi/result/robot-ozone-csi-ozone-csi-csi-csi.xml
Stopping ozone-csi_om_1       ... 
Stopping ozone-csi_datanode_1 ... 
Stopping ozone-csi_datanode_3 ... 
Stopping ozone-csi_datanode_2 ... 
Stopping ozone-csi_csi_1      ... 
Stopping ozone-csi_scm_1      ... 
Stopping ozone-csi_csi_1      ... done
Stopping ozone-csi_om_1       ... done
Stopping ozone-csi_datanode_3 ... done
Stopping ozone-csi_datanode_2 ... done
Stopping ozone-csi_datanode_1 ... done
Stopping ozone-csi_scm_1      ... done
Removing ozone-csi_om_1       ... 
Removing ozone-csi_datanode_1 ... 
Removing ozone-csi_datanode_3 ... 
Removing ozone-csi_datanode_2 ... 
Removing ozone-csi_csi_1      ... 
Removing ozone-csi_scm_1      ... 
Removing ozone-csi_om_1       ... done
Removing ozone-csi_datanode_3 ... done
Removing ozone-csi_datanode_2 ... done
Removing ozone-csi_scm_1      ... done
Removing ozone-csi_csi_1      ... done
Removing ozone-csi_datanode_1 ... done
Removing network ozone-csi_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-csi/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-csi/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi.xml
removed 'ozone-csi/result/robot-ozone-csi-ozone-csi-csi-csi.xml'
removed 'ozone-csi/result/log.html'
removed 'ozone-csi/result/report.html'
renamed 'ozone-csi/result/dn-audit-5152db46ff9c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-5152db46ff9c.log'
renamed 'ozone-csi/result/dn-audit-8ce0ee3ac4c1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-8ce0ee3ac4c1.log'
renamed 'ozone-csi/result/dn-audit-926af3422a98.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-926af3422a98.log'
renamed 'ozone-csi/result/docker-ozone-csi-ozone-csi-csi-csi.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-ozone-csi-csi-csi.log'
renamed 'ozone-csi/result/om-audit-5ae2d3977970.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/om-audit-5ae2d3977970.log'
renamed 'ozone-csi/result/scm-audit-dcd6a7d5fb5a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/scm-audit-dcd6a7d5fb5a.log'
Executing test in ozone-om-prepare
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data': Operation not permitted
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om2_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_om1_1 ... done
SECONDS: 38
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1d80b96f50b4/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1d80b96f50b4/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1d80b96f50b4/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1d80b96f50b4/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6f75d399-3d63-49fd-a1eb-e80c0582f3d7 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6f75d399-3d63-49fd-a1eb-e80c0582f3d7 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 58
SCM is out of safe mode.
Safe mode is off
Found OM leader for service omservice: om1 : LEADER (om1)
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | FAIL |
Test timeout 5 minutes exceeded.
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | FAIL |
3 tests, 2 passed, 1 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.xml
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_dn1_1_HddsDatanodeService.stack
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_dn2_1_HddsDatanodeService.stack
jstack 8 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_dn3_1_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_om1_1_OzoneManagerStarter.stack
Error response from daemon: Container 0c949940a1b139ca39dc25bbe0ff94b4a7741111bea2833b34191451f3cf6a7e is not running
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_om3_1_OzoneManagerStarter.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_scm_1_StorageContainerManagerStarter.stack
jstack 1357 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/result/ozone-om-prepare_scm_1_OzoneAdmin.stack
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing network ozone-om-prepare_net
ERROR: Test execution of ozone-om-prepare is FAILED!!!!
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare.xml
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.xml'
renamed 'ozone-om-prepare/result/dn-audit-0491a343f877.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-0491a343f877.log'
renamed 'ozone-om-prepare/result/dn-audit-76e47983fa7e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-76e47983fa7e.log'
renamed 'ozone-om-prepare/result/dn-audit-c1b9a4237557.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-c1b9a4237557.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.log'
renamed 'ozone-om-prepare/result/om-audit-f675f83e5104.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-f675f83e5104.log'
renamed 'ozone-om-prepare/result/om-audit-f78fd346cac8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-f78fd346cac8.log'
renamed 'ozone-om-prepare/result/ozone-om-prepare_dn1_1_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_dn1_1_HddsDatanodeService.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_dn2_1_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_dn2_1_HddsDatanodeService.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_dn3_1_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_dn3_1_HddsDatanodeService.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_om1_1_OzoneManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_om1_1_OzoneManagerStarter.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_om3_1_OzoneManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_om3_1_OzoneManagerStarter.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_scm_1_OzoneAdmin.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_scm_1_OzoneAdmin.stack'
renamed 'ozone-om-prepare/result/ozone-om-prepare_scm_1_StorageContainerManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/ozone-om-prepare_scm_1_StorageContainerManagerStarter.stack'
renamed 'ozone-om-prepare/result/scm-audit-1d80b96f50b4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-1d80b96f50b4.log'
Executing test in ozone-topology
Removing network ozone-topology_net
Network ozone-topology_net not found.
Creating network "ozone-topology_net" with driver "bridge"
Creating ozone-topology_datanode_6_1 ... 
Creating ozone-topology_datanode_1_1 ... 
Creating ozone-topology_om_1         ... 
Creating ozone-topology_datanode_5_1 ... 
Creating ozone-topology_datanode_2_1 ... 
Creating ozone-topology_recon_1      ... 
Creating ozone-topology_scm_1        ... 
Creating ozone-topology_datanode_3_1 ... 
Creating ozone-topology_datanode_4_1 ... 
Creating ozone-topology_datanode_1_1 ... done
Creating ozone-topology_datanode_5_1 ... done
Creating ozone-topology_recon_1      ... done
Creating ozone-topology_datanode_2_1 ... done
Creating ozone-topology_scm_1        ... done
Creating ozone-topology_datanode_6_1 ... done
Creating ozone-topology_om_1         ... done
Creating ozone-topology_datanode_3_1 ... done
Creating ozone-topology_datanode_4_1 ... done
SECONDS: 70
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 15870e435033/10.5.0.71 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 15870e435033/10.5.0.71 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 15870e435033/10.5.0.71 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 15870e435033/10.5.0.71 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 15870e435033/10.5.0.71 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6a99fe70-29b5-41f8-922c-4b36a3616564 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6a99fe70-29b5-41f8-922c-4b36a3616564 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6a99fe70-29b5-41f8-922c-4b36a3616564 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.5.0.71:9860 after 8 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=4) >= required datanodes (=4) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 86
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm.xml
==============================================================================
Cli :: Smoketest ozone cluster startup                                        
==============================================================================
Run printTopology                                                     | PASS |
------------------------------------------------------------------------------
Run printTopology -o                                                  | PASS |
------------------------------------------------------------------------------
Run printTopology --operational-state IN_SERVICE                      | PASS |
------------------------------------------------------------------------------
Run printTopology --node-state HEALTHY                                | PASS |
------------------------------------------------------------------------------
Cli :: Smoketest ozone cluster startup                                | PASS |
4 tests, 4 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-1.xml
==============================================================================
Recon                                                                         
==============================================================================
Recon.Recon-Api :: Smoke test to start cluster with docker-compose environm...
==============================================================================
Check if Recon picks up OM data                                       | PASS |
------------------------------------------------------------------------------
Check if Recon picks up DN heartbeats                                 | PASS |
------------------------------------------------------------------------------
Check if Recon Web UI is up                                           | PASS |
------------------------------------------------------------------------------
Check web UI access                                                   | PASS |
------------------------------------------------------------------------------
Check admin only api access                                           | PASS |
------------------------------------------------------------------------------
Check unhealthy, (admin) api access                                   | PASS |
------------------------------------------------------------------------------
Check normal api access                                               | PASS |
------------------------------------------------------------------------------
Recon.Recon-Api :: Smoke test to start cluster with docker-compose... | PASS |
7 tests, 7 passed, 0 failed
==============================================================================
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary Endpoint fo...
==============================================================================
Check volume creation                                                 | PASS |
------------------------------------------------------------------------------
Check bucket creation                                                 | PASS |
------------------------------------------------------------------------------
Check keys creation                                                   | PASS |
------------------------------------------------------------------------------
Check Summary api access                                              | PASS |
------------------------------------------------------------------------------
Check Disk Usage api access                                           | PASS |
------------------------------------------------------------------------------
Check Quota Usage api access                                          | PASS |
------------------------------------------------------------------------------
Check File Size Distribution api access                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Root                                    | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Volume                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Bucket                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Key                                     | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Directory                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Disk Usage                                      | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Volume Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Bucket Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace File Size Distribution Root                     | PASS |
------------------------------------------------------------------------------
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary En... | PASS |
16 tests, 16 passed, 0 failed
==============================================================================
Recon                                                                 | PASS |
23 tests, 23 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-2.xml
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-3.xml
Stopping ozone-topology_datanode_3_1 ... 
Stopping ozone-topology_datanode_2_1 ... 
Stopping ozone-topology_datanode_1_1 ... 
Stopping ozone-topology_datanode_3_1 ... done
Stopping ozone-topology_datanode_1_1 ... done
Stopping ozone-topology_datanode_2_1 ... done
==============================================================================
readdata-first-half :: Smoketest ozone cluster startup                        
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-first-half :: Smoketest ozone cluster startup                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-4.xml
Starting datanode_1 ... 
Starting datanode_2 ... 
Starting datanode_3 ... 
Starting datanode_1 ... done
Starting datanode_3 ... done
Starting datanode_2 ... done
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is available on datanode_1
Port 9858 is available on datanode_2
Port 9858 is available on datanode_3
Stopping ozone-topology_datanode_4_1 ... 
Stopping ozone-topology_datanode_5_1 ... 
Stopping ozone-topology_datanode_6_1 ... 
Stopping ozone-topology_datanode_5_1 ... done
Stopping ozone-topology_datanode_4_1 ... done
Stopping ozone-topology_datanode_6_1 ... done
==============================================================================
readdata-second-half :: Smoketest ozone cluster startup                       
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-second-half :: Smoketest ozone cluster startup               | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-5.xml
Stopping ozone-topology_scm_1        ... 
Stopping ozone-topology_datanode_3_1 ... 
Stopping ozone-topology_recon_1      ... 
Stopping ozone-topology_datanode_2_1 ... 
Stopping ozone-topology_om_1         ... 
Stopping ozone-topology_datanode_1_1 ... 
Stopping ozone-topology_om_1         ... done
Stopping ozone-topology_datanode_2_1 ... done
Stopping ozone-topology_recon_1      ... done
Stopping ozone-topology_datanode_3_1 ... done
Stopping ozone-topology_datanode_1_1 ... done
Stopping ozone-topology_scm_1        ... done
Removing ozone-topology_datanode_4_1 ... 
Removing ozone-topology_scm_1        ... 
Removing ozone-topology_datanode_3_1 ... 
Removing ozone-topology_recon_1      ... 
Removing ozone-topology_datanode_2_1 ... 
Removing ozone-topology_om_1         ... 
Removing ozone-topology_datanode_5_1 ... 
Removing ozone-topology_datanode_1_1 ... 
Removing ozone-topology_datanode_6_1 ... 
Removing ozone-topology_recon_1      ... done
Removing ozone-topology_datanode_6_1 ... done
Removing ozone-topology_scm_1        ... done
Removing ozone-topology_datanode_4_1 ... done
Removing ozone-topology_datanode_3_1 ... done
Removing ozone-topology_datanode_2_1 ... done
Removing ozone-topology_om_1         ... done
Removing ozone-topology_datanode_5_1 ... done
Removing ozone-topology_datanode_1_1 ... done
Removing network ozone-topology_net
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-topology/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-topology/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology.xml
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-1.xml'
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-2.xml'
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-3.xml'
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-4.xml'
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm-5.xml'
removed 'ozone-topology/result/robot-ozone-topology-ozone-topology-basic-scm.xml'
removed 'ozone-topology/result/log.html'
removed 'ozone-topology/result/report.html'
renamed 'ozone-topology/result/dn-audit-026c7becc292.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-026c7becc292.log'
renamed 'ozone-topology/result/dn-audit-159c02cd6e98.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-159c02cd6e98.log'
renamed 'ozone-topology/result/dn-audit-38ee866d2b5d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-38ee866d2b5d.log'
renamed 'ozone-topology/result/dn-audit-71d946715855.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-71d946715855.log'
renamed 'ozone-topology/result/dn-audit-a6a394323b97.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-a6a394323b97.log'
renamed 'ozone-topology/result/dn-audit-dd10a52322c1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-dd10a52322c1.log'
renamed 'ozone-topology/result/docker-ozone-topology-ozone-topology-basic-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-ozone-topology-basic-scm.log'
renamed 'ozone-topology/result/om-audit-5e5255f7c857.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/om-audit-5e5255f7c857.log'
renamed 'ozone-topology/result/scm-audit-15870e435033.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-topology/scm-audit-15870e435033.log'
Executing test in ozones3-haproxy
Removing network ozones3-haproxy_default
Network ozones3-haproxy_default not found.
Creating network "ozones3-haproxy_default" with the default driver
Pulling s3g (haproxy:latest)...
latest: Pulling from library/haproxy
Digest: sha256:ebdd23975d25d1fb360ee54f81af26ca9fff6fa05516d43980c99ee5a88ff56e
Status: Downloaded newer image for haproxy:latest
Creating ozones3-haproxy_om_1 ... 
Creating ozones3-haproxy_s3g3_1 ... 
Creating ozones3-haproxy_s3g2_1 ... 
Creating ozones3-haproxy_scm_1  ... 
Creating ozones3-haproxy_datanode_1 ... 
Creating ozones3-haproxy_datanode_2 ... 
Creating ozones3-haproxy_datanode_3 ... 
Creating ozones3-haproxy_s3g_1      ... 
Creating ozones3-haproxy_s3g1_1     ... 
Creating ozones3-haproxy_scm_1      ... done
Creating ozones3-haproxy_s3g2_1     ... done
Creating ozones3-haproxy_datanode_2 ... done
Creating ozones3-haproxy_om_1       ... done
Creating ozones3-haproxy_datanode_3 ... done
Creating ozones3-haproxy_datanode_1 ... done
Creating ozones3-haproxy_s3g_1      ... done
Creating ozones3-haproxy_s3g1_1     ... done
Creating ozones3-haproxy_s3g3_1     ... done
SECONDS: 48
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 126e161209d2/172.19.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.3:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 126e161209d2/172.19.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.3:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0f2ecc23-6644-4299-b755-ad89b870a14b is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.3:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0f2ecc23-6644-4299-b755-ad89b870a14b is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.3:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0f2ecc23-6644-4299-b755-ad89b870a14b is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.3:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=1) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 62
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 68
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozones3-haproxy/result/robot-ozones3-haproxy-ozones3-haproxy-basic-scm.xml
Stopping ozones3-haproxy_s3g1_1     ... 
Stopping ozones3-haproxy_datanode_1 ... 
Stopping ozones3-haproxy_s3g_1      ... 
Stopping ozones3-haproxy_datanode_3 ... 
Stopping ozones3-haproxy_datanode_2 ... 
Stopping ozones3-haproxy_s3g2_1     ... 
Stopping ozones3-haproxy_scm_1      ... 
Stopping ozones3-haproxy_s3g3_1     ... 
Stopping ozones3-haproxy_om_1       ... 
Stopping ozones3-haproxy_s3g_1      ... done
Stopping ozones3-haproxy_s3g1_1     ... done
Stopping ozones3-haproxy_s3g2_1     ... done
Stopping ozones3-haproxy_s3g3_1     ... done
Stopping ozones3-haproxy_om_1       ... done
Stopping ozones3-haproxy_datanode_1 ... done
Stopping ozones3-haproxy_datanode_2 ... done
Stopping ozones3-haproxy_datanode_3 ... done
Stopping ozones3-haproxy_scm_1      ... done
Removing ozones3-haproxy_s3g1_1     ... 
Removing ozones3-haproxy_datanode_1 ... 
Removing ozones3-haproxy_s3g_1      ... 
Removing ozones3-haproxy_datanode_3 ... 
Removing ozones3-haproxy_datanode_2 ... 
Removing ozones3-haproxy_s3g2_1     ... 
Removing ozones3-haproxy_scm_1      ... 
Removing ozones3-haproxy_s3g3_1     ... 
Removing ozones3-haproxy_om_1       ... 
Removing ozones3-haproxy_s3g1_1     ... done
Removing ozones3-haproxy_om_1       ... done
Removing ozones3-haproxy_s3g2_1     ... done
Removing ozones3-haproxy_s3g_1      ... done
Removing ozones3-haproxy_datanode_3 ... done
Removing ozones3-haproxy_s3g3_1     ... done
Removing ozones3-haproxy_scm_1      ... done
Removing ozones3-haproxy_datanode_2 ... done
Removing ozones3-haproxy_datanode_1 ... done
Removing network ozones3-haproxy_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozones3-haproxy/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozones3-haproxy/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy.xml
removed 'ozones3-haproxy/result/robot-ozones3-haproxy-ozones3-haproxy-basic-scm.xml'
removed 'ozones3-haproxy/result/log.html'
removed 'ozones3-haproxy/result/report.html'
renamed 'ozones3-haproxy/result/dn-audit-61aa7acc0f60.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/dn-audit-61aa7acc0f60.log'
renamed 'ozones3-haproxy/result/dn-audit-8ce128119dc7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/dn-audit-8ce128119dc7.log'
renamed 'ozones3-haproxy/result/dn-audit-bf1dbf9f05f1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/dn-audit-bf1dbf9f05f1.log'
renamed 'ozones3-haproxy/result/docker-ozones3-haproxy-ozones3-haproxy-basic-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/docker-ozones3-haproxy-ozones3-haproxy-basic-scm.log'
renamed 'ozones3-haproxy/result/om-audit-49cb2bfd58b2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/om-audit-49cb2bfd58b2.log'
renamed 'ozones3-haproxy/result/s3g-audit-345eb7b426dc.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/s3g-audit-345eb7b426dc.log'
renamed 'ozones3-haproxy/result/s3g-audit-db377e1f3527.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/s3g-audit-db377e1f3527.log'
renamed 'ozones3-haproxy/result/s3g-audit-fca1c85e4ea2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/s3g-audit-fca1c85e4ea2.log'
renamed 'ozones3-haproxy/result/scm-audit-126e161209d2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozones3-haproxy/scm-audit-126e161209d2.log'
Executing test in ozonescripts
Removing network ozonescripts_default
Network ozonescripts_default not found.
Creating network "ozonescripts_default" with the default driver
Building datanode
Sending build context to Docker daemon  30.21kB
Step 1/17 : ARG OZONE_RUNNER_IMAGE
Step 2/17 : ARG OZONE_RUNNER_VERSION
Step 3/17 : FROM ${OZONE_RUNNER_IMAGE}:${OZONE_RUNNER_VERSION}
 ---> 2f81b649e1b7
Step 4/17 : RUN sudo yum install -y openssh-clients openssh-server
 ---> Running in de855a875b0d
Loaded plugins: fastestmirror, ovl
Determining fastest mirrors
 * base: mirror.lstn.net
 * epel: pubmirror3.math.uh.edu
 * extras: ridgewireless.mm.fcix.net
 * updates: mirrors.raystedman.org
Resolving Dependencies
--> Running transaction check
---> Package openssh-clients.x86_64 0:7.4p1-22.el7_9 will be installed
--> Processing Dependency: openssh = 7.4p1-22.el7_9 for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: fipscheck-lib(x86-64) >= 1.3.0 for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: libfipscheck.so.1()(64bit) for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: libedit.so.0()(64bit) for package: openssh-clients-7.4p1-22.el7_9.x86_64
---> Package openssh-server.x86_64 0:7.4p1-22.el7_9 will be installed
--> Processing Dependency: libwrap.so.0()(64bit) for package: openssh-server-7.4p1-22.el7_9.x86_64
--> Running transaction check
---> Package fipscheck-lib.x86_64 0:1.4.1-6.el7 will be installed
--> Processing Dependency: /usr/bin/fipscheck for package: fipscheck-lib-1.4.1-6.el7.x86_64
---> Package libedit.x86_64 0:3.0-12.20121213cvs.el7 will be installed
---> Package openssh.x86_64 0:7.4p1-22.el7_9 will be installed
---> Package tcp_wrappers-libs.x86_64 0:7.6-77.el7 will be installed
--> Running transaction check
---> Package fipscheck.x86_64 0:1.4.1-6.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

================================================================================
 Package               Arch       Version                     Repository   Size
================================================================================
Installing:
 openssh-clients       x86_64     7.4p1-22.el7_9              updates     655 k
 openssh-server        x86_64     7.4p1-22.el7_9              updates     459 k
Installing for dependencies:
 fipscheck             x86_64     1.4.1-6.el7                 base         21 k
 fipscheck-lib         x86_64     1.4.1-6.el7                 base         11 k
 libedit               x86_64     3.0-12.20121213cvs.el7      base         92 k
 openssh               x86_64     7.4p1-22.el7_9              updates     510 k
 tcp_wrappers-libs     x86_64     7.6-77.el7                  base         66 k

Transaction Summary
================================================================================
Install  2 Packages (+5 Dependent packages)

Total download size: 1.8 M
Installed size: 5.8 M
Downloading packages:
[91mhttp://mirror.nodesdirect.com/centos/7.9.2009/updates/x86_64/Packages/openssh-server-7.4p1-22.el7_9.x86_64.rpm: [Errno 14] HTTP Error 404 - Not Found
[0m[91mTrying other mirror.
To address this issue please refer to the below wiki article 

https://wiki.centos.org/yum-errors

If above article doesn't help to resolve this issue please use https://bugs.centos.org/.

[0m[91mhttp://mirrors.tripadvisor.com/centos/7.9.2009/updates/x86_64/Packages/openssh-7.4p1-22.el7_9.x86_64.rpm: [Errno 12] Timeout on http://mirrors.tripadvisor.com/centos/7.9.2009/updates/x86_64/Packages/openssh-7.4p1-22.el7_9.x86_64.rpm: (28, 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds')
Trying other mirror.
[0m--------------------------------------------------------------------------------
Total                                               60 kB/s | 1.8 MB  00:30     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : fipscheck-1.4.1-6.el7.x86_64                                 1/7 
  Installing : fipscheck-lib-1.4.1-6.el7.x86_64                             2/7 
  Installing : openssh-7.4p1-22.el7_9.x86_64                                3/7 
  Installing : tcp_wrappers-libs-7.6-77.el7.x86_64                          4/7 
  Installing : libedit-3.0-12.20121213cvs.el7.x86_64                        5/7 
  Installing : openssh-clients-7.4p1-22.el7_9.x86_64                        6/7 
  Installing : openssh-server-7.4p1-22.el7_9.x86_64                         7/7 
  Verifying  : fipscheck-lib-1.4.1-6.el7.x86_64                             1/7 
  Verifying  : openssh-server-7.4p1-22.el7_9.x86_64                         2/7 
  Verifying  : fipscheck-1.4.1-6.el7.x86_64                                 3/7 
  Verifying  : libedit-3.0-12.20121213cvs.el7.x86_64                        4/7 
  Verifying  : openssh-clients-7.4p1-22.el7_9.x86_64                        5/7 
  Verifying  : tcp_wrappers-libs-7.6-77.el7.x86_64                          6/7 
  Verifying  : openssh-7.4p1-22.el7_9.x86_64                                7/7 

Installed:
  openssh-clients.x86_64 0:7.4p1-22.el7_9                                       
  openssh-server.x86_64 0:7.4p1-22.el7_9                                        

Dependency Installed:
  fipscheck.x86_64 0:1.4.1-6.el7            fipscheck-lib.x86_64 0:1.4.1-6.el7  
  libedit.x86_64 0:3.0-12.20121213cvs.el7   openssh.x86_64 0:7.4p1-22.el7_9     
  tcp_wrappers-libs.x86_64 0:7.6-77.el7    

Complete!
Removing intermediate container de855a875b0d
 ---> bef6535dba1a
Step 5/17 : RUN sudo ssh-keygen -A
 ---> Running in 80a65db42d6e
ssh-keygen: generating new host keys: RSA1 RSA DSA ECDSA ED25519 
Removing intermediate container 80a65db42d6e
 ---> e9c188fdc3b1
Step 6/17 : RUN sudo mkdir -p /run/sshd
 ---> Running in 97ea22d52d55
Removing intermediate container 97ea22d52d55
 ---> 7c72abb551c0
Step 7/17 : RUN sudo sed -i "s/.*UsePrivilegeSeparation.*/UsePrivilegeSeparation no/g" /etc/ssh/sshd_config
 ---> Running in aa33aa37b76f
Removing intermediate container aa33aa37b76f
 ---> 492be5316cf4
Step 8/17 : RUN sudo sed -i "s/.*PermitUserEnvironment.*/PermitUserEnvironment yes/g" /etc/ssh/sshd_config
 ---> Running in f47518e769ea
Removing intermediate container f47518e769ea
 ---> d2fad5419c0a
Step 9/17 : RUN sudo sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
 ---> Running in e71805a035cd
Removing intermediate container e71805a035cd
 ---> 7b6271ebe792
Step 10/17 : RUN sudo usermod -d /opt hadoop
 ---> Running in 1f9516c4d185
Removing intermediate container 1f9516c4d185
 ---> a888bf98cedc
Step 11/17 : ADD .ssh /opt/.ssh
 ---> e85111458388
Step 12/17 : RUN sudo chown -R hadoop /opt/.ssh
 ---> Running in 1a4988d99911
Removing intermediate container 1a4988d99911
 ---> 6763ea5b4fc2
Step 13/17 : RUN sudo chown hadoop /opt
 ---> Running in 6c61fef4be27
Removing intermediate container 6c61fef4be27
 ---> 21d32a878a93
Step 14/17 : RUN sudo chmod 600 /opt/.ssh/*
 ---> Running in 0eec1551db02
Removing intermediate container 0eec1551db02
 ---> 9791c7ceb9a2
Step 15/17 : RUN sudo chmod 700 /opt/.ssh
 ---> Running in 08c761ef8925
Removing intermediate container 08c761ef8925
 ---> bb60c09eb3b1
Step 16/17 : RUN sudo sh -c 'echo "export JAVA_HOME=/usr/lib/jvm/jre/" >> /etc/profile'
 ---> Running in 6bf266ca4389
Removing intermediate container 6bf266ca4389
 ---> 7c8af467d6a3
Step 17/17 : CMD ["sudo","/usr/sbin/sshd","-D"]
 ---> Running in 2c336f0d6026
Removing intermediate container 2c336f0d6026
 ---> 4b4b861b0cab
Successfully built 4b4b861b0cab
Successfully tagged ozone-runner-scripts:20220623-1
Image for service datanode was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating ozonescripts_om_1 ... 
Creating ozonescripts_datanode_1 ... 
Creating ozonescripts_scm_1      ... 
Creating ozonescripts_datanode_1 ... done
Creating ozonescripts_om_1       ... done
Creating ozonescripts_scm_1      ... done
Port 22 is available on scm
Port 22 is available on om
Port 22 is available on datanode
No OM HA service, no need to wait
+ docker-compose ps
+ awk '{print $1}'
+ grep datanode
+ xargs -n1 docker inspect --format '{{ .Config.Hostname }}'
+ docker-compose ps
+ xargs -I CONTAINER -n1 docker exec CONTAINER cp /opt/hadoop/etc/hadoop/workers /etc/hadoop/workers
+ awk '{print $1}'
+ grep ozonescripts
+ docker-compose exec -T scm /opt/hadoop/bin/ozone scm --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2022-12-23 08:02:05,790 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 5bfa290bc281/172.20.0.4
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.3.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a89ba1a4c485ddff7bf213efd871ee8807520e8a ; compiled by 'runner' on 2022-12-23T07:21Z
STARTUP_MSG:   java = 11.0.14.1
************************************************************/
2022-12-23 08:02:05,797 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-23 08:02:05,826 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-12-23 08:02:05,844 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2022-12-23 08:02:05,850 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-12-23 08:02:05,944 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2022-12-23 08:02:06,070 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2022-12-23 08:02:06,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2022-12-23 08:02:06,074 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2022-12-23 08:02:06,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2022-12-23 08:02:06,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2022-12-23 08:02:06,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2022-12-23 08:02:06,077 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2022-12-23 08:02:06,079 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-12-23 08:02:06,080 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-12-23 08:02:06,081 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2022-12-23 08:02:06,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2022-12-23 08:02:06,093 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-12-23 08:02:06,094 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-12-23 08:02:06,250 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
2022-12-23 08:02:06,261 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2022-12-23 08:02:06,376 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
2022-12-23 08:02:06,378 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
2022-12-23 08:02:06,379 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2022-12-23 08:02:06,380 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
2022-12-23 08:02:06,383 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
2022-12-23 08:02:06,384 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
2022-12-23 08:02:06,389 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
2022-12-23 08:02:06,391 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = null (default)
2022-12-23 08:02:06,392 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
2022-12-23 08:02:06,393 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
2022-12-23 08:02:06,463 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2022-12-23 08:02:06,464 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2022-12-23 08:02:06,464 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2022-12-23 08:02:06,464 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-12-23 08:02:06,467 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2022-12-23 08:02:06,482 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c] REGISTERED
2022-12-23 08:02:06,488 [main] INFO server.RaftServer: f77b3ae1-6f4b-452d-8796-94eb37332bef: addNew group-5F770461EC8C:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|priority:0|startupRole:FOLLOWER] returns group-5F770461EC8C:java.util.concurrent.CompletableFuture@24528a25[Not completed]
2022-12-23 08:02:06,493 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c] BIND: 0.0.0.0/0.0.0.0:0
2022-12-23 08:02:06,505 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c, L:/0.0.0.0:43919] ACTIVE
2022-12-23 08:02:06,512 [pool-2-thread-1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef: new RaftServerImpl for group-5F770461EC8C:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
2022-12-23 08:02:06,515 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2022-12-23 08:02:06,516 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2022-12-23 08:02:06,516 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2022-12-23 08:02:06,517 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2022-12-23 08:02:06,517 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-12-23 08:02:06,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2022-12-23 08:02:06,524 [pool-2-thread-1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: ConfigurationManager, init=-1: peers:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2022-12-23 08:02:06,525 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2022-12-23 08:02:06,530 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2022-12-23 08:02:06,531 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2022-12-23 08:02:06,538 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2022-12-23 08:02:06,540 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2022-12-23 08:02:06,541 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2022-12-23 08:02:06,571 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-12-23 08:02:06,572 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2022-12-23 08:02:06,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2022-12-23 08:02:06,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2022-12-23 08:02:06,574 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2022-12-23 08:02:06,575 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/002839e5-7489-419b-b8b3-5f770461ec8c does not exist. Creating ...
2022-12-23 08:02:06,594 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/002839e5-7489-419b-b8b3-5f770461ec8c/in_use.lock acquired by nodename 38@5bfa290bc281
2022-12-23 08:02:06,600 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/002839e5-7489-419b-b8b3-5f770461ec8c has been successfully formatted.
2022-12-23 08:02:06,604 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2022-12-23 08:02:06,611 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2022-12-23 08:02:06,612 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-12-23 08:02:06,614 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-12-23 08:02:06,616 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2022-12-23 08:02:06,618 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2022-12-23 08:02:06,623 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2022-12-23 08:02:06,624 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-12-23 08:02:06,630 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/002839e5-7489-419b-b8b3-5f770461ec8c
2022-12-23 08:02:06,631 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-12-23 08:02:06,631 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2022-12-23 08:02:06,633 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2022-12-23 08:02:06,634 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2022-12-23 08:02:06,635 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2022-12-23 08:02:06,636 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2022-12-23 08:02:06,636 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-12-23 08:02:06,637 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-12-23 08:02:06,647 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-12-23 08:02:06,647 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-12-23 08:02:06,659 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2022-12-23 08:02:06,659 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2022-12-23 08:02:06,659 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2022-12-23 08:02:06,666 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-12-23 08:02:06,666 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-12-23 08:02:06,668 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: start as a follower, conf=-1: peers:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2022-12-23 08:02:06,669 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-12-23 08:02:06,671 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: start f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState
2022-12-23 08:02:06,673 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2022-12-23 08:02:06,677 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2022-12-23 08:02:06,679 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F770461EC8C,id=f77b3ae1-6f4b-452d-8796-94eb37332bef
2022-12-23 08:02:06,681 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-12-23 08:02:06,682 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2022-12-23 08:02:06,683 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2022-12-23 08:02:06,684 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2022-12-23 08:02:06,687 [main] INFO server.RaftServer: f77b3ae1-6f4b-452d-8796-94eb37332bef: start RPC server
2022-12-23 08:02:06,696 [main] INFO server.GrpcService: f77b3ae1-6f4b-452d-8796-94eb37332bef: GrpcService started, listening on 9894
2022-12-23 08:02:06,699 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-f77b3ae1-6f4b-452d-8796-94eb37332bef: Started
2022-12-23 08:02:11,833 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO impl.FollowerState: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5162336229ns, electionTimeout:5155ms
2022-12-23 08:02:11,835 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: shutdown f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState
2022-12-23 08:02:11,835 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-12-23 08:02:11,844 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
2022-12-23 08:02:11,845 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-FollowerState] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: start f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1
2022-12-23 08:02:11,850 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO impl.LeaderElection: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2022-12-23 08:02:11,852 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO impl.LeaderElection: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2022-12-23 08:02:11,853 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: shutdown f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1
2022-12-23 08:02:11,854 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-12-23 08:02:11,854 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: change Leader from null to f77b3ae1-6f4b-452d-8796-94eb37332bef at term 1 for becomeLeader, leader elected after 5317ms
2022-12-23 08:02:11,861 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2022-12-23 08:02:11,866 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2022-12-23 08:02:11,867 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-12-23 08:02:11,874 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2022-12-23 08:02:11,874 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2022-12-23 08:02:11,874 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2022-12-23 08:02:11,885 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2022-12-23 08:02:11,889 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-12-23 08:02:11,892 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: start f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderStateImpl
2022-12-23 08:02:11,914 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker: Starting segment from index:0
2022-12-23 08:02:11,972 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderElection1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: set configuration 0: peers:[f77b3ae1-6f4b-452d-8796-94eb37332bef|rpc:5bfa290bc281:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2022-12-23 08:02:12,003 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/002839e5-7489-419b-b8b3-5f770461ec8c/current/log_inprogress_0
2022-12-23 08:02:12,701 [main] INFO server.RaftServer: f77b3ae1-6f4b-452d-8796-94eb37332bef: close
2022-12-23 08:02:12,702 [main] INFO server.GrpcService: f77b3ae1-6f4b-452d-8796-94eb37332bef: shutdown server GrpcServerProtocolService now
2022-12-23 08:02:12,702 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: shutdown
2022-12-23 08:02:12,703 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F770461EC8C,id=f77b3ae1-6f4b-452d-8796-94eb37332bef
2022-12-23 08:02:12,703 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO impl.RoleInfo: f77b3ae1-6f4b-452d-8796-94eb37332bef: shutdown f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-LeaderStateImpl
2022-12-23 08:02:12,711 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO impl.PendingRequests: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-PendingRequests: sendNotLeaderResponses
2022-12-23 08:02:12,722 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO impl.StateMachineUpdater: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-StateMachineUpdater: set stopIndex = 0
2022-12-23 08:02:12,723 [main] INFO server.GrpcService: f77b3ae1-6f4b-452d-8796-94eb37332bef: shutdown server GrpcServerProtocolService successfully
2022-12-23 08:02:12,723 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-StateMachineUpdater] INFO impl.StateMachineUpdater: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-StateMachineUpdater: Took a snapshot at index 0
2022-12-23 08:02:12,725 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-StateMachineUpdater] INFO impl.StateMachineUpdater: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-12-23 08:02:12,726 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c, L:/0.0.0.0:43919] CLOSE
2022-12-23 08:02:12,726 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c, L:/0.0.0.0:43919] INACTIVE
2022-12-23 08:02:12,727 [f77b3ae1-6f4b-452d-8796-94eb37332bef-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x97998c2c, L:/0.0.0.0:43919] UNREGISTERED
2022-12-23 08:02:12,732 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO server.RaftServer$Division: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C: closes. applyIndex: 0
2022-12-23 08:02:12,742 [f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-12-23 08:02:12,753 [f77b3ae1-6f4b-452d-8796-94eb37332bef-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f77b3ae1-6f4b-452d-8796-94eb37332bef@group-5F770461EC8C-SegmentedRaftLogWorker close()
2022-12-23 08:02:12,755 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-f77b3ae1-6f4b-452d-8796-94eb37332bef: Stopped
2022-12-23 08:02:12,755 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-12-23 08:02:12,759 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-002839e5-7489-419b-b8b3-5f770461ec8c; layoutVersion=4; scmId=f77b3ae1-6f4b-452d-8796-94eb37332bef
2022-12-23 08:02:13,735 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 5bfa290bc281/172.20.0.4
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
e1e05913867b: Warning: Permanently added 'e1e05913867b,172.20.0.2' (ECDSA) to the list of known hosts.
e1e05913867b: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
e1e05913867b: WARNING: /opt/hadoop/logs does not exist. Creating.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.3' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
+ sleep 10
+ docker-compose exec -T om /opt/hadoop/bin/ozone om --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2022-12-23 08:02:40,378 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:   host = 763c278532be/172.20.0.3
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.3.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.77.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.52.Final.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.77.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a89ba1a4c485ddff7bf213efd871ee8807520e8a ; compiled by 'runner' on 2022-12-23T07:22Z
STARTUP_MSG:   java = 11.0.14.1
************************************************************/
2022-12-23 08:02:40,398 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-23 08:02:41,281 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2022-12-23 08:02:41,620 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-12-23 08:02:41,682 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.20.0.3:9862
2022-12-23 08:02:41,683 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-12-23 08:02:41,683 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
2022-12-23 08:02:41,707 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-12-23 08:02:41,804 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.20.0.4:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-002839e5-7489-419b-b8b3-5f770461ec8c;layoutVersion=3
2022-12-23 08:02:42,090 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at 763c278532be/172.20.0.3
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
e1e05913867b: Warning: Permanently added 'e1e05913867b,172.20.0.2' (ECDSA) to the list of known hosts.
e1e05913867b: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
e1e05913867b: datanode is running as process 73.  Stop it first.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.3' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm: scm is running as process 521.  Stop it first.
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     13 ?        S      0:00 /usr/sbin/sshd -D
     73 ?        Sl     0:10 /usr/lib/jvm/jre/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dlog4j.configurationFile=/etc/hadoop/dn-audit-log4j2.properties -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-datanode-e1e05913867b.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.HddsDatanodeService
    269 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      6 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 /usr/sbin/sshd -D
    258 ?        Sl     0:07 /usr/lib/jvm/jre/bin/java -Dproc_om -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/om-audit-log4j2.properties -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-om-763c278532be.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.om.OzoneManagerStarter
    334 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      6 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 /usr/sbin/sshd -D
    521 ?        Sl     0:12 /usr/lib/jvm/jre/bin/java -Dproc_scm -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/scm-audit-log4j2.properties -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-scm-5bfa290bc281.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter
   1322 ?        Rs     0:00 ps xa
==============================================================================
Single Node :: Smoketest for one datanode                                     
==============================================================================
Basic Freon smoketest for one datanode                                | PASS |
------------------------------------------------------------------------------
Single Node :: Smoketest for one datanode                             | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm.xml
==============================================================================
Pipeline :: Test ozone admin pipeline command                                 
==============================================================================
Create pipeline                                                       | PASS |
------------------------------------------------------------------------------
List pipelines                                                        | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host                                     | PASS |
------------------------------------------------------------------------------
Deactivate pipeline                                                   | PASS |
------------------------------------------------------------------------------
Activate pipeline                                                     | PASS |
------------------------------------------------------------------------------
Close pipeline                                                        | PASS |
------------------------------------------------------------------------------
Incomplete command                                                    | PASS |
------------------------------------------------------------------------------
Pipeline :: Test ozone admin pipeline command                         | PASS |
7 tests, 7 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm-1.xml
Stopping datanodes
e1e05913867b: Warning: Permanently added 'e1e05913867b,172.20.0.2' (ECDSA) to the list of known hosts.
e1e05913867b: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.3' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm: WARNING: scm did not stop gracefully after 60 seconds: Trying to kill with kill -9
Stopping ozonescripts_scm_1      ... 
Stopping ozonescripts_datanode_1 ... 
Stopping ozonescripts_om_1       ... 
Stopping ozonescripts_datanode_1 ... done
Stopping ozonescripts_om_1       ... done
Stopping ozonescripts_scm_1      ... done
Removing ozonescripts_scm_1      ... 
Removing ozonescripts_datanode_1 ... 
Removing ozonescripts_om_1       ... 
Removing ozonescripts_om_1       ... done
Removing ozonescripts_scm_1      ... done
Removing ozonescripts_datanode_1 ... done
Removing network ozonescripts_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonescripts/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonescripts/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonescripts.xml
removed 'ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm-1.xml'
removed 'ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm.xml'
removed 'ozonescripts/result/log.html'
removed 'ozonescripts/result/report.html'
renamed 'ozonescripts/result/docker-ozonescripts-ozonescripts-single_node-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-ozonescripts-single_node-scm.log'
renamed 'ozonescripts/result/om-audit-763c278532be.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonescripts/om-audit-763c278532be.log'
Executing test in restart
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/om': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data': Operation not permitted
Removing network restart_net
Network restart_net not found.
Creating network "restart_net" with driver "bridge"
Creating restart_dn1_1 ... 
Creating restart_dn3_1 ... 
Creating restart_om_1  ... 
Creating restart_s3g_1 ... 
Creating restart_scm_1 ... 
Creating restart_recon_1 ... 
Creating restart_dn2_1   ... 
Creating restart_om_1    ... done
Creating restart_s3g_1   ... done
Creating restart_dn1_1   ... done
Creating restart_scm_1   ... done
Creating restart_recon_1 ... done
Creating restart_dn3_1   ... done
Creating restart_dn2_1   ... done
SECONDS: 46
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 3c22e8e0fdfa/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 3c22e8e0fdfa/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 3c22e8e0fdfa/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 3c22e8e0fdfa/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:8bba8729-5e02-45fa-bfb1-6268a112ff45 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:8bba8729-5e02-45fa-bfb1-6268a112ff45 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:8bba8729-5e02-45fa-bfb1-6268a112ff45 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=2) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 60
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-1.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-2.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-3.xml
Stopping restart_recon_1 ... 
Stopping restart_dn2_1   ... 
Stopping restart_scm_1   ... 
Stopping restart_s3g_1   ... 
Stopping restart_dn3_1   ... 
Stopping restart_om_1    ... 
Stopping restart_dn1_1   ... 
Stopping restart_s3g_1   ... done
Stopping restart_recon_1 ... done
Stopping restart_om_1    ... done
Stopping restart_dn1_1   ... done
Stopping restart_dn3_1   ... done
Stopping restart_dn2_1   ... done
Stopping restart_scm_1   ... done
Removing restart_recon_1 ... 
Removing restart_dn2_1   ... 
Removing restart_scm_1   ... 
Removing restart_s3g_1   ... 
Removing restart_dn3_1   ... 
Removing restart_om_1    ... 
Removing restart_dn1_1   ... 
Removing restart_s3g_1   ... done
Removing restart_dn1_1   ... done
Removing restart_dn3_1   ... done
Removing restart_dn2_1   ... done
Removing restart_scm_1   ... done
Removing restart_recon_1 ... done
Removing restart_om_1    ... done
Removing network restart_net
Removing network restart_net
Network restart_net not found.
Creating network "restart_net" with driver "bridge"
Creating restart_dn1_1 ... 
Creating restart_recon_1 ... 
Creating restart_om_1    ... 
Creating restart_s3g_1   ... 
Creating restart_dn3_1   ... 
Creating restart_scm_1   ... 
Creating restart_dn2_1   ... 
Creating restart_recon_1 ... done
Creating restart_s3g_1   ... done
Creating restart_dn1_1   ... done
Creating restart_dn3_1   ... done
Creating restart_scm_1   ... done
Creating restart_om_1    ... done
Creating restart_dn2_1   ... done
SECONDS: 45
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1a6fcca567ec/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 1a6fcca567ec/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:8bba8729-5e02-45fa-bfb1-6268a112ff45 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:8bba8729-5e02-45fa-bfb1-6268a112ff45 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62741) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:false, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=2)
SECONDS: 55
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-4.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-5.xml
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-6.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-7.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-8.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-restart-restart-generate-scm-9.xml
Stopping restart_scm_1   ... 
Stopping restart_dn2_1   ... 
Stopping restart_s3g_1   ... 
Stopping restart_dn3_1   ... 
Stopping restart_om_1    ... 
Stopping restart_dn1_1   ... 
Stopping restart_recon_1 ... 
Stopping restart_s3g_1   ... done
Stopping restart_recon_1 ... done
Stopping restart_om_1    ... done
Stopping restart_dn2_1   ... done
Stopping restart_dn1_1   ... done
Stopping restart_dn3_1   ... done
Stopping restart_scm_1   ... done
Removing restart_scm_1   ... 
Removing restart_dn2_1   ... 
Removing restart_s3g_1   ... 
Removing restart_dn3_1   ... 
Removing restart_om_1    ... 
Removing restart_dn1_1   ... 
Removing restart_recon_1 ... 
Removing restart_recon_1 ... done
Removing restart_dn2_1   ... done
Removing restart_om_1    ... done
Removing restart_dn3_1   ... done
Removing restart_dn1_1   ... done
Removing restart_s3g_1   ... done
Removing restart_scm_1   ... done
Removing network restart_net
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart.xml
removed 'restart/result/robot-restart-restart-generate-scm-1.xml'
removed 'restart/result/robot-restart-restart-generate-scm-2.xml'
removed 'restart/result/robot-restart-restart-generate-scm-3.xml'
removed 'restart/result/robot-restart-restart-generate-scm-4.xml'
removed 'restart/result/robot-restart-restart-generate-scm-5.xml'
removed 'restart/result/robot-restart-restart-generate-scm-6.xml'
removed 'restart/result/robot-restart-restart-generate-scm-7.xml'
removed 'restart/result/robot-restart-restart-generate-scm-8.xml'
removed 'restart/result/robot-restart-restart-generate-scm-9.xml'
removed 'restart/result/robot-restart-restart-generate-scm.xml'
removed 'restart/result/log.html'
removed 'restart/result/report.html'
renamed 'restart/result/dn-audit-0187fd9dcbd3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-0187fd9dcbd3.log'
renamed 'restart/result/dn-audit-28721a0ce414.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-28721a0ce414.log'
renamed 'restart/result/dn-audit-6f9466cce7af.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-6f9466cce7af.log'
renamed 'restart/result/dn-audit-7d20b30873d2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-7d20b30873d2.log'
renamed 'restart/result/dn-audit-8b813140f3ba.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-8b813140f3ba.log'
renamed 'restart/result/dn-audit-e964e7535afc.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/dn-audit-e964e7535afc.log'
renamed 'restart/result/docker-restart-restart-generate-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/docker-restart-restart-generate-scm.log'
renamed 'restart/result/om-audit-1a98df86d266.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/om-audit-1a98df86d266.log'
renamed 'restart/result/om-audit-dc701955f384.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/om-audit-dc701955f384.log'
renamed 'restart/result/s3g-audit-08b215a15d37.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/s3g-audit-08b215a15d37.log'
renamed 'restart/result/s3g-audit-88a746c84df8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/s3g-audit-88a746c84df8.log'
renamed 'restart/result/scm-audit-1a6fcca567ec.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/scm-audit-1a6fcca567ec.log'
renamed 'restart/result/scm-audit-3c22e8e0fdfa.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/restart/scm-audit-3c22e8e0fdfa.log'
Exception in thread "main" java.net.SocketException: Socket closed
	at java.base/java.net.PlainSocketImpl.socketAccept(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)
	at java.base/java.net.ServerSocket.accept(ServerSocket.java:533)
	at org.apache.hadoop.test.JacocoServer.main(JacocoServer.java:60)
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/report.html
