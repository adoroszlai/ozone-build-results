rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test in compatibility
Removing network compatibility_default
Network compatibility_default not found.
Creating network "compatibility_default" with the default driver
Pulling datanode (apache/ozone-runner:20220623-1)...
20220623-1: Pulling from apache/ozone-runner
Digest: sha256:ba2ed07322bc8f888150fa2a1ec0523fca85e09c8eb9779445f8bca0d58cff97
Status: Downloaded newer image for apache/ozone-runner:20220623-1
Creating compatibility_datanode_1 ... 
Creating compatibility_recon_1    ... 
Creating compatibility_scm_1      ... 
Creating compatibility_s3g_1      ... 
Creating compatibility_om_1       ... 
Creating compatibility_datanode_1 ... done
Creating compatibility_om_1       ... done
Creating compatibility_recon_1    ... done
Creating compatibility_scm_1      ... done
Creating compatibility_s3g_1      ... done
WARNING: HADOOP_OPTS has been deprecated by OZONE_OPTS.
SECONDS: 30
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5a04ef9655d4/172.18.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5a04ef9655d4/172.18.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5a04ef9655d4/172.18.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:eca90ac0-6671-4e7d-8629-c842dd3a8fae is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:eca90ac0-6671-4e7d-8629-c842dd3a8fae is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:eca90ac0-6671-4e7d-8629-c842dd3a8fae is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.6:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. SCM is out of safe mode.
WARNING: HADOOP_OPTS has been deprecated by OZONE_OPTS.
SECONDS: 37
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Dn :: Test datanode compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Dn :: Test datanode compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-compatibility-compatibility-dn-datanode.xml
==============================================================================
Om :: Test om compatibility                                                   
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Om :: Test om compatibility                                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-compatibility-compatibility-dn-datanode-1.xml
==============================================================================
Recon :: Test recon compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Recon :: Test recon compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-compatibility-compatibility-dn-datanode-2.xml
==============================================================================
Scm :: Test scm compatibility                                                 
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Scm :: Test scm compatibility                                         | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-compatibility-compatibility-dn-datanode-3.xml
==============================================================================
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility                
==============================================================================
Create a container and check container schema version                 | PASS |
------------------------------------------------------------------------------
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility        | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-compatibility-compatibility-dn-datanode-4.xml
Stopping compatibility_om_1       ... 
Stopping compatibility_s3g_1      ... 
Stopping compatibility_scm_1      ... 
Stopping compatibility_recon_1    ... 
Stopping compatibility_datanode_1 ... 
Stopping compatibility_s3g_1      ... done
Stopping compatibility_om_1       ... done
Stopping compatibility_recon_1    ... done
Stopping compatibility_datanode_1 ... done
Stopping compatibility_scm_1      ... done
Removing compatibility_om_1       ... 
Removing compatibility_s3g_1      ... 
Removing compatibility_scm_1      ... 
Removing compatibility_recon_1    ... 
Removing compatibility_datanode_1 ... 
Removing compatibility_s3g_1      ... done
Removing compatibility_datanode_1 ... done
Removing compatibility_om_1       ... done
Removing compatibility_recon_1    ... done
Removing compatibility_scm_1      ... done
Removing network compatibility_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/compatibility/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/compatibility/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility.xml
removed 'compatibility/result/robot-compatibility-compatibility-dn-datanode-1.xml'
removed 'compatibility/result/robot-compatibility-compatibility-dn-datanode-2.xml'
removed 'compatibility/result/robot-compatibility-compatibility-dn-datanode-3.xml'
removed 'compatibility/result/robot-compatibility-compatibility-dn-datanode-4.xml'
removed 'compatibility/result/robot-compatibility-compatibility-dn-datanode.xml'
removed 'compatibility/result/log.html'
removed 'compatibility/result/report.html'
renamed 'compatibility/result/dn-audit-ffbff0f21ec7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility/dn-audit-ffbff0f21ec7.log'
renamed 'compatibility/result/docker-compatibility-compatibility-dn-datanode.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-compatibility-dn-datanode.log'
renamed 'compatibility/result/om-audit-b14d4cd926a7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility/om-audit-b14d4cd926a7.log'
renamed 'compatibility/result/s3g-audit-8fcd96eea9a1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility/s3g-audit-8fcd96eea9a1.log'
renamed 'compatibility/result/scm-audit-5a04ef9655d4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/compatibility/scm-audit-5a04ef9655d4.log'
Executing test in upgrade
Executing test in /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade
--- RUNNING NON-ROLLING UPGRADE TEST FROM 1.2.1 TO 1.3.0 ---
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/dn4': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/dn5': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/data': Operation not permitted
--- SETTING UP OLD VERSION 1.2.1 ---
--- RUNNING WITH OLD VERSION 1.2.1 ---
Removing network ha_net
Network ha_net not found.
Creating network "ha_net" with driver "bridge"
Pulling om1 (apache/ozone:1.2.1)...
Get "https://registry-1.docker.io/v2/": EOF
Removing network ha_net
ERROR: Test execution of /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade is FAILED!!!!
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/upgrades/non-rolling-upgrade/1.2.1-1.3.0/result/docker-1.2.1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/result/1.2.1-1.3.0/docker-1.2.1.log'
[ ERROR ] Reading XML source '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/upgrade/result/*.xml' failed: No such file or directory

Try --help for usage information.
ERROR: Test execution of upgrade is FAILED!!!!
renamed 'upgrade/result/1.2.1-1.3.0' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/upgrade/1.2.1-1.3.0'
Executing test in xcompat
Starting cluster with COMPOSE_FILE=new-cluster.yaml:clients.yaml
Removing network xcompat_default
Network xcompat_default not found.
Creating network "xcompat_default" with the default driver
Pulling old_client_1_1_0 (apache/ozone:1.1.0)...
1.1.0: Pulling from apache/ozone
Digest: sha256:6dd13dca7a08ad072b027d30187363bc3552c63947325e871cb51199fbaef172
Status: Downloaded newer image for apache/ozone:1.1.0
Pulling old_client_1_2_1 (apache/ozone:1.2.1)...
1.2.1: Pulling from apache/ozone
Digest: sha256:1a5f4e28568aaa4aaea6ed560d45b167e0dd8274660e81d746379c2aa6594b7b
Status: Downloaded newer image for apache/ozone:1.2.1
Pulling old_client_1_0_0 (apache/ozone:1.0.0)...
received unexpected HTTP status: 503 Service Unavailable
Removing network xcompat_default
ERROR: Test execution of xcompat is FAILED!!!!
renamed 'xcompat/result/docker-xcompat.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/xcompat/docker-xcompat.log'
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/report.html
