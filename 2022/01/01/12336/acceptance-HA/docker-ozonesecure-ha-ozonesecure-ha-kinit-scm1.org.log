Attaching to ozonesecure-ha_om3_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_kdc_1, ozonesecure-ha_kms_1, ozonesecure-ha_om2_1, ozonesecure-ha_recon_1, ozonesecure-ha_om1_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_datanode2_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-01-01 01:12:05,826 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = d689e1354c2c/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2022-01-01 01:12:05,913 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-01-01 01:12:07,722 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-01-01 01:12:08,394 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-01-01 01:12:09,912 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-01-01 01:12:09,914 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-01-01 01:12:11,072 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d689e1354c2c ip:172.25.0.102
datanode1_1  | 2022-01-01 01:12:14,411 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-01-01 01:12:15,508 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-01-01 01:12:15,509 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-01-01 01:12:17,633 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-01-01 01:12:17,633 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-01-01 01:12:17,633 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-01-01 01:12:17,698 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-01-01 01:12:21,940 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-01-01 01:12:22,016 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:d689e1354c2c
datanode1_1  | 2022-01-01 01:12:22,034 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-01-01 01:12:22,054 [main] ERROR client.DNCertificateClient: Invalid domain d689e1354c2c
datanode1_1  | 2022-01-01 01:12:22,062 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@d689e1354c2c
datanode1_1  | 2022-01-01 01:12:28,181 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-01-01 01:12:28,254 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/946568622539.crt.
datanode1_1  | 2022-01-01 01:12:28,280 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-857524461429.crt.
datanode1_1  | 2022-01-01 01:12:28,286 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-01-01 01:12:28,309 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-01-01 01:12:28,498 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2022-01-01 01:12:29,693 [main] INFO reflections.Reflections: Reflections took 919 ms to scan 2 urls, producing 85 keys and 173 values 
datanode1_1  | 2022-01-01 01:12:30,163 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-01-01 01:12:31,346 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-01-01 01:12:31,453 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-01-01 01:12:31,460 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-01-01 01:12:31,466 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-01-01 01:12:31,647 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-01-01 01:12:31,830 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-01-01 01:12:31,847 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-01-01 01:12:31,854 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-01-01 01:12:31,854 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-01-01 01:12:31,867 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-01-01 01:12:32,045 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-01-01 01:12:32,055 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-01-01 01:12:38,759 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-01-01 01:12:39,264 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-01-01 01:12:39,860 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-01-01 01:12:39,860 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-01-01 01:12:39,861 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-01-01 01:12:39,863 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-01-01 01:12:39,869 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-01-01 01:12:39,874 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-01-01 01:12:39,893 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-01-01 01:12:48,525 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-01-01 01:12:48,557 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:12:48,558 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-01-01 01:12:48,650 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-01-01 01:12:49,519 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-01-01 01:12:51,245 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-01-01 01:12:51,245 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-01-01 01:12:51,245 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-01-01 01:12:51,432 [main] INFO util.log: Logging initialized @54177ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-01-01 01:12:52,217 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-01-01 01:12:52,266 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-01-01 01:12:52,289 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-01-01 01:12:52,301 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-01-01 01:12:52,301 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-01-01 01:12:52,321 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-01-01 01:12:52,574 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-01-01 01:12:52,586 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode1_1  | 2022-01-01 01:12:52,816 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-01-01 01:12:52,820 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-01-01 01:12:52,822 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2022-01-01 01:12:52,921 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-01-01 01:12:52,944 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b132063{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-01-01 01:12:52,950 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@706dee4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-01-01 01:12:53,502 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-01-01 01:12:53,575 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@123a21ad{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-6586574911255746544/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-01-01 01:12:53,630 [main] INFO server.AbstractConnector: Started ServerConnector@475b796d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-01-01 01:12:53,635 [main] INFO server.Server: Started @56379ms
datanode1_1  | 2022-01-01 01:12:53,644 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-01-01 01:12:53,648 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-01-01 01:12:53,650 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-01-01 01:12:53,677 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-01-01 01:12:53,819 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@642f424a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-01-01 01:12:54,416 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-01-01 01:12:57,900 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode1_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:633)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:280)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:468)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	... 1 more
datanode1_1  | 2022-01-01 01:12:57,901 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode1_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:633)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:280)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:468)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	... 1 more
datanode1_1  | 2022-01-01 01:12:58,307 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-01-01 01:12:58,314 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-01-01 01:12:58,820 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 458bfdff-96fb-4b4a-96de-6879eec60ac8
datanode1_1  | 2022-01-01 01:12:59,011 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start RPC server
datanode1_1  | 2022-01-01 01:12:59,019 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 458bfdff-96fb-4b4a-96de-6879eec60ac8: GrpcService started, listening on 9856
datanode1_1  | 2022-01-01 01:12:59,024 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 458bfdff-96fb-4b4a-96de-6879eec60ac8: GrpcService started, listening on 9857
datanode1_1  | 2022-01-01 01:12:59,033 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 458bfdff-96fb-4b4a-96de-6879eec60ac8: GrpcService started, listening on 9858
datanode1_1  | 2022-01-01 01:12:59,070 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 458bfdff-96fb-4b4a-96de-6879eec60ac8 is started using port 9858 for RATIS
datanode1_1  | 2022-01-01 01:12:59,073 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 458bfdff-96fb-4b4a-96de-6879eec60ac8 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-01-01 01:12:59,074 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 458bfdff-96fb-4b4a-96de-6879eec60ac8 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-01-01 01:12:59,074 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$345/0x00000008405ce840@4d5c2905] INFO util.JvmPauseMonitor: JvmPauseMonitor-458bfdff-96fb-4b4a-96de-6879eec60ac8: Started
datanode1_1  | 2022-01-01 01:12:59,222 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-01-01 01:12:59,222 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-01-01 01:13:11,378 [grpc-default-executor-0] INFO server.RaftServer: 458bfdff-96fb-4b4a-96de-6879eec60ac8: addNew group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-F8541548C104:java.util.concurrent.CompletableFuture@4db76556[Not completed]
datanode1_1  | 2022-01-01 01:13:11,540 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8: new RaftServerImpl for group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-01-01 01:13:11,563 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-01-01 01:13:11,567 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-01-01 01:13:11,567 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-01-01 01:13:11,568 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:11,568 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-01-01 01:13:11,571 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-01-01 01:13:11,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-01-01 01:13:11,637 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-01-01 01:13:11,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-01-01 01:13:11,691 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-01-01 01:13:11,711 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-01-01 01:13:11,720 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 does not exist. Creating ...
datanode1_1  | 2022-01-01 01:13:11,768 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/in_use.lock acquired by nodename 7@d689e1354c2c
datanode1_1  | 2022-01-01 01:13:11,805 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 has been successfully formatted.
datanode1_1  | 2022-01-01 01:13:11,911 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F8541548C104: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-01-01 01:13:11,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:11,947 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-01-01 01:13:12,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-01-01 01:13:12,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-01-01 01:13:12,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:12,120 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-01-01 01:13:12,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-01-01 01:13:12,168 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104
datanode1_1  | 2022-01-01 01:13:12,169 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-01-01 01:13:12,173 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-01-01 01:13:12,174 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:12,174 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-01-01 01:13:12,178 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-01-01 01:13:12,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-01-01 01:13:12,187 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-01-01 01:13:12,195 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-01-01 01:13:12,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:12,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:12,287 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:12,293 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:12,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:12,320 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-01-01 01:13:12,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-01-01 01:13:12,330 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-01-01 01:13:12,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-01-01 01:13:12,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-01-01 01:13:12,497 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:12,511 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-01-01 01:13:12,518 [pool-23-thread-1] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FollowerState
datanode1_1  | 2022-01-01 01:13:12,529 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F8541548C104,id=458bfdff-96fb-4b4a-96de-6879eec60ac8
datanode1_1  | 2022-01-01 01:13:13,551 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-F8541548C104, 1, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:13,565 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FOLLOWER: accept ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-01-01 01:13:13,567 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:24732aa1-1492-41aa-844a-173d185ef1c3
datanode1_1  | 2022-01-01 01:13:13,570 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FollowerState
datanode1_1  | 2022-01-01 01:13:13,574 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-01-01 01:12:05,257 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 6842de8f6a86/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2022-01-01 01:12:05,334 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-01-01 01:12:07,380 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-01-01 01:12:08,248 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-01-01 01:12:09,365 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-01-01 01:12:09,382 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-01-01 01:12:10,737 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6842de8f6a86 ip:172.25.0.103
datanode2_1  | 2022-01-01 01:12:14,463 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-01-01 01:12:15,594 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-01-01 01:12:15,603 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-01-01 01:12:17,898 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-01-01 01:12:17,899 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-01-01 01:12:17,899 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-01-01 01:12:17,900 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-01-01 01:12:24,348 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-01-01 01:12:24,465 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:6842de8f6a86
datanode2_1  | 2022-01-01 01:12:24,488 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-01-01 01:12:24,504 [main] ERROR client.DNCertificateClient: Invalid domain 6842de8f6a86
datanode2_1  | 2022-01-01 01:12:24,519 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@6842de8f6a86
datanode2_1  | 2022-01-01 01:12:29,381 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-01-01 01:12:29,745 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-857524461429.crt.
datanode2_1  | 2022-01-01 01:12:29,785 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-01-01 01:12:29,811 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/948298220736.crt.
datanode2_1  | 2022-01-01 01:12:29,811 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-01-01 01:12:29,948 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2022-01-01 01:12:30,696 [main] INFO reflections.Reflections: Reflections took 551 ms to scan 2 urls, producing 85 keys and 173 values 
datanode2_1  | 2022-01-01 01:12:31,212 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-01-01 01:12:32,299 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-01-01 01:12:32,381 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-01-01 01:12:32,424 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-01-01 01:12:32,427 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-01-01 01:12:32,677 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-01-01 01:12:32,917 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-01-01 01:12:32,923 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-01-01 01:12:32,951 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-01-01 01:12:32,952 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-01-01 01:12:32,952 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-01-01 01:12:33,136 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-01-01 01:12:33,163 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-01-01 01:12:39,876 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-01-01 01:12:40,392 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-01-01 01:12:41,316 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-01-01 01:12:41,333 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-01-01 01:12:41,342 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-01-01 01:12:41,343 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-01-01 01:12:41,355 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:12:41,356 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-01-01 01:12:41,357 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-01-01 01:12:49,400 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-01-01 01:12:49,416 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:12:49,416 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-01-01 01:12:49,507 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-01-01 01:12:50,948 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-01-01 01:12:52,478 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-01-01 01:12:52,499 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-01-01 01:12:52,499 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-01-01 01:12:52,638 [main] INFO util.log: Logging initialized @55225ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-01-01 01:12:53,301 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-01-01 01:12:53,334 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-01-01 01:12:53,355 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-01-01 01:12:53,356 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-01-01 01:12:53,356 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-01-01 01:12:53,395 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-01-01 01:12:53,635 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-01-01 01:12:53,641 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode2_1  | 2022-01-01 01:12:53,948 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-01-01 01:12:53,957 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-01-01 01:12:53,961 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-01-01 01:12:54,180 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-01-01 01:12:54,204 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@37bac0f4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-01-01 01:12:54,247 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@63f819a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-01-01 01:12:54,879 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-01-01 01:12:54,933 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@13ac1657{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1701357965093482686/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-01-01 01:12:54,985 [main] INFO server.AbstractConnector: Started ServerConnector@125ed27{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-01-01 01:12:54,986 [main] INFO server.Server: Started @57572ms
datanode2_1  | 2022-01-01 01:12:55,031 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-01-01 01:12:55,032 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-01-01 01:12:55,042 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-01-01 01:12:55,090 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-01-01 01:12:55,276 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42b8b22c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-01-01 01:12:55,574 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-01-01 01:12:58,322 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-01-01 01:12:58,358 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-01-01 01:12:59,068 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:12:59,250 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 24732aa1-1492-41aa-844a-173d185ef1c3: start RPC server
datanode2_1  | 2022-01-01 01:12:59,274 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 24732aa1-1492-41aa-844a-173d185ef1c3: GrpcService started, listening on 9856
datanode2_1  | 2022-01-01 01:12:59,290 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 24732aa1-1492-41aa-844a-173d185ef1c3: GrpcService started, listening on 9857
datanode2_1  | 2022-01-01 01:12:59,304 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 24732aa1-1492-41aa-844a-173d185ef1c3: GrpcService started, listening on 9858
datanode2_1  | 2022-01-01 01:12:59,333 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 24732aa1-1492-41aa-844a-173d185ef1c3 is started using port 9858 for RATIS
datanode2_1  | 2022-01-01 01:12:59,345 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 24732aa1-1492-41aa-844a-173d185ef1c3 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-01-01 01:12:59,346 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 24732aa1-1492-41aa-844a-173d185ef1c3 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-01-01 01:12:59,346 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$345/0x00000008405ce840@29fadd11] INFO util.JvmPauseMonitor: JvmPauseMonitor-24732aa1-1492-41aa-844a-173d185ef1c3: Started
datanode2_1  | 2022-01-01 01:12:59,479 [Datanode State Machine Daemon Thread] ERROR statemachine.DatanodeStateMachine: Unable to finish the execution.
datanode2_1  | java.util.ConcurrentModificationException
datanode2_1  | 	at java.base/java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1043)
datanode2_1  | 	at java.base/java.util.ArrayList$Itr.next(ArrayList.java:997)
datanode2_1  | 	at org.apache.hadoop.hdds.protocol.DatanodeDetails.toProtoBuilder(DatanodeDetails.java:419)
datanode2_1  | 	at org.apache.hadoop.hdds.protocol.DatanodeDetails.toProto(DatanodeDetails.java:380)
datanode2_1  | 	at org.apache.hadoop.hdds.protocol.DatanodeDetails.getProtoBufMessage(DatanodeDetails.java:376)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask$Builder.build(HeartbeatEndpointTask.java:516)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.initEndPointTask(RunningDatanodeState.java:102)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.<init>(RunningDatanodeState.java:67)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.getTask(StateContext.java:575)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:611)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-01-01 01:12:06,684 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 9f382dc742e3/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2022-01-01 01:12:06,776 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-01-01 01:12:08,784 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-01-01 01:12:10,001 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-01-01 01:12:10,970 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-01-01 01:12:10,977 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-01-01 01:12:12,004 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9f382dc742e3 ip:172.25.0.104
datanode3_1  | 2022-01-01 01:12:15,803 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-01-01 01:12:16,841 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-01-01 01:12:16,842 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-01-01 01:12:19,036 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-01-01 01:12:19,042 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-01-01 01:12:19,063 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-01-01 01:12:19,068 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-01-01 01:12:25,041 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-01-01 01:12:25,117 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:9f382dc742e3
datanode3_1  | 2022-01-01 01:12:25,128 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-01-01 01:12:25,149 [main] ERROR client.DNCertificateClient: Invalid domain 9f382dc742e3
datanode3_1  | 2022-01-01 01:12:25,175 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@9f382dc742e3
datanode3_1  | 2022-01-01 01:12:30,317 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-01-01 01:12:30,408 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-857524461429.crt.
datanode3_1  | 2022-01-01 01:12:30,448 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-01-01 01:12:30,458 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/949221940755.crt.
datanode3_1  | 2022-01-01 01:12:30,461 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-01-01 01:12:30,554 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2022-01-01 01:12:31,475 [main] INFO reflections.Reflections: Reflections took 718 ms to scan 2 urls, producing 85 keys and 173 values 
datanode3_1  | 2022-01-01 01:12:31,930 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-01-01 01:12:33,148 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-01-01 01:12:33,249 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-01-01 01:12:33,290 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-01-01 01:12:33,291 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-01-01 01:12:33,519 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-01-01 01:12:33,698 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-01-01 01:12:33,712 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-01-01 01:12:33,734 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-01-01 01:12:33,735 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-01-01 01:12:33,753 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-01-01 01:12:33,919 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-01-01 01:12:33,946 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-01-01 01:12:41,213 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-01-01 01:12:41,875 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-01-01 01:12:42,597 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-01-01 01:12:42,598 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-01-01 01:12:42,605 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-01-01 01:12:42,607 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-01-01 01:12:42,614 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:12:42,615 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-01-01 01:12:42,619 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-01-01 01:12:49,847 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-01-01 01:13:13,576 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-FollowerState
datanode1_1  | 2022-01-01 01:13:13,588 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104 replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t1. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104:t1, leader=null, voted=24732aa1-1492-41aa-844a-173d185ef1c3, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:14,278 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F8541548C104 with new leaderId: 24732aa1-1492-41aa-844a-173d185ef1c3
datanode1_1  | 2022-01-01 01:13:14,311 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: change Leader from null to 24732aa1-1492-41aa-844a-173d185ef1c3 at term 1 for appendEntries, leader elected after 2362ms
datanode1_1  | 2022-01-01 01:13:14,500 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:14,518 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:280)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:468)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2022-01-01 01:12:59,549 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-01-01 01:12:59,549 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-01-01 01:13:04,544 [Command processor thread] INFO server.RaftServer: 24732aa1-1492-41aa-844a-173d185ef1c3: addNew group-3D91C85C85AC:[24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-3D91C85C85AC:java.util.concurrent.CompletableFuture@497d5a4e[Not completed]
datanode2_1  | 2022-01-01 01:13:04,676 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3: new RaftServerImpl for group-3D91C85C85AC:[24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-01-01 01:13:04,683 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-01-01 01:13:04,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-01-01 01:13:04,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-01-01 01:13:04,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:04,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-01-01 01:13:04,688 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-01-01 01:13:04,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-01-01 01:13:04,717 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: ConfigurationManager, init=-1: [24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-01-01 01:13:04,723 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-01-01 01:13:04,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-01-01 01:13:04,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-01-01 01:13:04,818 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac does not exist. Creating ...
datanode2_1  | 2022-01-01 01:13:04,868 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac/in_use.lock acquired by nodename 8@6842de8f6a86
datanode2_1  | 2022-01-01 01:13:04,905 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac has been successfully formatted.
datanode2_1  | 2022-01-01 01:13:04,957 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-3D91C85C85AC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-01-01 01:13:05,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:05,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-01-01 01:13:05,231 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-01-01 01:13:05,246 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:13:05,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:05,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-01-01 01:13:05,486 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-01-01 01:13:05,527 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac
datanode2_1  | 2022-01-01 01:13:05,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-01-01 01:13:05,543 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:05,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:05,551 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-01-01 01:13:05,551 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-01-01 01:13:05,561 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-01-01 01:13:05,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-01-01 01:13:05,563 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-01-01 01:13:15,088 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-F8541548C104-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/current/log_inprogress_0
datanode1_1  | 2022-01-01 01:13:18,381 [grpc-default-executor-0] INFO server.RaftServer: 458bfdff-96fb-4b4a-96de-6879eec60ac8: addNew group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-BD59923C342B:java.util.concurrent.CompletableFuture@22ba7c77[Not completed]
datanode1_1  | 2022-01-01 01:13:18,387 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8: new RaftServerImpl for group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-01-01 01:13:18,390 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-01-01 01:13:18,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-01-01 01:13:18,393 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-01-01 01:13:18,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-01-01 01:13:18,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-01-01 01:13:18,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-01-01 01:13:18,398 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b does not exist. Creating ...
datanode1_1  | 2022-01-01 01:13:18,404 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/in_use.lock acquired by nodename 7@d689e1354c2c
datanode1_1  | 2022-01-01 01:13:18,410 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b has been successfully formatted.
datanode1_1  | 2022-01-01 01:13:18,448 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BD59923C342B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-01-01 01:13:18,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:18,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-01-01 01:13:18,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-01-01 01:13:18,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-01-01 01:13:18,453 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:18,458 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-01-01 01:13:18,458 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-01-01 01:13:18,467 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b
datanode1_1  | 2022-01-01 01:13:18,467 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-01-01 01:13:18,468 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-01-01 01:13:18,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:18,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-01-01 01:13:18,471 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-01-01 01:13:18,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-01-01 01:13:18,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-01-01 01:13:18,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-01-01 01:13:18,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:18,474 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:18,481 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:18,481 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:18,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:18,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-01-01 01:13:18,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-01-01 01:13:18,482 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-01-01 01:13:18,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-01-01 01:13:18,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-01-01 01:13:18,489 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:18,489 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-01-01 01:13:18,494 [pool-23-thread-1] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:18,496 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD59923C342B,id=458bfdff-96fb-4b4a-96de-6879eec60ac8
datanode1_1  | 2022-01-01 01:13:22,315 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 1, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:22,315 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FOLLOWER: accept ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-01-01 01:13:22,315 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:24732aa1-1492-41aa-844a-173d185ef1c3
datanode1_1  | 2022-01-01 01:13:22,315 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:22,316 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:22,316 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-01-01 01:13:22,340 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t1. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B:t1, leader=null, voted=24732aa1-1492-41aa-844a-173d185ef1c3, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:27,372 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031925141ns, electionTimeout:5031ms
datanode1_1  | 2022-01-01 01:13:27,372 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:27,373 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2022-01-01 01:13:27,376 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-01-01 01:13:27,376 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1
datanode1_1  | 2022-01-01 01:13:27,379 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:27,575 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 2, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:27,593 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-CANDIDATE: reject ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: already has voted for 458bfdff-96fb-4b4a-96de-6879eec60ac8 at current term 2
datanode1_1  | 2022-01-01 01:13:27,593 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:FAIL-t2. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B:t2, leader=null, voted=458bfdff-96fb-4b4a-96de-6879eec60ac8, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:29,287 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-01-01 01:13:29,310 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection:   Response 0: 458bfdff-96fb-4b4a-96de-6879eec60ac8<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t2
datanode3_1  | 2022-01-01 01:12:49,864 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:12:49,870 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-01-01 01:12:50,011 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-01-01 01:12:51,488 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-01-01 01:12:52,776 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-01-01 01:12:52,776 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-01-01 01:12:52,776 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-01-01 01:12:53,007 [main] INFO util.log: Logging initialized @54856ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-01-01 01:12:53,844 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-01-01 01:12:53,881 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-01-01 01:12:53,909 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-01-01 01:12:53,916 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-01-01 01:12:53,917 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-01-01 01:12:53,935 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-01-01 01:12:54,239 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-01-01 01:12:54,264 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode3_1  | 2022-01-01 01:12:54,504 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-01-01 01:12:54,504 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-01-01 01:12:54,517 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2022-01-01 01:12:54,624 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-01-01 01:12:54,640 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e196238{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-01-01 01:12:54,645 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c2063e0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-01-01 01:12:55,246 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-01-01 01:12:55,316 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ab959e8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-11019678774269539995/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-01-01 01:12:55,396 [main] INFO server.AbstractConnector: Started ServerConnector@43600de0{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-01-01 01:12:55,402 [main] INFO server.Server: Started @57251ms
datanode3_1  | 2022-01-01 01:12:55,434 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-01-01 01:12:55,434 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-01-01 01:12:55,441 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-01-01 01:12:55,446 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-01-01 01:12:55,578 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b47e8e0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-01-01 01:12:55,961 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-01-01 01:12:58,563 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-01-01 01:12:58,588 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-01-01 01:12:59,163 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:12:59,409 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 75beef28-1584-4115-9505-884f6f5c519b: start RPC server
datanode3_1  | 2022-01-01 01:12:59,440 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 75beef28-1584-4115-9505-884f6f5c519b: GrpcService started, listening on 9856
datanode3_1  | 2022-01-01 01:12:59,463 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 75beef28-1584-4115-9505-884f6f5c519b: GrpcService started, listening on 9857
datanode3_1  | 2022-01-01 01:12:59,466 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 75beef28-1584-4115-9505-884f6f5c519b: GrpcService started, listening on 9858
datanode3_1  | 2022-01-01 01:12:59,507 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 75beef28-1584-4115-9505-884f6f5c519b is started using port 9858 for RATIS
datanode3_1  | 2022-01-01 01:12:59,513 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 75beef28-1584-4115-9505-884f6f5c519b is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-01-01 01:12:59,513 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 75beef28-1584-4115-9505-884f6f5c519b is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-01-01 01:12:59,514 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$345/0x00000008405ce840@34d2be94] INFO util.JvmPauseMonitor: JvmPauseMonitor-75beef28-1584-4115-9505-884f6f5c519b: Started
datanode3_1  | 2022-01-01 01:12:59,680 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-01-01 01:12:59,681 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-01-01 01:13:14,963 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 75beef28-1584-4115-9505-884f6f5c519b: Failed requestVote 24732aa1-1492-41aa-844a-173d185ef1c3->75beef28-1584-4115-9505-884f6f5c519b#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 75beef28-1584-4115-9505-884f6f5c519b: group-F8541548C104 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode2_1  | 2022-01-01 01:13:05,656 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:05,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:05,719 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:05,723 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:05,747 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:05,763 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-01-01 01:13:05,767 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-01-01 01:13:05,775 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-01-01 01:13:05,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-01-01 01:13:05,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-01-01 01:13:06,159 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: start as a follower, conf=-1: [24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode1_1  | 2022-01-01 01:13:29,310 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2022-01-01 01:13:29,317 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode1_1  | 2022-01-01 01:13:29,317 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1
datanode1_1  | 2022-01-01 01:13:29,317 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-LeaderElection1] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:29,324 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: receive requestVote(ELECTION, 75beef28-1584-4115-9505-884f6f5c519b, group-BD59923C342B, 2, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:29,329 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FOLLOWER: reject ELECTION from 75beef28-1584-4115-9505-884f6f5c519b: already has voted for 458bfdff-96fb-4b4a-96de-6879eec60ac8 at current term 2
datanode1_1  | 2022-01-01 01:13:29,329 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B replies to ELECTION vote request: 75beef28-1584-4115-9505-884f6f5c519b<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:FAIL-t2. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B:t2, leader=null, voted=458bfdff-96fb-4b4a-96de-6879eec60ac8, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:32,645 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 3, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:32,645 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FOLLOWER: accept ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-01-01 01:13:32,645 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:24732aa1-1492-41aa-844a-173d185ef1c3
datanode1_1  | 2022-01-01 01:13:32,646 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:32,646 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-01-01 01:13:32,647 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:32,655 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t3. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B:t3, leader=null, voted=24732aa1-1492-41aa-844a-173d185ef1c3, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:32,909 [Command processor thread] INFO server.RaftServer: 458bfdff-96fb-4b4a-96de-6879eec60ac8: addNew group-CED3CA6A01AC:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-CED3CA6A01AC:java.util.concurrent.CompletableFuture@62fd5186[Not completed]
datanode1_1  | 2022-01-01 01:13:32,911 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8: new RaftServerImpl for group-CED3CA6A01AC:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-01-01 01:13:32,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-01-01 01:13:32,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-01-01 01:13:32,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-01-01 01:13:32,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:32,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-01-01 01:13:32,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-01-01 01:13:32,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-01-01 01:13:32,913 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-01-01 01:13:32,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-01-01 01:13:32,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-01-01 01:13:32,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-01-01 01:13:32,914 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d83b488f-4512-497f-b5fa-ced3ca6a01ac does not exist. Creating ...
datanode1_1  | 2022-01-01 01:13:32,916 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d83b488f-4512-497f-b5fa-ced3ca6a01ac/in_use.lock acquired by nodename 7@d689e1354c2c
datanode2_1  | 2022-01-01 01:13:06,167 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-01-01 01:13:06,188 [pool-23-thread-1] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState
datanode2_1  | 2022-01-01 01:13:06,224 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3D91C85C85AC,id=24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:13:06,337 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac
datanode2_1  | 2022-01-01 01:13:06,339 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac.
datanode2_1  | 2022-01-01 01:13:06,348 [Command processor thread] INFO server.RaftServer: 24732aa1-1492-41aa-844a-173d185ef1c3: addNew group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-F8541548C104:java.util.concurrent.CompletableFuture@a6d46c[Not completed]
datanode2_1  | 2022-01-01 01:13:06,353 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3: new RaftServerImpl for group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-01-01 01:13:06,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-01-01 01:13:06,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-01-01 01:13:06,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-01-01 01:13:06,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:06,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-01-01 01:13:06,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-01-01 01:13:06,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-01-01 01:13:06,361 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-01-01 01:13:06,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-01-01 01:13:06,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-01-01 01:13:06,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-01-01 01:13:06,366 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 does not exist. Creating ...
datanode2_1  | 2022-01-01 01:13:06,389 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/in_use.lock acquired by nodename 8@6842de8f6a86
datanode2_1  | 2022-01-01 01:13:06,391 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 has been successfully formatted.
datanode2_1  | 2022-01-01 01:13:06,401 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F8541548C104: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-01-01 01:13:06,401 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:06,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-01-01 01:13:06,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-01-01 01:13:06,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:13:06,428 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:06,428 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-01-01 01:13:06,429 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-01-01 01:13:06,430 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104
datanode2_1  | 2022-01-01 01:13:06,430 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-01-01 01:13:06,431 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:06,431 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:06,436 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-01-01 01:13:06,438 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-01-01 01:13:06,438 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-01-01 01:13:06,438 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-01-01 01:13:06,438 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-01-01 01:13:06,439 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:06,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:06,446 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:06,449 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:06,449 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:06,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-01-01 01:13:06,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-01-01 01:13:06,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-01-01 01:13:06,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-01-01 01:13:06,454 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-01-01 01:13:06,455 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:06,457 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-01-01 01:13:06,457 [pool-23-thread-1] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState
datanode2_1  | 2022-01-01 01:13:06,457 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F8541548C104,id=24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:13:06,458 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e5481fd7-e475-47a4-9362-f8541548c104
datanode2_1  | 2022-01-01 01:13:11,360 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5178910414ns, electionTimeout:5137ms
datanode2_1  | 2022-01-01 01:13:11,361 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState
datanode2_1  | 2022-01-01 01:13:11,361 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:11,366 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:11,366 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1
datanode2_1  | 2022-01-01 01:13:11,379 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-01-01 01:13:11,381 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-01-01 01:13:11,381 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1
datanode2_1  | 2022-01-01 01:13:11,382 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-01-01 01:13:11,383 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3D91C85C85AC with new leaderId: 24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:13:11,384 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: change Leader from null to 24732aa1-1492-41aa-844a-173d185ef1c3 at term 1 for becomeLeader, leader elected after 6364ms
datanode2_1  | 2022-01-01 01:13:11,412 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-01-01 01:13:11,467 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:11,472 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-01-01 01:13:11,535 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-01-01 01:13:11,535 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-01-01 01:13:11,536 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): Loaded
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): setting up network...
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Jan 01 01:10:31 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jan 01 01:10:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:10:43 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1640999443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:10:44 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1640999444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:02 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1640999462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:07 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1640999467, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1640999444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1640999462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:25 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999485, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:31 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1640999491, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999485, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999496, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1640999491, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:41 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1640999501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1640999501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999496, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:11:50 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1640999510, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 2022-01-01 01:13:32,923 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d83b488f-4512-497f-b5fa-ced3ca6a01ac has been successfully formatted.
datanode1_1  | 2022-01-01 01:13:32,994 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-CED3CA6A01AC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-01-01 01:13:33,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-01-01 01:13:33,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-01-01 01:13:33,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-01-01 01:13:33,035 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-01-01 01:13:33,036 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:33,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-01-01 01:13:33,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-01-01 01:13:33,069 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d83b488f-4512-497f-b5fa-ced3ca6a01ac
datanode1_1  | 2022-01-01 01:13:33,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-01-01 01:13:33,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-01-01 01:13:33,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:33,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-01-01 01:13:33,074 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-01-01 01:13:33,074 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-01-01 01:13:33,074 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-01-01 01:13:33,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-01-01 01:13:33,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-01-01 01:13:33,132 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:33,141 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:33,146 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-01-01 01:13:33,147 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-01-01 01:13:33,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-01-01 01:13:33,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-01-01 01:13:33,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-01-01 01:13:33,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-01-01 01:13:33,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-01-01 01:13:33,152 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-01-01 01:13:33,170 [pool-23-thread-1] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-01-01 01:13:33,171 [pool-23-thread-1] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState
datanode1_1  | 2022-01-01 01:13:33,173 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CED3CA6A01AC,id=458bfdff-96fb-4b4a-96de-6879eec60ac8
datanode1_1  | 2022-01-01 01:13:33,178 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d83b488f-4512-497f-b5fa-ced3ca6a01ac
datanode1_1  | 2022-01-01 01:13:33,179 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d83b488f-4512-497f-b5fa-ced3ca6a01ac.
datanode1_1  | 2022-01-01 01:13:37,920 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: receive requestVote(ELECTION, 75beef28-1584-4115-9505-884f6f5c519b, group-BD59923C342B, 4, (t:0, i:0))
datanode1_1  | 2022-01-01 01:13:37,920 [grpc-default-executor-0] INFO impl.VoteContext: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FOLLOWER: accept ELECTION from 75beef28-1584-4115-9505-884f6f5c519b: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-01-01 01:13:37,920 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:75beef28-1584-4115-9505-884f6f5c519b
datanode1_1  | 2022-01-01 01:13:37,921 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:37,921 [grpc-default-executor-0] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState
datanode1_1  | 2022-01-01 01:13:37,921 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-FollowerState was interrupted: {}
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2022-01-01 01:13:15,633 [grpc-default-executor-0] INFO server.RaftServer: 75beef28-1584-4115-9505-884f6f5c519b: addNew group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-F8541548C104:java.util.concurrent.CompletableFuture@2e8a698b[Not completed]
datanode3_1  | 2022-01-01 01:13:15,715 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b: new RaftServerImpl for group-F8541548C104:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-01-01 01:13:15,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-01-01 01:13:15,729 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-01-01 01:13:15,730 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-01-01 01:13:15,730 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:13:15,731 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-01-01 01:13:15,731 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-01-01 01:13:15,733 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-01-01 01:13:15,759 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-01-01 01:13:15,760 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-01-01 01:13:15,768 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-01-01 01:13:15,770 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-01-01 01:13:15,780 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 does not exist. Creating ...
datanode3_1  | 2022-01-01 01:13:15,798 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/in_use.lock acquired by nodename 8@9f382dc742e3
datanode3_1  | 2022-01-01 01:13:15,814 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104 has been successfully formatted.
datanode3_1  | 2022-01-01 01:13:15,881 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F8541548C104: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-01-01 01:13:15,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:13:15,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-01-01 01:13:15,949 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-01-01 01:13:15,974 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:13:16,001 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:16,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-01-01 01:13:16,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-01-01 01:13:16,177 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104
datanode3_1  | 2022-01-01 01:13:16,179 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-01-01 01:13:16,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:16,185 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:16,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-01-01 01:13:16,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-01-01 01:13:16,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-01-01 01:13:16,214 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-01-01 01:13:16,215 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-01-01 01:13:16,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:16,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:16,434 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Jan 01 01:11:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:11:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1640999510, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:10 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:16 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1640999536, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1640999538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:19 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1640999539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:20 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1640999540, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1640999538, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1640999539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1640999540, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1640999536, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:12:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999571, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:12:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jan 01 01:12:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1640999535, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode3_1  | 2022-01-01 01:13:16,446 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-01-01 01:13:16,540 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:16,544 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-01-01 01:13:16,547 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-01-01 01:13:16,551 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-01-01 01:13:16,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-01-01 01:13:16,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-01-01 01:13:16,785 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:16,807 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-01-01 01:13:16,814 [pool-23-thread-1] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-FollowerState
datanode3_1  | 2022-01-01 01:13:16,852 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F8541548C104,id=75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:13:17,805 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F8541548C104 with new leaderId: 24732aa1-1492-41aa-844a-173d185ef1c3
datanode3_1  | 2022-01-01 01:13:17,816 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: change Leader from null to 24732aa1-1492-41aa-844a-173d185ef1c3 at term 1 for appendEntries, leader elected after 1903ms
datanode3_1  | 2022-01-01 01:13:17,826 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode3_1  | 2022-01-01 01:13:17,853 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: inconsistency entries. Reply:24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#3:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode3_1  | 2022-01-01 01:13:17,954 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:17,986 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-01-01 01:13:18,698 [75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-F8541548C104-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/current/log_inprogress_0
datanode3_1  | 2022-01-01 01:13:19,366 [grpc-default-executor-0] INFO server.RaftServer: 75beef28-1584-4115-9505-884f6f5c519b: addNew group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-BD59923C342B:java.util.concurrent.CompletableFuture@92fc36f[Not completed]
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
kdc_1        | Jan 01 01:12:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1640999536, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jan 01 01:12:59 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1640999579, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:13:04 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1640999584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:13:05 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1640999585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:13:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1640999579, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:13:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1640999584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:13:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1640999585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:13:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999571, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jan 01 01:13:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999604, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:13:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1640999444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:13:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:13:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:13:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:13:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:13:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999604, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:13:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:13:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:14:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:14:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:14:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:15:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:15:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2022-01-01 01:13:19,369 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b: new RaftServerImpl for group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-01-01 01:13:19,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-01-01 01:13:19,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-01-01 01:13:19,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-01-01 01:13:19,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:13:19,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-01-01 01:13:19,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-01-01 01:13:19,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-01-01 01:13:19,375 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-01-01 01:13:19,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-01-01 01:13:19,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-01-01 01:13:19,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-01-01 01:13:19,376 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b does not exist. Creating ...
datanode3_1  | 2022-01-01 01:13:19,386 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/in_use.lock acquired by nodename 8@9f382dc742e3
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Jan 01 01:15:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:15:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:16:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:16:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:16:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:16:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:16:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999805, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:16:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999805, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999805, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:16:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999815, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:16:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999815, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999815, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:17:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999829, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:17:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999829, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:17:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:17:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:17:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999833, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-01-01 01:13:11,535 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077816619ns, electionTimeout:5071ms
datanode2_1  | 2022-01-01 01:13:11,545 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState
datanode2_1  | 2022-01-01 01:13:11,545 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:11,545 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:11,546 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2
datanode2_1  | 2022-01-01 01:13:11,582 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:11,635 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:11,638 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-01-01 01:13:11,685 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderStateImpl
datanode2_1  | 2022-01-01 01:13:11,954 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-01-01 01:13:12,233 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-LeaderElection1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC: set configuration 0: [24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-01-01 01:13:12,428 [24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-3D91C85C85AC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac/current/log_inprogress_0
datanode2_1  | 2022-01-01 01:13:13,641 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-01-01 01:13:13,781 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.LeaderElection:   Response 0: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t1
datanode2_1  | 2022-01-01 01:13:13,781 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2 ELECTION round 0: result PASSED
datanode2_1  | 2022-01-01 01:13:13,783 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2
datanode2_1  | 2022-01-01 01:13:13,789 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-01-01 01:13:13,789 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F8541548C104 with new leaderId: 24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:13:13,790 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: change Leader from null to 24732aa1-1492-41aa-844a-173d185ef1c3 at term 1 for becomeLeader, leader elected after 7387ms
datanode2_1  | 2022-01-01 01:13:13,790 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-01-01 01:13:13,791 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:13,806 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-01-01 01:13:13,807 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-01-01 01:13:13,816 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-01-01 01:13:13,816 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-01-01 01:13:13,816 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-01-01 01:13:13,832 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-01-01 01:13:13,968 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-01-01 01:13:13,979 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:13:13,981 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-01-01 01:13:13,984 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-01-01 01:13:14,002 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-01-01 01:13:14,014 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-01-01 01:13:14,039 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-01-01 01:13:14,049 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:13:14,052 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-01-01 01:13:14,052 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-01-01 01:13:14,053 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-01-01 01:13:14,054 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-01-01 01:13:14,074 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderStateImpl
datanode2_1  | 2022-01-01 01:13:14,075 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-01-01 01:13:14,115 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e5481fd7-e475-47a4-9362-f8541548c104/current/log_inprogress_0
datanode2_1  | 2022-01-01 01:13:14,158 [24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104-LeaderElection2] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:19,395 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b has been successfully formatted.
datanode3_1  | 2022-01-01 01:13:19,396 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BD59923C342B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-01-01 01:13:19,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:13:19,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-01-01 01:13:19,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-01-01 01:13:19,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:13:19,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:19,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-01-01 01:13:19,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-01-01 01:13:19,402 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b
datanode3_1  | 2022-01-01 01:13:19,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-01-01 01:13:19,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:19,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:19,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-01-01 01:13:19,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-01-01 01:13:19,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-01-01 01:13:19,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-01-01 01:13:19,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-01-01 01:13:19,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:19,440 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:19,441 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-01-01 01:13:19,441 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-01-01 01:13:19,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:19,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-01-01 01:13:19,442 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-01-01 01:13:19,442 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-01-01 01:13:19,442 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-01-01 01:13:19,442 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-01-01 01:13:19,467 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:19,467 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-01-01 01:13:19,468 [pool-23-thread-1] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:19,470 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD59923C342B,id=75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:13:22,323 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 1, (t:0, i:0))
datanode3_1  | 2022-01-01 01:13:22,325 [grpc-default-executor-0] INFO impl.VoteContext: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FOLLOWER: reject ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: our priority 1 > candidate's priority 0
datanode3_1  | 2022-01-01 01:13:22,327 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:24732aa1-1492-41aa-844a-173d185ef1c3
datanode3_1  | 2022-01-01 01:13:22,327 [grpc-default-executor-0] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:22,327 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-01-01 01:13:22,335 [grpc-default-executor-0] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
kdc_1        | Jan 01 01:17:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:17:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:17:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999878, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:17:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999878, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999878, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999883, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999883, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999883, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999887, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999896, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999896, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2022-01-01 01:13:37,939 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B replies to ELECTION vote request: 75beef28-1584-4115-9505-884f6f5c519b<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t4. Peer's state: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B:t4, leader=null, voted=75beef28-1584-4115-9505-884f6f5c519b, raftlog=458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:38,208 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState] INFO impl.FollowerState: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037607186ns, electionTimeout:5034ms
datanode1_1  | 2022-01-01 01:13:38,209 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState
datanode1_1  | 2022-01-01 01:13:38,209 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-01-01 01:13:38,209 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-01-01 01:13:38,209 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-FollowerState] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2
datanode1_1  | 2022-01-01 01:13:38,214 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO impl.LeaderElection: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-01-01 01:13:38,215 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO impl.LeaderElection: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-01-01 01:13:38,215 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: shutdown 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2
datanode1_1  | 2022-01-01 01:13:38,216 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-01-01 01:13:38,216 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CED3CA6A01AC with new leaderId: 458bfdff-96fb-4b4a-96de-6879eec60ac8
datanode1_1  | 2022-01-01 01:13:38,227 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: change Leader from null to 458bfdff-96fb-4b4a-96de-6879eec60ac8 at term 1 for becomeLeader, leader elected after 5193ms
datanode1_1  | 2022-01-01 01:13:38,257 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-01-01 01:13:38,281 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-01-01 01:13:38,282 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-01-01 01:13:38,328 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-01-01 01:13:38,342 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-01-01 01:13:38,344 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-01-01 01:13:38,354 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-01-01 01:13:38,360 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-01-01 01:13:38,383 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO impl.RoleInfo: 458bfdff-96fb-4b4a-96de-6879eec60ac8: start 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderStateImpl
datanode1_1  | 2022-01-01 01:13:38,406 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-01-01 01:13:38,408 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d83b488f-4512-497f-b5fa-ced3ca6a01ac/current/log_inprogress_0
datanode1_1  | 2022-01-01 01:13:38,426 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC-LeaderElection2] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-CED3CA6A01AC: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-01-01 01:13:38,465 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD59923C342B with new leaderId: 75beef28-1584-4115-9505-884f6f5c519b
datanode1_1  | 2022-01-01 01:13:38,465 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: change Leader from null to 75beef28-1584-4115-9505-884f6f5c519b at term 4 for appendEntries, leader elected after 20015ms
datanode1_1  | 2022-01-01 01:13:38,520 [grpc-default-executor-0] INFO server.RaftServer$Division: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-01-01 01:13:38,520 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-01-01 01:13:38,522 [458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 458bfdff-96fb-4b4a-96de-6879eec60ac8@group-BD59923C342B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/current/log_inprogress_0
datanode1_1  | 2022-01-01 01:13:57,099 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:957437904283.
datanode3_1  | 2022-01-01 01:13:22,338 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t1. Peer's state: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B:t1, leader=null, voted=null, raftlog=75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:27,401 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5066246664ns, electionTimeout:5064ms
datanode3_1  | 2022-01-01 01:13:27,402 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:27,402 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-01-01 01:13:27,405 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-01-01 01:13:27,406 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1
datanode3_1  | 2022-01-01 01:13:27,411 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:27,506 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 2, (t:0, i:0))
datanode3_1  | 2022-01-01 01:13:27,507 [grpc-default-executor-0] INFO impl.VoteContext: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-CANDIDATE: reject ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: already has voted for 75beef28-1584-4115-9505-884f6f5c519b at current term 2
datanode3_1  | 2022-01-01 01:13:27,510 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t2. Peer's state: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B:t2, leader=null, voted=75beef28-1584-4115-9505-884f6f5c519b, raftlog=75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:29,232 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: receive requestVote(ELECTION, 458bfdff-96fb-4b4a-96de-6879eec60ac8, group-BD59923C342B, 2, (t:0, i:0))
datanode3_1  | 2022-01-01 01:13:29,232 [grpc-default-executor-0] INFO impl.VoteContext: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-CANDIDATE: reject ELECTION from 458bfdff-96fb-4b4a-96de-6879eec60ac8: already has voted for 75beef28-1584-4115-9505-884f6f5c519b at current term 2
datanode3_1  | 2022-01-01 01:13:29,233 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B replies to ELECTION vote request: 458bfdff-96fb-4b4a-96de-6879eec60ac8<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t2. Peer's state: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B:t2, leader=null, voted=75beef28-1584-4115-9505-884f6f5c519b, raftlog=75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:29,375 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-01-01 01:13:29,376 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection:   Response 0: 75beef28-1584-4115-9505-884f6f5c519b<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:FAIL-t2
datanode3_1  | 2022-01-01 01:13:29,376 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection:   Response 1: 75beef28-1584-4115-9505-884f6f5c519b<-24732aa1-1492-41aa-844a-173d185ef1c3#0:FAIL-t2
datanode3_1  | 2022-01-01 01:13:29,377 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2022-01-01 01:13:29,378 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-01-01 01:13:29,378 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1
datanode3_1  | 2022-01-01 01:13:29,390 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection1] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:32,620 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b: new RaftServerImpl for group-AB6694BD9221:[75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-01-01 01:13:32,620 [Command processor thread] INFO server.RaftServer: 75beef28-1584-4115-9505-884f6f5c519b: addNew group-AB6694BD9221:[75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-AB6694BD9221:java.util.concurrent.CompletableFuture@448bb430[Not completed]
datanode3_1  | 2022-01-01 01:13:32,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-01-01 01:13:32,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-01-01 01:13:32,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-01-01 01:13:32,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:17,044 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104.
datanode2_1  | 2022-01-01 01:13:17,049 [Command processor thread] INFO server.RaftServer: 24732aa1-1492-41aa-844a-173d185ef1c3: addNew group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-BD59923C342B:java.util.concurrent.CompletableFuture@65b2732d[Not completed]
datanode2_1  | 2022-01-01 01:13:17,055 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3: new RaftServerImpl for group-BD59923C342B:[458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-01-01 01:13:17,055 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-01-01 01:13:17,055 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-01-01 01:13:17,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-01-01 01:13:17,057 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:17,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-01-01 01:13:17,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-01-01 01:13:17,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-01-01 01:13:17,061 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: ConfigurationManager, init=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-01-01 01:13:17,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-01-01 01:13:17,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-01-01 01:13:17,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-01-01 01:13:17,063 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b does not exist. Creating ...
datanode2_1  | 2022-01-01 01:13:17,073 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/in_use.lock acquired by nodename 8@6842de8f6a86
datanode2_1  | 2022-01-01 01:13:17,078 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b has been successfully formatted.
datanode2_1  | 2022-01-01 01:13:17,083 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BD59923C342B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-01-01 01:13:17,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-01-01 01:13:17,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-01-01 01:13:17,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-01-01 01:13:17,084 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-01-01 01:13:17,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:17,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-01-01 01:13:17,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-01-01 01:13:17,090 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b
datanode2_1  | 2022-01-01 01:13:17,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-01-01 01:13:17,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1        | Jan 01 01:18:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999896, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999896, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999896, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:18:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:18:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:18:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:18:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999935, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:19:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1640999443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999975, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:19:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
datanode2_1  | 2022-01-01 01:13:17,113 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:17,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-01-01 01:13:17,119 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-01-01 01:13:17,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-01-01 01:13:17,126 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-01-01 01:13:17,126 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-01-01 01:13:17,128 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-01-01 01:13:17,136 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:17,142 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:17,145 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
kdc_1        | Jan 01 01:19:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:19:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999975, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:19:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1640999990, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:19:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1640999990, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:20:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000017, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:20:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000017, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:20:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000026, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:20:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000026, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:20:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000034, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:20:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:20:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:20:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000034, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:20:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000041, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:20:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000041, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:20:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000048, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:20:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000048, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:21:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-01-01 01:12:08,508 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2022-01-01 01:12:08,587 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-01-01 01:12:18,688 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-01-01 01:12:19,360 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-01-01 01:12:19,365 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-01-01 01:12:19,365 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-01-01 01:12:20,999 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-01-01 01:12:21,025 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-01-01 01:12:21,105 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-01-01 01:12:25,699 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-01-01 01:12:29,445 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-01-01 01:12:29,445 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-01-01 01:12:29,447 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-01-01 01:12:37,906 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-01-01 01:12:38,209 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-01-01 01:12:38,209 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-01-01 01:12:38,255 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-01-01 01:12:38,256 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-01-01 01:12:38,259 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-01-01 01:12:38,259 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-01-01 01:12:38,269 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-01-01 01:12:38,271 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:1214e676-068e-4ac1-9115-7b01b3dcff10,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:om1
om1_1        | 2022-01-01 01:12:39,160 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-01-01 01:12:41,174 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2;layoutVersion=0
om1_1        | 2022-01-01 01:12:41,271 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-01-01 01:12:51,154 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kdc_1        | Jan 01 01:21:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:22:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:22:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:22:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:22:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:22:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:22:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:22:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000166, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:22:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000166, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:23:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:23:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:24:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:24:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:25:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:25:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:26:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:26:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:27:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:27:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:27:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000474, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:28:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000474, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:28:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:28:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:29:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:29:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:30:21 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:30:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1641000621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jan 01 01:30:31 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000631, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jan 01 01:30:31 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1641000631, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jan 01 01:30:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jan 01 01:30:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2022-01-01 01:12:51,213 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-01-01 01:13:00,484 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-01-01 01:13:01,735 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-01-01 01:13:01,750 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-01-01 01:13:01,751 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-01-01 01:13:01,865 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-01-01 01:13:02,224 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2022-01-01 01:13:03,854 [main] INFO reflections.Reflections: Reflections took 1268 ms to scan 1 urls, producing 97 keys and 262 values [using 2 cores]
om1_1        | 2022-01-01 01:13:05,910 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-01-01 01:13:05,910 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-01-01 01:13:05,910 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-01-01 01:13:13,244 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-01-01 01:13:14,014 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-857524461429.crt.
om1_1        | 2022-01-01 01:13:14,045 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/960910686427.crt.
om1_1        | 2022-01-01 01:13:14,074 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-01-01 01:13:14,321 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-01-01 01:13:15,559 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-01-01 01:13:15,583 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-01-01 01:13:16,809 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-01-01 01:13:16,810 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-01-01 01:13:17,545 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2022-01-01 01:13:18,116 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-01-01 01:13:18,126 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-01-01 01:13:18,268 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-01-01 01:13:19,177 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-01-01 01:13:19,244 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-01-01 01:13:19,459 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-01-01 01:13:19,518 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-01-01 01:13:20,542 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-01-01 01:13:20,845 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-01-01 01:13:20,847 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-01-01 01:13:20,850 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-01-01 01:13:20,852 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-01-01 01:13:20,853 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-01-01 01:13:20,857 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-01-01 01:13:20,863 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-01-01 01:13:20,867 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-01-01 01:13:20,868 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-01-01 01:13:24,597 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-01-01 01:13:24,619 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-01-01 01:13:24,626 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-01-01 01:13:24,744 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-01-01 01:13:24,830 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@21f8aa9c[Not completed]
om1_1        | 2022-01-01 01:13:24,830 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-01-01 01:13:24,999 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-01-01 01:13:25,018 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-01-01 01:13:25,022 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-01-01 01:13:25,023 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-01-01 01:13:25,037 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-01-01 01:13:25,040 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-01-01 01:13:25,042 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-01-01 01:13:17,147 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-01-01 01:13:17,153 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-01-01 01:13:17,154 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-01-01 01:13:17,156 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-01-01 01:13:17,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-01-01 01:13:17,159 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-01-01 01:13:17,180 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: start as a follower, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:17,187 [pool-23-thread-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-01-01 01:13:17,187 [pool-23-thread-1] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:17,200 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD59923C342B,id=24732aa1-1492-41aa-844a-173d185ef1c3
datanode2_1  | 2022-01-01 01:13:17,207 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b
datanode2_1  | 2022-01-01 01:13:17,898 [grpc-default-executor-0] INFO leader.FollowerInfo: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2022-01-01 01:13:19,510 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b.
datanode2_1  | 2022-01-01 01:13:22,288 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5101002542ns, electionTimeout:5056ms
datanode2_1  | 2022-01-01 01:13:22,288 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:22,288 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:22,289 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:22,289 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3
datanode2_1  | 2022-01-01 01:13:22,303 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:22,351 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-01-01 01:13:22,358 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.LeaderElection:   Response 0: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t1
datanode2_1  | 2022-01-01 01:13:22,358 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3 ELECTION round 0: result REJECTED
datanode2_1  | 2022-01-01 01:13:22,359 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2022-01-01 01:13:22,359 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3
datanode2_1  | 2022-01-01 01:13:22,359 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection3] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:27,456 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5096903572ns, electionTimeout:5085ms
datanode2_1  | 2022-01-01 01:13:27,457 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:27,457 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:27,457 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:27,457 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4
datanode2_1  | 2022-01-01 01:13:27,474 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:32,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-01-01 01:13:32,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-01-01 01:13:32,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-01-01 01:13:32,623 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: ConfigurationManager, init=-1: [75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-01-01 01:13:32,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-01-01 01:13:32,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-01-01 01:13:32,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-01-01 01:13:32,624 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c4e544bd-06bc-4975-8f23-ab6694bd9221 does not exist. Creating ...
datanode3_1  | 2022-01-01 01:13:32,627 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c4e544bd-06bc-4975-8f23-ab6694bd9221/in_use.lock acquired by nodename 8@9f382dc742e3
datanode3_1  | 2022-01-01 01:13:32,633 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c4e544bd-06bc-4975-8f23-ab6694bd9221 has been successfully formatted.
datanode3_1  | 2022-01-01 01:13:32,634 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-AB6694BD9221: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-01-01 01:13:32,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-01-01 01:13:32,636 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-01-01 01:13:32,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-01-01 01:13:32,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:13:32,638 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:32,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-01-01 01:13:32,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-01-01 01:13:32,641 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c4e544bd-06bc-4975-8f23-ab6694bd9221
datanode3_1  | 2022-01-01 01:13:32,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-01-01 01:13:32,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:32,642 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:32,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-01-01 01:13:32,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-01-01 01:13:32,644 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-01-01 01:13:32,645 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-01-01 01:13:32,645 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-01-01 01:13:32,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-01-01 01:13:32,653 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:32,657 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-01-01 01:13:32,658 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-01-01 01:12:08,103 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2022-01-01 01:12:08,198 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-01-01 01:12:17,965 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-01-01 01:12:18,527 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-01-01 01:12:18,532 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-01-01 01:12:18,532 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-01-01 01:12:20,715 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-01-01 01:12:20,718 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-01-01 01:12:20,876 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-01-01 01:12:25,290 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-01-01 01:12:29,107 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-01-01 01:12:29,110 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-01-01 01:12:29,117 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-01-01 01:12:33,696 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-01-01 01:12:34,235 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-01-01 01:12:34,242 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-01-01 01:12:34,263 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-01-01 01:12:34,290 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-01-01 01:12:34,314 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-01-01 01:12:34,321 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-01-01 01:12:34,322 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-01-01 01:12:34,343 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:1214e676-068e-4ac1-9115-7b01b3dcff10,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:om2
om2_1        | 2022-01-01 01:12:35,727 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-01-01 01:12:37,750 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2;layoutVersion=0
om2_1        | 2022-01-01 01:12:37,917 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-01-01 01:12:47,658 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-01-01 01:13:32,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-01-01 01:13:32,662 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-01-01 01:13:32,663 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-01-01 01:13:32,663 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-01-01 01:13:32,663 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-01-01 01:13:32,666 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-01-01 01:13:32,668 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: start as a follower, conf=-1: [75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-01-01 01:13:32,710 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: receive requestVote(ELECTION, 24732aa1-1492-41aa-844a-173d185ef1c3, group-BD59923C342B, 3, (t:0, i:0))
datanode3_1  | 2022-01-01 01:13:32,712 [grpc-default-executor-0] INFO impl.VoteContext: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FOLLOWER: reject ELECTION from 24732aa1-1492-41aa-844a-173d185ef1c3: our priority 1 > candidate's priority 0
datanode3_1  | 2022-01-01 01:13:32,712 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:24732aa1-1492-41aa-844a-173d185ef1c3
datanode3_1  | 2022-01-01 01:13:32,713 [grpc-default-executor-0] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:32,714 [grpc-default-executor-0] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:32,714 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2022-01-01 01:12:47,716 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-01-01 01:12:55,867 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-01-01 01:12:56,465 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-01-01 01:12:56,465 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-01-01 01:12:56,465 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-01-01 01:12:56,493 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-01-01 01:12:56,670 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2022-01-01 01:12:58,547 [main] INFO reflections.Reflections: Reflections took 1639 ms to scan 1 urls, producing 97 keys and 262 values [using 2 cores]
om2_1        | 2022-01-01 01:13:00,652 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-01-01 01:13:00,653 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-01-01 01:13:00,666 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-01-01 01:13:08,778 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-01-01 01:13:09,427 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-857524461429.crt.
om2_1        | 2022-01-01 01:13:09,447 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/957437904283.crt.
om2_1        | 2022-01-01 01:13:09,491 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-01-01 01:13:09,767 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-01-01 01:13:10,672 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-01-01 01:13:10,699 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-01-01 01:13:12,154 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-01-01 01:13:12,155 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-01-01 01:13:12,996 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2022-01-01 01:13:13,437 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-01-01 01:13:25,044 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-01-01 01:13:25,105 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-01-01 01:13:25,106 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-01-01 01:13:25,140 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-01-01 01:13:25,204 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-01-01 01:13:25,210 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-01-01 01:12:07,093 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2022-01-01 01:12:07,177 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-01-01 01:12:17,026 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-01-01 01:12:18,117 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-01-01 01:12:18,122 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-01-01 01:12:18,127 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-01-01 01:12:19,147 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-01-01 01:12:19,147 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-01-01 01:12:19,182 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-01-01 01:12:23,129 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-01-01 01:12:26,796 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-01-01 01:12:26,815 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-01-01 01:12:26,817 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-01-01 01:12:37,599 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-01-01 01:12:37,895 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-01-01 01:12:37,898 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-01-01 01:12:37,909 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-01-01 01:12:37,939 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-01-01 01:12:37,944 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-01-01 01:12:37,951 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-01-01 01:12:37,951 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-01-01 01:12:37,968 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:1214e676-068e-4ac1-9115-7b01b3dcff10,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:om3
om3_1        | 2022-01-01 01:12:38,997 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | 2022-01-01 01:13:25,264 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-01-01 01:13:25,341 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-01-01 01:13:25,376 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-01-01 01:13:25,465 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-01-01 01:13:25,484 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-01-01 01:13:25,500 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-01-01 01:13:25,567 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-01-01 01:13:25,569 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-01-01 01:13:25,674 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-01-01 01:13:25,746 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-01-01 01:13:25,761 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-01-01 01:13:25,801 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-01-01 01:13:25,801 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-01-01 01:13:25,803 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-01-01 01:13:25,804 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-01-01 01:13:25,818 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-01-01 01:13:25,819 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-01-01 01:13:25,834 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-01-01 01:13:25,839 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-01-01 01:13:32,714 [pool-23-thread-1] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-01-01 01:13:32,809 [grpc-default-executor-0] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B replies to ELECTION vote request: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t3. Peer's state: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B:t3, leader=null, voted=null, raftlog=75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:32,840 [pool-23-thread-1] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState
datanode3_1  | 2022-01-01 01:13:32,878 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AB6694BD9221,id=75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:13:32,935 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c4e544bd-06bc-4975-8f23-ab6694bd9221
datanode3_1  | 2022-01-01 01:13:32,938 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=c4e544bd-06bc-4975-8f23-ab6694bd9221.
datanode3_1  | 2022-01-01 01:13:37,898 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184172472ns, electionTimeout:5098ms
datanode3_1  | 2022-01-01 01:13:37,898 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState
datanode3_1  | 2022-01-01 01:13:37,899 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-01-01 01:13:37,899 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-01-01 01:13:37,899 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2
datanode3_1  | 2022-01-01 01:13:37,908 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:37,949 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-01-01 01:13:37,950 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.LeaderElection:   Response 0: 75beef28-1584-4115-9505-884f6f5c519b<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t4
datanode3_1  | 2022-01-01 01:13:37,950 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-01-01 01:13:37,950 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2
datanode3_1  | 2022-01-01 01:13:37,950 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
datanode3_1  | 2022-01-01 01:13:37,951 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD59923C342B with new leaderId: 75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:13:37,951 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: change Leader from null to 75beef28-1584-4115-9505-884f6f5c519b at term 4 for becomeLeader, leader elected after 18552ms
datanode3_1  | 2022-01-01 01:13:37,955 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-01-01 01:13:37,978 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState] INFO impl.FollowerState: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5138206299ns, electionTimeout:5098ms
datanode3_1  | 2022-01-01 01:13:37,979 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState
datanode3_1  | 2022-01-01 01:13:37,980 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-01-01 01:13:37,980 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-01-01 01:13:37,980 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-FollowerState] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3
datanode3_1  | 2022-01-01 01:13:38,014 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:38,015 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-01-01 01:13:38,054 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-01-01 01:13:38,066 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-01-01 01:13:38,067 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-01-01 01:13:38,067 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO impl.LeaderElection: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-01-01 01:13:38,067 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: shutdown 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3
datanode3_1  | 2022-01-01 01:13:38,067 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-01-01 01:13:38,068 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AB6694BD9221 with new leaderId: 75beef28-1584-4115-9505-884f6f5c519b
datanode3_1  | 2022-01-01 01:13:38,068 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: change Leader from null to 75beef28-1584-4115-9505-884f6f5c519b at term 1 for becomeLeader, leader elected after 5433ms
datanode3_1  | 2022-01-01 01:13:38,074 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-01-01 01:13:38,076 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:38,079 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-01-01 01:13:38,079 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-01-01 01:13:38,079 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-01-01 01:13:38,081 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-01-01 01:13:38,116 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:38,122 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-01-01 01:13:38,123 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-01-01 01:13:38,133 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-01-01 01:13:38,138 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-01-01 01:13:38,141 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderStateImpl
datanode3_1  | 2022-01-01 01:13:38,199 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-01-01 01:13:38,199 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:13:38,201 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-01-01 01:13:38,207 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-01-01 01:13:38,252 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c4e544bd-06bc-4975-8f23-ab6694bd9221/current/log_inprogress_0
datanode3_1  | 2022-01-01 01:13:38,221 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-01-01 01:13:38,263 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-01-01 01:13:38,271 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-01-01 01:13:38,287 [75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221-LeaderElection3] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-AB6694BD9221: set configuration 0: [75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-01-01 01:13:38,325 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-01-01 01:13:38,328 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-01-01 01:13:38,328 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-01-01 01:13:38,328 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-01-01 01:13:38,329 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-01-01 01:13:38,330 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-01-01 01:13:38,338 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO impl.RoleInfo: 75beef28-1584-4115-9505-884f6f5c519b: start 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderStateImpl
datanode3_1  | 2022-01-01 01:13:38,342 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-01-01 01:13:38,349 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/current/log_inprogress_0
datanode3_1  | 2022-01-01 01:13:38,370 [75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B-LeaderElection2] INFO server.RaftServer$Division: 75beef28-1584-4115-9505-884f6f5c519b@group-BD59923C342B: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-01-01 01:13:56,870 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:957437904283.
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-01-01 01:12:40,718 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2;layoutVersion=0
om3_1        | 2022-01-01 01:12:40,926 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-01-01 01:12:50,407 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 2022-01-01 01:13:13,438 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-01-01 01:13:13,534 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-01-01 01:13:14,615 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-01-01 01:13:14,694 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-01-01 01:13:15,001 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-01-01 01:13:15,094 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-01-01 01:13:16,151 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-01-01 01:13:16,535 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-01-01 01:13:16,540 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-01-01 01:13:16,543 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-01-01 01:13:16,546 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-01-01 01:13:16,548 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-01-01 01:13:16,549 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-01-01 01:13:16,593 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-01-01 01:13:16,599 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-01-01 01:13:16,600 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-01-01 01:13:21,127 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-01-01 01:13:21,136 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-01-01 01:13:21,142 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-01-01 01:13:21,218 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-01-01 01:13:21,247 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@21f8aa9c[Not completed]
om2_1        | 2022-01-01 01:13:21,247 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-01-01 01:13:21,339 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-01-01 01:13:21,344 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-01-01 01:13:21,351 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-01-01 01:13:21,352 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-01-01 01:13:21,352 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-01-01 01:13:21,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-01-01 01:13:21,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-01-01 01:13:21,359 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-01-01 01:13:21,378 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-01-01 01:13:21,378 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-01-01 01:13:21,410 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-01-01 01:13:21,412 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-01-01 01:13:21,414 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-01-01 01:13:21,592 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-01-01 01:13:21,592 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om2
om2_1        | 2022-01-01 01:13:21,694 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-01-01 01:13:21,742 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-01-01 01:13:21,778 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-01-01 01:13:21,809 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-01-01 01:13:21,861 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-01-01 01:13:21,875 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-01-01 01:13:21,940 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-01-01 01:13:21,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-01-01 01:13:21,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-01-01 01:13:22,032 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-01-01 01:13:22,047 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-01-01 01:13:22,050 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-01-01 01:13:22,055 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-01-01 01:13:22,061 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-01-01 01:13:22,073 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-01-01 01:13:22,076 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-01-01 01:13:22,098 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-01-01 01:13:22,103 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-01-01 01:13:22,160 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-01-01 01:13:22,163 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-01-01 01:13:22,210 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-01-01 01:13:22,210 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-01-01 01:13:27,518 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-01-01 01:13:27,519 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.LeaderElection:   Response 0: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t2
datanode2_1  | 2022-01-01 01:13:27,519 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2022-01-01 01:13:27,519 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-01-01 01:13:27,519 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4
datanode2_1  | 2022-01-01 01:13:27,519 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection4] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:29,246 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: receive requestVote(ELECTION, 75beef28-1584-4115-9505-884f6f5c519b, group-BD59923C342B, 2, (t:0, i:0))
datanode2_1  | 2022-01-01 01:13:29,290 [grpc-default-executor-0] INFO impl.VoteContext: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FOLLOWER: reject ELECTION from 75beef28-1584-4115-9505-884f6f5c519b: already has voted for 24732aa1-1492-41aa-844a-173d185ef1c3 at current term 2
datanode2_1  | 2022-01-01 01:13:29,299 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B replies to ELECTION vote request: 75beef28-1584-4115-9505-884f6f5c519b<-24732aa1-1492-41aa-844a-173d185ef1c3#0:FAIL-t2. Peer's state: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B:t2, leader=null, voted=24732aa1-1492-41aa-844a-173d185ef1c3, raftlog=24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:29,301 [grpc-default-executor-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: receive requestVote(ELECTION, 458bfdff-96fb-4b4a-96de-6879eec60ac8, group-BD59923C342B, 2, (t:0, i:0))
datanode2_1  | 2022-01-01 01:13:29,320 [grpc-default-executor-1] INFO impl.VoteContext: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FOLLOWER: reject ELECTION from 458bfdff-96fb-4b4a-96de-6879eec60ac8: already has voted for 24732aa1-1492-41aa-844a-173d185ef1c3 at current term 2
datanode2_1  | 2022-01-01 01:13:29,348 [grpc-default-executor-1] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B replies to ELECTION vote request: 458bfdff-96fb-4b4a-96de-6879eec60ac8<-24732aa1-1492-41aa-844a-173d185ef1c3#0:FAIL-t2. Peer's state: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B:t2, leader=null, voted=24732aa1-1492-41aa-844a-173d185ef1c3, raftlog=24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:32,627 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5107964661ns, electionTimeout:5095ms
datanode2_1  | 2022-01-01 01:13:32,629 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:32,629 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:32,629 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:32,629 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5
datanode2_1  | 2022-01-01 01:13:32,637 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:32,835 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-01-01 01:13:32,835 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.LeaderElection:   Response 0: 24732aa1-1492-41aa-844a-173d185ef1c3<-458bfdff-96fb-4b4a-96de-6879eec60ac8#0:OK-t3
datanode2_1  | 2022-01-01 01:13:32,835 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.LeaderElection:   Response 1: 24732aa1-1492-41aa-844a-173d185ef1c3<-75beef28-1584-4115-9505-884f6f5c519b#0:FAIL-t3
datanode2_1  | 2022-01-01 01:13:32,836 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2022-01-01 01:13:32,836 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-01-01 01:13:32,836 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5
datanode2_1  | 2022-01-01 01:13:32,836 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection5] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:37,921 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: receive requestVote(ELECTION, 75beef28-1584-4115-9505-884f6f5c519b, group-BD59923C342B, 4, (t:0, i:0))
datanode2_1  | 2022-01-01 01:13:37,926 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.FollowerState: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5090056080ns, electionTimeout:5054ms
datanode2_1  | 2022-01-01 01:13:37,930 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:37,931 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2022-01-01 01:13:37,931 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-01-01 01:13:37,931 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection6
datanode2_1  | 2022-01-01 01:13:37,931 [grpc-default-executor-0] INFO impl.VoteContext: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-CANDIDATE: accept ELECTION from 75beef28-1584-4115-9505-884f6f5c519b: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-01-01 01:13:37,931 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: changes role from CANDIDATE to FOLLOWER at term 4 for candidate:75beef28-1584-4115-9505-884f6f5c519b
datanode2_1  | 2022-01-01 01:13:37,931 [grpc-default-executor-0] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: shutdown 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection6
datanode2_1  | 2022-01-01 01:13:37,931 [grpc-default-executor-0] INFO impl.RoleInfo: 24732aa1-1492-41aa-844a-173d185ef1c3: start 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-FollowerState
datanode2_1  | 2022-01-01 01:13:37,932 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection6] INFO impl.LeaderElection: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-LeaderElection6: skip running since this is already CLOSING
datanode2_1  | 2022-01-01 01:13:37,957 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B replies to ELECTION vote request: 75beef28-1584-4115-9505-884f6f5c519b<-24732aa1-1492-41aa-844a-173d185ef1c3#0:OK-t4. Peer's state: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B:t4, leader=null, voted=75beef28-1584-4115-9505-884f6f5c519b, raftlog=24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLog:OPENED:c-1, conf=-1: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:38,437 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD59923C342B with new leaderId: 75beef28-1584-4115-9505-884f6f5c519b
datanode2_1  | 2022-01-01 01:13:38,442 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: change Leader from null to 75beef28-1584-4115-9505-884f6f5c519b at term 4 for appendEntries, leader elected after 21354ms
datanode2_1  | 2022-01-01 01:13:38,547 [grpc-default-executor-0] INFO server.RaftServer$Division: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B: set configuration 0: [458bfdff-96fb-4b4a-96de-6879eec60ac8|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 75beef28-1584-4115-9505-884f6f5c519b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 24732aa1-1492-41aa-844a-173d185ef1c3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-01-01 01:13:38,550 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-01-01 01:13:38,552 [24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 24732aa1-1492-41aa-844a-173d185ef1c3@group-BD59923C342B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e8f729a-8cb4-46b5-85d7-bd59923c342b/current/log_inprogress_0
datanode2_1  | 2022-01-01 01:13:56,981 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:957437904283.
datanode2_1  | 2022-01-01 01:14:17,904 [java.util.concurrent.ThreadPoolExecutor$Worker@6c7f8119[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode2_1  | 2022-01-01 01:15:17,990 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=257,entriesCount=1,lastEntry=(t:1, i:1)
datanode2_1  | 2022-01-01 01:15:18,016 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=258,entriesCount=1,lastEntry=(t:1, i:2)
datanode2_1  | 2022-01-01 01:15:18,298 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=261,entriesCount=1,lastEntry=(t:1, i:3)
datanode2_1  | 2022-01-01 01:15:18,332 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=263,entriesCount=1,lastEntry=(t:1, i:4)
datanode2_1  | 2022-01-01 01:16:13,478 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=524,entriesCount=1,lastEntry=(t:1, i:5)
om1_1        | 2022-01-01 01:13:25,841 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-01-01 01:13:26,005 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-01-01 01:13:26,015 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-01-01 01:13:26,126 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-01-01 01:13:26,127 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-01-01 01:13:26,142 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-01-01 01:13:26,147 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-01-01 01:13:26,148 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-01-01 01:13:26,148 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-01-01 01:13:26,151 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-01-01 01:13:26,158 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-01-01 01:13:26,453 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-01-01 01:13:26,516 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-01-01 01:13:26,516 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-01-01 01:13:26,728 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-01-01 01:13:26,728 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-01-01 01:13:26,730 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-01-01 01:13:26,735 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-01-01 01:13:26,746 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-01-01 01:13:26,755 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-01-01 01:13:26,775 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-01-01 01:13:27,081 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-01-01 01:13:27,112 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$406/0x00000008405d7040@71b38b11] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-01-01 01:13:27,112 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-01-01 01:13:27,112 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-01-01 01:13:27,119 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-01-01 01:13:27,119 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-01-01 01:13:27,133 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-01-01 01:13:27,146 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-01-01 01:13:27,298 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode2_1  | 2022-01-01 01:16:13,499 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=525,entriesCount=1,lastEntry=(t:1, i:6)
datanode2_1  | 2022-01-01 01:16:13,512 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=526,entriesCount=1,lastEntry=(t:1, i:7)
datanode2_1  | 2022-01-01 01:16:13,529 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=530,entriesCount=1,lastEntry=(t:1, i:8)
datanode2_1  | 2022-01-01 01:17:36,241 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=810,entriesCount=1,lastEntry=(t:1, i:9)
datanode2_1  | 2022-01-01 01:17:36,257 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=811,entriesCount=1,lastEntry=(t:1, i:10)
datanode2_1  | 2022-01-01 01:17:36,282 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=812,entriesCount=1,lastEntry=(t:1, i:11)
datanode2_1  | 2022-01-01 01:17:36,316 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=815,entriesCount=1,lastEntry=(t:1, i:12)
datanode2_1  | 2022-01-01 01:19:45,563 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1114,entriesCount=1,lastEntry=(t:1, i:13)
datanode2_1  | 2022-01-01 01:19:45,581 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1115,entriesCount=1,lastEntry=(t:1, i:14)
datanode2_1  | 2022-01-01 01:19:45,596 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1117,entriesCount=1,lastEntry=(t:1, i:15)
datanode2_1  | 2022-01-01 01:19:45,606 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1119,entriesCount=1,lastEntry=(t:1, i:16)
datanode2_1  | 2022-01-01 01:20:46,263 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1401,entriesCount=1,lastEntry=(t:1, i:17)
datanode2_1  | 2022-01-01 01:20:46,267 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1402,entriesCount=1,lastEntry=(t:1, i:18)
datanode2_1  | 2022-01-01 01:20:46,279 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1403,entriesCount=1,lastEntry=(t:1, i:19)
datanode2_1  | 2022-01-01 01:20:46,280 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1404,entriesCount=1,lastEntry=(t:1, i:20)
datanode2_1  | 2022-01-01 01:20:56,608 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1646,entriesCount=1,lastEntry=(t:1, i:21)
datanode2_1  | 2022-01-01 01:20:56,620 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1647,entriesCount=1,lastEntry=(t:1, i:22)
datanode2_1  | 2022-01-01 01:20:56,627 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1648,entriesCount=1,lastEntry=(t:1, i:23)
datanode2_1  | 2022-01-01 01:20:56,634 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1649,entriesCount=1,lastEntry=(t:1, i:24)
datanode2_1  | 2022-01-01 01:20:59,469 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1900,entriesCount=1,lastEntry=(t:1, i:25)
datanode2_1  | 2022-01-01 01:20:59,484 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1901,entriesCount=1,lastEntry=(t:1, i:26)
datanode2_1  | 2022-01-01 01:20:59,493 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1902,entriesCount=1,lastEntry=(t:1, i:27)
datanode2_1  | 2022-01-01 01:20:59,504 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1905,entriesCount=1,lastEntry=(t:1, i:28)
datanode2_1  | 2022-01-01 01:21:04,441 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2155,entriesCount=1,lastEntry=(t:1, i:29)
datanode2_1  | 2022-01-01 01:21:04,532 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2156,entriesCount=1,lastEntry=(t:1, i:30)
datanode2_1  | 2022-01-01 01:21:04,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2157,entriesCount=1,lastEntry=(t:1, i:31)
datanode2_1  | 2022-01-01 01:21:04,619 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2158,entriesCount=1,lastEntry=(t:1, i:32)
datanode2_1  | 2022-01-01 01:21:04,849 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2172,entriesCount=1,lastEntry=(t:1, i:33)
datanode2_1  | 2022-01-01 01:21:04,934 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2180,entriesCount=1,lastEntry=(t:1, i:34)
datanode2_1  | 2022-01-01 01:21:05,004 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2187,entriesCount=1,lastEntry=(t:1, i:35)
datanode2_1  | 2022-01-01 01:21:05,103 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2196,entriesCount=1,lastEntry=(t:1, i:36)
datanode2_1  | 2022-01-01 01:21:05,188 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2204,entriesCount=1,lastEntry=(t:1, i:37)
datanode2_1  | 2022-01-01 01:21:05,188 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2205,entriesCount=1,lastEntry=(t:1, i:38)
datanode2_1  | 2022-01-01 01:21:09,422 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2457,entriesCount=1,lastEntry=(t:1, i:39)
datanode2_1  | 2022-01-01 01:21:09,882 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2458,entriesCount=1,lastEntry=(t:1, i:40)
datanode2_1  | 2022-01-01 01:21:10,000 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2470,entriesCount=1,lastEntry=(t:1, i:41)
datanode2_1  | 2022-01-01 01:21:10,186 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2484,entriesCount=1,lastEntry=(t:1, i:42)
datanode2_1  | 2022-01-01 01:21:10,234 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2488,entriesCount=1,lastEntry=(t:1, i:43)
datanode2_1  | 2022-01-01 01:21:10,275 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2493,entriesCount=1,lastEntry=(t:1, i:44)
datanode2_1  | 2022-01-01 01:21:10,296 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2496,entriesCount=1,lastEntry=(t:1, i:45)
datanode2_1  | 2022-01-01 01:21:10,311 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2497,entriesCount=1,lastEntry=(t:1, i:46)
datanode2_1  | 2022-01-01 01:21:13,336 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2748,entriesCount=1,lastEntry=(t:1, i:47)
datanode2_1  | 2022-01-01 01:21:13,663 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2749,entriesCount=1,lastEntry=(t:1, i:48)
datanode2_1  | 2022-01-01 01:21:13,663 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2750,entriesCount=1,lastEntry=(t:1, i:49)
datanode2_1  | 2022-01-01 01:21:13,881 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2769,entriesCount=1,lastEntry=(t:1, i:50)
datanode2_1  | 2022-01-01 01:21:13,896 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2770,entriesCount=1,lastEntry=(t:1, i:51)
datanode2_1  | 2022-01-01 01:21:14,027 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2771,entriesCount=1,lastEntry=(t:1, i:52)
datanode2_1  | 2022-01-01 01:21:14,118 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2781,entriesCount=1,lastEntry=(t:1, i:53)
datanode2_1  | 2022-01-01 01:21:14,124 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2782,entriesCount=1,lastEntry=(t:1, i:54)
datanode2_1  | 2022-01-01 01:21:56,155 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3049,entriesCount=1,lastEntry=(t:1, i:55)
datanode2_1  | 2022-01-01 01:21:56,210 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3050,entriesCount=1,lastEntry=(t:1, i:56)
datanode2_1  | 2022-01-01 01:21:56,235 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3051,entriesCount=1,lastEntry=(t:1, i:57)
datanode2_1  | 2022-01-01 01:21:56,307 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3052,entriesCount=1,lastEntry=(t:1, i:58)
datanode2_1  | 2022-01-01 01:21:56,319 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3054,entriesCount=1,lastEntry=(t:1, i:59)
datanode2_1  | 2022-01-01 01:21:56,340 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3056,entriesCount=1,lastEntry=(t:1, i:60)
datanode2_1  | 2022-01-01 01:22:05,880 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3309,entriesCount=1,lastEntry=(t:1, i:61)
datanode2_1  | 2022-01-01 01:22:05,891 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3310,entriesCount=1,lastEntry=(t:1, i:62)
datanode2_1  | 2022-01-01 01:22:05,898 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3313,entriesCount=1,lastEntry=(t:1, i:63)
datanode2_1  | 2022-01-01 01:22:05,901 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3315,entriesCount=1,lastEntry=(t:1, i:64)
datanode2_1  | 2022-01-01 01:22:20,661 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3568,entriesCount=1,lastEntry=(t:1, i:65)
datanode2_1  | 2022-01-01 01:22:20,688 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3569,entriesCount=1,lastEntry=(t:1, i:66)
datanode2_1  | 2022-01-01 01:22:20,740 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3570,entriesCount=1,lastEntry=(t:1, i:67)
datanode2_1  | 2022-01-01 01:22:20,828 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3571,entriesCount=1,lastEntry=(t:1, i:68)
datanode2_1  | 2022-01-01 01:22:20,829 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3572,entriesCount=1,lastEntry=(t:1, i:69)
datanode2_1  | 2022-01-01 01:22:24,010 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3818,entriesCount=1,lastEntry=(t:1, i:70)
om1_1        | 2022-01-01 01:13:27,299 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-01-01 01:13:27,300 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-01-01 01:13:27,437 [Listener at om1/9862] INFO util.log: Logging initialized @44963ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-01-01 01:13:28,219 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-01-01 01:13:28,272 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-01-01 01:13:28,275 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-01-01 01:13:28,282 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-01-01 01:13:28,283 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-01-01 01:13:28,292 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-01-01 01:13:28,553 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-01-01 01:13:28,559 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om1_1        | 2022-01-01 01:13:28,758 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-01-01 01:13:28,774 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-01-01 01:13:28,775 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2022-01-01 01:13:28,879 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-01-01 01:13:28,911 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d2dc60{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-01-01 01:13:28,915 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@41f05f1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-01-01 01:13:29,660 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-01-01 01:13:29,732 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2a47fb5d{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-7448236730998119656/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-01-01 01:13:29,781 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@5cdb7b{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-01-01 01:13:29,784 [Listener at om1/9862] INFO server.Server: Started @47310ms
om1_1        | 2022-01-01 01:13:29,802 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-01-01 01:13:29,802 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-01-01 01:13:29,808 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-01-01 01:13:29,808 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-01-01 01:13:29,809 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-01-01 01:13:30,061 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2022-01-01 01:13:30,140 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@756476a3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-01-01 01:13:31,730 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-01-01 01:13:31,749 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om1_1        | 2022-01-01 01:13:31,758 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om2
om1_1        | 2022-01-01 01:13:31,759 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-01-01 01:13:31,761 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-01-01 01:13:31,761 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1        | java.lang.InterruptedException: sleep interrupted
om1_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om1_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om1_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om1_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2022-01-01 01:13:31,820 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:OK-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-01-01 01:13:22,247 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-01-01 01:13:22,251 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-01-01 01:13:22,254 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-01-01 01:13:22,264 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-01-01 01:13:22,275 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-01-01 01:13:22,277 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-01-01 01:13:22,644 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-01-01 01:13:22,714 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-01-01 01:13:22,714 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-01-01 01:13:22,943 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-01-01 01:13:22,945 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-01-01 01:13:22,947 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-01-01 01:13:22,956 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-01-01 01:13:22,963 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-01-01 01:13:22,976 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-01-01 01:13:23,003 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-01-01 01:13:23,241 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-01-01 01:13:23,266 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$406/0x00000008405d7040@71b38b11] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-01-01 01:13:23,270 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-01-01 01:13:23,271 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-01-01 01:13:23,272 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-01-01 01:13:23,280 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-01-01 01:13:23,291 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-01-01 01:13:23,299 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-01-01 01:13:23,495 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-01-01 01:13:23,495 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-01-01 01:13:23,495 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-01-01 01:13:23,630 [Listener at om2/9862] INFO util.log: Logging initialized @44602ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-01-01 01:13:24,198 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-01-01 01:13:24,239 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-01-01 01:13:24,242 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-01-01 01:13:24,248 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-01-01 01:13:24,255 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-01-01 01:13:24,285 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-01-01 01:13:24,568 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-01-01 01:13:24,580 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om2_1        | 2022-01-01 01:13:24,682 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-01-01 01:13:24,682 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-01-01 01:13:24,696 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-01-01 01:13:24,816 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-01-01 01:13:24,824 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d2dc60{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-01-01 01:13:24,844 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@41f05f1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-01-01 01:13:25,336 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-01-01 01:13:25,401 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2a47fb5d{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-10289309375232044585/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2022-01-01 01:12:50,543 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-01-01 01:12:59,170 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-01-01 01:13:00,047 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-01-01 01:13:00,058 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-01-01 01:13:00,068 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-01-01 01:13:00,201 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-01-01 01:13:00,625 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2022-01-01 01:13:02,813 [main] INFO reflections.Reflections: Reflections took 1429 ms to scan 1 urls, producing 97 keys and 262 values [using 2 cores]
om3_1        | 2022-01-01 01:13:04,847 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-01-01 01:13:04,847 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-01-01 01:13:04,847 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-01-01 01:13:12,285 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-01-01 01:13:12,986 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-857524461429.crt.
om3_1        | 2022-01-01 01:13:13,008 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/960585905812.crt.
om3_1        | 2022-01-01 01:13:13,024 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-01-01 01:13:13,223 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-01-01 01:13:14,356 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-01-01 01:13:14,374 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-01-01 01:13:15,819 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-01-01 01:13:15,821 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-01-01 01:13:16,758 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2022-01-01 01:13:17,077 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-01-01 01:13:17,112 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-01-01 01:13:17,235 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-01-01 01:13:18,122 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-01-01 01:13:18,174 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-01-01 01:13:18,342 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-01-01 01:13:18,459 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-01-01 01:13:19,641 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-01-01 01:13:19,927 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-01-01 01:13:19,929 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-01-01 01:13:19,931 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-01-01 01:13:19,932 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-01-01 01:13:19,934 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-01-01 01:13:19,939 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-01-01 01:13:19,941 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-01-01 01:13:19,943 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-01-01 01:13:19,944 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-01-01 01:13:22,555 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-01-01 01:13:22,559 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-01-01 01:13:22,567 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-01-01 01:13:22,645 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-01-01 01:13:22,677 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@410c1f44[Not completed]
om3_1        | 2022-01-01 01:13:22,682 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-01-01 01:13:22,875 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-01-01 01:13:22,957 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-01-01 01:13:22,989 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-01-01 01:13:22,991 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-01-01 01:13:22,992 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-01-01 01:13:22,992 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-01-01 01:13:22,992 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-01-01 01:13:22,994 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-01-01 01:13:22,998 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-01-01 01:13:23,157 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-01-01 01:13:32,711 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 7231ms
om1_1        | 2022-01-01 01:13:33,173 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-01-01 01:13:33,197 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-01-01 01:13:33,496 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-01-01 01:13:33,496 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om2 at current term 1
om1_1        | 2022-01-01 01:13:33,496 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=om2, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-01-01 01:13:33,712 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38751
om1_1        | 2022-01-01 01:13:33,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:13:33,876 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-01-01 01:13:36,670 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-01-01 01:13:37,259 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46384
om1_1        | 2022-01-01 01:13:37,287 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:13:51,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46422
om1_1        | 2022-01-01 01:13:51,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:13:53,110 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om1_1        | 2022-01-01 01:14:04,122 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46490
om1_1        | 2022-01-01 01:14:04,137 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:04,892 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46494
om1_1        | 2022-01-01 01:14:04,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:09,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46510
om1_1        | 2022-01-01 01:14:09,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:13:25,457 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@5cdb7b{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-01-01 01:13:25,458 [Listener at om2/9862] INFO server.Server: Started @46431ms
om2_1        | 2022-01-01 01:13:25,470 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-01-01 01:13:25,470 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-01-01 01:13:25,477 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-01-01 01:13:25,484 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-01-01 01:13:25,491 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-01-01 01:13:25,903 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2022-01-01 01:13:26,007 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@756476a3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-01-01 01:13:26,056 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45305
om2_1        | 2022-01-01 01:13:26,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:13:28,029 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5066391878ns, electionTimeout:5044ms
om2_1        | 2022-01-01 01:13:28,036 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-01-01 01:13:28,049 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-01-01 01:13:28,057 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-01-01 01:13:28,057 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-01-01 01:13:28,113 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-01-01 01:13:31,924 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om2_1        | 2022-01-01 01:13:31,933 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:OK-t1
om2_1        | 2022-01-01 01:13:31,938 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om2_1        | 2022-01-01 01:13:31,942 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-01-01 01:13:31,943 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om2_1        | 2022-01-01 01:13:31,943 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om2 at term 1 for becomeLeader, leader elected after 10178ms
om2_1        | 2022-01-01 01:13:31,983 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1        | 2022-01-01 01:13:32,006 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-01-01 01:13:32,007 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-01-01 01:13:32,039 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2022-01-01 01:13:32,040 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2022-01-01 01:13:32,043 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2022-01-01 01:13:32,056 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-01-01 01:13:32,063 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | 2022-01-01 01:13:32,105 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-01-01 01:13:32,105 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-01-01 01:13:32,113 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-01-01 01:13:32,121 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-01-01 01:13:32,127 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-01-01 01:13:32,127 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-01-01 01:13:32,145 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-01-01 01:13:32,145 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-01-01 01:13:32,145 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-01-01 01:13:32,145 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-01-01 01:13:32,146 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-01-01 01:13:32,146 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-01-01 01:13:32,163 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderStateImpl
om2_1        | 2022-01-01 01:13:32,221 [om2@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-01-01 01:13:32,466 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
datanode2_1  | 2022-01-01 01:22:24,020 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3819,entriesCount=1,lastEntry=(t:1, i:71)
datanode2_1  | 2022-01-01 01:22:24,030 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3820,entriesCount=1,lastEntry=(t:1, i:72)
datanode2_1  | 2022-01-01 01:22:30,199 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4069,entriesCount=1,lastEntry=(t:1, i:73)
datanode2_1  | 2022-01-01 01:22:30,317 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4070,entriesCount=1,lastEntry=(t:1, i:74)
datanode2_1  | 2022-01-01 01:22:30,398 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4071,entriesCount=1,lastEntry=(t:1, i:75)
datanode2_1  | 2022-01-01 01:22:30,450 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4072,entriesCount=1,lastEntry=(t:1, i:76)
datanode2_1  | 2022-01-01 01:22:30,476 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4075,entriesCount=1,lastEntry=(t:1, i:77)
datanode2_1  | 2022-01-01 01:22:30,614 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4083,entriesCount=1,lastEntry=(t:1, i:78)
datanode2_1  | 2022-01-01 01:22:30,625 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4085,entriesCount=1,lastEntry=(t:1, i:79)
datanode2_1  | 2022-01-01 01:22:30,739 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4096,entriesCount=1,lastEntry=(t:1, i:80)
datanode2_1  | 2022-01-01 01:22:30,742 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4098,entriesCount=1,lastEntry=(t:1, i:81)
datanode2_1  | 2022-01-01 01:22:30,746 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4099,entriesCount=1,lastEntry=(t:1, i:82)
datanode2_1  | 2022-01-01 01:22:30,860 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4109,entriesCount=1,lastEntry=(t:1, i:83)
datanode2_1  | 2022-01-01 01:22:30,865 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4110,entriesCount=1,lastEntry=(t:1, i:84)
datanode2_1  | 2022-01-01 01:22:36,311 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4358,entriesCount=1,lastEntry=(t:1, i:85)
datanode2_1  | 2022-01-01 01:22:36,335 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4359,entriesCount=1,lastEntry=(t:1, i:86)
datanode2_1  | 2022-01-01 01:22:36,338 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4360,entriesCount=1,lastEntry=(t:1, i:87)
datanode2_1  | 2022-01-01 01:22:36,420 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4361,entriesCount=1,lastEntry=(t:1, i:88)
datanode2_1  | 2022-01-01 01:22:36,420 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4362,entriesCount=1,lastEntry=(t:1, i:89)
datanode2_1  | 2022-01-01 01:22:36,421 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4363,entriesCount=1,lastEntry=(t:1, i:90)
datanode2_1  | 2022-01-01 01:22:40,287 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4611,entriesCount=1,lastEntry=(t:1, i:91)
datanode2_1  | 2022-01-01 01:22:40,325 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4612,entriesCount=1,lastEntry=(t:1, i:92)
datanode2_1  | 2022-01-01 01:22:40,356 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4613,entriesCount=1,lastEntry=(t:1, i:93)
datanode2_1  | 2022-01-01 01:22:40,427 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4614,entriesCount=1,lastEntry=(t:1, i:94)
datanode2_1  | 2022-01-01 01:22:40,445 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4616,entriesCount=1,lastEntry=(t:1, i:95)
datanode2_1  | 2022-01-01 01:22:40,450 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4617,entriesCount=1,lastEntry=(t:1, i:96)
datanode2_1  | 2022-01-01 01:22:48,496 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4871,entriesCount=1,lastEntry=(t:1, i:97)
datanode2_1  | 2022-01-01 01:22:48,507 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4872,entriesCount=1,lastEntry=(t:1, i:98)
datanode2_1  | 2022-01-01 01:22:48,524 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4873,entriesCount=1,lastEntry=(t:1, i:99)
datanode2_1  | 2022-01-01 01:22:48,530 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4875,entriesCount=1,lastEntry=(t:1, i:100)
datanode2_1  | 2022-01-01 01:22:53,594 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5125,entriesCount=1,lastEntry=(t:1, i:101)
datanode2_1  | 2022-01-01 01:22:53,687 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5126,entriesCount=1,lastEntry=(t:1, i:102)
datanode2_1  | 2022-01-01 01:22:53,763 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5127,entriesCount=1,lastEntry=(t:1, i:103)
datanode2_1  | 2022-01-01 01:22:53,764 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5128,entriesCount=1,lastEntry=(t:1, i:104)
datanode2_1  | 2022-01-01 01:22:53,815 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5132,entriesCount=1,lastEntry=(t:1, i:105)
datanode2_1  | 2022-01-01 01:22:53,821 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5133,entriesCount=1,lastEntry=(t:1, i:106)
datanode2_1  | 2022-01-01 01:22:53,829 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5134,entriesCount=1,lastEntry=(t:1, i:107)
datanode2_1  | 2022-01-01 01:22:53,838 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5135,entriesCount=1,lastEntry=(t:1, i:108)
datanode2_1  | 2022-01-01 01:23:00,902 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5387,entriesCount=1,lastEntry=(t:1, i:109)
datanode2_1  | 2022-01-01 01:23:01,055 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5388,entriesCount=1,lastEntry=(t:1, i:110)
datanode2_1  | 2022-01-01 01:23:01,129 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5393,entriesCount=1,lastEntry=(t:1, i:111)
datanode2_1  | 2022-01-01 01:23:01,235 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5403,entriesCount=1,lastEntry=(t:1, i:112)
om2_1        | 2022-01-01 01:13:33,350 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-01-01 01:13:33,547 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-01-01 01:13:33,552 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-LEADER: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-01-01 01:13:33,563 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=om2, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c0, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-01-01 01:13:33,824 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-01-01 01:13:37,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36508
om2_1        | 2022-01-01 01:13:37,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:13:51,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36546
om2_1        | 2022-01-01 01:13:51,413 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:13:52,237 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om2_1        | 2022-01-01 01:14:04,203 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36614
om2_1        | 2022-01-01 01:14:04,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:04,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36618
om2_1        | 2022-01-01 01:14:04,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:09,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36634
om2_1        | 2022-01-01 01:14:09,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:10,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36638
om2_1        | 2022-01-01 01:14:10,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:15,398 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36652
om2_1        | 2022-01-01 01:14:15,403 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:25,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36694
om2_1        | 2022-01-01 01:14:25,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:31,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36708
om2_1        | 2022-01-01 01:14:31,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:32,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36712
om2_1        | 2022-01-01 01:14:32,090 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:36,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37129
om2_1        | 2022-01-01 01:14:36,306 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:37,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36728
om2_1        | 2022-01-01 01:14:37,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:42,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36742
om2_1        | 2022-01-01 01:14:42,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:57,233 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36810
om2_1        | 2022-01-01 01:14:57,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:14:57,793 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-source for user:root
om2_1        | 2022-01-01 01:15:01,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36816
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-01-01 01:10:38,376 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
recon_1      | STARTUP_MSG:   java = 11.0.10
recon_1      | ************************************************************/
recon_1      | 2022-01-01 01:10:38,412 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-01-01 01:10:41,224 [main] INFO reflections.Reflections: Reflections took 271 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-01-01 01:10:43,258 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-01-01 01:10:43,472 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-01-01 01:10:44,418 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-01-01 01:10:44,419 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-01-01 01:10:45,242 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-01-01 01:10:44,009 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-01-01 01:10:44,010 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-01-01 01:10:44,363 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-01-01 01:10:44,363 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-01-01 01:10:44,363 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-01-01 01:10:44,564 [main] INFO util.log: Logging initialized @6077ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-01-01 01:14:10,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46514
om1_1        | 2022-01-01 01:14:10,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2022-01-01 01:10:44,997 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-01-01 01:10:45,027 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-01-01 01:10:45,029 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
om1_1        | 2022-01-01 01:14:15,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46528
om1_1        | 2022-01-01 01:14:15,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:25,535 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46570
om1_1        | 2022-01-01 01:14:25,559 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:31,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46584
om1_1        | 2022-01-01 01:14:31,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2022-01-01 01:10:45,029 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-01-01 01:10:45,029 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-01-01 01:10:45,044 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-01-01 01:10:45,483 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
om1_1        | 2022-01-01 01:14:32,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46588
om1_1        | 2022-01-01 01:14:32,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om3_1        | 2022-01-01 01:13:23,157 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-01-01 01:13:23,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-01-01 01:13:23,186 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-01-01 01:13:23,188 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-01-01 01:13:23,209 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-01-01 01:13:23,414 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2022-01-01 01:13:23,561 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-01-01 01:14:37,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46604
om1_1        | 2022-01-01 01:14:37,132 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:41,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46618
om1_1        | 2022-01-01 01:14:41,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:57,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46686
datanode2_1  | 2022-01-01 01:23:01,264 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5406,entriesCount=1,lastEntry=(t:1, i:113)
datanode2_1  | 2022-01-01 01:23:01,298 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5410,entriesCount=1,lastEntry=(t:1, i:114)
datanode2_1  | 2022-01-01 01:23:01,624 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5434,entriesCount=1,lastEntry=(t:1, i:115)
datanode2_1  | 2022-01-01 01:23:01,629 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5435,entriesCount=1,lastEntry=(t:1, i:116)
datanode2_1  | 2022-01-01 01:23:04,785 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5687,entriesCount=1,lastEntry=(t:1, i:117)
om1_1        | 2022-01-01 01:14:57,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:14:57,808 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-source for user:root
om1_1        | 2022-01-01 01:15:01,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46692
om1_1        | 2022-01-01 01:15:01,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2022-01-01 01:10:45,530 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-01-01 01:13:23,570 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-01-01 01:13:23,580 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-01-01 01:13:23,673 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-01-01 01:13:23,722 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-01-01 01:13:23,899 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-01-01 01:13:23,988 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-01-01 01:23:04,788 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5688,entriesCount=1,lastEntry=(t:1, i:118)
datanode2_1  | 2022-01-01 01:23:04,798 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5689,entriesCount=1,lastEntry=(t:1, i:119)
datanode2_1  | 2022-01-01 01:23:04,804 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5690,entriesCount=1,lastEntry=(t:1, i:120)
datanode2_1  | 2022-01-01 01:23:19,598 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5945,entriesCount=1,lastEntry=(t:1, i:121)
s3g_1        | 2022-01-01 01:10:45,716 [main] INFO s3.Gateway: Starting Ozone S3 gateway
om1_1        | 2022-01-01 01:15:02,339 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-target for user:root
om1_1        | 2022-01-01 01:15:06,074 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46708
om1_1        | 2022-01-01 01:15:06,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2022-01-01 01:10:45,747 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-01-01 01:10:45,751 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
s3g_1        | 2022-01-01 01:10:45,886 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-01-01 01:10:45,887 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-01-01 01:10:45,889 [main] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2022-01-01 01:13:23,996 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
recon_1      | 2022-01-01 01:10:49,188 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
datanode2_1  | 2022-01-01 01:23:19,604 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5946,entriesCount=1,lastEntry=(t:1, i:122)
datanode2_1  | 2022-01-01 01:23:19,608 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5947,entriesCount=1,lastEntry=(t:1, i:123)
datanode2_1  | 2022-01-01 01:23:19,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5948,entriesCount=1,lastEntry=(t:1, i:124)
datanode2_1  | 2022-01-01 01:23:34,535 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6203,entriesCount=1,lastEntry=(t:1, i:125)
om1_1        | 2022-01-01 01:15:10,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46722
om1_1        | 2022-01-01 01:15:10,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:20,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46772
om1_1        | 2022-01-01 01:15:20,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:25,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46780
om3_1        | 2022-01-01 01:13:24,071 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-01-01 01:13:24,074 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-01-01 01:13:24,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-01-01 01:13:24,095 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
s3g_1        | 2022-01-01 01:10:45,981 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-01-01 01:10:46,015 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@acb0951{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-01-01 01:10:46,016 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2ed3b1f5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
datanode2_1  | 2022-01-01 01:23:34,536 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6204,entriesCount=1,lastEntry=(t:1, i:126)
datanode2_1  | 2022-01-01 01:23:34,547 [java.util.concurrent.ThreadPoolExecutor$Worker@3d642f2d[State = -1, empty queue]] WARN server.GrpcLogAppender: 24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104->75beef28-1584-4115-9505-884f6f5c519b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6205,entriesCount=1,lastEntry=(t:1, i:127)
datanode2_1  | 2022-01-01 01:25:54,585 [Thread-692] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-921D9F21931A->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=167, seq=0, Watch-ALL_COMMITTED(130), Message:<EMPTY>, reply=RaftClientReply:client-921D9F21931A->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=167, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 167 and log index 130 is not yet replicated to ALL_COMMITTED, logIndex=130, commits[24732aa1-1492-41aa-844a-173d185ef1c3:c140, 458bfdff-96fb-4b4a-96de-6879eec60ac8:c140, 75beef28-1584-4115-9505-884f6f5c519b:c127]
datanode2_1  | 2022-01-01 01:26:57,580 [Thread-730] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A62714547BF1->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=178, seq=0, Watch-ALL_COMMITTED(134), Message:<EMPTY>, reply=RaftClientReply:client-A62714547BF1->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=178, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 178 and log index 134 is not yet replicated to ALL_COMMITTED, logIndex=134, commits[24732aa1-1492-41aa-844a-173d185ef1c3:c144, 458bfdff-96fb-4b4a-96de-6879eec60ac8:c144, 75beef28-1584-4115-9505-884f6f5c519b:c127]
datanode2_1  | 2022-01-01 01:27:58,580 [Thread-767] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-53BDAB94AD6F->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=182, seq=0, Watch-ALL_COMMITTED(139), Message:<EMPTY>, reply=RaftClientReply:client-53BDAB94AD6F->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=182, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 182 and log index 139 is not yet replicated to ALL_COMMITTED, logIndex=139, commits[24732aa1-1492-41aa-844a-173d185ef1c3:c148, 458bfdff-96fb-4b4a-96de-6879eec60ac8:c148, 75beef28-1584-4115-9505-884f6f5c519b:c127]
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-01-01 01:10:50,266 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-01-01 01:10:50,324 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-01-01 01:10:50,325 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-01-01 01:10:52,871 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-01-01 01:10:52,871 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-01-01 01:13:24,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-01-01 01:13:24,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-01-01 01:13:24,146 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-01-01 01:13:24,152 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-01-01 01:15:25,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:30,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46794
om1_1        | 2022-01-01 01:15:30,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:34,619 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46808
om1_1        | 2022-01-01 01:15:34,631 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2022-01-01 01:28:58,580 [Thread-808] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-298B96D3E41D->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=187, seq=0, Watch-ALL_COMMITTED(143), Message:<EMPTY>, reply=RaftClientReply:client-298B96D3E41D->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=187, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 187 and log index 143 is not yet replicated to ALL_COMMITTED, logIndex=143, commits[24732aa1-1492-41aa-844a-173d185ef1c3:c152, 458bfdff-96fb-4b4a-96de-6879eec60ac8:c152, 75beef28-1584-4115-9505-884f6f5c519b:c127]
datanode2_1  | 2022-01-01 01:30:00,580 [Thread-846] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-EAF1383B2A8A->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=192, seq=0, Watch-ALL_COMMITTED(146), Message:<EMPTY>, reply=RaftClientReply:client-EAF1383B2A8A->24732aa1-1492-41aa-844a-173d185ef1c3@group-F8541548C104, cid=192, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 192 and log index 146 is not yet replicated to ALL_COMMITTED, logIndex=146, commits[24732aa1-1492-41aa-844a-173d185ef1c3:c156, 458bfdff-96fb-4b4a-96de-6879eec60ac8:c156, 75beef28-1584-4115-9505-884f6f5c519b:c127]
s3g_1        | 2022-01-01 01:10:52,906 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jan 01, 2022 1:10:56 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-01-01 01:10:56,313 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@259195fe{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-3194484607336616595/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-01-01 01:10:56,336 [main] INFO server.AbstractConnector: Started ServerConnector@66629f63{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-01-01 01:10:56,336 [main] INFO server.Server: Started @17851ms
om3_1        | 2022-01-01 01:13:24,165 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-01-01 01:13:24,309 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-01-01 01:13:24,329 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-01-01 01:15:39,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46824
recon_1      | 2022-01-01 01:10:52,871 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-01-01 01:10:52,897 [main] INFO util.log: Logging initialized @16365ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-01-01 01:10:53,143 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-01-01 01:10:53,173 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-01-01 01:10:53,175 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-01-01 01:10:53,175 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-01-01 01:10:53,175 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-01-01 01:10:53,178 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
om1_1        | 2022-01-01 01:15:39,137 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:43,786 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46830
om1_1        | 2022-01-01 01:15:43,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:48,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46844
om1_1        | 2022-01-01 01:15:48,340 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:52,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46882
om1_1        | 2022-01-01 01:15:52,638 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:15:56,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46906
om1_1        | 2022-01-01 01:15:56,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:01,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46912
om1_1        | 2022-01-01 01:16:01,508 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2022-01-01 01:10:56,338 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
om2_1        | 2022-01-01 01:15:01,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:02,318 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-target for user:root
om2_1        | 2022-01-01 01:15:06,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36832
om2_1        | 2022-01-01 01:15:06,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:10,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36846
s3g_1        | 2022-01-01 01:19:34,304 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5533708096, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:19:34,337 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5533708096
s3g_1        | 2022-01-01 01:19:40,666 [qtp1677568775-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7847264725, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:19:40,686 [qtp1677568775-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7847264725
s3g_1        | 2022-01-01 01:19:41,946 [qtp1677568775-22] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-01-01 01:10:53,409 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-01-01 01:10:54,098 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-01-01 01:10:54,127 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-01-01 01:10:54,135 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-01-01 01:10:54,177 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-01-01 01:10:55,989 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 2022-01-01 01:19:41,960 [qtp1677568775-22] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-01-01 01:15:10,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:20,626 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36896
om2_1        | 2022-01-01 01:15:20,636 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:05,820 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46928
om1_1        | 2022-01-01 01:16:05,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-01-01 01:13:24,482 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1        | 2022-01-01 01:19:41,960 [qtp1677568775-22] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1        | 2022-01-01 01:19:41,966 [qtp1677568775-22] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-01-01 01:19:41,966 [qtp1677568775-22] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-01-01 01:19:42,283 [qtp1677568775-22] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-01-01 01:19:55,801 [qtp1677568775-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9384619119, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
om2_1        | 2022-01-01 01:15:25,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36904
om2_1        | 2022-01-01 01:15:25,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:30,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36918
om1_1        | 2022-01-01 01:16:10,448 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46944
om1_1        | 2022-01-01 01:16:10,498 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:15,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46958
om3_1        | 2022-01-01 01:13:24,502 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-01-01 01:13:24,532 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
recon_1      | 2022-01-01 01:10:56,673 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-01-01 01:10:56,758 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-01-01 01:10:56,767 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-01-01 01:10:56,983 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-01-01 01:10:57,222 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1      | 2022-01-01 01:10:57,341 [main] INFO reflections.Reflections: Reflections took 115 ms to scan 3 urls, producing 103 keys and 217 values 
recon_1      | 2022-01-01 01:10:57,465 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
s3g_1        | 2022-01-01 01:19:55,820 [qtp1677568775-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9384619119
s3g_1        | 2022-01-01 01:19:56,426 [qtp1677568775-22] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-omljfbdanu, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:19:56,441 [qtp1677568775-22] INFO endpoint.BucketEndpoint: Location is /ozone-test-omljfbdanu
s3g_1        | 2022-01-01 01:20:07,816 [qtp1677568775-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-acmegzauxv, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
om3_1        | 2022-01-01 01:13:24,564 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-01-01 01:13:24,565 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-01-01 01:13:24,573 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-01-01 01:13:24,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-01-01 01:15:30,267 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:34,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36932
om2_1        | 2022-01-01 01:15:34,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:36,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38523
om2_1        | 2022-01-01 01:15:36,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:15,094 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:19,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46988
om1_1        | 2022-01-01 01:16:19,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:26,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47006
om1_1        | 2022-01-01 01:16:26,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:33,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47032
s3g_1        | 2022-01-01 01:20:07,844 [qtp1677568775-18] INFO endpoint.BucketEndpoint: Location is /bucket-acmegzauxv
s3g_1        | 2022-01-01 01:20:23,394 [qtp1677568775-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5333357034, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:23,407 [qtp1677568775-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5333357034
s3g_1        | 2022-01-01 01:20:23,933 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2999313279, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1      | 2022-01-01 01:10:57,508 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-01-01 01:10:57,517 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-01-01 01:10:57,528 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-01-01 01:10:57,614 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-01-01 01:10:57,712 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
om3_1        | 2022-01-01 01:13:24,591 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-01-01 01:13:24,958 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-01-01 01:13:25,076 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-01-01 01:13:25,076 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-01-01 01:13:25,288 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om2_1        | 2022-01-01 01:15:39,189 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36948
om2_1        | 2022-01-01 01:15:39,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:43,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36954
om2_1        | 2022-01-01 01:15:43,850 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:33,605 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:42,975 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47052
om1_1        | 2022-01-01 01:16:43,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:50,078 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47094
om1_1        | 2022-01-01 01:16:50,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:54,598 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47108
s3g_1        | 2022-01-01 01:20:23,949 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2999313279
s3g_1        | 2022-01-01 01:20:24,441 [qtp1677568775-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4320353850, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:24,459 [qtp1677568775-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4320353850
s3g_1        | 2022-01-01 01:20:24,933 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4320353850, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:24,951 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4320353850
s3g_1        | 2022-01-01 01:20:25,426 [qtp1677568775-24] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: invalid_bucket_ozone-test-0075601568
recon_1      | 2022-01-01 01:10:57,849 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-01-01 01:10:58,011 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
om2_1        | 2022-01-01 01:15:48,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36992
om2_1        | 2022-01-01 01:15:48,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:52,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37006
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-01-01 01:10:41,842 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-01-01 01:10:41,922 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-01-01 01:10:42,566 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-01-01 01:10:42,844 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-01-01 01:10:42,845 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-01-01 01:10:43,661 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-01-01 01:10:43,661 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-01-01 01:10:43,702 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-01-01 01:10:48,118 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-01-01 01:10:48,118 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-01-01 01:10:48,175 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-01-01 01:10:52,463 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-01-01 01:10:56,099 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-01-01 01:10:56,099 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-01-01 01:10:56,839 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-01-01 01:10:56,840 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-01-01 01:10:56,841 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:1214e676-068e-4ac1-9115-7b01b3dcff10,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:scm-sub@scm1.org
scm1.org_1   | 2022-01-01 01:10:57,183 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-01-01 01:10:57,426 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-01-01 01:10:57,557 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-01-01 01:10:57,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:10:57,564 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-01-01 01:10:57,564 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:10:57,564 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:10:57,566 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-01-01 01:10:57,569 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:10:57,570 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-01-01 01:10:57,575 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-01-01 01:10:57,898 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-01-01 01:10:57,906 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-01-01 01:10:57,907 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-01-01 01:10:57,928 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-01-01 01:10:57,937 [main] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: addNew group-CD2E3D8DB0C2:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|priority:0] returns group-CD2E3D8DB0C2:java.util.concurrent.CompletableFuture@3af7d855[Not completed]
scm1.org_1   | 2022-01-01 01:10:57,963 [pool-2-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10: new RaftServerImpl for group-CD2E3D8DB0C2:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-01-01 01:10:57,968 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-01-01 01:10:57,973 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-01-01 01:10:57,974 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-01-01 01:13:25,296 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-01-01 01:13:25,306 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-01-01 01:13:25,308 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-01-01 01:13:25,314 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-01-01 01:13:25,319 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
scm1.org_1   | 2022-01-01 01:10:57,974 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-01-01 01:10:57,975 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-01-01 01:10:57,975 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-01-01 01:10:57,976 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-01-01 01:10:57,980 [pool-2-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: ConfigurationManager, init=-1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-01-01 01:10:57,982 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
recon_1      | 2022-01-01 01:10:58,011 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-01-01 01:10:58,111 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-01-01 01:15:52,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:15:57,016 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37030
om2_1        | 2022-01-01 01:15:57,021 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:01,551 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37036
om2_1        | 2022-01-01 01:16:01,569 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:54,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:16:59,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47132
om1_1        | 2022-01-01 01:16:59,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:572)
recon_1      | 2022-01-01 01:10:58,128 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-01-01 01:10:58,128 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
om1_1        | 2022-01-01 01:17:03,269 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47150
om3_1        | 2022-01-01 01:13:25,338 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-01-01 01:13:25,546 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:511)
om1_1        | 2022-01-01 01:17:03,297 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:08,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47156
om1_1        | 2022-01-01 01:17:08,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-01-01 01:13:25,570 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-01-01 01:16:05,892 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37052
om3_1        | 2022-01-01 01:13:25,570 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
recon_1      | 2022-01-01 01:10:58,581 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
om2_1        | 2022-01-01 01:16:05,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:10,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37068
om2_1        | 2022-01-01 01:16:10,546 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:15,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37082
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:502)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
om3_1        | 2022-01-01 01:13:25,572 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$406/0x00000008405d7040@1a120e41] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
recon_1      | 2022-01-01 01:10:58,582 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
recon_1      | 2022-01-01 01:10:58,674 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-01-01 01:10:58,674 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-01-01 01:10:58,684 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-01-01 01:10:58,726 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-01-01 01:10:58,733 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7323c38c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-01-01 01:10:58,734 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33fec21{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-01-01 01:10:59,124 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-01-01 01:10:59,128 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-01-01 01:11:01,363 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1b06c3f8{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-7364813766331326190/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-01-01 01:11:01,381 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@68f79b7c{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-01-01 01:11:01,381 [Listener at 0.0.0.0/9891] INFO server.Server: Started @24849ms
recon_1      | 2022-01-01 01:11:01,387 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-01-01 01:11:01,388 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-01-01 01:11:01,403 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-01-01 01:11:01,403 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-01-01 01:11:01,419 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-01-01 01:11:01,427 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-01-01 01:11:01,427 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-01-01 01:11:01,427 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-01-01 01:11:01,427 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-01-01 01:11:01,428 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-01-01 01:11:03,658 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:05,659 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:07,661 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:09,663 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:11,664 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:14,166 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:1214e676-068e-4ac1-9115-7b01b3dcff10 is not the leader. Could not determine the leader node.
om3_1        | 2022-01-01 01:13:25,576 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-01-01 01:13:25,582 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-01-01 01:13:25,592 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-01-01 01:13:25,670 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-01-01 01:13:25,838 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-01-01 01:13:25,839 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-01-01 01:13:25,839 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-01-01 01:13:25,957 [Listener at om3/9862] INFO util.log: Logging initialized @44121ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-01-01 01:13:26,462 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-01-01 01:13:26,503 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-01-01 01:13:26,510 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-01-01 01:13:26,517 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-01-01 01:13:26,517 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-01-01 01:13:26,528 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-01-01 01:13:26,765 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-01-01 01:13:26,767 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om3_1        | 2022-01-01 01:13:26,889 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-01-01 01:13:26,892 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-01-01 01:13:26,894 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-01-01 01:13:26,991 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-01-01 01:13:27,002 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6311640d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-01-01 01:13:27,004 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@25ee6683{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-01-01 01:13:27,471 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-01-01 01:13:27,555 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@17c95612{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-1189229089365803451/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-01-01 01:13:27,606 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@16b1dee7{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-01-01 01:13:27,607 [Listener at om3/9862] INFO server.Server: Started @45771ms
om3_1        | 2022-01-01 01:13:27,626 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-01-01 01:13:27,627 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-01-01 01:13:27,635 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-01-01 01:13:27,638 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-01-01 01:13:27,664 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-01-01 01:13:28,215 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2022-01-01 01:13:28,244 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4746d52d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-01-01 01:13:28,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46055
om3_1        | 2022-01-01 01:13:28,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-01-01 01:13:30,451 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5140077831ns, electionTimeout:5127ms
om3_1        | 2022-01-01 01:13:30,462 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-01-01 01:13:30,464 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-01-01 01:13:30,471 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-01-01 01:13:30,473 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-01-01 01:13:30,525 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-01-01 01:13:32,690 [grpc-default-executor-2] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-01-01 01:13:32,691 [grpc-default-executor-2] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-01-01 01:13:32,820 [grpc-default-executor-2] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-01-01 01:13:33,022 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
om3_1        | 2022-01-01 01:13:33,023 [grpc-default-executor-3] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-01-01 01:13:33,025 [grpc-default-executor-3] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-01-01 01:13:33,032 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 9462ms
om3_1        | 2022-01-01 01:13:33,492 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-01-01 01:13:33,521 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om3_1        | 2022-01-01 01:13:33,522 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-01-01 01:13:33,522 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-01-01 01:17:12,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47170
om1_1        | 2022-01-01 01:17:12,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:17,395 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47184
om1_1        | 2022-01-01 01:17:17,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:21,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47222
om1_1        | 2022-01-01 01:17:21,768 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:26,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47230
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
om2_1        | 2022-01-01 01:16:15,173 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:117)
om2_1        | 2022-01-01 01:16:19,543 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37112
om2_1        | 2022-01-01 01:16:19,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:26,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:30,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47244
om1_1        | 2022-01-01 01:17:30,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:35,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47258
scm1.org_1   | 2022-01-01 01:10:57,990 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-01-01 01:10:58,006 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-01-01 01:10:58,008 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 does not exist. Creating ...
scm1.org_1   | 2022-01-01 01:10:58,054 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/in_use.lock acquired by nodename 14@scm1.org
scm1.org_1   | 2022-01-01 01:10:58,087 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 has been successfully formatted.
scm1.org_1   | 2022-01-01 01:10:58,113 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-01-01 01:10:58,122 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-01-01 01:10:58,138 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-01-01 01:10:58,146 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:10:58,171 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-01-01 01:10:58,340 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-01-01 01:10:58,362 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-01-01 01:10:58,362 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-01-01 01:10:58,375 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm1.org_1   | 2022-01-01 01:10:58,376 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-01-01 01:10:58,376 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-01-01 01:10:58,377 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-01-01 01:10:58,377 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-01-01 01:10:58,378 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-01-01 01:10:58,383 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-01-01 01:10:58,383 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-01-01 01:10:58,384 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-01-01 01:10:58,433 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-01-01 01:10:58,434 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-01-01 01:10:58,445 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-01-01 01:10:58,445 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-01-01 01:10:58,459 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-01-01 01:10:58,460 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-01-01 01:10:58,460 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-01-01 01:10:58,461 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-01-01 01:10:58,462 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-01-01 01:10:58,462 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-01-01 01:10:58,517 [main] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: start as a follower, conf=-1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-01-01 01:10:58,528 [main] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-01-01 01:10:58,529 [main] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState
scm1.org_1   | 2022-01-01 01:10:58,546 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD2E3D8DB0C2,id=1214e676-068e-4ac1-9115-7b01b3dcff10
scm1.org_1   | 2022-01-01 01:10:58,552 [main] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: start RPC server
scm1.org_1   | 2022-01-01 01:10:58,647 [main] INFO server.GrpcService: 1214e676-068e-4ac1-9115-7b01b3dcff10: GrpcService started, listening on 9894
scm1.org_1   | 2022-01-01 01:10:58,656 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@24534cb0] INFO util.JvmPauseMonitor: JvmPauseMonitor-1214e676-068e-4ac1-9115-7b01b3dcff10: Started
scm1.org_1   | 2022-01-01 01:11:03,604 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.FollowerState: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5075102710ns, electionTimeout:5072ms
scm1.org_1   | 2022-01-01 01:11:03,606 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState
scm1.org_1   | 2022-01-01 01:11:03,606 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-01-01 01:11:03,609 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-01-01 01:11:03,609 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1
scm1.org_1   | 2022-01-01 01:11:03,621 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.LeaderElection: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-01-01 01:11:03,622 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.LeaderElection: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-01-01 01:11:03,622 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1
scm1.org_1   | 2022-01-01 01:11:03,623 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-01-01 01:11:03,623 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: change Leader from null to 1214e676-068e-4ac1-9115-7b01b3dcff10 at term 1 for becomeLeader, leader elected after 5510ms
scm1.org_1   | 2022-01-01 01:11:03,635 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-01-01 01:11:03,640 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-01-01 01:11:03,641 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-01-01 01:11:03,650 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om2_1        | 2022-01-01 01:16:26,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37138
om2_1        | 2022-01-01 01:16:26,794 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:33,638 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37156
om2_1        | 2022-01-01 01:16:33,643 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:36,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46313
om2_1        | 2022-01-01 01:16:36,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om1_1        | 2022-01-01 01:17:35,092 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:39,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47274
om1_1        | 2022-01-01 01:17:39,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om3_1        | 2022-01-01 01:13:33,533 [grpc-default-executor-3] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:164)
om2_1        | 2022-01-01 01:16:43,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37176
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om1_1        | 2022-01-01 01:17:44,257 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47280
om2_1        | 2022-01-01 01:16:43,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:50,127 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37218
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:56079)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:16,168 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-01-01 01:17:44,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:49,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47318
om1_1        | 2022-01-01 01:17:49,090 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:49,697 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:17837-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:17:53,319 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47332
om1_1        | 2022-01-01 01:17:53,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:57,799 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47356
om1_1        | 2022-01-01 01:17:57,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:17:58,354 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:17837-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 2022-01-01 01:16:50,134 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:54,651 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37232
om2_1        | 2022-01-01 01:16:54,662 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:16:59,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37256
om2_1        | 2022-01-01 01:16:59,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:03,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37274
om2_1        | 2022-01-01 01:17:03,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:08,126 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37280
om2_1        | 2022-01-01 01:17:08,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:12,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37294
om2_1        | 2022-01-01 01:17:12,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:17,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37308
om2_1        | 2022-01-01 01:17:17,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:21,807 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37346
om2_1        | 2022-01-01 01:17:21,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:26,114 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37354
om2_1        | 2022-01-01 01:17:26,126 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:30,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37368
om2_1        | 2022-01-01 01:17:30,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:35,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37382
om2_1        | 2022-01-01 01:17:35,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:36,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40249
om2_1        | 2022-01-01 01:17:36,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:39,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37398
om2_1        | 2022-01-01 01:17:39,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:44,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37404
om2_1        | 2022-01-01 01:17:44,339 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:49,115 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37442
om2_1        | 2022-01-01 01:17:49,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:49,667 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:17837-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-01-01 01:11:01,984 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
recon_1      | 2022-01-01 01:11:18,170 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm3.org_1   | Sleeping for 5 seconds
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 2022-01-01 01:11:20,435 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-01-01 01:11:20,436 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-01-01 01:11:20,437 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-01-01 01:11:20,439 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-01-01 01:11:20,440 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-01-01 01:11:20,539 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-01-01 01:11:20,539 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-01-01 01:11:20,556 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-01-01 01:11:02,000 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-01-01 01:11:02,121 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-01-01 01:11:02,121 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
recon_1      | 2022-01-01 01:11:20,556 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-01-01 01:11:20,656 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-01-01 01:11:20,659 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 101 milliseconds.
recon_1      | 2022-01-01 01:11:20,684 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 95 milliseconds to process 0 existing database records.
recon_1      | 2022-01-01 01:11:20,711 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 27 milliseconds for processing 0 containers.
scm3.org_1   | 2022-01-01 01:11:40,763 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
om3_1        | 2022-01-01 01:13:33,877 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-01-01 01:13:36,625 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-01-01 01:13:53,342 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om3_1        | 2022-01-01 01:14:57,804 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-source for user:root
om3_1        | 2022-01-01 01:15:02,331 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:17837-target for user:root
om3_1        | 2022-01-01 01:17:49,679 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:17837-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-01-01 01:11:02,220 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:18:02,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47362
om1_1        | 2022-01-01 01:18:02,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:06,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47378
om1_1        | 2022-01-01 01:18:06,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-01-01 01:11:02,220 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-01-01 01:11:02,227 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-01-01 01:11:21,428 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:11:21,429 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-01-01 01:18:11,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47392
om1_1        | 2022-01-01 01:18:11,317 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:16,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47406
om1_1        | 2022-01-01 01:18:16,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-01-01 01:11:02,431 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-01-01 01:11:02,431 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-01-01 01:11:04,674 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:06,676 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:08,677 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:10,679 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:12,682 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:14,880 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:1214e676-068e-4ac1-9115-7b01b3dcff10 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2022-01-01 01:18:20,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47436
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm1.org_1   | 2022-01-01 01:11:03,650 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-01-01 01:11:03,651 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2022-01-01 01:17:53,377 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37456
om2_1        | 2022-01-01 01:17:53,382 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:17:57,848 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37480
om2_1        | 2022-01-01 01:17:57,852 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 2022-01-01 01:11:21,541 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:21,545 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:23,547 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:23,548 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm3.org_1   | 2022-01-01 01:11:40,799 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-01-01 01:18:20,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:25,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47450
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
om2_1        | 2022-01-01 01:17:58,336 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:17837-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1      | 2022-01-01 01:11:23,548 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2022-01-01 01:11:41,209 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-01-01 01:11:41,215 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-01-01 01:11:41,336 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-01-01 01:11:41,336 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm1.org_1   | 2022-01-01 01:11:03,660 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-01-01 01:11:03,662 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-01-01 01:11:03,670 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl
scm1.org_1   | 2022-01-01 01:11:03,700 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-01-01 01:11:03,752 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 0: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 2022-01-01 01:11:25,550 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:25,552 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
om1_1        | 2022-01-01 01:18:25,565 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:17:58,335 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:17837-target
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 2022-01-01 01:11:25,553 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:27,554 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:27,556 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
scm3.org_1   | 2022-01-01 01:11:41,349 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-01-01 01:11:41,717 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-01-01 01:11:41,717 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-01-01 01:11:42,788 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-01-01 01:11:44,022 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1      | 2022-01-01 01:11:27,557 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:29,558 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
om1_1        | 2022-01-01 01:18:29,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47464
om1_1        | 2022-01-01 01:18:29,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-01-01 01:11:44,022 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-01-01 01:11:44,024 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 2022-01-01 01:18:34,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47478
scm3.org_1   | 2022-01-01 01:11:45,089 [main] INFO ha.HASecurityUtils: Init response: GETCERT
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-01-01 01:11:29,560 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:29,560 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:31,562 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:31,563 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:31,564 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:33,565 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm1.org_1   | 2022-01-01 01:11:03,815 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_0
recon_1      | 2022-01-01 01:11:33,566 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:33,566 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:35,568 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:35,574 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 2022-01-01 01:11:04,658 [main] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: close
scm1.org_1   | 2022-01-01 01:11:04,659 [main] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: shutdown
scm1.org_1   | 2022-01-01 01:11:04,659 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD2E3D8DB0C2,id=1214e676-068e-4ac1-9115-7b01b3dcff10
scm1.org_1   | 2022-01-01 01:11:04,659 [main] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl
scm1.org_1   | 2022-01-01 01:11:04,664 [main] INFO impl.PendingRequests: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-01-01 01:11:04,667 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-01-01 01:11:04,667 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-01-01 01:11:04,671 [main] INFO impl.StateMachineUpdater: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-01-01 01:11:04,672 [main] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: closes. applyIndex: 0
scm1.org_1   | 2022-01-01 01:11:04,675 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-01-01 01:11:04,677 [main] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-01-01 01:11:04,679 [main] INFO server.GrpcService: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown server with port 9894 now
scm1.org_1   | 2022-01-01 01:11:04,683 [main] INFO server.GrpcService: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown server with port 9894 successfully
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2022-01-01 01:11:04,683 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031fc40@24534cb0] INFO util.JvmPauseMonitor: JvmPauseMonitor-1214e676-068e-4ac1-9115-7b01b3dcff10: Stopped
scm1.org_1   | 2022-01-01 01:11:04,684 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-01-01 01:11:04,686 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2; layoutVersion=2; scmId=1214e676-068e-4ac1-9115-7b01b3dcff10
scm1.org_1   | 2022-01-01 01:11:04,699 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm3.org_1   | 2022-01-01 01:11:45,199 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-01-01 01:11:45,200 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-01-01 01:11:45,211 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:f44d6013-5a2d-49ef-9eb3-f2fb3659b167,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:scm-sub@scm3.org
scm3.org_1   | 2022-01-01 01:11:46,427 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-01-01 01:11:46,450 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2, SCMID f44d6013-5a2d-49ef-9eb3-f2fb3659b167
scm3.org_1   | 2022-01-01 01:11:46,451 [main] INFO server.StorageContainerManager: Primary SCM Node ID 1214e676-068e-4ac1-9115-7b01b3dcff10
scm3.org_1   | 2022-01-01 01:11:46,510 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-01-01 01:11:48,788 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
om1_1        | 2022-01-01 01:18:34,164 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:38,509 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47486
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-01-01 01:11:06,462 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om1_1        | 2022-01-01 01:18:38,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:42,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47500
om1_1        | 2022-01-01 01:18:42,767 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:52,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47550
om1_1        | 2022-01-01 01:18:52,468 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:18:58,951 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47578
om1_1        | 2022-01-01 01:18:58,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:03,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47584
om1_1        | 2022-01-01 01:19:03,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:07,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47600
om1_1        | 2022-01-01 01:19:07,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:29,657 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47808
om1_1        | 2022-01-01 01:19:29,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:33,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:34953
om1_1        | 2022-01-01 01:19:33,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:37,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47826
om1_1        | 2022-01-01 01:19:37,996 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:19:53,173 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47902
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-01-01 01:19:53,192 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:20:20,808 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48002
om3_1        | 2022-01-01 01:20:24,948 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-4320353850 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
om1_1        | 2022-01-01 01:20:20,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:20:24,952 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-4320353850 in volume:s3v
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 2022-01-01 01:18:02,307 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37486
om2_1        | 2022-01-01 01:18:02,312 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2022-01-01 01:18:06,919 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37502
om2_1        | 2022-01-01 01:18:06,924 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:07,445 [IPC Server handler 7 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:17837-target Bucket:unreadable-link 
om2_1        | 2022-01-01 01:18:11,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37516
om2_1        | 2022-01-01 01:18:11,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om2_1        | 2022-01-01 01:18:16,115 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37530
om2_1        | 2022-01-01 01:18:16,122 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:16,659 [IPC Server handler 33 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:17837-source Bucket:unreadable-bucket Key:
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | 2022-01-01 01:11:35,575 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:37,576 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:37,578 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 2022-01-01 01:18:20,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37560
om2_1        | 2022-01-01 01:18:20,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-01-01 01:11:37,579 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:39,583 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:39,584 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | 2022-01-01 01:11:16,881 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:18,883 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:20,974 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-01-01 01:11:48,802 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-01-01 01:11:48,897 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
recon_1      | 2022-01-01 01:11:39,585 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:41,588 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
s3g_1        | 2022-01-01 01:20:25,679 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
scm1.org_1   | 2022-01-01 01:11:06,470 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-01-01 01:11:06,559 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-01-01 01:11:06,560 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-01-01 01:11:48,903 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-01-01 01:11:48,962 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
recon_1      | 2022-01-01 01:11:41,589 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
s3g_1        |   <Code>InvalidBucketName</Code>
s3g_1        |   <Message>The specified bucket is not valid.</Message>
scm1.org_1   | 2022-01-01 01:11:06,617 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-01-01 01:11:06,618 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 2022-01-01 01:11:41,590 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:43,596 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
om3_1        | 2022-01-01 01:20:33,821 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9804720151 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
scm2.org_1   | 2022-01-01 01:11:22,018 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-01-01 01:11:06,649 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-01-01 01:11:06,677 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        |   <Resource>invalid_bucket_ozone-test-0075601568</Resource>
scm2.org_1   | 2022-01-01 01:11:22,022 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-01-01 01:11:22,024 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-01-01 01:11:24,078 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-01-01 01:11:24,112 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-01-01 01:11:24,112 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-01-01 01:11:24,115 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:763bf6f7-3694-4790-8e44-c4f88a97de1a,clusterId:CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2,subject:scm-sub@scm2.org
scm2.org_1   | 2022-01-01 01:11:26,407 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-01-01 01:11:26,426 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2, SCMID 763bf6f7-3694-4790-8e44-c4f88a97de1a
scm1.org_1   | 2022-01-01 01:11:06,984 [main] INFO reflections.Reflections: Reflections took 173 ms to scan 3 urls, producing 103 keys and 217 values 
scm2.org_1   | 2022-01-01 01:11:26,426 [main] INFO server.StorageContainerManager: Primary SCM Node ID 1214e676-068e-4ac1-9115-7b01b3dcff10
scm2.org_1   | 2022-01-01 01:11:26,467 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-01-01 01:18:25,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37574
om2_1        | 2022-01-01 01:18:25,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-01-01 01:11:48,964 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-01-01 01:11:49,001 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:29,452 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm2.org_1   | /************************************************************
om1_1        | 2022-01-01 01:20:29,502 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48036
om1_1        | 2022-01-01 01:20:29,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:20:33,799 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9804720151 in volume:s3v
om2_1        | 2022-01-01 01:18:29,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37588
om2_1        | 2022-01-01 01:18:29,923 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-01-01 01:11:43,598 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:43,601 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:45,611 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:45,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:45,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:47,616 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:47,617 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 2022-01-01 01:18:34,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37602
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:88)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:08,983 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-7365940470/ozone-test-6600273006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-01-01 01:21:08,994 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-6600273006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-6600273006/multipartKey2. Entity too small.
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
scm3.org_1   | 2022-01-01 01:11:49,036 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2022-01-01 01:11:49,339 [main] INFO reflections.Reflections: Reflections took 142 ms to scan 3 urls, producing 103 keys and 217 values 
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
scm1.org_1   | 2022-01-01 01:11:07,575 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm3.org_1   | 2022-01-01 01:11:49,920 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-01-01 01:11:50,055 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/906263465560.crt.
scm3.org_1   | 2022-01-01 01:11:50,058 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-01-01 01:11:50,064 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d6cbb15f7a29221fcbd8f2c3bc9f5073c12c12d7 ; compiled by 'runner' on 2022-01-01T00:49Z
scm1.org_1   | 2022-01-01 01:11:07,705 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-01-01 01:11:07,708 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/857524461429.crt.
scm1.org_1   | 2022-01-01 01:11:07,712 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-01-01 01:11:07,832 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-01-01 01:11:07,832 [main] INFO server.StorageContainerManager: SCM login successful.
om2_1        | 2022-01-01 01:18:34,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:36,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42297
om2_1        | 2022-01-01 01:18:36,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:38,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37610
om2_1        | 2022-01-01 01:18:38,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:42,799 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37624
om2_1        | 2022-01-01 01:18:42,806 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:52,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37674
om2_1        | 2022-01-01 01:18:52,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:18:59,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37702
om2_1        | 2022-01-01 01:18:59,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:19:03,112 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37718
om2_1        | 2022-01-01 01:19:03,114 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1      | 2022-01-01 01:11:47,618 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:49,619 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
recon_1      | 2022-01-01 01:11:49,621 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:49,622 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:51,624 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2022-01-01 01:11:50,332 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-01-01 01:11:50,342 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-01-01 01:11:50,402 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-01-01 01:11:50,684 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm1.org_1   | 2022-01-01 01:11:07,870 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-01-01 01:11:08,068 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-01-01 01:11:08,318 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-01-01 01:11:08,318 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-01-01 01:11:51,625 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
recon_1      | 2022-01-01 01:11:51,629 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm3.org_1   | 2022-01-01 01:11:51,047 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-01-01 01:11:51,047 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-01-01 01:11:51,219 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
recon_1      | 2022-01-01 01:11:53,632 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm3.org_1   | 2022-01-01 01:11:51,311 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:f44d6013-5a2d-49ef-9eb3-f2fb3659b167
scm3.org_1   | 2022-01-01 01:11:51,466 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-01-01 01:11:51,620 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-01-01 01:11:51,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-01-01 01:11:51,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-01-01 01:11:29,479 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-01-01 01:11:53,633 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:53,633 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:55,635 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:55,636 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:55,637 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2022-01-01 01:11:08,465 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 2022-01-01 01:19:07,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37724
om2_1        | 2022-01-01 01:19:07,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1      | 2022-01-01 01:11:57,639 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:57,640 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-01-01 01:11:08,499 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:1214e676-068e-4ac1-9115-7b01b3dcff10
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:20:37,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48060
om1_1        | 2022-01-01 01:20:37,304 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:10,063 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
scm1.org_1   | 2022-01-01 01:11:08,601 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-01-01 01:11:08,668 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-01-01 01:11:51,622 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | , partNumber: 2
scm2.org_1   | 2022-01-01 01:11:29,625 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-01-01 01:11:29,625 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-01-01 01:11:29,774 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-01-01 01:11:29,778 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-01-01 01:11:29,855 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:29,949 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm1.org_1   | 2022-01-01 01:11:08,669 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:11:08,669 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-01-01 01:21:10,064 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm2.org_1   | 2022-01-01 01:11:30,457 [main] INFO reflections.Reflections: Reflections took 275 ms to scan 3 urls, producing 103 keys and 217 values 
scm2.org_1   | 2022-01-01 01:11:31,448 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-01-01 01:11:31,689 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-01-01 01:11:31,698 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-01-01 01:11:51,622 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2022-01-01 01:19:29,720 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37932
om2_1        | 2022-01-01 01:19:29,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-01-01 01:11:31,701 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/885298752854.crt.
scm2.org_1   | 2022-01-01 01:11:31,956 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-01-01 01:20:44,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48080
scm1.org_1   | 2022-01-01 01:11:08,670 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:11:08,670 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2022-01-01 01:19:33,793 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40159
om2_1        | 2022-01-01 01:19:33,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:19:34,243 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:51,627 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-01-01 01:11:31,956 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-01-01 01:11:32,020 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:32,393 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:32,844 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
om1_1        | 2022-01-01 01:20:44,651 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:20:51,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48122
scm3.org_1   | 2022-01-01 01:11:51,632 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:11:08,671 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om1_1        | 2022-01-01 01:20:51,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:21:08,979 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-7365940470/ozone-test-6600273006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-01-01 01:21:08,980 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-6600273006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 2022-01-01 01:19:34,319 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:36,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43067
scm1.org_1   | 2022-01-01 01:11:08,673 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
recon_1      | 2022-01-01 01:11:57,641 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:11:59,642 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:59,643 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:11:59,644 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-01-01 01:11:08,674 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-01-01 01:11:08,675 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-01-01 01:11:09,462 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-01-01 01:11:51,633 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-6600273006/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 2022-01-01 01:19:36,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:19:38,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37950
om2_1        | 2022-01-01 01:19:38,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-01-01 01:12:01,645 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-01-01 01:11:32,844 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-01-01 01:11:51,635 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-01-01 01:11:52,830 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-01-01 01:11:52,838 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-01-01 01:11:52,838 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
recon_1      | 2022-01-01 01:12:01,647 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
scm3.org_1   | 2022-01-01 01:11:52,852 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-01-01 01:11:52,858 [main] INFO server.RaftServer: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: addNew group-CD2E3D8DB0C2:[] returns group-CD2E3D8DB0C2:java.util.concurrent.CompletableFuture@372954e1[Not completed]
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 2022-01-01 01:19:40,662 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:09,464 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm2.org_1   | 2022-01-01 01:11:33,066 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-01-01 01:11:33,168 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:763bf6f7-3694-4790-8e44-c4f88a97de1a
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:10,581 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
recon_1      | 2022-01-01 01:12:01,674 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:03,679 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
scm2.org_1   | 2022-01-01 01:11:33,438 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-01-01 01:11:33,593 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-01-01 01:19:40,668 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:41,195 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:52,891 [pool-14-thread-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: new RaftServerImpl for group-CD2E3D8DB0C2:[] with SCMStateMachine:uninitialized
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:10,069 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
scm3.org_1   | 2022-01-01 01:11:52,903 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-01-01 01:11:52,903 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-01-01 01:11:52,903 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2022-01-01 01:11:52,906 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm1.org_1   | 2022-01-01 01:11:09,464 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-01-01 01:11:09,475 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-01-01 01:11:09,477 [main] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: found a subdirectory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm3.org_1   | 2022-01-01 01:11:52,907 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-01-01 01:11:33,594 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-01-01 01:11:33,595 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | , partNumber: 1
om2_1        | 2022-01-01 01:19:41,200 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:41,236 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:43,370 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | , partNumber: 2
recon_1      | 2022-01-01 01:12:03,680 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:03,681 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:05,683 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:05,684 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:05,685 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:07,687 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-01-01 01:21:10,582 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
scm2.org_1   | 2022-01-01 01:11:33,603 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-01-01 01:11:09,482 [main] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: addNew group-CD2E3D8DB0C2:[] returns group-CD2E3D8DB0C2:java.util.concurrent.CompletableFuture@173511ff[Not completed]
scm1.org_1   | 2022-01-01 01:11:09,502 [pool-14-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10: new RaftServerImpl for group-CD2E3D8DB0C2:[] with SCMStateMachine:uninitialized
om2_1        | 2022-01-01 01:19:43,951 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:43,954 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:43,958 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:44,095 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:44,622 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:44,626 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | partName: "etag2"
scm1.org_1   | 2022-01-01 01:11:09,504 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-01-01 01:11:09,504 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
scm2.org_1   | 2022-01-01 01:11:33,603 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-01-01 01:11:33,604 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-01-01 01:11:33,611 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-01-01 01:11:33,612 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-01-01 01:11:33,613 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-01-01 01:11:34,230 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-01-01 01:11:34,232 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
recon_1      | 2022-01-01 01:12:07,691 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:07,692 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:09,700 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:09,700 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:09,701 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:11,702 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-01-01 01:11:09,504 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-01-01 01:11:09,505 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om1_1        | ]
om1_1        | 2022-01-01 01:21:10,069 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
scm1.org_1   | 2022-01-01 01:11:09,505 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-01-01 01:19:44,635 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:44,647 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:45,175 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:11:34,233 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-01-01 01:11:34,248 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
scm1.org_1   | 2022-01-01 01:11:09,505 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-01-01 01:11:34,258 [main] INFO server.RaftServer: 763bf6f7-3694-4790-8e44-c4f88a97de1a: addNew group-CD2E3D8DB0C2:[] returns group-CD2E3D8DB0C2:java.util.concurrent.CompletableFuture@6df11e91[Not completed]
scm2.org_1   | 2022-01-01 01:11:34,278 [pool-14-thread-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a: new RaftServerImpl for group-CD2E3D8DB0C2:[] with SCMStateMachine:uninitialized
om2_1        | 2022-01-01 01:19:45,178 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:45,180 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:45,184 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:45,641 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:52,907 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-01-01 01:11:52,908 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-01-01 01:11:09,506 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-01-01 01:11:09,510 [pool-14-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-01-01 01:11:09,511 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
recon_1      | 2022-01-01 01:12:11,705 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:11,710 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:13,715 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:13,718 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:13,718 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
recon_1      | 2022-01-01 01:12:15,721 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:15,722 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:15,723 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:17,724 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm2.org_1   | 2022-01-01 01:11:34,281 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-01-01 01:11:34,281 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-01-01 01:11:52,912 [pool-14-thread-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-01-01 01:11:52,912 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-01-01 01:11:52,916 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-01-01 01:19:45,643 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om3_1        | 2022-01-01 01:21:14,118 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm2.org_1   | 2022-01-01 01:11:34,282 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-01-01 01:11:09,513 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-01-01 01:11:09,513 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-01-01 01:11:09,521 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/in_use.lock acquired by nodename 7@scm1.org
om2_1        | 2022-01-01 01:19:45,648 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm3.org_1   | 2022-01-01 01:11:52,917 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-01-01 01:11:52,918 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 does not exist. Creating ...
scm3.org_1   | 2022-01-01 01:11:52,939 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/in_use.lock acquired by nodename 8@scm3.org
scm3.org_1   | 2022-01-01 01:11:52,965 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 has been successfully formatted.
om2_1        | 2022-01-01 01:19:45,652 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:46,163 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:46,166 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:46,172 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:48,795 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm3.org_1   | 2022-01-01 01:11:52,969 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-01-01 01:11:09,526 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=1214e676-068e-4ac1-9115-7b01b3dcff10} from /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/raft-meta
scm1.org_1   | 2022-01-01 01:11:09,564 [pool-14-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 0: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 2022-01-01 01:11:52,970 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-01-01 01:11:52,977 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
recon_1      | 2022-01-01 01:12:17,725 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:17,726 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:19,727 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:19,728 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:19,729 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:34,282 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-01-01 01:11:34,282 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-01-01 01:11:34,282 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-01-01 01:11:34,284 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:10,584 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 2022-01-01 01:11:09,565 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-01-01 01:11:09,566 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-01-01 01:11:09,572 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-01-01 01:11:09,573 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:11:09,594 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2022-01-01 01:11:34,288 [pool-14-thread-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-01-01 01:11:34,289 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-01-01 01:11:34,294 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-01-01 01:11:34,298 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-01-01 01:11:34,300 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 does not exist. Creating ...
om2_1        | 2022-01-01 01:19:49,355 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:49,358 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | partName: "etag2"
om1_1        | ]
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-01-01 01:11:34,318 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/in_use.lock acquired by nodename 8@scm2.org
scm2.org_1   | 2022-01-01 01:11:34,333 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2 has been successfully formatted.
scm2.org_1   | 2022-01-01 01:11:34,341 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om1_1        | 2022-01-01 01:21:10,586 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
scm1.org_1   | 2022-01-01 01:11:09,604 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-01-01 01:11:09,604 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-01-01 01:11:09,610 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm1.org_1   | 2022-01-01 01:11:09,610 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-01-01 01:11:09,611 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-01-01 01:11:09,612 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-01-01 01:11:09,612 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:14,673 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
recon_1      | 2022-01-01 01:12:21,730 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:21,731 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:21,732 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:23,734 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:23,735 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:23,736 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2022-01-01 01:11:09,612 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-01-01 01:11:09,614 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-01-01 01:11:09,614 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1      | 2022-01-01 01:12:25,737 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:25,738 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:25,742 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:27,743 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:27,746 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:27,748 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:29,754 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:29,755 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:29,756 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:31,759 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:31,760 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:31,762 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:33,765 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:33,768 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:33,769 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:35,777 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:35,778 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:35,779 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:37,781 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:37,783 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:37,785 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2022-01-01 01:11:52,977 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-01-01 01:19:49,375 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:49,379 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:53,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38026
scm2.org_1   | 2022-01-01 01:11:34,344 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-01-01 01:11:34,358 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-2
scm3.org_1   | 2022-01-01 01:11:53,011 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-01-01 01:11:53,027 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-01-01 01:11:53,029 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
recon_1      | 2022-01-01 01:12:39,787 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:39,789 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:39,792 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:15,210 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3
om3_1        | 2022-01-01 01:21:15,211 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
scm3.org_1   | 2022-01-01 01:11:53,045 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm3.org_1   | 2022-01-01 01:11:53,046 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
recon_1      | 2022-01-01 01:12:41,793 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:41,794 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
om2_1        | 2022-01-01 01:19:53,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:19:55,799 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:55,803 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:11:34,358 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-01-01 01:11:34,382 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-01-01 01:11:34,393 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-01-01 01:11:34,393 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-01-01 01:11:34,399 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm2.org_1   | 2022-01-01 01:11:34,400 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-01-01 01:11:34,401 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-01-01 01:11:34,402 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-01-01 01:11:34,403 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-01-01 01:11:34,404 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-01-01 01:11:34,407 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-01-01 01:11:34,408 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-01-01 01:11:34,408 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-01-01 01:11:34,419 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-01-01 01:11:34,419 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-01-01 01:11:34,432 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-01-01 01:11:34,434 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-01-01 01:11:34,439 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-01-01 01:11:34,439 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-01-01 01:11:34,441 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-01-01 01:11:34,442 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-01-01 01:11:34,443 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-01-01 01:11:34,445 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-01-01 01:11:34,482 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-01-01 01:11:34,483 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-01-01 01:11:34,483 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-01-01 01:11:34,716 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-01-01 01:11:34,716 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-01-01 01:11:34,719 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-01-01 01:11:34,721 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-01-01 01:11:34,770 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-01-01 01:11:34,781 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-01-01 01:11:34,789 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-01-01 01:11:34,846 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:14,108 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
scm3.org_1   | 2022-01-01 01:11:53,047 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm2.org_1   | 2022-01-01 01:11:34,853 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-01-01 01:11:34,854 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-01-01 01:11:34,887 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-01-01 01:11:34,903 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-01-01 01:11:34,931 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-01-01 01:11:53,049 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-01-01 01:11:53,052 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-01-01 01:11:53,054 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-01-01 01:11:53,056 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2022-01-01 01:21:18,760 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0888265347/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-7365940470
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-7365940470key: ozone-test-0888265347/multipartKey5
scm3.org_1   | 2022-01-01 01:11:53,059 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-01-01 01:11:53,059 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-01-01 01:11:53,086 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-01-01 01:11:53,091 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-01-01 01:11:53,111 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-01-01 01:11:53,112 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:20:32,294 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8908033537, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
scm1.org_1   | 2022-01-01 01:11:09,614 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-01-01 01:11:09,623 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-01-01 01:11:09,624 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-01-01 01:11:09,645 [pool-14-thread-1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 0: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-01-01 01:11:09,646 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_0
scm1.org_1   | 2022-01-01 01:11:09,648 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:09,649 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-01-01 01:11:53,140 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-01-01 01:11:53,141 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-01-01 01:11:09,730 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-1
om2_1        | 2022-01-01 01:19:56,424 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:12:41,795 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:43,797 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm1.org_1   | 2022-01-01 01:11:09,731 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-01-01 01:11:34,934 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
om2_1        | 2022-01-01 01:19:56,428 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:56,475 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:56,479 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:56,483 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:53,142 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-01-01 01:11:53,143 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-01-01 01:11:53,144 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-01-01 01:11:53,150 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-01-01 01:11:53,224 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
s3g_1        | 2022-01-01 01:20:32,306 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8908033537
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm3.org_1   | 2022-01-01 01:11:53,224 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-01-01 01:11:53,224 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-01-01 01:11:53,789 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-01-01 01:11:53,790 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-01-01 01:11:53,812 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-01-01 01:11:53,817 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
s3g_1        | 2022-01-01 01:20:32,788 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3563673165, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:32,806 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3563673165
s3g_1        | 2022-01-01 01:20:33,803 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
om2_1        | 2022-01-01 01:19:59,150 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:59,192 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:59,199 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:59,204 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-01-01 01:11:09,731 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-01-01 01:11:09,732 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-01-01 01:11:09,733 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>nosuchbucket-ozone-test-9804720151</Resource>
recon_1      | 2022-01-01 01:12:43,812 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:43,821 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:45,829 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:45,831 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:45,832 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:47,833 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:47,839 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:47,840 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:49,841 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:49,842 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:49,842 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:51,846 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-01-01 01:11:09,734 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-01-01 01:11:09,770 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-01-01 01:11:09,770 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-01-01 01:11:09,771 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-01-01 01:11:10,042 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-01-01 01:11:10,043 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-01-01 01:11:10,046 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
om2_1        | 2022-01-01 01:19:59,362 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:14,670 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-2
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm3.org_1   | 2022-01-01 01:11:53,909 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-01-01 01:11:53,919 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om2_1        | 2022-01-01 01:19:59,406 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:59,415 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:19:59,418 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,018 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,062 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,066 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,074 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,287 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:53,928 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-01-01 01:11:53,995 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-01-01 01:11:54,024 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-01-01 01:11:54,024 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-01-01 01:11:54,149 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm1.org_1   | 2022-01-01 01:11:10,050 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-01-01 01:11:10,105 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-01-01 01:11:10,139 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-01-01 01:11:10,151 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-01-01 01:11:34,946 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-01-01 01:11:54,190 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-01-01 01:11:54,251 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-01-01 01:11:54,262 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-01-01 01:11:54,282 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 2022-01-01 01:20:02,292 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:12:51,847 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:51,848 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-01-01 01:11:34,947 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm2.org_1   | 2022-01-01 01:11:34,954 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:11:34,956 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-01-01 01:11:34,994 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-01-01 01:11:35,026 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-01-01 01:11:35,104 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-01-01 01:12:53,849 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-01-01 01:11:10,192 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 2022-01-01 01:20:02,297 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,338 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,342 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,346 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2022-01-01 01:11:10,205 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-01-01 01:11:10,205 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-01-01 01:11:10,255 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-01-01 01:11:10,281 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-01-01 01:11:10,311 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:15,213 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3
om1_1        | 2022-01-01 01:21:15,217 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
scm3.org_1   | 2022-01-01 01:11:54,306 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-01-01 01:11:54,312 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:11:54,327 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-01-01 01:11:54,430 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-01-01 01:11:54,501 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-01-01 01:11:54,587 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-01-01 01:11:56,218 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-01-01 01:11:56,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm2.org_1   | 2022-01-01 01:11:36,059 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-01-01 01:11:36,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-01-01 01:11:36,103 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-01-01 01:11:36,110 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-01-01 01:11:36,157 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-01-01 01:11:36,162 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
recon_1      | 2022-01-01 01:12:53,850 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:53,851 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 140 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:55,852 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 141 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:55,853 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 142 failover attempts. Trying to failover immediately.
om3_1        | 2022-01-01 01:21:19,273 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-7365940470, Key:ozone-test-0441595465/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om2_1        | 2022-01-01 01:20:02,376 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:02,378 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
scm1.org_1   | 2022-01-01 01:11:10,318 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-01-01 01:11:10,328 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 0 containers.
scm1.org_1   | 2022-01-01 01:11:10,340 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-01-01 01:11:10,344 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:11:10,346 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om2_1        | 2022-01-01 01:20:03,357 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:03,799 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:03,875 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:03,880 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:03,919 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,037 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,049 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,053 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1      | 2022-01-01 01:12:55,854 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 143 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-01-01 01:11:56,296 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-01-01 01:11:56,306 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-01-01 01:11:56,370 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-01-01 01:11:56,372 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-01-01 01:11:56,582 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-01-01 01:11:56,615 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
recon_1      | 2022-01-01 01:12:56,267 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58606
recon_1      | 2022-01-01 01:12:56,308 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-01-01 01:11:36,283 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-01-01 01:11:36,314 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm1.org_1   | 2022-01-01 01:11:10,388 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-01-01 01:11:10,396 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-01-01 01:11:10,397 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 857524461429 on primary SCM
scm1.org_1   | 2022-01-01 01:11:10,406 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-01-01 01:11:10,448 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-01-01 01:11:10,503 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-01-01 01:11:11,245 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-01-01 01:11:11,252 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-01-01 01:11:11,276 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-01-01 01:11:11,277 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | 2022-01-01 01:12:57,871 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 144 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm3.org_1   | Threshold                                          0.1
scm3.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
om2_1        | 2022-01-01 01:20:04,174 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,188 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
recon_1      | 2022-01-01 01:12:57,873 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 145 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:57,886 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 146 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:12:57,889 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55096
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | Threshold                                          0.1
scm2.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
om2_1        | 2022-01-01 01:20:04,196 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,230 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:12:58,011 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:12:58,423 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46106
recon_1      | 2022-01-01 01:12:58,543 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:12:59,888 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 147 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:59,895 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 148 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:12:59,899 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 149 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:00,151 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/75beef28-1584-4115-9505-884f6f5c519b
recon_1      | 2022-01-01 01:13:00,189 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om2_1        | 2022-01-01 01:20:04,305 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:11,331 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-01-01 01:11:11,339 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | Max Size to Move per Iteration                     30GB
scm2.org_1   | Max Size to Move per Iteration                     30GB
om1_1        | 2022-01-01 01:21:18,760 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0888265347/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-7365940470
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om2_1        | 2022-01-01 01:20:04,318 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,327 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:04,351 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-01-01 01:11:36,314 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-01-01 01:11:36,315 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-7365940470key: ozone-test-0888265347/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2022-01-01 01:11:11,505 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-01-01 01:11:11,519 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-01-01 01:11:56,616 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-01-01 01:11:56,616 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om2_1        | 2022-01-01 01:20:07,704 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,704 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,765 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,768 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,773 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,815 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,819 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,864 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,872 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,886 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,918 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,920 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,929 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,944 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:13:00,360 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 75beef28-1584-4115-9505-884f6f5c519b to Node DB.
recon_1      | 2022-01-01 01:13:00,456 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/458bfdff-96fb-4b4a-96de-6879eec60ac8
recon_1      | 2022-01-01 01:13:00,458 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | Container Balancer Configuration values:
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm2.org_1   | 2022-01-01 01:11:36,323 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-01-01 01:11:36,330 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-01-01 01:11:36,331 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-01-01 01:11:36,340 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-01-01 01:11:36,341 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD2E3D8DB0C2,id=763bf6f7-3694-4790-8e44-c4f88a97de1a
scm2.org_1   | 2022-01-01 01:11:36,362 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 763bf6f7-3694-4790-8e44-c4f88a97de1a: start RPC server
scm2.org_1   | 2022-01-01 01:11:36,460 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: GrpcService started, listening on 9894
scm2.org_1   | 2022-01-01 01:11:36,477 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052f440@507187c1] INFO util.JvmPauseMonitor: JvmPauseMonitor-763bf6f7-3694-4790-8e44-c4f88a97de1a: Started
scm2.org_1   | 2022-01-01 01:11:36,478 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:36,480 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:36,480 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:38,329 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:38,347 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-01-01 01:11:38,347 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: change Leader from null to 1214e676-068e-4ac1-9115-7b01b3dcff10 at term 2 for installSnapshot, leader elected after 4006ms
scm2.org_1   | 2022-01-01 01:11:38,350 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Received notification to install snapshot at index 4
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:21:19,262 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-7365940470, Key:ozone-test-0441595465/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm3.org_1   | 2022-01-01 01:11:56,627 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-01-01 01:11:56,633 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
recon_1      | 2022-01-01 01:13:00,493 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 458bfdff-96fb-4b4a-96de-6879eec60ac8 to Node DB.
recon_1      | 2022-01-01 01:13:01,770 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          0.1
scm3.org_1   | 2022-01-01 01:11:56,633 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-01-01 01:11:56,635 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-01-01 01:11:56,638 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD2E3D8DB0C2,id=f44d6013-5a2d-49ef-9eb3-f2fb3659b167
scm3.org_1   | 2022-01-01 01:11:56,666 [Listener at 0.0.0.0/9860] INFO server.RaftServer: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: start RPC server
scm3.org_1   | 2022-01-01 01:11:56,757 [Listener at 0.0.0.0/9860] INFO server.GrpcService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: GrpcService started, listening on 9894
scm3.org_1   | 2022-01-01 01:11:56,775 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052fc40@193d73d3] INFO util.JvmPauseMonitor: JvmPauseMonitor-f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Started
scm3.org_1   | 2022-01-01 01:11:56,803 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
recon_1      | 2022-01-01 01:13:01,800 [IPC Server handler 14 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/24732aa1-1492-41aa-844a-173d185ef1c3
recon_1      | 2022-01-01 01:13:01,805 [IPC Server handler 14 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:01,851 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 24732aa1-1492-41aa-844a-173d185ef1c3 to Node DB.
recon_1      | 2022-01-01 01:13:01,904 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 150 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:01,908 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 151 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:01,920 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 152 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:02,320 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-01-01 01:13:03,426 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-01-01 01:13:03,928 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 153 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:03,929 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 154 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:03,930 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 155 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:04,988 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-01-01 01:13:04,992 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac. Trying to get from SCM.
scm1.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
scm1.org_1   | Max Size to Move per Iteration                     30GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-01-01 01:11:11,520 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-01-01 01:11:11,520 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-01-01 01:11:11,524 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-01-01 01:11:11,525 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-01-01 01:11:11,526 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: start as a follower, conf=0: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-01-01 01:11:11,527 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-01-01 01:11:11,528 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState
scm1.org_1   | 2022-01-01 01:11:11,530 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD2E3D8DB0C2,id=1214e676-068e-4ac1-9115-7b01b3dcff10
scm1.org_1   | 2022-01-01 01:11:11,532 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 1214e676-068e-4ac1-9115-7b01b3dcff10: start RPC server
scm1.org_1   | 2022-01-01 01:11:11,585 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 1214e676-068e-4ac1-9115-7b01b3dcff10: GrpcService started, listening on 9894
scm1.org_1   | 2022-01-01 01:11:11,589 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-01-01 01:11:11,589 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-01-01 01:11:11,593 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
om2_1        | 2022-01-01 01:20:07,985 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,988 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:07,994 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,168 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,211 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,224 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,229 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,291 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,297 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,300 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,323 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:11:56,803 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 2022-01-01 01:13:05,292 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]] to Recon pipeline metadata.
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
scm3.org_1   | 2022-01-01 01:11:56,803 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2022-01-01 01:22:15,762 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48492
om1_1        | 2022-01-01 01:22:15,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:22:31,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48584
om1_1        | 2022-01-01 01:22:31,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:22:50,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48686
om1_1        | 2022-01-01 01:22:50,755 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:28:01,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49482
om1_1        | 2022-01-01 01:28:01,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-01-01 01:30:27,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49910
om1_1        | 2022-01-01 01:30:27,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-01-01 01:12:04,325 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm2.org_1   | 2022-01-01 01:11:38,410 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 4.
scm2.org_1   | 2022-01-01 01:11:38,410 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:38,440 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm2.org_1   | 2022-01-01 01:11:39,755 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
recon_1      | 2022-01-01 01:13:05,459 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]].
recon_1      | 2022-01-01 01:13:05,499 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 135716.725us
scm3.org_1   | 2022-01-01 01:12:04,344 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-01-01 01:12:04,351 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: change Leader from null to 1214e676-068e-4ac1-9115-7b01b3dcff10 at term 2 for installSnapshot, leader elected after 11375ms
scm3.org_1   | 2022-01-01 01:12:04,363 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Received notification to install snapshot at index 10
recon_1      | 2022-01-01 01:13:05,509 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac reported by 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:05,515 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]] moved to OPEN state
recon_1      | 2022-01-01 01:13:05,538 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 5657.272us
recon_1      | 2022-01-01 01:13:05,938 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 156 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:05,939 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 157 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:05,940 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 158 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:06,418 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e5481fd7-e475-47a4-9362-f8541548c104. Trying to get from SCM.
recon_1      | 2022-01-01 01:13:06,427 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-01-01 01:13:06,429 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]].
om2_1        | 2022-01-01 01:20:08,327 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,331 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,404 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,661 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,666 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:11,593 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-01-01 01:11:11,598 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$439/0x0000000840547c40@1bb3e150] INFO util.JvmPauseMonitor: JvmPauseMonitor-1214e676-068e-4ac1-9115-7b01b3dcff10: Started
scm1.org_1   | 2022-01-01 01:11:11,685 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-01-01 01:11:11,696 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-01-01 01:11:11,696 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-01-01 01:11:11,936 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-01-01 01:11:11,937 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-01-01 01:11:11,958 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-01-01 01:11:11,983 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-01-01 01:11:11,985 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-01-01 01:11:11,986 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-01-01 01:11:11,986 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-01-01 01:11:12,024 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-01-01 01:11:12,049 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-01-01 01:11:12,050 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-01-01 01:11:12,050 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-01-01 01:11:12,125 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d0456ad] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-01-01 01:11:12,147 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-01-01 01:11:12,147 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-01-01 01:12:04,535 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 10.
scm3.org_1   | 2022-01-01 01:12:04,559 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:04,610 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm3.org_1   | 2022-01-01 01:12:07,227 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
om2_1        | 2022-01-01 01:20:08,673 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,692 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,734 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,736 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,739 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,767 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,771 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,773 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,805 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,812 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,818 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,842 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,846 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,851 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,876 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:39,764 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 2022-01-01 01:13:06,438 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 11273.243us
recon_1      | 2022-01-01 01:13:06,441 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 reported by 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:07,941 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 159 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:07,942 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 160 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:07,946 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 161 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:09,947 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 162 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:09,949 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 163 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:09,949 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 164 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:11,423 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 reported by 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm2.org_1   | 2022-01-01 01:11:39,765 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t0,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:39,779 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:39,846 [grpc-default-executor-0] INFO impl.RoleInfo: 763bf6f7-3694-4790-8e44-c4f88a97de1a: start 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-FollowerState
scm2.org_1   | 2022-01-01 01:11:39,862 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:39,865 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:39,893 [grpc-default-executor-0] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1640999498440.tar.gz
scm2.org_1   | 2022-01-01 01:11:39,920 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm3.org_1   |   }
scm3.org_1   | }
scm2.org_1   | 2022-01-01 01:11:39,926 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:07,270 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:07,274 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t0,IN_PROGRESS
scm3.org_1   | 2022-01-01 01:12:07,336 [grpc-default-executor-1] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1640999524614.tar.gz
scm3.org_1   | 2022-01-01 01:12:07,356 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,536 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,565 [grpc-default-executor-0] INFO impl.RoleInfo: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: start f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-FollowerState
scm3.org_1   | 2022-01-01 01:12:07,574 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-01-01 01:12:07,599 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-01-01 01:12:07,612 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   | configurationEntry {
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm1.org_1   | 2022-01-01 01:11:12,148 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-01-01 01:11:12,178 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6978ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-01-01 01:20:08,881 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:08,884 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:09,043 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,819 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:13:11,880 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-01-01 01:13:11,881 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 reported by 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-01-01 01:11:12,266 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
om2_1        | 2022-01-01 01:20:12,865 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,877 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm2.org_1   |   peers {
recon_1      | 2022-01-01 01:13:11,951 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 165 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:11,951 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 166 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-01-01 01:11:12,271 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:39,926 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:39,926 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:39,927 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:39,954 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1640999498440
scm2.org_1   | 2022-01-01 01:11:39,956 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1640999498440
scm2.org_1   | 2022-01-01 01:11:40,006 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,007 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,007 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,010 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2022-01-01 01:11:12,273 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-01-01 01:11:12,273 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-01-01 01:11:12,273 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | configurationEntry {
scm3.org_1   |   peers {
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 2022-01-01 01:13:11,952 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 167 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:13,826 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 reported by 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:13,953 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 168 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:13,954 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 169 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:13,955 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 170 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:15,956 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 171 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:15,957 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 172 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:15,958 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 173 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:16,089 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46152
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
recon_1      | 2022-01-01 01:13:16,135 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:13:16,137 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
om2_1        | 2022-01-01 01:20:12,880 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,905 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,907 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:12,275 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-01-01 01:11:12,308 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-01-01 01:11:12,309 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm1.org_1   | 2022-01-01 01:11:12,334 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-01-01 01:11:12,334 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-01-01 01:20:12,909 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:13:16,138 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 reported by 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm1.org_1   | 2022-01-01 01:11:12,335 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm1.org_1   | 2022-01-01 01:11:12,350 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om2_1        | 2022-01-01 01:20:12,919 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,922 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
scm3.org_1   |   }
scm3.org_1   | }
om2_1        | 2022-01-01 01:20:12,924 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:12,997 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:16,633 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:16,688 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:20:39,983 [qtp1677568775-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2828688019, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:39,998 [qtp1677568775-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2828688019
s3g_1        | 2022-01-01 01:20:40,991 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
recon_1      | 2022-01-01 01:13:16,138 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] moved to OPEN state
recon_1      | 2022-01-01 01:13:16,140 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 713.021us
om2_1        | 2022-01-01 01:20:16,691 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:16,694 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:20,863 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38126
scm2.org_1   |   peers {
scm1.org_1   | 2022-01-01 01:11:12,358 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fb3c930{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-01-01 01:11:12,359 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@25d6ae3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-01-01 01:13:17,089 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b. Trying to get from SCM.
recon_1      | 2022-01-01 01:13:17,193 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]] to Recon pipeline metadata.
scm3.org_1   |  from snapshot
scm1.org_1   | 2022-01-01 01:11:12,490 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-01-01 01:11:12,500 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6965c32{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-18159482441198286300/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-01-01 01:11:12,512 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@2199e1a4{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-01-01 01:11:12,512 [Listener at 0.0.0.0/9860] INFO server.Server: Started @7315ms
scm1.org_1   | 2022-01-01 01:11:12,514 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
recon_1      | 2022-01-01 01:13:17,206 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]].
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
recon_1      | 2022-01-01 01:13:17,217 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 23247.399us
om2_1        | 2022-01-01 01:20:20,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:20:23,393 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,014 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,021 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
recon_1      | 2022-01-01 01:13:17,217 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:17,959 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 174 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:17,961 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 175 failover attempts. Trying to failover immediately.
om2_1        | 2022-01-01 01:20:23,395 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:23,927 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:23,935 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        |   <Resource>ozonenosuchbucketqqweqwe-ozone-test-3438760966</Resource>
scm2.org_1   | 2022-01-01 01:11:40,022 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,038 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm3.org_1   | 2022-01-01 01:12:07,615 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:07,649 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1640999524614
scm3.org_1   | 2022-01-01 01:12:07,650 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
recon_1      | 2022-01-01 01:13:17,961 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 176 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:18,451 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-01-01 01:11:12,514 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-01-01 01:11:12,516 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-01-01 01:11:13,893 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46691
scm1.org_1   | 2022-01-01 01:11:13,913 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2022-01-01 01:20:24,440 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:24,442 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:24,931 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:11:40,041 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm1.org_1   | 2022-01-01 01:11:14,796 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41378
scm1.org_1   | 2022-01-01 01:11:14,810 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        |   <RequestId/>
s3g_1        | </Error>
scm3.org_1   | 2022-01-01 01:12:07,654 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1640999524614
scm3.org_1   | 2022-01-01 01:12:07,680 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,727 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
recon_1      | 2022-01-01 01:13:19,440 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:19,963 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 177 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:19,964 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 178 failover attempts. Trying to failover immediately.
om2_1        | 2022-01-01 01:20:24,936 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:24,944 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-4320353850 in volume:s3v
scm1.org_1   | 2022-01-01 01:11:15,269 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58192
scm1.org_1   | 2022-01-01 01:11:15,291 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:11:16,677 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.FollowerState: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5149532903ns, electionTimeout:5145ms
scm1.org_1   | 2022-01-01 01:11:16,680 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState
scm2.org_1   | 2022-01-01 01:11:40,044 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,045 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm3.org_1   | 2022-01-01 01:12:07,727 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
recon_1      | 2022-01-01 01:13:19,965 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 179 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-01-01 01:13:21,966 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 180 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:28,153 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm1.org_1   | 2022-01-01 01:11:16,682 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-01-01 01:11:16,685 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-01-01 01:11:16,687 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-FollowerState] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1
scm1.org_1   | 2022-01-01 01:11:16,703 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.LeaderElection: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
scm3.org_1   |   }
scm3.org_1   |   peers {
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm1.org_1   | 2022-01-01 01:11:16,704 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.LeaderElection: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1 ELECTION round 0: result PASSED (term=2)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:20:25,424 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:29,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38160
scm2.org_1   | 2022-01-01 01:11:40,047 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,047 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2022-01-01 01:11:16,705 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: shutdown 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:07,731 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2022-01-01 01:12:07,734 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 2022-01-01 01:11:16,705 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm2.org_1   | 2022-01-01 01:11:40,049 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,077 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,077 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,078 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:16,705 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-01-01 01:11:16,705 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
om2_1        | 2022-01-01 01:20:29,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-01-01 01:12:07,735 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm2.org_1   | 2022-01-01 01:11:40,081 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om2_1        | 2022-01-01 01:20:32,292 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:32,295 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:12:07,746 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   | 2022-01-01 01:12:07,747 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
om2_1        | 2022-01-01 01:20:32,786 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2022-01-01 01:11:16,709 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: change Leader from null to 1214e676-068e-4ac1-9115-7b01b3dcff10 at term 2 for becomeLeader, leader elected after 7141ms
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2022-01-01 01:12:07,772 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
om2_1        | 2022-01-01 01:20:32,789 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:33,291 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:33,295 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:33,786 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:33,788 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:33,795 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9804720151 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 181 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm1.org_1   | 2022-01-01 01:11:16,715 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-01-01 01:11:16,720 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm3.org_1   | 2022-01-01 01:12:07,781 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-01-01 01:12:07,782 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm3.org_1   | 2022-01-01 01:12:07,789 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,083 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,084 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,105 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,119 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,119 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,122 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,124 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm1.org_1   | 2022-01-01 01:11:16,720 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-01-01 01:11:16,725 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-01-01 01:11:16,725 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-01-01 01:11:16,726 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-01-01 01:11:16,730 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-01-01 01:11:16,732 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
recon_1      | 2022-01-01 01:13:31,525 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 2022-01-01 01:11:16,734 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO impl.RoleInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10: start 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl
scm1.org_1   | 2022-01-01 01:11:16,741 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-01-01 01:11:16,745 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_0 to /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_0-0
scm1.org_1   | 2022-01-01 01:11:16,750 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderElection1] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm1.org_1   | 2022-01-01 01:11:16,767 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_1
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm3.org_1   | 2022-01-01 01:12:07,790 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,125 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,126 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,127 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,165 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,166 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,165 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,170 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm3.org_1   | 2022-01-01 01:12:07,790 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm2.org_1   |  from snapshot
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-01-01 01:11:16,772 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm3.org_1   | 2022-01-01 01:12:07,813 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm2.org_1   | 2022-01-01 01:11:40,174 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,175 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,176 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 2022-01-01 01:11:16,772 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2022-01-01 01:11:16,774 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:11:16,775 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-01-01 01:11:16,777 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 182 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2022-01-01 01:11:16,778 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-01-01 01:11:16,782 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-01-01 01:11:16,782 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:20:36,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41633
om2_1        | 2022-01-01 01:20:36,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:20:37,338 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38184
om2_1        | 2022-01-01 01:20:37,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:20:39,981 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:39,984 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:40,496 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:40,501 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:40,988 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:40,990 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:44,678 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38204
scm1.org_1   | 2022-01-01 01:11:24,324 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:51898
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm1.org_1   | 2022-01-01 01:11:24,334 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:11:24,459 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 763bf6f7-3694-4790-8e44-c4f88a97de1a
scm1.org_1   | 2022-01-01 01:11:26,281 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:11:26,282 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-01-01 01:13:32,764 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46216
recon_1      | 2022-01-01 01:13:32,859 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-01-01 01:12:07,860 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-01-01 01:12:07,860 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,200 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm1.org_1   | 2022-01-01 01:11:26,282 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm3.org_1   | 2022-01-01 01:12:07,875 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,875 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm2.org_1   | 2022-01-01 01:11:40,201 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,207 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,208 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
recon_1      | 2022-01-01 01:13:32,860 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c4e544bd-06bc-4975-8f23-ab6694bd9221. Trying to get from SCM.
recon_1      | 2022-01-01 01:13:32,944 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]] to Recon pipeline metadata.
scm3.org_1   | configurationEntry {
scm1.org_1   | 2022-01-01 01:11:26,292 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 1282069.007us
scm1.org_1   | 2022-01-01 01:11:32,923 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58472
scm1.org_1   | 2022-01-01 01:11:32,983 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:11:37,053 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41726
scm1.org_1   | 2022-01-01 01:11:37,136 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:11:37,138 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: 1214e676-068e-4ac1-9115-7b01b3dcff10: Submitting SetConfiguration request to Ratis server with new SCM peers list: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:11:37,140 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: receive setConfiguration SetConfigurationRequest:client-ED070E95D10F->1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2, cid=0, seq=0, RW, null, peers:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:11:37,140 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-ED070E95D10F->1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2, cid=0, seq=0, RW, null, peers:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:11:37,152 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-01-01 01:20:44,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:20:47,183 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:47,188 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:47,699 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:47,702 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:47,706 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
om2_1        | 2022-01-01 01:20:51,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38254
om2_1        | 2022-01-01 01:20:51,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:20:54,121 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:54,124 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:54,653 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:54,655 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:13:32,946 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]].
recon_1      | 2022-01-01 01:13:32,946 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 1671.149us
recon_1      | 2022-01-01 01:13:32,947 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=c4e544bd-06bc-4975-8f23-ab6694bd9221 reported by 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:32,947 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]] moved to OPEN state
recon_1      | 2022-01-01 01:13:32,948 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 901.026us
recon_1      | 2022-01-01 01:13:32,949 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm3.org_1   |   }
scm3.org_1   |   peers {
om2_1        | 2022-01-01 01:20:54,657 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:37,152 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:11:37,152 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-01-01 01:11:37,169 [IPC Server handler 1 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm2.org_1   | 2022-01-01 01:11:40,213 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,213 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,214 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,233 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 2022-01-01 01:13:33,049 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58740
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm1.org_1   | 2022-01-01 01:11:37,170 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-01-01 01:11:37,170 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om2_1        | 2022-01-01 01:20:55,231 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,234 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,238 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,898 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,903 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,905 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:55,922 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:11:40,233 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm1.org_1   | 2022-01-01 01:11:37,207 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:37,229 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:07,875 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:07,876 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
recon_1      | 2022-01-01 01:13:33,083 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-01-01 01:11:40,234 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,235 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
recon_1      | 2022-01-01 01:13:33,088 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d83b488f-4512-497f-b5fa-ced3ca6a01ac. Trying to get from SCM.
recon_1      | 2022-01-01 01:13:33,125 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-01-01 01:13:33,126 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]].
recon_1      | 2022-01-01 01:13:33,127 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 1186.435us
recon_1      | 2022-01-01 01:13:33,127 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d83b488f-4512-497f-b5fa-ced3ca6a01ac reported by 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:33,127 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:458bfdff-96fb-4b4a-96de-6879eec60ac8, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]] moved to OPEN state
recon_1      | 2022-01-01 01:13:33,128 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 339.91us
recon_1      | 2022-01-01 01:13:33,128 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-01-01 01:12:07,883 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,923 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm1.org_1   | 2022-01-01 01:11:39,596 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-01-01 01:11:39,662 [grpc-default-executor-0] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1640999499608 in 53 milliseconds
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om2_1        | 2022-01-01 01:20:58,858 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:59,451 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:59,453 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:20:59,456 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:39,794 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received the first reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t0,IN_PROGRESS
recon_1      | 2022-01-01 01:13:34,822 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,236 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-01-01 01:11:39,805 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm2.org_1   | 2022-01-01 01:11:40,242 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:39,827 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
om2_1        | 2022-01-01 01:20:59,475 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
scm2.org_1   | 2022-01-01 01:11:40,244 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,260 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,260 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,264 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,269 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,269 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,270 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,271 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,285 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | 2022-01-01 01:11:39,830 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:39,833 [grpc-default-executor-0] INFO ha.SCMGrpcOutputStream: Sent 7517 bytes for cluster CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm1.org_1   | 2022-01-01 01:11:39,883 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 212 milliseconds
scm1.org_1   | 2022-01-01 01:11:39,891 [grpc-default-executor-0] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1640999499608
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
scm3.org_1   | 2022-01-01 01:12:07,923 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-01-01 01:12:07,924 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,924 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:07,924 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:07,925 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-01-01 01:12:07,940 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:07,961 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-01-01 01:12:07,972 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm1.org_1   | 2022-01-01 01:11:39,893 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:39,984 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:39,988 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 183 failover attempts. Trying to failover immediately.
recon_1      | 2022-01-01 01:13:36,239 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
om2_1        | 2022-01-01 01:21:00,006 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2022-01-01 01:11:39,989 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:39,994 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,028 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,034 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,027 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,036 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,037 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,051 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,061 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,065 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,066 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,067 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm2.org_1   | 2022-01-01 01:11:40,285 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-01-01 01:11:40,288 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-01-01 01:11:40,288 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   | 2022-01-01 01:12:07,982 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm3.org_1   | 2022-01-01 01:12:08,026 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm1.org_1   | 2022-01-01 01:11:40,080 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,098 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | }
om2_1        | 2022-01-01 01:21:00,523 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:00,524 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
scm1.org_1   | 2022-01-01 01:11:40,099 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,110 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,114 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,123 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,131 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm3.org_1   |   peers {
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:20:40,991 [qtp1677568775-24] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:91)
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-01-01 01:11:40,290 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:40,294 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,131 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,139 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,140 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm3.org_1   | 2022-01-01 01:12:08,086 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:08,111 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2022-01-01 01:11:40,309 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm3.org_1   | 2022-01-01 01:12:08,128 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm2.org_1   | 2022-01-01 01:11:40,310 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2022-01-01 01:11:40,312 [pool-16-thread-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: StateMachine successfully installed snapshot index 4. Reloading the StateMachine.
scm2.org_1   | 2022-01-01 01:11:40,313 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 4
scm1.org_1   | 2022-01-01 01:11:40,179 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,181 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm3.org_1   | 2022-01-01 01:12:08,182 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-01-01 01:12:08,186 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-01-01 01:12:08,201 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm2.org_1   | 2022-01-01 01:11:40,326 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 4
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2022-01-01 01:11:40,182 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,184 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,190 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm3.org_1   | 2022-01-01 01:12:08,220 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm2.org_1   | 2022-01-01 01:11:40,328 [pool-16-thread-1] INFO raftlog.RaftLog: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 4
scm2.org_1   | 2022-01-01 01:11:40,348 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2022-01-01 01:11:40,350 [grpc-default-executor-0] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#10:FAIL-t2,INCONSISTENCY,nextIndex=5,followerCommit=4
om2_1        | 2022-01-01 01:21:00,529 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:40,209 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,222 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,223 [grpc-default-executor-1] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,224 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,225 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   | 2022-01-01 01:11:40,351 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om2_1        | 2022-01-01 01:21:01,178 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:40,256 [grpc-default-executor-1] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,256 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,256 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,257 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om2_1        | 2022-01-01 01:21:01,181 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm3.org_1   |     address: "scm1.org:9894"
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm3.org_1   |   }
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm1.org_1   | 2022-01-01 01:11:40,257 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,279 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,280 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,280 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,282 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2022-01-01 01:11:40,282 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm3.org_1   |   peers {
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
scm2.org_1   | 2022-01-01 01:11:40,351 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 4
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om2_1        | 2022-01-01 01:21:01,183 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm2.org_1   | 2022-01-01 01:11:40,352 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm1.org_1   | 2022-01-01 01:11:40,299 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:11:40,327 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:11:40,339 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:11:40,340 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm2.org_1   | }
scm1.org_1   | 2022-01-01 01:11:40,341 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
om2_1        | 2022-01-01 01:21:01,210 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:01,601 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:02,413 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:02,415 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:02,418 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
scm1.org_1   | 2022-01-01 01:11:40,359 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateUnconditionally 0 -> 5
om2_1        | 2022-01-01 01:21:02,457 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:02,571 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:03,167 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   |  from snapshot
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:08,230 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:08,231 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-01-01 01:12:08,245 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:08,275 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm2.org_1   | 2022-01-01 01:11:40,353 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 1: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-01-01 01:21:03,169 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:12:08,282 [pool-16-thread-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: StateMachine successfully installed snapshot index 10. Reloading the StateMachine.
scm3.org_1   | 2022-01-01 01:12:08,282 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-01-01 01:12:08,287 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 10
scm1.org_1   | 2022-01-01 01:11:40,370 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=4
scm1.org_1   | 2022-01-01 01:11:40,371 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a-InstallSnapshotResponseHandler: Follower installed snapshot at index 4
scm1.org_1   | 2022-01-01 01:11:40,371 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: snapshotIndex: setUnconditionally 0 -> 4
scm2.org_1   | 2022-01-01 01:11:40,353 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-763bf6f7-3694-4790-8e44-c4f88a97de1a#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=4
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
scm3.org_1   | 2022-01-01 01:12:08,294 [pool-16-thread-1] INFO raftlog.RaftLog: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 10
scm3.org_1   | 2022-01-01 01:12:08,312 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: Failed appendEntries as snapshot (10) installation is in progress
scm1.org_1   | 2022-01-01 01:11:40,372 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: matchIndex: setUnconditionally 0 -> 4
scm1.org_1   | 2022-01-01 01:11:40,372 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: setUnconditionally 5 -> 5
scm1.org_1   | 2022-01-01 01:11:40,372 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a acknowledged installing snapshot
scm1.org_1   | 2022-01-01 01:11:40,372 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->763bf6f7-3694-4790-8e44-c4f88a97de1a: nextIndex: updateToMax old=5, new=5, updated? false
om2_1        | 2022-01-01 01:21:03,172 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:03,717 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:03,720 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm1.org_1   | 2022-01-01 01:11:41,929 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 5: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0], old=[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-01-01 01:11:42,119 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-01-01 01:11:42,277 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 763bf6f7-3694-4790-8e44-c4f88a97de1a.
scm1.org_1   | 2022-01-01 01:11:42,614 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:46232
scm1.org_1   | 2022-01-01 01:11:42,669 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om2_1        | 2022-01-01 01:21:03,722 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:03,757 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:11:40,358 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 763bf6f7-3694-4790-8e44-c4f88a97de1a: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->763bf6f7-3694-4790-8e44-c4f88a97de1a#0-t2,notify:(t:2, i:4)
scm3.org_1   | 2022-01-01 01:12:08,318 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: inconsistency entries. Reply:1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#7:FAIL-t2,INCONSISTENCY,nextIndex=11,followerCommit=10
scm3.org_1   | 2022-01-01 01:12:08,359 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: receive installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:08,360 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 10
scm3.org_1   | 2022-01-01 01:12:08,360 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set new configuration index: 7
scm3.org_1   | configurationEntry {
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om2_1        | 2022-01-01 01:21:04,521 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:04,523 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:04,524 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,099 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,105 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,107 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm2.org_1   | 2022-01-01 01:11:40,580 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2022-01-01 01:11:40,616 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 4
scm2.org_1   | 2022-01-01 01:11:40,617 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:40,622 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-01-01 01:11:40,765 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm1.org_1   | 2022-01-01 01:11:44,531 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:52210
scm1.org_1   | 2022-01-01 01:11:44,560 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   |   peers {
scm3.org_1   |     id: "1214e676-068e-4ac1-9115-7b01b3dcff10"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "763bf6f7-3694-4790-8e44-c4f88a97de1a"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-01-01 01:12:08,360 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:08,360 [grpc-default-executor-1] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: reply installSnapshot: 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm3.org_1   | 2022-01-01 01:12:08,366 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Completed INSTALL_SNAPSHOT, lastRequest: 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:08,675 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm3.org_1   | 2022-01-01 01:12:08,736 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 10
scm3.org_1   | 2022-01-01 01:12:08,750 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
scm1.org_1   | 2022-01-01 01:11:45,811 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:33724
scm1.org_1   | 2022-01-01 01:11:45,818 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:11:45,821 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: f44d6013-5a2d-49ef-9eb3-f2fb3659b167
scm1.org_1   | 2022-01-01 01:11:46,257 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:11:46,282 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 376912.003us
scm1.org_1   | 2022-01-01 01:11:47,421 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58688
scm2.org_1   | 2022-01-01 01:11:40,775 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
om2_1        | 2022-01-01 01:21:05,131 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:13:37,976 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b reported by 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:13:37,992 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]] moved to OPEN state
recon_1      | 2022-01-01 01:13:37,993 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 795.324us
recon_1      | 2022-01-01 01:13:47,174 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55248
recon_1      | 2022-01-01 01:13:47,188 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:13:57,481 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46306
recon_1      | 2022-01-01 01:13:57,620 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:13:57,662 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55306
recon_1      | 2022-01-01 01:13:57,665 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-01-01 01:13:57,813 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-01-01 01:11:40,783 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 4
scm2.org_1   | 2022-01-01 01:11:40,784 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-01-01 01:11:40,784 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-01-01 01:11:41,919 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 5: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-01-01 01:11:41,924 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: Starting segment from index:5
scm2.org_1   | 2022-01-01 01:11:42,097 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_5
scm2.org_1   | 2022-01-01 01:11:42,129 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 7: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-01-01 01:11:42,156 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:11:42,157 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-01-01 01:11:42,158 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-01-01 01:11:42,159 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-01-01 01:11:42,355 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-01-01 01:11:42,372 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-01-01 01:11:42,393 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-CD2E3D8DB0C2:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-01-01 01:11:42,404 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-01-01 01:11:42,406 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-01-01 01:11:42,408 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-01-01 01:11:42,669 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-01-01 01:11:42,722 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-01-01 01:11:42,722 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-01-01 01:11:43,491 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-01-01 01:11:43,493 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-01-01 01:11:43,580 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-01-01 01:11:43,738 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-01-01 01:11:43,739 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-01-01 01:11:43,744 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-01-01 01:11:43,745 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-01-01 01:11:43,988 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-01-01 01:11:44,031 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-01-01 01:11:44,031 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-01-01 01:11:44,032 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-01-01 01:11:44,169 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:44,185 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:44,185 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-01-01 01:11:44,735 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52bef30b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-01-01 01:11:44,775 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-01-01 01:11:44,775 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-01-01 01:11:44,778 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-01-01 01:11:44,856 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @18015ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-01-01 01:11:45,165 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-01-01 01:11:45,189 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-01-01 01:11:45,190 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-01-01 01:11:45,194 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-01-01 01:11:45,210 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-01-01 01:11:45,214 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-01-01 01:11:45,397 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-01-01 01:11:45,400 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm2.org_1   | 2022-01-01 01:11:45,554 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-01-01 01:11:45,568 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-01-01 01:11:45,573 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2022-01-01 01:11:45,675 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-01-01 01:11:45,681 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a8fa30a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-01-01 01:11:45,681 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3a516e4d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-01-01 01:11:45,878 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om2_1        | 2022-01-01 01:21:05,246 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,814 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,817 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:05,820 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:12:08,773 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-01-01 01:12:09,576 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
om2_1        | 2022-01-01 01:21:05,844 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:11:47,463 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:11:59,923 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:46462
scm1.org_1   | 2022-01-01 01:12:00,103 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:12:00,118 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: 1214e676-068e-4ac1-9115-7b01b3dcff10: Submitting SetConfiguration request to Ratis server with new SCM peers list: [1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0, f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:12:00,122 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: receive setConfiguration SetConfigurationRequest:client-ED070E95D10F->1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2, cid=1, seq=0, RW, null, peers:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0, f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:12:00,128 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-ED070E95D10F->1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2, cid=1, seq=0, RW, null, peers:[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0, f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:12:00,128 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-01-01 01:12:00,128 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-01-01 01:12:00,130 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-01-01 01:12:00,150 [IPC Server handler 1 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-01-01 01:12:00,152 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-01-01 01:12:00,152 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-01-01 01:12:00,178 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:00,243 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:03,703 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58870
scm1.org_1   | 2022-01-01 01:12:03,851 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:12:07,075 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-01-01 01:12:07,093 [grpc-default-executor-2] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1640999527077 in 15 milliseconds
scm1.org_1   | 2022-01-01 01:12:07,132 [grpc-default-executor-2] INFO ha.SCMGrpcOutputStream: Sent 8673 bytes for cluster CID-83388cfa-c5bb-400c-b134-cd2e3d8db0c2
scm1.org_1   | 2022-01-01 01:12:07,136 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 42 milliseconds
scm1.org_1   | 2022-01-01 01:12:07,141 [grpc-default-executor-2] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1640999527077
scm1.org_1   | 2022-01-01 01:12:07,421 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received the first reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:12:07,421 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
om2_1        | 2022-01-01 01:21:08,415 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:08,961 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:08,964 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:08,966 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:08,974 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-7365940470/ozone-test-6600273006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-01-01 01:21:08,974 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-6600273006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-6600273006/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:09,476 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:09,479 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:09,480 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,037 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,040 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,042 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,052 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-01-01 01:21:10,053 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-01-01 01:13:58,032 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManager.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 26925.779us
recon_1      | 2022-01-01 01:13:58,038 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-01-01 01:13:58,065 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58834
recon_1      | 2022-01-01 01:13:58,095 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:14:18,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58900
recon_1      | 2022-01-01 01:14:18,234 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55396
recon_1      | 2022-01-01 01:14:18,258 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:14:18,280 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-01-01 01:14:18,325 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46394
recon_1      | 2022-01-01 01:14:18,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:14:18,360 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManager.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 413.311us
recon_1      | 2022-01-01 01:14:18,360 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-01-01 01:14:18,413 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:14:36,246 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:14:36,246 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:14:36,341 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2022-01-01 01:12:09,640 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:20:47,184 [qtp1677568775-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2691640248, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 2022-01-01 01:20:47,204 [qtp1677568775-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2691640248
s3g_1        | 2022-01-01 01:20:54,123 [qtp1677568775-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7365940470, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:20:54,142 [qtp1677568775-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7365940470
scm1.org_1   | 2022-01-01 01:12:07,423 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:07,423 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-01-01 01:12:09,646 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 10
scm3.org_1   | 2022-01-01 01:12:09,653 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-01-01 01:12:09,671 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO impl.StateMachineUpdater: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-01-01 01:12:12,285 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 11: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-01-01 01:12:12,330 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: Starting segment from index:11
scm3.org_1   | 2022-01-01 01:12:12,550 [grpc-default-executor-0] INFO server.RaftServer$Division: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2: set configuration 13: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-01-01 01:12:12,770 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-CD2E3D8DB0C2:[f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-01-01 01:12:12,820 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-01-01 01:12:12,849 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-01-01 01:12:12,859 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
s3g_1        | 2022-01-01 01:21:08,983 [qtp1677568775-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-6600273006/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-6600273006/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2022-01-01 01:12:07,700 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:12:07,700 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:12:07,701 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm3.org_1   | 2022-01-01 01:12:13,778 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/83388cfa-c5bb-400c-b134-cd2e3d8db0c2/current/log_inprogress_11
scm3.org_1   | 2022-01-01 01:12:13,989 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:14,003 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-01-01 01:12:14,004 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-01-01 01:12:14,026 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-01-01 01:12:14,156 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-01-01 01:12:14,278 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-01-01 01:12:14,278 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-01-01 01:12:16,263 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-01-01 01:12:16,377 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-01-01 01:12:16,896 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-01-01 01:12:17,211 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-01-01 01:12:17,211 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-01-01 01:12:17,689 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-01-01 01:12:17,694 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-01-01 01:12:17,706 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-01-01 01:12:17,713 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-01-01 01:12:18,220 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-01-01 01:12:18,221 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-01-01 01:12:18,222 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-01-01 01:12:18,300 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-01-01 01:12:18,615 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-01-01 01:12:18,615 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-01-01 01:12:18,616 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-01-01 01:12:19,796 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052fc40@193d73d3] WARN util.JvmPauseMonitor: JvmPauseMonitor-f44d6013-5a2d-49ef-9eb3-f2fb3659b167: Detected pause in JVM or host machine (eg GC): pause of approximately 140306365ns.
scm1.org_1   | 2022-01-01 01:12:07,702 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:07,746 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
scm2.org_1   | 2022-01-01 01:11:45,900 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6608072d{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-18133371661398057653/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-01-01 01:11:45,928 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@43b9ef41{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-01-01 01:11:45,929 [Listener at 0.0.0.0/9860] INFO server.Server: Started @19088ms
scm2.org_1   | 2022-01-01 01:11:45,931 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-01-01 01:11:45,931 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-01-01 01:11:45,942 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-01-01 01:11:46,399 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:11:46,404 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-01-01 01:11:46,404 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-01-01 01:12:12,297 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 11: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-01-01 01:12:12,344 [grpc-default-executor-1] INFO server.RaftServer$Division: 763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2: set configuration 13: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:10,561 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,563 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,565 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:10,573 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-01-01 01:21:10,574 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:11,144 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:11,148 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:11,151 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:11,170 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:11,553 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:12,201 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:12,204 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:12,206 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:12,222 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:12:07,747 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:12:07,748 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:07,750 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:07,756 [grpc-default-executor-2] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=131ms
scm2.org_1   | 2022-01-01 01:12:27,084 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:12:28,105 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:07,758 [grpc-default-executor-2] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm3.org_1   | 2022-01-01 01:12:20,079 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@33ef701e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-01-01 01:12:20,205 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-01-01 01:12:29,098 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:12:37,389 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:07,827 [grpc-default-executor-2] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:12:07,835 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm3.org_1   | 2022-01-01 01:12:20,225 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm2.org_1   | 2022-01-01 01:12:40,390 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:07,836 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
om2_1        | 2022-01-01 01:21:12,592 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:13,337 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:13,340 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:12:20,227 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-01-01 01:12:20,512 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @33606ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-01-01 01:12:21,409 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-01-01 01:12:21,448 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
scm1.org_1   | 2022-01-01 01:12:07,837 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
om2_1        | 2022-01-01 01:21:13,345 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:13,364 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:12:40,740 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
scm3.org_1   | 2022-01-01 01:12:21,460 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-01-01 01:12:21,475 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-01-01 01:12:21,475 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-01-01 01:12:21,480 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-01-01 01:12:21,856 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-01-01 01:12:56,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40090
scm2.org_1   | 2022-01-01 01:12:56,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:12:57,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35196
scm2.org_1   | 2022-01-01 01:12:57,999 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:12:07,847 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
om2_1        | 2022-01-01 01:21:13,505 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:14,091 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2022-01-01 01:21:14,094 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:14,096 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:14,110 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm2.org_1   | 2022-01-01 01:12:58,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48200
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2022-01-01 01:12:21,858 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm3.org_1   | 2022-01-01 01:12:22,151 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm1.org_1   | 2022-01-01 01:12:07,877 [grpc-default-executor-2] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:12:07,889 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm3.org_1   | 2022-01-01 01:12:22,157 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm1.org_1   | 2022-01-01 01:12:07,894 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:12:07,895 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:07,897 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
scm3.org_1   | 2022-01-01 01:12:22,188 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2022-01-01 01:12:22,419 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-01-01 01:12:07,941 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:12:07,945 [grpc-default-executor-2] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2022-01-01 01:12:07,945 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:12:07,950 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
om2_1        | 2022-01-01 01:21:14,649 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:14,654 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:12:58,268 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm3.org_1   | 2022-01-01 01:12:22,429 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56b4951a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-01-01 01:12:22,439 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a8fa30a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-01-01 01:12:23,363 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-01-01 01:12:23,603 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@172f88b1{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-17650543570584110841/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-01-01 01:12:23,682 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@2f48adcc{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-01-01 01:12:23,682 [Listener at 0.0.0.0/9860] INFO server.Server: Started @36776ms
scm3.org_1   | 2022-01-01 01:12:23,754 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-01-01 01:12:23,754 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-01-01 01:21:14,658 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:12:23,771 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om2_1        | 2022-01-01 01:21:14,679 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2022-01-01 01:13:00,651 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/458bfdff-96fb-4b4a-96de-6879eec60ac8
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm2.org_1   | 2022-01-01 01:13:00,678 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-01-01 01:13:00,723 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2022-01-01 01:12:07,953 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:08,016 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm1.org_1   | 2022-01-01 01:12:08,123 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm2.org_1   | 2022-01-01 01:13:00,807 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-01-01 01:13:01,650 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/75beef28-1584-4115-9505-884f6f5c519b
scm2.org_1   | 2022-01-01 01:13:01,654 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-01-01 01:12:08,128 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | 2022-01-01 01:12:08,162 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:08,172 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm2.org_1   | 2022-01-01 01:13:01,655 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-01-01 01:13:01,720 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-01-01 01:13:01,793 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]].
scm3.org_1   | 2022-01-01 01:12:27,468 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:08,207 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-01-01 01:12:08,250 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-01-01 01:12:08,255 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-01-01 01:12:08,266 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:08,270 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-GrpcLogAppender: send 1214e676-068e-4ac1-9115-7b01b3dcff10->f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-01-01 01:12:08,330 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateUnconditionally 0 -> 11
scm1.org_1   | 2022-01-01 01:12:08,384 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: received a reply 1214e676-068e-4ac1-9115-7b01b3dcff10<-f44d6013-5a2d-49ef-9eb3-f2fb3659b167#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm1.org_1   | 2022-01-01 01:12:08,385 [grpc-default-executor-0] INFO server.GrpcLogAppender: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167-InstallSnapshotResponseHandler: Follower installed snapshot at index 10
scm1.org_1   | 2022-01-01 01:12:08,385 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: snapshotIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2022-01-01 01:12:08,386 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: matchIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2022-01-01 01:12:08,386 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: setUnconditionally 11 -> 11
scm1.org_1   | 2022-01-01 01:12:08,386 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167 acknowledged installing snapshot
scm1.org_1   | 2022-01-01 01:12:08,388 [grpc-default-executor-0] INFO leader.FollowerInfo: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2->f44d6013-5a2d-49ef-9eb3-f2fb3659b167: nextIndex: updateToMax old=11, new=11, updated? false
scm1.org_1   | 2022-01-01 01:12:12,271 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 11: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0], old=[1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-01-01 01:12:12,317 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-LeaderStateImpl] INFO server.RaftServer$Division: 1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2: set configuration 13: [f44d6013-5a2d-49ef-9eb3-f2fb3659b167|rpc:scm3.org:9894|priority:0, 1214e676-068e-4ac1-9115-7b01b3dcff10|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 763bf6f7-3694-4790-8e44-c4f88a97de1a|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-01-01 01:12:12,385 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: f44d6013-5a2d-49ef-9eb3-f2fb3659b167.
scm1.org_1   | 2022-01-01 01:12:19,155 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$439/0x0000000840547c40@1bb3e150] WARN util.JvmPauseMonitor: JvmPauseMonitor-1214e676-068e-4ac1-9115-7b01b3dcff10: Detected pause in JVM or host machine (eg GC): pause of approximately 120054936ns. No GCs detected.
scm1.org_1   | 2022-01-01 01:12:19,493 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:33948
scm1.org_1   | 2022-01-01 01:12:19,531 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:22,659 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:53542
scm1.org_1   | 2022-01-01 01:12:22,839 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:12:24,916 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42018
scm1.org_1   | 2022-01-01 01:12:25,023 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:12:25,364 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35028
scm1.org_1   | 2022-01-01 01:12:25,464 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:12:25,830 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41998
scm1.org_1   | 2022-01-01 01:12:25,950 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:25,952 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn d689e1354c2c, UUID: 458bfdff-96fb-4b4a-96de-6879eec60ac8
scm1.org_1   | 2022-01-01 01:12:27,044 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:27,050 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 628571.951us
scm1.org_1   | 2022-01-01 01:12:27,765 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48504
scm1.org_1   | 2022-01-01 01:12:27,836 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:27,837 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 6842de8f6a86, UUID: 24732aa1-1492-41aa-844a-173d185ef1c3
scm1.org_1   | 2022-01-01 01:12:28,085 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:28,235 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 211546.567us
scm1.org_1   | 2022-01-01 01:12:28,643 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52416
scm1.org_1   | 2022-01-01 01:12:28,748 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:28,752 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 9f382dc742e3, UUID: 75beef28-1584-4115-9505-884f6f5c519b
scm1.org_1   | 2022-01-01 01:12:29,081 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
scm1.org_1   | 2022-01-01 01:12:29,116 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 139965.608us
scm1.org_1   | 2022-01-01 01:12:36,768 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51104
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:14:48,265 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58998
recon_1      | 2022-01-01 01:14:48,286 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55494
recon_1      | 2022-01-01 01:14:48,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46494
scm3.org_1   | 2022-01-01 01:12:27,472 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-01-01 01:12:27,473 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-01-01 01:12:28,140 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:29,132 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:37,414 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:40,392 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:40,752 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:56,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49162
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 2022-01-01 01:12:56,356 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:01,800 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:13:01,843 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/24732aa1-1492-41aa-844a-173d185ef1c3
scm2.org_1   | 2022-01-01 01:13:01,875 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-01-01 01:13:01,878 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-01-01 01:13:01,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-01-01 01:13:01,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-01-01 01:13:01,885 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-01-01 01:13:01,885 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm3.org_1   | 2022-01-01 01:12:57,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36170
scm3.org_1   | 2022-01-01 01:12:57,883 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-01-01 01:14:48,369 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
scm2.org_1   | 2022-01-01 01:13:01,885 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-01-01 01:13:01,885 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm1.org_1   | 2022-01-01 01:12:36,807 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2022-01-01 01:12:58,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44654
recon_1      | 2022-01-01 01:14:48,404 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm2.org_1   | 2022-01-01 01:13:02,019 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]].
scm2.org_1   | 2022-01-01 01:13:02,042 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:12:58,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:00,642 [IPC Server handler 15 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/458bfdff-96fb-4b4a-96de-6879eec60ac8
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
scm3.org_1   | 2022-01-01 01:13:00,691 [IPC Server handler 15 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:14:48,483 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:02,360 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]].
scm2.org_1   | 2022-01-01 01:13:02,366 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:13:02,835 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]].
scm2.org_1   | 2022-01-01 01:13:02,842 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:13:03,000 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]].
scm2.org_1   | 2022-01-01 01:13:03,003 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 2022-01-01 01:15:18,165 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46596
recon_1      | 2022-01-01 01:15:18,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55602
scm2.org_1   | 2022-01-01 01:13:05,210 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-01-01 01:13:05,477 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:13:05,758 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@47a8420, cost 515274.261us
scm2.org_1   | 2022-01-01 01:13:06,415 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-01-01 01:13:11,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-01-01 01:13:13,831 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-01-01 01:13:00,817 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-01-01 01:13:00,937 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-01-01 01:13:01,642 [IPC Server handler 39 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/75beef28-1584-4115-9505-884f6f5c519b
scm3.org_1   | 2022-01-01 01:13:01,678 [IPC Server handler 39 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-01-01 01:15:18,222 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59102
scm1.org_1   | 2022-01-01 01:12:36,847 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: f3828f85-be4c-4d8c-90d3-757cec5d688b
scm2.org_1   | 2022-01-01 01:13:16,300 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48246
scm3.org_1   | 2022-01-01 01:13:01,682 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
recon_1      | 2022-01-01 01:15:18,224 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:15:18,228 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-01-01 01:12:37,369 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm2.org_1   | 2022-01-01 01:13:16,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:16,336 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-01-01 01:13:01,724 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-01-01 01:12:37,434 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 143853.894us
scm1.org_1   | 2022-01-01 01:12:37,971 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42030
recon_1      | 2022-01-01 01:15:18,259 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:15:36,342 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm2.org_1   | 2022-01-01 01:13:16,338 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@47a8420, cost 403.212us
scm2.org_1   | 2022-01-01 01:13:16,595 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
recon_1      | 2022-01-01 01:15:36,342 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:15:36,416 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm3.org_1   | 2022-01-01 01:13:01,793 [IPC Server handler 42 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/24732aa1-1492-41aa-844a-173d185ef1c3
scm3.org_1   | 2022-01-01 01:13:01,800 [IPC Server handler 42 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-01-01 01:13:01,802 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-01-01 01:13:01,804 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-01-01 01:13:01,804 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-01-01 01:13:01,804 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-01-01 01:13:01,804 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-01-01 01:13:01,805 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
scm2.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:15,186 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:15,192 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:15,195 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:15,204 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3
om2_1        | 2022-01-01 01:21:15,205 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0116506954/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3 because parts are in Invalid order.
scm3.org_1   | 2022-01-01 01:13:01,806 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-01-01 01:13:02,104 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]].
scm3.org_1   | 2022-01-01 01:13:02,136 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:02,195 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]].
scm3.org_1   | 2022-01-01 01:13:02,197 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:02,331 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]].
scm3.org_1   | 2022-01-01 01:13:02,343 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:02,820 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]].
scm3.org_1   | 2022-01-01 01:13:02,820 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:02,965 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]].
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-01-01 01:12:38,030 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:39,199 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48528
scm2.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-01-01 01:13:17,095 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm3.org_1   | 2022-01-01 01:13:02,966 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:05,225 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]] moved to OPEN state
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:15,776 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:08,985 [qtp1677568775-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm3.org_1   | 2022-01-01 01:13:05,507 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
om2_1        | 2022-01-01 01:21:15,778 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:15,780 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:16,357 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:13:05,689 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6305a154, cost 460190.187us
om2_1        | 2022-01-01 01:21:16,362 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:12:39,242 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:40,035 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44130
scm3.org_1   | 2022-01-01 01:13:06,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om2_1        | 2022-01-01 01:21:16,365 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:16,431 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,331 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,334 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,336 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,910 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,916 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:17,921 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:18,733 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:18,735 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:18,737 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:18,752 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0888265347/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-7365940470
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-7365940470key: ozone-test-0888265347/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-01-01 01:12:40,122 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:40,124 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 8df6a100-26af-4b64-8cfa-6fdbb5b7043a
scm1.org_1   | 2022-01-01 01:12:40,339 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52120
scm1.org_1   | 2022-01-01 01:12:40,383 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-01-01 01:13:11,419 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-01-01 01:13:13,827 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-01-01 01:13:16,308 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44706
scm3.org_1   | 2022-01-01 01:13:16,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:16,379 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-01-01 01:13:16,380 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6305a154, cost 435.413us
scm3.org_1   | 2022-01-01 01:13:16,576 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-01-01 01:12:40,397 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 84137.92us
scm1.org_1   | 2022-01-01 01:12:40,428 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:40,455 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 6fa9a54b-b3e2-4bfe-8a6b-c796923fcdbb
scm1.org_1   | 2022-01-01 01:12:40,487 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52442
scm1.org_1   | 2022-01-01 01:12:40,510 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:12:40,715 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:12:40,758 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 89355.783us
scm1.org_1   | 2022-01-01 01:12:45,503 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58966
scm1.org_1   | 2022-01-01 01:12:45,567 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:12:56,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34528
s3g_1        |   <Code>EntityTooSmall</Code>
s3g_1        |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1        |   <Resource>ozone-test-6600273006/multipartKey2</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:102)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm2.org_1   | 2022-01-01 01:13:17,096 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-01-01 01:13:32,839 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48310
scm2.org_1   | 2022-01-01 01:13:32,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:32,976 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-01-01 01:12:56,391 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:32,982 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@47a8420, cost 395.012us
scm2.org_1   | 2022-01-01 01:13:33,061 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40224
scm2.org_1   | 2022-01-01 01:13:33,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:12:57,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53216
scm1.org_1   | 2022-01-01 01:12:57,999 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:12:58,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54348
scm1.org_1   | 2022-01-01 01:12:58,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:00,728 [IPC Server handler 83 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/458bfdff-96fb-4b4a-96de-6879eec60ac8
scm1.org_1   | 2022-01-01 01:13:00,762 [IPC Server handler 83 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 946568622539, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-01-01 01:13:00,883 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-01-01 01:13:00,921 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d83b488f-4512-497f-b5fa-ced3ca6a01ac to datanode:458bfdff-96fb-4b4a-96de-6879eec60ac8
scm1.org_1   | 2022-01-01 01:13:00,979 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-01-01 01:13:01,527 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]].
scm1.org_1   | 2022-01-01 01:13:01,534 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:13:01,535 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 138513.227us
scm1.org_1   | 2022-01-01 01:13:01,649 [IPC Server handler 73 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/75beef28-1584-4115-9505-884f6f5c519b
scm1.org_1   | 2022-01-01 01:13:01,686 [IPC Server handler 73 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 949221940755, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-01-01 01:13:01,794 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-01-01 01:13:01,800 [IPC Server handler 76 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/24732aa1-1492-41aa-844a-173d185ef1c3
scm1.org_1   | 2022-01-01 01:13:01,803 [IPC Server handler 76 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 948298220736, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-01-01 01:13:33,151 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:458bfdff-96fb-4b4a-96de-6879eec60ac8, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-01-01 01:13:33,153 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@47a8420, cost 1537.746us
scm2.org_1   | 2022-01-01 01:13:37,975 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-01-01 01:13:37,976 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@47a8420, cost 361.211us
scm2.org_1   | 2022-01-01 01:13:47,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35354
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2022-01-01 01:13:47,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:53,360 [763bf6f7-3694-4790-8e44-c4f88a97de1a@group-CD2E3D8DB0C2-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-01-01 01:13:57,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48396
scm2.org_1   | 2022-01-01 01:13:57,642 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:57,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35410
scm2.org_1   | 2022-01-01 01:13:57,861 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:13:57,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40320
scm2.org_1   | 2022-01-01 01:13:58,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:14:18,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40386
scm2.org_1   | 2022-01-01 01:14:18,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:14:18,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35500
scm2.org_1   | 2022-01-01 01:14:18,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48482
scm2.org_1   | 2022-01-01 01:14:18,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:14:18,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:14:48,413 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35598
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:19,241 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:19,246 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:19,250 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:19,257 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-7365940470, Key:ozone-test-0441595465/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
scm3.org_1   | 2022-01-01 01:13:17,093 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-01-01 01:13:17,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-01-01 01:13:17,097 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-01-01 01:13:17,098 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-01-01 01:13:17,098 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-01-01 01:13:32,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44764
scm3.org_1   | 2022-01-01 01:13:33,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:33,002 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]] moved to OPEN state
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2022-01-01 01:13:01,816 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-01-01 01:13:01,824 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2022-01-01 01:21:19,770 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:19,771 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:19,774 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:20,429 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:20,431 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:20,433 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:20,448 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:23,343 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:23,958 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:23,960 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:23,962 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:23,982 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:26,544 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,130 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,132 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,137 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,768 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,770 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:27,772 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,384 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,386 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,388 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,928 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,933 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:28,934 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,606 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,607 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,609 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,716 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,723 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,726 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,765 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,772 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,774 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-01-01 01:13:01,866 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c4e544bd-06bc-4975-8f23-ab6694bd9221 to datanode:75beef28-1584-4115-9505-884f6f5c519b
scm1.org_1   | 2022-01-01 01:13:01,959 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-01-01 01:13:01,972 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-01-01 01:13:01,974 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-01-01 01:13:01,974 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-01-01 01:13:01,984 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]].
scm1.org_1   | 2022-01-01 01:13:02,001 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-01-01 01:13:02,008 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm3.org_1   | 2022-01-01 01:13:33,004 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6305a154, cost 428.613us
scm3.org_1   | 2022-01-01 01:13:33,068 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49300
scm3.org_1   | 2022-01-01 01:13:33,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:33,145 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:458bfdff-96fb-4b4a-96de-6879eec60ac8, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-01-01 01:13:33,149 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6305a154, cost 1948.757us
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm3.org_1   | 2022-01-01 01:13:37,987 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-01-01 01:13:37,991 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6305a154, cost 3920.016us
scm2.org_1   | 2022-01-01 01:14:48,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48584
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2022-01-01 01:21:29,773 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:13:02,009 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
scm2.org_1   | 2022-01-01 01:14:48,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40488
scm2.org_1   | 2022-01-01 01:14:48,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:02,088 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 217476.733us
scm1.org_1   | 2022-01-01 01:13:02,095 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac to datanode:24732aa1-1492-41aa-844a-173d185ef1c3
scm3.org_1   | 2022-01-01 01:13:47,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36328
scm2.org_1   | 2022-01-01 01:14:48,566 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2022-01-01 01:13:02,185 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]].
scm1.org_1   | 2022-01-01 01:13:02,206 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:13:02,207 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 111758.906us
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm2.org_1   | 2022-01-01 01:14:48,567 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:18,280 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48690
scm2.org_1   | 2022-01-01 01:15:18,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40594
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm2.org_1   | 2022-01-01 01:15:18,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35706
scm2.org_1   | 2022-01-01 01:15:18,310 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:18,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:18,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:02,358 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 to datanode:458bfdff-96fb-4b4a-96de-6879eec60ac8
scm1.org_1   | 2022-01-01 01:13:02,359 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 to datanode:24732aa1-1492-41aa-844a-173d185ef1c3
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
scm1.org_1   | 2022-01-01 01:13:02,360 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 to datanode:75beef28-1584-4115-9505-884f6f5c519b
scm1.org_1   | 2022-01-01 01:13:02,643 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]].
scm2.org_1   | 2022-01-01 01:15:48,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35812
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm3.org_1   | 2022-01-01 01:13:47,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:53,500 [f44d6013-5a2d-49ef-9eb3-f2fb3659b167@group-CD2E3D8DB0C2-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-01-01 01:13:57,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44852
scm3.org_1   | 2022-01-01 01:13:57,641 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:48,204 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48796
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2022-01-01 01:13:02,657 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:13:02,667 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 305659.217us
scm2.org_1   | 2022-01-01 01:15:48,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:48,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40700
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 2022-01-01 01:13:02,689 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b to datanode:458bfdff-96fb-4b4a-96de-6879eec60ac8
scm1.org_1   | 2022-01-01 01:13:02,693 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b to datanode:75beef28-1584-4115-9505-884f6f5c519b
scm3.org_1   | 2022-01-01 01:13:57,645 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36382
scm3.org_1   | 2022-01-01 01:13:57,720 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:48,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:15:48,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:16:18,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40814
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm2.org_1   | 2022-01-01 01:16:18,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48912
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:15:48,170 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59208
recon_1      | 2022-01-01 01:15:48,190 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55708
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm2.org_1   | 2022-01-01 01:16:18,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35928
scm2.org_1   | 2022-01-01 01:16:18,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:16:18,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:16:18,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:13:57,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49392
scm3.org_1   | 2022-01-01 01:13:58,057 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:18,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49458
scm1.org_1   | 2022-01-01 01:13:02,693 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b to datanode:24732aa1-1492-41aa-844a-173d185ef1c3
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 2022-01-01 01:15:48,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:15:48,250 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:15:48,278 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46702
scm1.org_1   | 2022-01-01 01:13:02,895 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]].
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
recon_1      | 2022-01-01 01:15:48,305 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:18,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44946
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm3.org_1   | 2022-01-01 01:14:18,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:29,782 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,790 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,790 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,824 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:29,833 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:31,155 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,373 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om2_1        | 2022-01-01 01:21:33,380 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,419 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,423 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,428 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,936 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,937 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,940 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,970 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,972 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,974 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,989 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,990 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,993 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,994 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:33,996 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:34,003 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:16:34,951 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2022-01-01 01:16:48,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40922
scm2.org_1   | 2022-01-01 01:16:48,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49018
recon_1      | 2022-01-01 01:16:18,176 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59328
scm2.org_1   | 2022-01-01 01:16:48,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36036
scm2.org_1   | 2022-01-01 01:16:48,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:16:48,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:16:48,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:18,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41038
scm2.org_1   | 2022-01-01 01:17:18,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:18,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49136
scm2.org_1   | 2022-01-01 01:17:18,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36154
scm2.org_1   | 2022-01-01 01:17:18,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:18,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:48,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49244
scm2.org_1   | 2022-01-01 01:17:48,272 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41146
scm2.org_1   | 2022-01-01 01:17:48,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36260
scm2.org_1   | 2022-01-01 01:17:48,293 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:48,307 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:17:48,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:18,149 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41274
scm2.org_1   | 2022-01-01 01:18:18,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49362
scm2.org_1   | 2022-01-01 01:18:18,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:18,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36478
scm3.org_1   | 2022-01-01 01:14:18,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:18,406 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:48,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36576
scm3.org_1   | 2022-01-01 01:14:48,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49556
scm3.org_1   | 2022-01-01 01:14:48,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45038
scm3.org_1   | 2022-01-01 01:14:48,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:48,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:14:48,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
recon_1      | 2022-01-01 01:16:18,235 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46822
recon_1      | 2022-01-01 01:16:18,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:16:18,256 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:16:18,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55824
scm1.org_1   | 2022-01-01 01:13:02,909 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:18:18,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:18,285 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36376
scm2.org_1   | 2022-01-01 01:18:18,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:48,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41370
om2_1        | 2022-01-01 01:21:34,051 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:34,054 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:34,067 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:35,343 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm3.org_1   | 2022-01-01 01:15:18,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49666
scm1.org_1   | 2022-01-01 01:13:02,925 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 230232.918us
scm1.org_1   | 2022-01-01 01:13:02,942 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=6e8f729a-8cb4-46b5-85d7-bd59923c342b contains same datanodes as previous pipelines: PipelineID=e5481fd7-e475-47a4-9362-f8541548c104 nodeIds: 458bfdff-96fb-4b4a-96de-6879eec60ac8, 75beef28-1584-4115-9505-884f6f5c519b, 24732aa1-1492-41aa-844a-173d185ef1c3
scm1.org_1   | 2022-01-01 01:13:05,104 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35899
scm1.org_1   | 2022-01-01 01:13:05,192 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 2022-01-01 01:16:18,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:16:20,714 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-01-01 01:16:20,731 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 17 milliseconds for processing 2 containers.
recon_1      | 2022-01-01 01:16:20,793 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
om2_1        | 2022-01-01 01:21:35,344 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:35,346 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:35,363 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:36,118 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:36,121 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:36,123 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:16:20,794 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 753.819us
recon_1      | 2022-01-01 01:16:20,796 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 314.608us
recon_1      | 2022-01-01 01:16:20,799 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 256.807us
recon_1      | 2022-01-01 01:16:20,805 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 5120.132us
recon_1      | 2022-01-01 01:16:20,805 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 374.409us
recon_1      | 2022-01-01 01:16:20,806 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 95 milliseconds.
recon_1      | 2022-01-01 01:16:36,424 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om2_1        | 2022-01-01 01:21:36,697 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38785
om2_1        | 2022-01-01 01:21:36,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:21:38,939 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:39,446 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:39,448 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:39,450 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm3.org_1   | 2022-01-01 01:15:18,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:15:18,311 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45144
scm3.org_1   | 2022-01-01 01:15:18,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
scm3.org_1   | 2022-01-01 01:15:18,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36678
scm3.org_1   | 2022-01-01 01:15:18,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:15:48,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49772
scm3.org_1   | 2022-01-01 01:15:48,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:15:48,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45256
recon_1      | 2022-01-01 01:16:36,424 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:16:36,451 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
scm3.org_1   | 2022-01-01 01:15:48,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36784
scm3.org_1   | 2022-01-01 01:15:48,316 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:15:48,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:48,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36474
scm2.org_1   | 2022-01-01 01:18:48,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:48,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49476
scm2.org_1   | 2022-01-01 01:18:48,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:18:48,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:40,012 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:40,015 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
om2_1        | 2022-01-01 01:21:40,017 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:40,038 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:13:05,343 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1d951a37-d3ee-4ed3-a2b5-3d91c85c85ac, Nodes: 24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.090Z[UTC]] moved to OPEN state
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
scm3.org_1   | 2022-01-01 01:16:18,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49892
scm3.org_1   | 2022-01-01 01:16:18,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45374
scm3.org_1   | 2022-01-01 01:16:18,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36906
scm3.org_1   | 2022-01-01 01:16:18,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:16:18,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:16:18,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:40,047 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:40,048 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:40,057 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:13:05,417 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-01-01 01:19:18,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36722
scm2.org_1   | 2022-01-01 01:19:18,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49706
scm2.org_1   | 2022-01-01 01:19:18,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:19:18,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:05,434 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 74114.152us
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2022-01-01 01:13:05,470 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 2022-01-01 01:21:10,054 [qtp1677568775-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-0116506954/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
om2_1        | 2022-01-01 01:21:40,058 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:40,062 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:16:48,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37006
scm3.org_1   | 2022-01-01 01:16:48,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45474
scm1.org_1   | 2022-01-01 01:13:05,963 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42142
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-01-01 01:19:18,273 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41606
scm3.org_1   | 2022-01-01 01:16:48,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50006
scm3.org_1   | 2022-01-01 01:16:48,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:40,109 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:42,957 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:43,533 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:43,536 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:43,539 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:44,131 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-01-01 01:13:06,077 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:13:06,447 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-01-01 01:13:08,830 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:53678
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om2_1        | 2022-01-01 01:21:44,134 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:44,136 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:44,150 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:44,932 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:16:48,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:16:48,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:16:54,290 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2022-01-01 01:17:18,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45592
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om2_1        | 2022-01-01 01:21:44,933 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:17:18,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37128
scm1.org_1   | 2022-01-01 01:13:08,898 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:13:09,497 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35162
scm2.org_1   | 2022-01-01 01:19:18,316 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:19:48,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36830
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm1.org_1   | 2022-01-01 01:13:09,555 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:13:11,424 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-01-01 01:13:13,859 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-01-01 01:19:48,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49816
scm3.org_1   | 2022-01-01 01:17:18,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:17:18,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50114
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm2.org_1   | 2022-01-01 01:19:48,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:19:48,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:15,812 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51232
om2_1        | 2022-01-01 01:21:44,936 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:45,585 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm2.org_1   | 2022-01-01 01:19:48,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41720
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
scm1.org_1   | 2022-01-01 01:13:15,820 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:13:16,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54404
scm1.org_1   | 2022-01-01 01:13:16,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:17:18,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:17:18,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:46,130 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,132 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm3.org_1   | 2022-01-01 01:17:48,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50222
scm3.org_1   | 2022-01-01 01:17:48,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2022-01-01 01:13:16,555 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-01-01 01:13:16,580 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-01-01 01:13:16,591 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 33977.222us
scm1.org_1   | 2022-01-01 01:13:16,599 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm2.org_1   | 2022-01-01 01:19:48,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:20:18,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41830
scm3.org_1   | 2022-01-01 01:17:48,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45700
scm3.org_1   | 2022-01-01 01:17:48,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:17:48,287 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37234
scm1.org_1   | 2022-01-01 01:13:16,601 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-01-01 01:13:16,601 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-01-01 01:13:16,605 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-01-01 01:13:16,605 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-01-01 01:13:16,614 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-01-01 01:13:16,614 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-01-01 01:13:17,155 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39321
scm3.org_1   | 2022-01-01 01:17:48,364 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:18,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50340
scm3.org_1   | 2022-01-01 01:18:18,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45808
scm3.org_1   | 2022-01-01 01:18:18,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37354
scm3.org_1   | 2022-01-01 01:18:18,285 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:18,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:18,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:48,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50438
scm3.org_1   | 2022-01-01 01:18:48,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45930
scm3.org_1   | 2022-01-01 01:18:48,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37448
scm3.org_1   | 2022-01-01 01:18:48,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:48,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:18:48,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:18,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37700
scm3.org_1   | 2022-01-01 01:19:18,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46160
scm3.org_1   | 2022-01-01 01:19:18,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:18,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:18,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50684
scm3.org_1   | 2022-01-01 01:19:18,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:48,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50792
scm3.org_1   | 2022-01-01 01:19:48,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46276
scm3.org_1   | 2022-01-01 01:19:48,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:48,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:19:48,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37808
scm3.org_1   | 2022-01-01 01:19:48,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:18,207 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50902
scm3.org_1   | 2022-01-01 01:20:18,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37914
scm3.org_1   | 2022-01-01 01:20:18,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46386
scm3.org_1   | 2022-01-01 01:20:18,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:18,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:18,343 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:48,211 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38038
scm3.org_1   | 2022-01-01 01:20:48,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46500
scm3.org_1   | 2022-01-01 01:20:48,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51022
om2_1        | 2022-01-01 01:21:46,134 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,689 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,690 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:13:17,160 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:13:19,205 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44256
scm1.org_1   | 2022-01-01 01:13:19,221 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:13:20,131 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52254
scm1.org_1   | 2022-01-01 01:13:20,158 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:13:22,191 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59086
scm1.org_1   | 2022-01-01 01:13:22,324 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:13:32,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54458
scm1.org_1   | 2022-01-01 01:13:32,903 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39907
scm1.org_1   | 2022-01-01 01:13:32,926 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:13:33,037 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:33,066 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c4e544bd-06bc-4975-8f23-ab6694bd9221, Nodes: 75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:01.866Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-01-01 01:13:33,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34658
scm1.org_1   | 2022-01-01 01:13:33,119 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 48424.233us
scm1.org_1   | 2022-01-01 01:13:33,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:33,147 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d83b488f-4512-497f-b5fa-ced3ca6a01ac, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:458bfdff-96fb-4b4a-96de-6879eec60ac8, CreationTimestamp2022-01-01T01:13:00.915Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-01-01 01:13:33,210 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 59807.17us
scm1.org_1   | 2022-01-01 01:13:37,991 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e8f729a-8cb4-46b5-85d7-bd59923c342b, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:75beef28-1584-4115-9505-884f6f5c519b, CreationTimestamp2022-01-01T01:13:02.689Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-01-01 01:13:38,024 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 30818.308us
scm1.org_1   | 2022-01-01 01:13:47,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53372
scm1.org_1   | 2022-01-01 01:13:47,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:53,103 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42294
scm1.org_1   | 2022-01-01 01:13:53,134 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:13:53,203 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 55781.821us
scm2.org_1   | 2022-01-01 01:20:18,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36940
scm2.org_1   | 2022-01-01 01:20:18,254 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49926
scm2.org_1   | 2022-01-01 01:20:18,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:20:18,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:20:18,344 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2022-01-01 01:21:46,693 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,727 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:20:48,138 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41950
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm3.org_1   | 2022-01-01 01:20:48,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:48,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:20:48,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:21:18,138 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51174
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om2_1        | 2022-01-01 01:21:46,731 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,733 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,747 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,749 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:21:18,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46656
scm1.org_1   | 2022-01-01 01:13:53,210 [IPC Server handler 50 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-01-01 01:13:53,287 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManager.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 51572.699us
om2_1        | 2022-01-01 01:21:46,751 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:46,797 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:47,527 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:20:48,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37056
scm2.org_1   | 2022-01-01 01:20:48,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50046
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
scm3.org_1   | 2022-01-01 01:21:18,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38188
scm1.org_1   | 2022-01-01 01:13:53,352 [1214e676-068e-4ac1-9115-7b01b3dcff10@group-CD2E3D8DB0C2-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
om2_1        | 2022-01-01 01:21:48,367 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:48,369 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm1.org_1   | 2022-01-01 01:13:53,367 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 39948.261us
scm1.org_1   | 2022-01-01 01:13:53,402 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 35274.424us
scm3.org_1   | 2022-01-01 01:21:18,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:21:18,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm3.org_1   | 2022-01-01 01:21:18,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:20:48,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:20:48,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm3.org_1   | 2022-01-01 01:21:48,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51302
scm3.org_1   | 2022-01-01 01:21:48,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38318
scm1.org_1   | 2022-01-01 01:13:53,402 [IPC Server handler 50 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-01-01 01:13:56,931 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52698
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm2.org_1   | 2022-01-01 01:20:48,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:21:18,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42102
scm2.org_1   | 2022-01-01 01:21:18,212 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37208
scm2.org_1   | 2022-01-01 01:21:18,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50200
scm3.org_1   | 2022-01-01 01:21:48,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46788
scm3.org_1   | 2022-01-01 01:21:48,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:21:48,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om2_1        | 2022-01-01 01:21:48,371 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm2.org_1   | 2022-01-01 01:21:18,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:21:18,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:21:18,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:21:34,951 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2022-01-01 01:21:48,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37344
scm2.org_1   | 2022-01-01 01:21:48,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42232
scm2.org_1   | 2022-01-01 01:21:48,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50340
om2_1        | 2022-01-01 01:21:48,391 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:21:48,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:21:48,327 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
scm3.org_1   | 2022-01-01 01:21:54,291 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2022-01-01 01:22:18,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38442
scm3.org_1   | 2022-01-01 01:22:18,202 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46902
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm3.org_1   | 2022-01-01 01:22:18,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51436
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm2.org_1   | 2022-01-01 01:21:48,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:21:48,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:22:18,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:22:18,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:48,397 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:48,417 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm1.org_1   | 2022-01-01 01:13:56,949 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2022-01-01 01:22:18,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37470
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm3.org_1   | 2022-01-01 01:22:18,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:22:48,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47068
om2_1        | 2022-01-01 01:21:48,431 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:48,433 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm1.org_1   | 2022-01-01 01:13:57,102 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48790
scm2.org_1   | 2022-01-01 01:22:18,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42366
scm3.org_1   | 2022-01-01 01:22:48,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:57,111 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2022-01-01 01:21:48,435 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:48,464 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm3.org_1   | 2022-01-01 01:22:48,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51586
scm3.org_1   | 2022-01-01 01:22:48,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38600
scm3.org_1   | 2022-01-01 01:22:48,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm2.org_1   | 2022-01-01 01:22:18,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:22:18,268 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:22:18,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50446
scm2.org_1   | 2022-01-01 01:22:18,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
om2_1        | 2022-01-01 01:21:51,037 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm3.org_1   | 2022-01-01 01:22:48,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:18,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51678
scm3.org_1   | 2022-01-01 01:23:18,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38692
scm3.org_1   | 2022-01-01 01:23:18,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:57,215 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42296
scm1.org_1   | 2022-01-01 01:13:57,247 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-01-01 01:13:57,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54546
scm1.org_1   | 2022-01-01 01:13:57,623 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:13:57,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53436
scm1.org_1   | 2022-01-01 01:13:57,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:22:48,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50614
scm2.org_1   | 2022-01-01 01:22:48,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:22:48,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37628
scm2.org_1   | 2022-01-01 01:22:48,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42516
scm2.org_1   | 2022-01-01 01:22:48,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:22:48,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:18,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42602
scm1.org_1   | 2022-01-01 01:13:57,806 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36053
scm1.org_1   | 2022-01-01 01:13:57,918 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:13:57,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34760
scm1.org_1   | 2022-01-01 01:13:58,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:04,962 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42366
scm1.org_1   | 2022-01-01 01:14:04,968 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:14:16,043 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42400
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
om2_1        | 2022-01-01 01:21:51,645 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:51,646 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:51,648 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:52,184 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:52,186 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm3.org_1   | 2022-01-01 01:23:18,226 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47156
scm3.org_1   | 2022-01-01 01:23:18,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:18,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:48,138 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51746
scm3.org_1   | 2022-01-01 01:23:48,149 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47226
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm2.org_1   | 2022-01-01 01:23:18,225 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:18,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37712
om2_1        | 2022-01-01 01:21:52,191 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:52,205 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:14:16,046 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:14:16,064 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManager.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 17523.099us
scm1.org_1   | 2022-01-01 01:14:18,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34826
scm1.org_1   | 2022-01-01 01:14:18,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54638
scm1.org_1   | 2022-01-01 01:14:18,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:18,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:48,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:48,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38756
scm3.org_1   | 2022-01-01 01:23:48,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:23:48,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:24:18,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51834
om2_1        | 2022-01-01 01:21:53,456 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:53,458 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:53,461 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:56,352 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:56,930 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:23:18,277 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50700
scm2.org_1   | 2022-01-01 01:23:18,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:18,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:48,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42670
recon_1      | 2022-01-01 01:16:48,199 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59432
recon_1      | 2022-01-01 01:16:48,210 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55930
recon_1      | 2022-01-01 01:16:48,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:16:48,230 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46928
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm3.org_1   | 2022-01-01 01:24:18,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:24:18,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38842
scm3.org_1   | 2022-01-01 01:24:18,211 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47310
scm3.org_1   | 2022-01-01 01:24:18,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:24:18,255 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:56,932 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:56,934 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:57,477 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:57,479 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:57,481 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:59,440 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:59,442 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:16:48,235 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:16:48,328 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:17:18,124 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47048
recon_1      | 2022-01-01 01:17:18,166 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59548
recon_1      | 2022-01-01 01:17:18,192 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:18,320 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42175
scm1.org_1   | 2022-01-01 01:14:18,351 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:14:18,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53520
scm1.org_1   | 2022-01-01 01:14:18,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:42,628 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52430
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm2.org_1   | 2022-01-01 01:23:48,154 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:48,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37778
scm2.org_1   | 2022-01-01 01:23:48,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50770
scm2.org_1   | 2022-01-01 01:23:48,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:23:48,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
recon_1      | 2022-01-01 01:17:18,209 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:17:18,236 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56048
recon_1      | 2022-01-01 01:17:18,265 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:17:36,452 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:17:36,452 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:17:36,492 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm3.org_1   | 2022-01-01 01:24:48,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47382
scm3.org_1   | 2022-01-01 01:24:48,212 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51896
scm3.org_1   | 2022-01-01 01:24:48,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:42,632 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2022-01-01 01:21:59,443 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
scm3.org_1   | 2022-01-01 01:24:48,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38912
scm3.org_1   | 2022-01-01 01:24:48,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:24:48,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:59,475 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm3.org_1   | 2022-01-01 01:25:18,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51980
scm2.org_1   | 2022-01-01 01:24:18,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42758
scm2.org_1   | 2022-01-01 01:24:18,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:21:59,479 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
scm1.org_1   | 2022-01-01 01:14:48,249 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53618
scm1.org_1   | 2022-01-01 01:14:48,262 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54736
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om2_1        | 2022-01-01 01:21:59,481 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:21:59,494 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:24:18,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37868
scm2.org_1   | 2022-01-01 01:24:18,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50854
scm3.org_1   | 2022-01-01 01:25:18,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38994
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
scm2.org_1   | 2022-01-01 01:24:18,245 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:24:18,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:25:18,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47464
om2_1        | 2022-01-01 01:22:00,032 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm1.org_1   | 2022-01-01 01:14:48,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34920
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm2.org_1   | 2022-01-01 01:24:48,160 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42824
scm2.org_1   | 2022-01-01 01:24:48,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50922
scm3.org_1   | 2022-01-01 01:25:18,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:00,036 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-01-01 01:14:48,350 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2022-01-01 01:14:48,386 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:14:48,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:25:18,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:25:18,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:24:48,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37934
scm2.org_1   | 2022-01-01 01:24:48,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:11,254 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42594
scm1.org_1   | 2022-01-01 01:15:11,259 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2022-01-01 01:25:48,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39060
scm3.org_1   | 2022-01-01 01:25:48,225 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52048
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 2022-01-01 01:21:10,056 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm1.org_1   | 2022-01-01 01:15:18,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54846
scm3.org_1   | 2022-01-01 01:25:48,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47524
scm2.org_1   | 2022-01-01 01:24:48,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm2.org_1   | 2022-01-01 01:24:48,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:18,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42904
scm2.org_1   | 2022-01-01 01:25:18,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38020
scm1.org_1   | 2022-01-01 01:15:18,275 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35024
scm3.org_1   | 2022-01-01 01:25:48,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:25:48,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:25:48,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:18,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52124
om2_1        | 2022-01-01 01:22:00,039 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,066 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,068 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:15:18,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:18,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:18,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51004
scm2.org_1   | 2022-01-01 01:25:18,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:18,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53724
scm3.org_1   | 2022-01-01 01:26:18,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39144
scm3.org_1   | 2022-01-01 01:26:18,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:18,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:00,070 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,081 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,625 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,627 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,629 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,654 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,657 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
scm3.org_1   | 2022-01-01 01:26:18,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47606
scm3.org_1   | 2022-01-01 01:26:18,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:48,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52198
scm3.org_1   | 2022-01-01 01:26:48,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47678
scm2.org_1   | 2022-01-01 01:25:18,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:48,160 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42970
scm2.org_1   | 2022-01-01 01:25:48,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38082
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>ozone-test-0116506954/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
scm2.org_1   | 2022-01-01 01:25:48,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:48,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:25:48,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51070
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm2.org_1   | 2022-01-01 01:25:48,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:00,660 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,670 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm2.org_1   | 2022-01-01 01:26:18,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43054
scm2.org_1   | 2022-01-01 01:26:18,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38166
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm1.org_1   | 2022-01-01 01:15:18,299 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:18,357 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:23,522 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42646
scm1.org_1   | 2022-01-01 01:15:23,525 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:15:23,612 [IPC Server handler 17 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 32964.885us
scm3.org_1   | 2022-01-01 01:26:48,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39206
scm3.org_1   | 2022-01-01 01:26:48,208 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:48,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:48,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:26:54,292 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm3.org_1   | 2022-01-01 01:27:18,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52286
scm3.org_1   | 2022-01-01 01:27:18,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39294
scm3.org_1   | 2022-01-01 01:27:18,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:27:18,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47778
scm3.org_1   | 2022-01-01 01:27:18,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:27:18,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:23,612 [IPC Server handler 17 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-01-01 01:15:23,691 [IPC Server handler 17 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 66059.574us
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
om2_1        | 2022-01-01 01:22:00,672 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,674 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:00,713 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,136 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,690 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:15:48,283 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53830
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
om2_1        | 2022-01-01 01:22:04,691 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,695 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:15:48,284 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54946
scm3.org_1   | 2022-01-01 01:27:48,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52348
scm3.org_1   | 2022-01-01 01:27:48,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39364
scm3.org_1   | 2022-01-01 01:27:48,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:26:18,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:26:18,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:04,711 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,713 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2022-01-01 01:15:48,285 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35130
scm1.org_1   | 2022-01-01 01:15:48,310 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:48,315 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:15:48,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:10,332 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-01-01 01:16:18,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35248
scm1.org_1   | 2022-01-01 01:16:18,273 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55064
scm1.org_1   | 2022-01-01 01:16:18,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:18,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:18,324 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53948
scm1.org_1   | 2022-01-01 01:16:18,359 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:20,163 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42860
scm1.org_1   | 2022-01-01 01:16:20,167 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:16:20,775 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38455
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm3.org_1   | 2022-01-01 01:27:48,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:27:48,259 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47830
scm3.org_1   | 2022-01-01 01:27:48,276 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:18,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47936
scm3.org_1   | 2022-01-01 01:28:18,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52454
scm3.org_1   | 2022-01-01 01:28:18,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:18,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39470
scm3.org_1   | 2022-01-01 01:28:18,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:18,255 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:48,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52520
scm3.org_1   | 2022-01-01 01:28:48,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48008
scm3.org_1   | 2022-01-01 01:28:48,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:48,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39536
scm3.org_1   | 2022-01-01 01:28:48,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:28:48,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:18,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52604
scm3.org_1   | 2022-01-01 01:29:18,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39614
om2_1        | 2022-01-01 01:22:04,715 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,722 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,724 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,726 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:04,751 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm2.org_1   | 2022-01-01 01:26:18,273 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51150
scm2.org_1   | 2022-01-01 01:26:18,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:26:34,952 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2022-01-01 01:26:48,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43122
scm2.org_1   | 2022-01-01 01:26:48,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:26:48,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38232
scm2.org_1   | 2022-01-01 01:26:48,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51222
scm2.org_1   | 2022-01-01 01:26:48,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:26:48,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:27:18,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43214
scm2.org_1   | 2022-01-01 01:27:18,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38316
scm2.org_1   | 2022-01-01 01:27:18,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:27:18,296 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51318
scm2.org_1   | 2022-01-01 01:27:18,305 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:27:18,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:27:48,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38390
scm2.org_1   | 2022-01-01 01:27:48,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43278
scm2.org_1   | 2022-01-01 01:27:48,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51376
scm2.org_1   | 2022-01-01 01:27:48,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
om2_1        | 2022-01-01 01:22:07,313 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,873 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,877 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,885 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,909 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,911 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,913 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,920 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,922 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,929 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:07,995 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:08,553 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,151 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,152 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,154 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,657 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,658 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:09,661 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:16:20,787 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:16:27,416 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52826
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 2022-01-01 01:16:27,419 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:16:34,196 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42904
scm1.org_1   | 2022-01-01 01:16:34,202 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:16:43,544 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52864
scm3.org_1   | 2022-01-01 01:29:18,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48094
scm3.org_1   | 2022-01-01 01:29:18,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:18,225 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:18,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:48,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52670
scm3.org_1   | 2022-01-01 01:29:48,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39684
scm3.org_1   | 2022-01-01 01:29:48,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48166
scm3.org_1   | 2022-01-01 01:29:48,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:48,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:29:48,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:30:18,155 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52792
scm3.org_1   | 2022-01-01 01:30:18,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48286
scm3.org_1   | 2022-01-01 01:30:18,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:30:18,191 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39796
scm3.org_1   | 2022-01-01 01:30:18,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-01-01 01:30:18,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:43,554 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:16:48,249 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54058
scm1.org_1   | 2022-01-01 01:16:48,303 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35354
scm1.org_1   | 2022-01-01 01:16:48,312 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:48,354 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:16:48,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55168
scm1.org_1   | 2022-01-01 01:16:48,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:17:18,259 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55292
scm1.org_1   | 2022-01-01 01:17:18,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54172
scm1.org_1   | 2022-01-01 01:17:18,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:17:18,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:17:18,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35478
scm1.org_1   | 2022-01-01 01:17:18,307 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:17:23,491 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43096
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:17:48,101 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59656
recon_1      | 2022-01-01 01:17:48,159 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:17:48,207 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47154
recon_1      | 2022-01-01 01:17:48,237 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:17:48,250 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56154
recon_1      | 2022-01-01 01:17:48,327 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:18:18,177 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59780
scm2.org_1   | 2022-01-01 01:27:48,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:27:48,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:18,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51482
scm2.org_1   | 2022-01-01 01:28:18,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:18,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43378
scm2.org_1   | 2022-01-01 01:28:18,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38490
scm2.org_1   | 2022-01-01 01:28:18,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:18,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:48,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43452
om2_1        | 2022-01-01 01:22:09,672 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:10,469 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:10,471 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:10,473 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,026 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,028 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,030 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,563 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,564 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:11,568 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:15,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38624
om2_1        | 2022-01-01 01:22:15,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:22:18,493 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:18,500 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:19,019 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:19,021 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:19,514 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:19,515 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:19,517 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:22,125 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:22,622 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:22,624 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:22,625 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:22,628 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,113 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,114 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,116 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,117 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,122 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,149 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-01-01 01:17:23,512 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 2022-01-01 01:18:18,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47268
recon_1      | 2022-01-01 01:18:18,254 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:18:18,291 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:48,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:48,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38562
scm2.org_1   | 2022-01-01 01:28:48,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51544
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm1.org_1   | 2022-01-01 01:17:23,527 [IPC Server handler 25 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 12814.313us
scm1.org_1   | 2022-01-01 01:17:48,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54278
scm1.org_1   | 2022-01-01 01:17:48,299 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55394
scm1.org_1   | 2022-01-01 01:17:48,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35578
scm1.org_1   | 2022-01-01 01:17:48,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:17:48,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:23,165 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:17:48,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:18,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54396
scm1.org_1   | 2022-01-01 01:18:18,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55506
scm1.org_1   | 2022-01-01 01:18:18,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35700
scm1.org_1   | 2022-01-01 01:18:18,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:48,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:28:48,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:18,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43532
scm2.org_1   | 2022-01-01 01:29:18,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38636
scm2.org_1   | 2022-01-01 01:29:18,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51634
scm2.org_1   | 2022-01-01 01:29:18,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:18,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:18,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:48,149 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43600
scm2.org_1   | 2022-01-01 01:29:48,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38706
scm2.org_1   | 2022-01-01 01:29:48,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:48,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51704
scm2.org_1   | 2022-01-01 01:29:48,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:29:48,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:30:18,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38826
scm2.org_1   | 2022-01-01 01:30:18,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43720
scm2.org_1   | 2022-01-01 01:30:18,218 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:30:18,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-01-01 01:30:18,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51824
scm2.org_1   | 2022-01-01 01:30:18,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 2022-01-01 01:18:18,294 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56272
recon_1      | 2022-01-01 01:18:18,335 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-01-01 01:22:23,306 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:18:18,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:18,353 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:43,385 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43372
scm1.org_1   | 2022-01-01 01:18:43,395 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:18:48,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35802
scm1.org_1   | 2022-01-01 01:18:48,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55616
scm1.org_1   | 2022-01-01 01:18:48,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54494
scm1.org_1   | 2022-01-01 01:18:48,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:48,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:48,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:18:53,024 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53362
scm1.org_1   | 2022-01-01 01:18:53,027 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:19:18,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54744
om2_1        | 2022-01-01 01:22:23,335 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:19:18,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55858
scm1.org_1   | 2022-01-01 01:19:18,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36040
recon_1      | 2022-01-01 01:18:36,497 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:18:36,497 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:18:36,534 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
scm1.org_1   | 2022-01-01 01:19:18,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:19:18,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:19:18,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm1.org_1   | 2022-01-01 01:19:41,263 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43710
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:10,576 [qtp1677568775-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-0116506954/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om2_1        | 2022-01-01 01:22:23,895 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,896 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
om2_1        | 2022-01-01 01:22:23,898 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:23,901 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,432 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,434 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,436 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,437 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,439 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,447 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,456 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:24,614 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
om2_1        | 2022-01-01 01:22:24,660 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,428 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
om2_1        | 2022-01-01 01:22:25,430 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,431 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,435 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,911 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,913 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,915 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:25,924 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:19:41,274 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:19:48,160 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55966
scm1.org_1   | 2022-01-01 01:19:48,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54852
scm1.org_1   | 2022-01-01 01:19:48,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36150
scm1.org_1   | 2022-01-01 01:19:48,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:19:48,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:19:48,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:19:56,494 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43788
scm1.org_1   | 2022-01-01 01:19:56,501 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:20:08,391 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53756
scm1.org_1   | 2022-01-01 01:20:08,393 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:20:18,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36262
scm1.org_1   | 2022-01-01 01:20:18,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54966
om2_1        | 2022-01-01 01:22:26,437 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:26,439 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:20:18,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:18,279 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56078
scm1.org_1   | 2022-01-01 01:20:18,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:18,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:23,477 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43884
scm1.org_1   | 2022-01-01 01:20:23,481 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:20:23,495 [IPC Server handler 47 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 13840.201us
scm1.org_1   | 2022-01-01 01:20:48,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55082
scm1.org_1   | 2022-01-01 01:20:48,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36380
scm1.org_1   | 2022-01-01 01:20:48,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56198
scm1.org_1   | 2022-01-01 01:20:48,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:48,245 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:48,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:20:55,939 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44020
scm1.org_1   | 2022-01-01 01:20:55,947 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:21:03,747 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53996
scm1.org_1   | 2022-01-01 01:21:03,750 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:21:10,335 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm1.org_1   | 2022-01-01 01:21:16,414 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54046
scm1.org_1   | 2022-01-01 01:21:16,422 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:21:18,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36532
scm1.org_1   | 2022-01-01 01:21:18,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56348
scm1.org_1   | 2022-01-01 01:21:18,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55234
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om2_1        | 2022-01-01 01:22:27,444 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:27,446 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:27,448 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:27,450 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:27,453 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:31,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38708
om2_1        | 2022-01-01 01:22:31,238 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:22:33,957 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:33,959 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
om2_1        | 2022-01-01 01:22:34,464 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:34,465 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:34,467 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:34,575 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:35,372 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:35,375 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:21:18,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:21:18,308 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:21:18,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:21:20,857 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35425
scm1.org_1   | 2022-01-01 01:21:20,862 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om2_1        | 2022-01-01 01:22:35,377 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:21:23,482 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 10355.018us
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om2_1        | 2022-01-01 01:22:35,379 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:35,934 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:35,945 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:21:34,020 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54140
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
scm1.org_1   | 2022-01-01 01:21:34,032 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:21:48,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55362
scm1.org_1   | 2022-01-01 01:21:48,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36670
om2_1        | 2022-01-01 01:22:35,946 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm1.org_1   | 2022-01-01 01:21:48,259 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56480
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
scm1.org_1   | 2022-01-01 01:21:48,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:21:48,281 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:35,973 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:36,728 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39479
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2022-01-01 01:21:48,327 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:18,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36788
scm1.org_1   | 2022-01-01 01:22:18,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55488
scm1.org_1   | 2022-01-01 01:22:18,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56608
scm1.org_1   | 2022-01-01 01:22:18,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:18,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:18,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:19,528 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44402
scm1.org_1   | 2022-01-01 01:22:19,530 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:22:23,134 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54358
scm1.org_1   | 2022-01-01 01:22:23,143 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:22:23,477 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 7511.953us
scm1.org_1   | 2022-01-01 01:22:24,605 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52320
scm1.org_1   | 2022-01-01 01:22:24,666 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:22:24,729 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33676
scm1.org_1   | 2022-01-01 01:22:24,756 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:22:34,478 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44468
scm1.org_1   | 2022-01-01 01:22:34,480 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:22:35,961 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54416
scm1.org_1   | 2022-01-01 01:22:35,964 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:22:48,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36946
scm1.org_1   | 2022-01-01 01:22:48,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56762
scm1.org_1   | 2022-01-01 01:22:48,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:48,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55646
scm1.org_1   | 2022-01-01 01:22:48,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:48,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:22:54,421 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44570
scm1.org_1   | 2022-01-01 01:22:54,427 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:23:18,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37034
scm1.org_1   | 2022-01-01 01:23:18,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56850
scm1.org_1   | 2022-01-01 01:23:18,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55734
scm1.org_1   | 2022-01-01 01:23:18,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:23:18,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:23:18,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:22:36,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:22:36,817 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:36,820 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:36,827 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:37,513 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:37,516 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:18:48,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59880
recon_1      | 2022-01-01 01:18:48,206 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47382
recon_1      | 2022-01-01 01:18:48,208 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56374
recon_1      | 2022-01-01 01:18:48,243 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:18:48,258 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:18:48,279 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:19:18,225 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47618
om2_1        | 2022-01-01 01:22:37,518 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,116 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,118 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,121 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,794 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,797 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:38,799 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:39,529 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:39,532 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:39,534 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:39,670 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,299 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1        | 2022-01-01 01:22:40,301 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,303 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,306 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,783 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,785 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:40,786 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,255 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om2_1        | 2022-01-01 01:22:41,258 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,260 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,262 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,738 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,739 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,740 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:41,749 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:42,259 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:42,260 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:42,262 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:42,458 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,133 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,135 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,137 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,139 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,768 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,773 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:43,775 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:44,433 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:44,435 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:44,436 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:44,440 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,195 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,198 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,200 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,210 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,859 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:45,861 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:50,807 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38810
om2_1        | 2022-01-01 01:22:50,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:22:53,754 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:22:53,757 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:19:18,250 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56616
recon_1      | 2022-01-01 01:19:18,266 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
scm1.org_1   | 2022-01-01 01:23:23,485 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44650
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:10,580 [qtp1677568775-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm1.org_1   | 2022-01-01 01:23:23,487 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 2022-01-01 01:19:18,276 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60120
recon_1      | 2022-01-01 01:19:18,303 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-01-01 01:22:54,407 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:19:18,317 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-01-01 01:23:23,497 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 9017.68us
scm1.org_1   | 2022-01-01 01:23:48,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37102
scm1.org_1   | 2022-01-01 01:23:48,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:23:48,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55808
s3g_1        | <Error>
recon_1      | 2022-01-01 01:19:36,543 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-01-01 01:23:48,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:23:48,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56920
scm1.org_1   | 2022-01-01 01:23:48,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-01-01 01:19:36,543 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:19:36,615 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm1.org_1   | 2022-01-01 01:23:55,115 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44720
scm1.org_1   | 2022-01-01 01:23:55,123 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:24:18,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37190
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>ozone-test-0116506954/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 2022-01-01 01:24:18,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:24:18,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57018
om2_1        | 2022-01-01 01:22:54,408 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2022-01-01 01:22:54,410 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2022-01-01 01:24:18,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55886
scm1.org_1   | 2022-01-01 01:24:18,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:24:18,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:24:48,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37262
scm1.org_1   | 2022-01-01 01:24:48,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:24:48,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55956
om2_1        | 2022-01-01 01:23:36,810 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34007
scm1.org_1   | 2022-01-01 01:24:48,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57072
scm1.org_1   | 2022-01-01 01:24:48,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm1.org_1   | 2022-01-01 01:24:48,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:24:57,700 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44884
scm1.org_1   | 2022-01-01 01:24:57,705 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:25:18,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37338
scm1.org_1   | 2022-01-01 01:25:18,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56038
scm1.org_1   | 2022-01-01 01:25:18,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57154
scm1.org_1   | 2022-01-01 01:25:18,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:18,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:18,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:48,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37404
scm1.org_1   | 2022-01-01 01:25:48,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56104
scm1.org_1   | 2022-01-01 01:25:48,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:48,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:48,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57222
scm1.org_1   | 2022-01-01 01:25:48,308 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:25:58,375 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45032
scm1.org_1   | 2022-01-01 01:25:58,384 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:26:10,336 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-01-01 01:26:18,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37492
scm1.org_1   | 2022-01-01 01:26:18,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:18,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56186
scm1.org_1   | 2022-01-01 01:26:18,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57308
scm1.org_1   | 2022-01-01 01:26:18,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:18,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:20,907 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37423
scm1.org_1   | 2022-01-01 01:26:20,909 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:26:23,487 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45102
scm1.org_1   | 2022-01-01 01:26:23,498 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:26:23,507 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 8052.05us
scm1.org_1   | 2022-01-01 01:26:48,139 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37554
scm1.org_1   | 2022-01-01 01:26:48,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57372
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om2_1        | 2022-01-01 01:23:36,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:23:55,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41889
om2_1        | 2022-01-01 01:23:55,094 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:23:55,095 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,098 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,105 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,313 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,954 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,955 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:55,958 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:56,083 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:56,698 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:56,700 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:23:56,702 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:24:36,869 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39681
om2_1        | 2022-01-01 01:24:36,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:24:57,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39427
om2_1        | 2022-01-01 01:24:57,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:24:57,626 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:24:57,629 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:24:57,683 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:25:36,921 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34451
om2_1        | 2022-01-01 01:25:36,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:25:54,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40709
om2_1        | 2022-01-01 01:25:54,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:25:54,629 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:25:58,354 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:25:58,356 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:25:58,358 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:26:36,990 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40975
om2_1        | 2022-01-01 01:26:36,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:26:57,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45119
om2_1        | 2022-01-01 01:26:57,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:26:57,643 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:26:59,717 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:26:59,719 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:26:59,721 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:27:37,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43993
om2_1        | 2022-01-01 01:27:37,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:27:58,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43667
om2_1        | 2022-01-01 01:27:58,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:27:58,608 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:01,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39606
om2_1        | 2022-01-01 01:28:01,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:28:01,859 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:01,861 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:01,863 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:02,331 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:19:48,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60228
recon_1      | 2022-01-01 01:19:48,204 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47722
om2_1        | 2022-01-01 01:28:05,280 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:26:48,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:48,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56258
scm1.org_1   | 2022-01-01 01:26:48,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:48,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:59,740 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45190
scm1.org_1   | 2022-01-01 01:26:59,742 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2022-01-01 01:28:05,283 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
scm1.org_1   | 2022-01-01 01:26:59,790 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34440
recon_1      | 2022-01-01 01:19:48,219 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-01-01 01:28:05,943 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:19:48,225 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
recon_1      | 2022-01-01 01:19:48,232 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56724
recon_1      | 2022-01-01 01:19:48,245 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-01-01 01:28:05,945 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:05,947 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:28:37,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42337
recon_1      | 2022-01-01 01:20:18,284 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47838
recon_1      | 2022-01-01 01:20:18,286 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60344
om2_1        | 2022-01-01 01:28:37,076 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:28:58,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45091
om2_1        | 2022-01-01 01:28:58,611 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:28:58,611 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:20:18,289 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-01-01 01:26:59,799 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55132
scm1.org_1   | 2022-01-01 01:26:59,799 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53088
recon_1      | 2022-01-01 01:20:18,302 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56842
recon_1      | 2022-01-01 01:20:18,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
recon_1      | 2022-01-01 01:20:18,343 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1      | 2022-01-01 01:20:36,616 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm1.org_1   | 2022-01-01 01:26:59,806 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:26:59,812 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:26:59,832 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:27:18,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56336
scm1.org_1   | 2022-01-01 01:27:18,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37644
scm1.org_1   | 2022-01-01 01:27:18,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57468
scm1.org_1   | 2022-01-01 01:27:18,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:27:18,299 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:27:18,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-01-01 01:20:36,616 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:20:36,683 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om2_1        | 2022-01-01 01:29:06,090 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:29:06,095 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:29:06,096 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:29:37,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46383
om2_1        | 2022-01-01 01:29:37,127 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:30:00,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41717
om2_1        | 2022-01-01 01:30:00,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:30:00,617 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,011 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,015 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,027 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm1.org_1   | 2022-01-01 01:27:48,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37716
scm1.org_1   | 2022-01-01 01:27:48,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57532
scm1.org_1   | 2022-01-01 01:27:48,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56410
scm1.org_1   | 2022-01-01 01:27:48,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:27:48,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:27:48,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:28:01,876 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45356
scm1.org_1   | 2022-01-01 01:28:01,912 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:28:01,996 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53252
scm1.org_1   | 2022-01-01 01:28:02,030 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55298
scm1.org_1   | 2022-01-01 01:28:02,062 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34608
scm1.org_1   | 2022-01-01 01:28:02,064 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:28:02,069 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:28:02,071 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om2_1        | 2022-01-01 01:30:07,219 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,877 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,879 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,880 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:07,883 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:08,456 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:08,458 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:08,461 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:08,487 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,028 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,030 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,032 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,034 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,560 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,563 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,565 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:09,599 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,211 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,213 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,216 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,224 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,824 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,826 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,827 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:10,838 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:11,535 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:11,537 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:11,542 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:11,552 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:12,341 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:12,346 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:12,348 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,056 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,058 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,060 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,069 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,689 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,691 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,692 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:13,703 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:14,368 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:14,370 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:14,372 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:14,379 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,100 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,102 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,103 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,111 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,784 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,786 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,787 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:15,797 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:16,537 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | 2022-01-01 01:28:18,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37818
scm1.org_1   | 2022-01-01 01:28:18,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57630
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm1.org_1   | 2022-01-01 01:28:18,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
om2_1        | 2022-01-01 01:30:16,542 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
scm1.org_1   | 2022-01-01 01:28:18,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm1.org_1   | 2022-01-01 01:28:18,252 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56520
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm1.org_1   | 2022-01-01 01:28:18,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:28:23,486 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45430
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om2_1        | 2022-01-01 01:30:16,547 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm1.org_1   | 2022-01-01 01:28:23,487 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:28:23,497 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 8639.555us
scm1.org_1   | 2022-01-01 01:28:48,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37886
scm1.org_1   | 2022-01-01 01:28:48,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57702
om2_1        | 2022-01-01 01:30:16,556 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,263 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm1.org_1   | 2022-01-01 01:28:48,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:28:48,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56582
scm1.org_1   | 2022-01-01 01:28:48,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om2_1        | 2022-01-01 01:30:17,265 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om2_1        | 2022-01-01 01:30:17,267 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,278 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,981 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,983 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,984 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:17,991 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:18,864 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:14,111 [qtp1677568775-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-0116506954/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-1
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
scm1.org_1   | 2022-01-01 01:28:48,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:29:06,116 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45528
scm1.org_1   | 2022-01-01 01:29:06,123 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:29:18,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37970
scm1.org_1   | 2022-01-01 01:29:18,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56658
scm1.org_1   | 2022-01-01 01:29:18,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:29:18,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57794
om2_1        | 2022-01-01 01:30:18,866 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:18,867 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:19,571 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:19,573 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:19,575 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm1.org_1   | 2022-01-01 01:29:18,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-01-01 01:30:20,231 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:20,233 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
recon_1      | 2022-01-01 01:20:48,215 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47956
recon_1      | 2022-01-01 01:20:48,237 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60458
recon_1      | 2022-01-01 01:20:48,237 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56958
om2_1        | 2022-01-01 01:30:20,234 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
om2_1        | 2022-01-01 01:30:27,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40034
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm1.org_1   | 2022-01-01 01:29:18,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:29:23,487 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45580
scm1.org_1   | 2022-01-01 01:29:23,492 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2022-01-01 01:30:27,717 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-01-01 01:29:23,502 [IPC Server handler 23 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 9691.071us
scm1.org_1   | 2022-01-01 01:29:48,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38038
scm1.org_1   | 2022-01-01 01:29:48,229 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:29:48,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56726
scm1.org_1   | 2022-01-01 01:29:48,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57848
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1      | 2022-01-01 01:20:48,258 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:20:48,266 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:20:48,267 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:21:18,188 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60610
recon_1      | 2022-01-01 01:21:18,238 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48104
recon_1      | 2022-01-01 01:21:18,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om2_1        | 2022-01-01 01:30:31,079 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:38593
om2_1        | 2022-01-01 01:30:31,084 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-01-01 01:30:31,085 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:31,091 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 7051e917c9b3a00f35d02ac3b36928013655c73eb045f0b4b1769b73787c12bd
om2_1        | 2022-01-01 01:30:37,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43673
om2_1        | 2022-01-01 01:30:37,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-01-01 01:29:48,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-01-01 01:21:18,266 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57112
recon_1      | 2022-01-01 01:21:18,310 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2022-01-01 01:29:48,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:30:07,067 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45678
scm1.org_1   | 2022-01-01 01:30:07,082 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:30:09,578 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55632
scm1.org_1   | 2022-01-01 01:30:09,592 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-01-01 01:30:18,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38152
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2022-01-01 01:30:18,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56846
scm1.org_1   | 2022-01-01 01:30:18,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:30:18,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57976
scm1.org_1   | 2022-01-01 01:30:18,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:30:18,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-01-01 01:30:23,519 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45768
scm1.org_1   | 2022-01-01 01:30:23,539 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-01-01 01:30:23,566 [IPC Server handler 43 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@3b5503ae, cost 25020.734us
recon_1      | 2022-01-01 01:21:18,324 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:21:20,733 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-01-01 01:21:20,740 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 7 milliseconds for processing 2 containers.
recon_1      | 2022-01-01 01:21:20,873 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-01-01 01:21:20,875 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 526.711us
recon_1      | 2022-01-01 01:21:20,876 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 250.705us
recon_1      | 2022-01-01 01:21:20,877 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 243.005us
recon_1      | 2022-01-01 01:21:20,878 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 347.308us
recon_1      | 2022-01-01 01:21:20,880 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 367.808us
recon_1      | 2022-01-01 01:21:20,881 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 44 milliseconds.
recon_1      | 2022-01-01 01:21:36,684 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:21:36,684 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:21:36,715 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:14,114 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>ozone-test-0116506954/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:21:48,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60742
recon_1      | 2022-01-01 01:21:48,236 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57238
recon_1      | 2022-01-01 01:21:48,250 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:21:48,282 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:21:48,296 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48236
recon_1      | 2022-01-01 01:21:48,335 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:18,198 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57366
recon_1      | 2022-01-01 01:22:18,217 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48356
recon_1      | 2022-01-01 01:22:18,219 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60872
recon_1      | 2022-01-01 01:22:18,233 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:18,246 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:18,263 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:36,716 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:22:36,717 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:22:36,777 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:14,681 [qtp1677568775-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-0116506954/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-7365940470/ozone-test-0116506954/multipartKey3-3c8c5744-e726-4966-b6c5-0789df4550ca-107544580553506849-2
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:22:48,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57524
recon_1      | 2022-01-01 01:22:48,218 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48520
recon_1      | 2022-01-01 01:22:48,220 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32794
recon_1      | 2022-01-01 01:22:48,234 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:48,262 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:22:48,302 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:18,119 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32880
recon_1      | 2022-01-01 01:23:18,122 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:18,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48610
recon_1      | 2022-01-01 01:23:18,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57612
recon_1      | 2022-01-01 01:23:18,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:18,267 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:36,790 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:23:36,790 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:23:36,844 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:14,682 [qtp1677568775-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>ozone-test-0116506954/multipartKey3</Resource>
s3g_1        |   <RequestId/>
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:23:48,150 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48672
recon_1      | 2022-01-01 01:23:48,157 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32948
recon_1      | 2022-01-01 01:23:48,171 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:48,173 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57680
recon_1      | 2022-01-01 01:23:48,192 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:23:48,248 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:24:18,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57762
recon_1      | 2022-01-01 01:24:18,179 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33036
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1      | 2022-01-01 01:24:18,195 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:24:18,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48774
recon_1      | 2022-01-01 01:24:18,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:24:18,228 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:24:36,848 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:24:36,848 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:24:36,900 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:24:48,101 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33100
recon_1      | 2022-01-01 01:24:48,104 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:15,218 [qtp1677568775-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-7365940470, , key: ozone-test-0116506954/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-7365940470 key: ozone-test-0116506954/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:632)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1005)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1160)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 2022-01-01 01:24:48,124 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48828
recon_1      | 2022-01-01 01:24:48,187 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:24:48,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57836
recon_1      | 2022-01-01 01:24:48,218 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:18,126 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33188
recon_1      | 2022-01-01 01:25:18,149 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48910
recon_1      | 2022-01-01 01:25:18,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57914
recon_1      | 2022-01-01 01:25:18,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:18,238 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:18,255 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:36,902 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:25:36,902 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:25:36,967 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:25:48,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33252
recon_1      | 2022-01-01 01:25:48,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57976
recon_1      | 2022-01-01 01:25:48,237 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:48,259 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:25:48,281 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48988
recon_1      | 2022-01-01 01:25:48,298 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:18,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33332
recon_1      | 2022-01-01 01:26:18,156 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58062
recon_1      | 2022-01-01 01:26:18,186 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:18,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49060
recon_1      | 2022-01-01 01:26:18,224 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:18,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:20,742 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-01-01 01:26:20,745 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
recon_1      | 2022-01-01 01:26:20,913 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-01-01 01:26:20,914 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 992.418us
recon_1      | 2022-01-01 01:26:20,915 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 436.708us
recon_1      | 2022-01-01 01:26:20,916 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 355.707us
recon_1      | 2022-01-01 01:26:20,916 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 258.904us
recon_1      | 2022-01-01 01:26:20,917 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@3e23577e, cost 367.707us
recon_1      | 2022-01-01 01:26:20,917 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 20 milliseconds.
recon_1      | 2022-01-01 01:26:36,971 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:26:36,971 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:26:37,003 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:15,220 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPartOrder</Code>
s3g_1        |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1        |   <Resource>ozone-test-0116506954/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:97)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:26:48,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33400
recon_1      | 2022-01-01 01:26:48,122 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:48,217 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58134
recon_1      | 2022-01-01 01:26:48,227 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49124
recon_1      | 2022-01-01 01:26:48,236 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:26:48,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:18,156 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58212
recon_1      | 2022-01-01 01:27:18,176 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33490
recon_1      | 2022-01-01 01:27:18,188 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:18,217 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49224
recon_1      | 2022-01-01 01:27:18,220 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:18,299 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:37,004 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:27:37,004 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:27:37,052 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:27:48,114 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33556
recon_1      | 2022-01-01 01:27:48,126 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:48,188 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58290
recon_1      | 2022-01-01 01:27:48,193 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49282
recon_1      | 2022-01-01 01:27:48,243 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:27:48,268 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:28:18,173 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33664
recon_1      | 2022-01-01 01:28:18,187 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49388
recon_1      | 2022-01-01 01:28:18,206 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:28:18,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:18,754 [qtp1677568775-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1      | 2022-01-01 01:28:18,259 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58390
recon_1      | 2022-01-01 01:28:18,275 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:28:37,053 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:28:37,053 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:28:37,096 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:28:48,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33728
recon_1      | 2022-01-01 01:28:48,106 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:28:48,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49454
recon_1      | 2022-01-01 01:28:48,195 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58462
recon_1      | 2022-01-01 01:28:48,205 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:28:48,235 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:18,180 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49546
recon_1      | 2022-01-01 01:29:18,197 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33808
recon_1      | 2022-01-01 01:29:18,203 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:18,216 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:18,245 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58530
recon_1      | 2022-01-01 01:29:18,258 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:37,097 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:29:37,097 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:29:37,137 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor50.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-01-01 01:29:48,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33878
recon_1      | 2022-01-01 01:29:48,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:48,162 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58602
recon_1      | 2022-01-01 01:29:48,192 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49614
recon_1      | 2022-01-01 01:29:48,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:29:48,251 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:30:18,181 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58722
recon_1      | 2022-01-01 01:30:18,190 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34002
recon_1      | 2022-01-01 01:30:18,218 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:30:18,228 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:30:18,281 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49734
recon_1      | 2022-01-01 01:30:18,296 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-01-01 01:30:37,138 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-01-01 01:30:37,138 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-01-01 01:30:37,245 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor50.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:19,266 [qtp1677568775-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:482)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:21:59,492 [qtp1677568775-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-ozone-test-7365940470/ozone-test-0521622504/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:00,079 [qtp1677568775-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-ozone-test-7365940470/ozone-test-0521622504/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:18,499 [qtp1677568775-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6288845136, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:22:18,511 [qtp1677568775-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6288845136
s3g_1        | 2022-01-01 01:22:19,021 [qtp1677568775-22] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-25458, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:22:19,030 [qtp1677568775-22] INFO endpoint.BucketEndpoint: Location is /destbucket-25458
s3g_1        | 2022-01-01 01:22:25,926 [qtp1677568775-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:26,440 [qtp1677568775-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:27,455 [qtp1677568775-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchKey</Code>
s3g_1        |   <Message>The specified key does not exist</Message>
s3g_1        |   <Resource>nonnonexistentkey</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:33,958 [qtp1677568775-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2150355720, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:22:33,969 [qtp1677568775-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2150355720
s3g_1        | 2022-01-01 01:22:45,862 [qtp1677568775-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>bucket-ozone-test-2150355720-nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:22:53,756 [qtp1677568775-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1284303479, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:22:53,768 [qtp1677568775-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1284303479
s3g_1        | 2022-01-01 01:25:54,538 [qtp1677568775-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #167 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #167 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-01-01 01:25:54,548 [qtp1677568775-22] INFO scm.XceiverClientRatis: Could not commit index 130 on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to all the nodes. Server 75beef28-1584-4115-9505-884f6f5c519b has failed. Committed by majority.
s3g_1        | 2022-01-01 01:25:54,548 [qtp1677568775-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200050 bcsId: 130 on Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]. Failed nodes: [75beef28-1584-4115-9505-884f6f5c519b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-01-01 01:26:56,796 [qtp1677568775-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-01-01 01:26:56,803 [qtp1677568775-17] INFO scm.XceiverClientRatis: Could not commit index 134 on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to all the nodes. Server 75beef28-1584-4115-9505-884f6f5c519b has failed. Committed by majority.
s3g_1        | 2022-01-01 01:26:56,804 [qtp1677568775-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200053 bcsId: 134 on Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]. Failed nodes: [75beef28-1584-4115-9505-884f6f5c519b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-01-01 01:27:57,940 [qtp1677568775-18] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #182 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #182 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-01-01 01:27:57,947 [qtp1677568775-18] INFO scm.XceiverClientRatis: Could not commit index 139 on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to all the nodes. Server 75beef28-1584-4115-9505-884f6f5c519b has failed. Committed by majority.
s3g_1        | 2022-01-01 01:27:57,947 [qtp1677568775-18] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200054 bcsId: 139 on Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]. Failed nodes: [75beef28-1584-4115-9505-884f6f5c519b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-01-01 01:28:05,281 [qtp1677568775-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0288273416, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:28:05,297 [qtp1677568775-18] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0288273416
s3g_1        | 2022-01-01 01:28:58,478 [qtp1677568775-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #187 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #187 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-01-01 01:28:58,503 [qtp1677568775-23] INFO scm.XceiverClientRatis: Could not commit index 143 on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to all the nodes. Server 75beef28-1584-4115-9505-884f6f5c519b has failed. Committed by majority.
s3g_1        | 2022-01-01 01:28:58,504 [qtp1677568775-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200055 bcsId: 143 on Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]. Failed nodes: [75beef28-1584-4115-9505-884f6f5c519b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-01-01 01:29:59,903 [qtp1677568775-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-01-01 01:29:59,908 [qtp1677568775-22] INFO scm.XceiverClientRatis: Could not commit index 146 on pipeline Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]] to all the nodes. Server 75beef28-1584-4115-9505-884f6f5c519b has failed. Committed by majority.
s3g_1        | 2022-01-01 01:29:59,908 [qtp1677568775-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200056 bcsId: 146 on Pipeline[ Id: e5481fd7-e475-47a4-9362-f8541548c104, Nodes: 458bfdff-96fb-4b4a-96de-6879eec60ac8{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}24732aa1-1492-41aa-844a-173d185ef1c3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}75beef28-1584-4115-9505-884f6f5c519b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:24732aa1-1492-41aa-844a-173d185ef1c3, CreationTimestamp2022-01-01T01:13:02.322Z[UTC]]. Failed nodes: [75beef28-1584-4115-9505-884f6f5c519b{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-01-01 01:30:12,362 [qtp1677568775-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=10000-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:30:18,869 [qtp1677568775-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-0</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:30:19,576 [qtp1677568775-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:30:20,236 [qtp1677568775-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2022-01-01 01:30:31,090 [qtp1677568775-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6411291915, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-01-01 01:30:31,099 [qtp1677568775-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6411291915
